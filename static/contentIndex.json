{"README":{"title":"README","links":[],"tags":[],"content":"Today-I-Learned\n📝 Today I Learned - A list of all things I learn on daily basis."},"TODO":{"title":"TODO","links":[],"tags":[],"content":"Functional Programming\n\n 第 1 章 我们在做什么？\n 第 2 章 一等公民的函数\n 第 2 章 一等公民的函数\n\nGo Programming Language\n\n 第十章 包和工具\n 第十一章 测试\n 第十二章 反射\n 第九章 - 基于共享变量的并发\n 第八章 - Goroutines 和 Channels\n 第七章 - 接口\n 第六章 - 方法\n 第五章 - 函数\n 第四章 - 复合数据结构- [x] 数组- [x] 切片- [x] 映射- [x] 结构体\n 第三章 - 基础数据结构- [x] 复数- [x] 浮点数- [x] 布尔型- [x] 字符串- [x] 常量\n 第二章 - 程序结构- [x] 命名- [x] 声明- [x] 类型- [x] 包和文件- [x] 作用域\n 第一章 - 入门\n\nSQL 必知必会\n\n 第十四章 组合查询\n 第十五章 插入数据\n 第十六章 更新和删除数据\n 第十七章 创建和操纵表\n 第十八章 使用视图\n 第十九章 使用存储过程\n 第二十章 管理事务处理\n 第二十一章 使用游标\n 第二十二章 高级SQL特性\n 第八章 使用函数处理数据\n 第九章 汇总数据\n 第十章 分组数据\n 第十一章 使用子查询\n 第十二章 联结表\n 第十三章 创建高级联结\n 第七章 创建计算字段\n 第六章 用通配符进行过滤\n 第五章 高级数据过滤\n 第四章 过滤数据\n 第三章 排序检索数据\n 第二章 检索数据\n 第一章 了解 SQL\n"},"algorithm/1":{"title":"1","links":[],"tags":[],"content":"1. 两数之和\n题目描述\n给定一个整数数组 nums 和一个整数目标值 target，请你在该数组中找出 和为目标值 target 的那 两个 整数，并返回它们的数组下标。\n你可以假设每种输入只会对应一个答案。但是，数组中同一个元素在答案里不能重复出现。\n你可以按任意顺序返回答案。\n示例 1：\n输入：nums = [2,7,11,15], target = 9\n输出：[0,1]\n解释：因为 nums[0] + nums[1] == 9 ，返回 [0, 1] 。\n\n示例 2：\n输入：nums = [3,2,4], target = 6\n输出：[1,2]\n\n示例 3：\n输入：nums = [3,3], target = 6\n输出：[0,1]\n\n提示：\n\n2 &lt;= nums.length &lt;= 104\n-109 &lt;= nums[i] &lt;= 109\n-109 &lt;= target &lt;= 109\n只会存在一个有效答案\n\n**进阶：**你可以想出一个时间复杂度小于 O(n2) 的算法吗？\n解法一\nfunction twoSum(nums: number[], target: number): number[] {\n  for (let i = 0; i &lt; nums.length; i++) {\n    for (let j = i + 1; j &lt; nums.length; j++) {\n      if (nums[i] + nums[j] === target) {\n        return [i, j];\n      }\n    }\n  }\n}\n简单粗暴些，两重循环，遍历所有情况看相加是否等于目标和，如果符合直接输出。\n\n\n时间复杂度：两层 for 循环，O(n²)\n\n\n空间复杂度：O(1)\n\n\n解法二\n在上边的解法中看下第二个 for 循环步骤：\nfor(let j = i + 1; j &lt; nums.length; j++){\n    if(nums[i] + nums[j] === target){...}\n我们换个理解方式：\nfor(let j = i + 1; j &lt; nums.length; j++){\n    let sub = target - nums[i];\n    if(nums[j] === sub){...}\n第二层 for 循环无非是遍历所有的元素，看哪个元素等于 sub ，时间复杂度为 O(n)。\n有没有一种方法，不用遍历就可以找到元素里有没有等于 sub 的？—— hash table ！！！\n我们可以把数组的每个元素保存为 hash 的 key，下标保存为 hash 的 value 。\n这样只需判断 sub 在不在 hash 的 key 里就可以了，而此时的时间复杂度仅为 O(1)！\n需要注意的地方是，还需判断找到的元素不是当前元素，因为题目里讲一个元素只能用一次。\nfunction twoSum(nums: number[], target: number): number[] {\n  const map = new Map(nums.map((n, i) =&gt; [n, i]));\n  for (let i = 0; i &lt; nums.length; i++) {\n    const sub = target - nums[i];\n    if (map.has(sub) &amp;&amp; map.get(sub) != i) {\n      return [i, map.get(sub)];\n    }\n  }\n}\n\n\n时间复杂度：比解法一少了一个 for 循环，降为 O(n)\n\n\n空间复杂度：所谓的空间换时间，这里就能体现出来， 开辟了一个 hash table ，空间复杂度变为 O(n)\n\n\nfor 循环还可以将其和哈希表结合起来，就不需要判断是否是当前元素了：\nuse std::collections::HashMap;\n \nimpl Solution {\n    pub fn two_sum(nums: Vec&lt;i32&gt;, target: i32) -&gt; Vec&lt;i32&gt; {\n        let mut map = HashMap::with_capacity(nums.len());\n        for i in 0..nums.len() {\n            if let Some(k) = map.get(&amp;(target - nums[i])){\n                if *k != i {\n                    return vec![*k as i32, i as i32];\n                }\n            }\n            map.insert(nums[i], i);\n        }\n        panic!(&quot;not found&quot;);\n    }\n}"},"algorithm/100/141":{"title":"141","links":[],"tags":[],"content":"141. 环形链表\n题目描述\n给你一个链表的头节点 head ，判断链表中是否有环。\n如果链表中有某个节点，可以通过连续跟踪 next 指针再次到达，则链表中存在环。 为了表示给定链表中的环，评测系统内部使用整数 pos 来表示链表尾连接到链表中的位置（索引从 0 开始）。注意：pos 不作为参数进行传递 。仅仅是为了标识链表的实际情况。\n如果链表中存在环 ，则返回 true 。 否则，返回 false 。\n示例 1：\n\n输入：head = [3,2,0,-4], pos = 1\n输出：true\n解释：链表中有一个环，其尾部连接到第二个节点。\n\n示例 2：\n\n输入：head = [1,2], pos = 0\n输出：true\n解释：链表中有一个环，其尾部连接到第一个节点。\n\n示例 3：\n\n输入：head = [1], pos = -1\n输出：false\n解释：链表中没有环。\n\n提示：\n\n\n链表中节点的数目范围是 [0, 104]\n\n\n-105 &lt;= Node.val &lt;= 105\n\n\npos 为 -1 或者链表中的一个 有效索引 。\n\n\n进阶： 你能用 O(1)（即，常量）内存解决此问题吗？\n解法\n方法一：哈希表\n遍历链表，并使用哈希表记录每个节点。当某个节点二次出现时，则表示存在环，直接返回 true。否则链表遍历结束，返回 false。\n时间复杂度 O(n)，空间复杂度 O(n)。其中 n 是链表中的节点数。\nfunction hasCycle(head: ListNode | null): boolean {\n    const set = new Set&lt;ListNode&gt;();\n    let node = head;\n    while (node !== null) {\n        if (set.has(node)) {\n            return true;\n        }\n        set.add(node);\n        node = node.next;\n    }\n    return false;\n}\n方法二：快慢指针\n我们定义快慢指针 fast 和 slow，初始时均指向 head。\n快指针每次走两步，慢指针每次走一步，不断循环。当快慢指针相遇时，说明链表存在环。如果循环结束依然没有相遇，说明链表不存在环。\n时间复杂度 O(n)，空间复杂度 O(1)。其中 n 是链表中的节点数。\nfunction hasCycle(head: ListNode | null): boolean {\n    let slow = head;\n    let fast = head;\n    while (fast !== null &amp;&amp; fast.next !== null) {\n        slow = slow.next;\n        fast = fast.next.next;\n        if (slow === fast) {\n            return true;\n        }\n    }\n    return false;\n}\n\n这里一开始，我选择判断条件时，有点迷糊，使用 fast 还是 slow，貌似二者没多大区别，确实没多大区别，因为只要其中有一个为 null ，这说明链表不存在环，走到尾部了，但是由于 fast 是快指针，其更快走到。\n"},"algorithm/100/142":{"title":"142","links":[],"tags":[],"content":"142. 环形链表 II\n题目描述\n给定一个链表的头节点  head ，返回链表开始入环的第一个节点。 如果链表无环，则返回 null。\n如果链表中有某个节点，可以通过连续跟踪 next 指针再次到达，则链表中存在环。 为了表示给定链表中的环，评测系统内部使用整数 pos 来表示链表尾连接到链表中的位置（索引从 0 开始）。如果 pos 是 -1，则在该链表中没有环。注意：pos 不作为参数进行传递，仅仅是为了标识链表的实际情况。\n不允许修改 链表。\n示例 1：\n\n输入：head = [3,2,0,-4], pos = 1\n输出：返回索引为 1 的链表节点\n解释：链表中有一个环，其尾部连接到第二个节点。\n\n示例 2：\n\n输入：head = [1,2], pos = 0\n输出：返回索引为 0 的链表节点\n解释：链表中有一个环，其尾部连接到第一个节点。\n\n示例 3：\n\n输入：head = [1], pos = -1\n输出：返回 null\n解释：链表中没有环。\n\n提示：\n\n链表中节点的数目范围在范围 [0, 104] 内\n-105 &lt;= Node.val &lt;= 105\npos 的值为 -1 或者链表中的一个有效索引\n\n**进阶：**你是否可以使用 O(1) 空间解决此题？\n解法\n方法一：快慢指针\n我们先利用快慢指针判断链表是否有环，如果有环的话，快慢指针一定会相遇，且相遇的节点一定在环中。\n如果没有环，快指针会先到达链表尾部，直接返回 null 即可。\n如果有环，我们再定义一个答案指针 ans 指向链表头部，然后让 ans 和慢指针一起向前走，每次走一步，直到 ans 和慢指针相遇，相遇的节点即为环的入口节点。\n为什么这样能找到环的入口节点呢？\n我们不妨假设链表头节点到环入口的距离为 x，环入口到相遇节点的距离为 y，相遇节点到环入口的距离为 z，那么慢指针走过的距离为 x+y，快指针走过的距离为 x+y+k×(y+z)，其中 k 是快指针在环中绕了 k 圈。\n\n由于快指针速度是慢指针的 2 倍，因此有 2×(x+y)=x+y+k×(y+z)，可以推出 ， x+y=k×(y+z)，即 x=(k−1)×(y+z)+z 。\n根据上式分析，k \\ge 1 即快指针必须绕一圈才能和慢指针相遇，且在环内会存在相遇多次的情况。\n不妨取第一次相遇时，即绕环第一圈 k=1时，存在 x = z，也即是说，如果我们定义一个答案指针 ans 指向链表头部，快慢指针相遇后，然后 ans 和慢指针一起向前走，那么它们一定会在环入口相遇。\n时间复杂度 O(n)，其中  n 是链表中节点的数目。空间复杂度  O(1)。\nfunction detectCycle(head: ListNode | null): ListNode | null {\n    let [slow, fast] = [head, head];\n    while (fast &amp;&amp; fast.next) {\n        slow = slow.next;\n        fast = fast.next.next;\n        if (slow === fast) {\n            let ans = head;\n            while (ans !== slow) {\n                ans = ans.next;\n                slow = slow.next;\n            }\n            return ans;\n        }\n    }\n    return null;\n}"},"algorithm/2":{"title":"2","links":[],"tags":[],"content":"2. 两数相加\n题目描述\n给你两个 非空 的链表，表示两个非负的整数。它们每位数字都是按照 逆序 的方式存储的，并且每个节点只能存储 一位 数字。\n请你将两个数相加，并以相同形式返回一个表示和的链表。\n你可以假设除了数字 0 之外，这两个数都不会以 0 开头。\n\n示例 1：\n输入：l1 = [2,4,3], l2 = [5,6,4]\n输出：[7,0,8]\n解释：342 + 465 = 807.\n\n示例 2：\n输入：l1 = [0], l2 = [0]\n输出：[0]\n\n示例 3：\n输入：l1 = [9,9,9,9,9,9,9], l2 = [9,9,9,9]\n输出：[8,9,9,9,0,0,0,1]\n\n提示：\n\n每个链表中的节点数在范围 [1, 100] 内\n0 &lt;= Node.val &lt;= 9\n题目数据保证列表表示的数字不含前导零\n\n方法一：模拟\n我们同时遍历两个链表 l1 和 l2，并使用变量 carry 表示当前是否有进位。\n每次遍历时，我们取出对应链表的当前位，计算它们与进位 carry 的和，然后更新进位的值，最后将当前位的值加入答案链表。如果两个链表都遍历完了，并且进位为 0 时，遍历结束。\n最后我们返回答案链表的头节点即可。\nfunction addTwoNumbers(\n  l1: ListNode | null,\n  l2: ListNode | null\n): ListNode | null {\n  const dummy = new ListNode();\n  let cur = dummy;\n  let sum = 0;\n  while (l1 != null || l2 != null || sum !== 0) {\n    if (l1 != null) {\n      sum += l1.val;\n      l1 = l1.next;\n    }\n    if (l2 != null) {\n      sum += l2.val;\n      l2 = l2.next;\n    }\n    cur.next = new ListNode(sum % 10);\n    cur = cur.next;\n    sum = Math.floor(sum / 10);\n  }\n  return dummy.next;\n}\n时间复杂度：O(max(m，n))，m 和 n 代表 l1 和 l2 的长度。\n空间复杂度：O(max(m，n))，m 和 n 代表 l1 和 l2 的长度。而其实新的 ListNode 最大长度是 O(max(m，n)) + 1，因为 head 没有存储值。\n照例使用 rust 实现一遍，温习语法：\nimpl Solution {\n    pub fn add_two_numbers(mut l1: Option&lt;Box&lt;ListNode&gt;&gt;, mut l2: Option&lt;Box&lt;ListNode&gt;&gt;) -&gt; Option&lt;Box&lt;ListNode&gt;&gt; {\n        let mut dummy = Some(Box::new(ListNode::new(0)));\n        let mut cur = &amp;mut dummy;\n        let mut sum = 0;\n        while l1.is_some() || l2.is_some() || sum != 0 {\n            if let Some(node) = l1 {\n                sum += node.val;\n                l1 = node.next;\n            }\n            if let Some(node) = l2 {\n                sum += node.val;\n                l2 = node.next;\n            }\n            cur.as_mut().unwrap().next = Some(Box::new(ListNode::new(sum % 10)));\n            cur = &amp;mut cur.as_mut().unwrap().next;\n            sum /= 10\n        }\n        dummy.unwrap().next.take()\n    }\n}\n\n为什么可变引用，使用时还需要调用 as_mut 方法？\n在 Rust 中，可变引用（mutable reference）本身是可变的，但是默认情况下，它所指向的数据是不可变的。这意味着你可以通过可变引用修改它指向的数据，但是不能在默认情况下通过可变引用修改数据的可变性（如上，不能通过可变引用修改结构体的字段值）。\n"},"algorithm/20":{"title":"20","links":[],"tags":[],"content":"20. 有效的括号\n题目描述\n给定一个只包括 &#039;(&#039;，&#039;)&#039;，&#039;{&#039;，&#039;}&#039;，&#039;[&#039;，&#039;]&#039; 的字符串 s ，判断字符串是否有效。\n有效字符串需满足：\n\n左括号必须用相同类型的右括号闭合。\n左括号必须以正确的顺序闭合。\n每个右括号都有一个对应的相同类型的左括号。\n\n示例 1：\n输入：s = &quot;()&quot;\n输出：true\n\n示例 2：\n输入：s = &quot;()[]{}&quot;\n输出：true\n\n示例 3：\n输入：s = &quot;(]&quot;\n输出：false\n\n提示：\n\n1 &lt;= s.length &lt;= 104\ns 仅由括号 &#039;()[]{}&#039; 组成\n\n解法\n方法一：暴力判断\n在循环中，不断地消除配对的左右括号，直至无法再次消除，然后判断字符串是否为空：\nfunction isValid(s: string): boolean {\n    let length = 0;\n    do {\n        length = s.length;\n        s = s.replace(&quot;{}&quot;, &quot;&quot;).replace(&quot;[]&quot;, &quot;&quot;).replace(&quot;()&quot;, &quot;&quot;)\n    }while(length != s.length);\n    return s.length === 0;\n};\n时间复杂度为 O(n^2)，没有额外的数据结构，空间复杂度为 O(1)。\n方法二：栈\n遍历括号字符串 s，遇到左括号时，压入当前的左括号；遇到右括号时，弹出栈顶元素（若栈为空，直接返回 false），判断是否匹配，若不匹配，直接返回 false。\n也可以选择遇到左括号时，将右括号压入栈中；遇到右括号时，弹出栈顶元素（若栈为空，直接返回 false），判断是否是相等。若不匹配，直接返回 false。\n\n两者的区别仅限于括号转换时机，一个是在入栈时，一个是在出栈时。\n\n遍历结束，若栈为空，说明括号字符串有效，返回 true；否则，返回 false。\n时间复杂度 O(n)，空间复杂度 O(n)。其中 n为括号字符串 s 的长度。"},"algorithm/200/206":{"title":"206","links":[],"tags":[],"content":"206. 反转链表\n题目描述\n给你单链表的头节点 head ，请你反转链表，并返回反转后的链表。\n示例 1：\n\n输入：head = [1,2,3,4,5]\n输出：[5,4,3,2,1]\n\n示例 2：\n\n输入：head = [1,2]\n输出：[2,1]\n\n示例 3：\n输入：head = []\n输出：[]\n\n提示：\n\n链表中节点的数目范围是 [0, 5000]\n-5000 &lt;= Node.val &lt;= 5000\n\n**进阶：**链表可以选用迭代或递归方式完成反转。你能否用两种方法解决这道题？\n解法\n方法一：头插法（迭代）\n创建虚拟头节点 dummy，遍历链表，将每个节点依次插入  dummy 的下一个节点。遍历结束，返回 。dummy.next\n时间复杂度 O(n)，空间复杂度 O(1)。其中 n 为链表的长度：\nfunction reverseList(head: ListNode | null): ListNode | null {\n    if(head == null) {\n        return head;\n    }\n    let pre = null , cur = head;\n    while(cur) {\n        const next = cur.next;\n        cur.next = pre;\n        pre = cur;\n        cur = next;\n    }\n    return pre;\n};\n方法二：递归\n递归反转链表的第二个节点到尾部的所有节点，然后 head 插在反转后的链表的尾部。\n时间复杂度 O(n)，空间复杂度 O(n)。其中 n 为链表的长度。\nfunction reverseList(head: ListNode | null): ListNode | null {\n    if (head === null || head.next === null) {\n        return head;\n    }\n    const last = reverseList(head.next);\n    head.next.next = head;\n    head.next = null;\n    return last;\n};"},"algorithm/200/215":{"title":"215","links":[],"tags":[],"content":"215. 数组中的第 K 个最大元素\n题目描述\n给定整数数组 nums 和整数 k，请返回数组中第 k 个最大的元素。\n请注意，你需要找的是数组排序后的第 k 个最大的元素，而不是第 k 个不同的元素。\n你必须设计并实现时间复杂度为 O(n) 的算法解决此问题。\n示例 1:\n输入: [3,2,1,5,6,4], k = 2\n输出: 5\n示例 2:\n输入: [3,2,3,1,2,4,5,5,6], k = 4\n输出: 4\n提示：\n\n1 &lt;= k &lt;= nums.length &lt;= 105\n-104 &lt;= nums[i] &lt;= 104\n\n解法\n方法一：排序\n我们可以将数组 nums 升序排列，然后获取 nums[n−k]，时间复杂度 O(n×logn)，其中 n 表示数组 nums 的长度。\n这是根据题目意思能得到的最直接的解法，时间复杂度较高；"},"algorithm/200/225":{"title":"225","links":[],"tags":[],"content":"225. 用队列实现栈\n题目描述\n请你仅使用两个队列实现一个后入先出（LIFO）的栈，并支持普通栈的全部四种操作（push、top、pop 和 empty）。\n实现 MyStack 类：\n\nvoid push(int x) 将元素 x 压入栈顶。\nint pop() 移除并返回栈顶元素。\nint top() 返回栈顶元素。\nboolean empty() 如果栈是空的，返回 true ；否则，返回 false 。\n\n注意：\n\n你只能使用队列的基本操作 —— 也就是 push to back、peek/pop from front、size 和 is empty 这些操作。\n你所使用的语言也许不支持队列。 你可以使用 list （列表）或者 deque（双端队列）来模拟一个队列 , 只要是标准的队列操作即可。\n\n示例：\n输入：\n[&quot;MyStack&quot;, &quot;push&quot;, &quot;push&quot;, &quot;top&quot;, &quot;pop&quot;, &quot;empty&quot;]\n[[], [1], [2], [], [], []]\n输出：\n[null, null, null, 2, 2, false]\n\n解释：\nMyStack myStack = new MyStack();\nmyStack.push(1);\nmyStack.push(2);\nmyStack.top(); // 返回 2\nmyStack.pop(); // 返回 2\nmyStack.empty(); // 返回 False\n\n提示：\n\n1 &lt;= x &lt;= 9\n最多调用100 次 push、pop、top 和 empty\n每次调用 pop 和 top 都保证栈不为空\n\n**进阶：**你能否仅用一个队列来实现栈。\n解法\n方法一：两个队列\n我们使用两个队列 q1 和 q2，其中 q1 用于存储栈中的元素，而 q2 用于辅助实现栈的操作。\n\npush 操作：将元素压入 q2，然后将 q1 中的元素依次弹出并压入 q2，最后交换q1 和 q2 的引用。时间复杂度 O(n)。\npop 操作：直接弹出q1 的队首元素。时间复杂度 O(1)。\ntop 操作：直接返回 q1 的队首元素。时间复杂度  O(1)。\nempty 操作：判断 q1 是否为空。时间复杂度  O(1)。\n\n空间复杂度  O(n)，其中 n 是栈中元素的个数。\nclass MyStack {\n    q1: number[] = [];\n    q2: number[] = [];\n \n    push(x: number): void {\n        this.q2.push(x);\n        while (this.q1.length) {\n            this.q2.push(this.q1.shift()!);\n        }\n        [this.q1, this.q2] = [this.q2, this.q1];\n    }\n \n    pop(): number {\n        return this.q1.shift()!;\n    }\n \n    top(): number {\n        return this.q1[0];\n    }\n \n    empty(): boolean {\n        return this.q1.length === 0;\n    }\n}\n方法二：一个队列\n入栈操作时，首先获得入栈前的元素个数 n，然后将元素入队到队列，再将队列中的前 n 个元素（即除了新入栈的元素之外的全部元素）依次出队并入队到队列，此时队列的前端的元素即为新入栈的元素，且队列的前端和后端分别对应栈顶和栈底。\n\npush 操作：将元素压入 queue，然后将已入队的元素依次出队并压入队尾，时间复杂度 O(n)。\n\n空间复杂度  O(n)，其中 n 是栈中元素的个数。\nclass MyStack {\n    queue: number[] = [];\n \n    push(x: number): void {\n        const length = this.queue.length\n        this.queue.push(x)\n \n        for (let i = 0; i &lt; length; i++) {\n            this.queue.push(this.queue.shift());\n        }\n    }\n \n    pop(): number {\n        return this.queue.shift();\n    }\n \n    top(): number {\n        return this.queue[0];\n    }\n \n    empty(): boolean {\n        return this.queue.length === 0;\n    }\n}"},"algorithm/200/232":{"title":"232","links":[],"tags":[],"content":"232. 用栈实现队列\n题目描述\n请你仅使用两个栈实现先入先出队列。队列应当支持一般队列支持的所有操作（push、pop、peek、empty）：\n实现 MyQueue 类：\n\nvoid push(int x) 将元素 x 推到队列的末尾\nint pop() 从队列的开头移除并返回元素\nint peek() 返回队列开头的元素\nboolean empty() 如果队列为空，返回 true ；否则，返回 false\n\n说明：\n\n你 只能 使用标准的栈操作 —— 也就是只有 push to top, peek/pop from top, size, 和 is empty 操作是合法的。\n你所使用的语言也许不支持栈。你可以使用 list 或者 deque（双端队列）来模拟一个栈，只要是标准的栈操作即可。\n\n示例 1：\n输入：\n[&quot;MyQueue&quot;, &quot;push&quot;, &quot;push&quot;, &quot;peek&quot;, &quot;pop&quot;, &quot;empty&quot;]\n[[], [1], [2], [], [], []]\n输出：\n[null, null, null, 1, 1, false]\n\n解释：\nMyQueue myQueue = new MyQueue();\nmyQueue.push(1); // queue is: [1]\nmyQueue.push(2); // queue is: [1, 2] (leftmost is front of the queue)\nmyQueue.peek(); // return 1\nmyQueue.pop(); // return 1, queue is [2]\nmyQueue.empty(); // return false\n\n提示：\n\n1 &lt;= x &lt;= 9\n最多调用 100 次 push、pop、peek 和 empty\n假设所有操作都是有效的 （例如，一个空的队列不会调用 pop 或者 peek 操作）\n\n进阶：\n\n你能否实现每个操作均摊时间复杂度为 O(1) 的队列？换句话说，执行 n 个操作的总时间复杂度为 O(n) ，即使其中一个操作可能花费较长时间。\n\n解法\n方法一：双栈\n使用两个栈，其中栈 stk1用于入队，另一个栈 stk2 用于出队。\n入队时，直接将元素入栈 stk1。时间复杂度 O(1) 。\n出队时，先判断栈 stk2 是否为空，如果为空，则将栈 stk1 中的元素全部出栈并入栈 stk2，然后再从栈 stk2 中出栈一个元素。如果栈 stk2 不为空，则直接从栈 stk2 中出栈一个元素。均摊时间复杂度 O(1)。\n获取队首元素时，先判断栈 stk2 是否为空，如果为空，则将栈 stk1 中的元素全部出栈并入栈 stk2，然后再从栈 stk2 中获取栈顶元素。如果栈 stk2 不为空，则直接从栈 stk2 中获取栈顶元素。均摊时间复杂度 O(1)。\n判断队列是否为空时，只要判断两个栈是否都为空即可。时间复杂度 O(1)。\nclass MyQueue {\n    stk1: number[];\n    stk2: number[];\n \n    constructor() {\n        this.stk1 = [];\n        this.stk2 = [];\n    }\n \n    push(x: number): void {\n        this.stk1.push(x);\n    }\n \n    pop(): number {\n        this.move();\n        return this.stk2.pop();\n    }\n \n    peek(): number {\n        this.move();\n        return this.stk2[this.stk2.length - 1];\n    }\n \n    empty(): boolean {\n        return !this.stk1.length &amp;&amp; !this.stk2.length;\n    }\n \n    move(): void {\n        if (!this.stk2.length) {\n            while (this.stk1.length) {\n                this.stk2.push(this.stk1.pop());\n            }\n        }\n    }\n}"},"algorithm/24":{"title":"24","links":[],"tags":[],"content":"24. 两两交换链表中的节点\n题目描述\n给你一个链表，两两交换其中相邻的节点，并返回交换后链表的头节点。你必须在不修改节点内部的值的情况下完成本题（即，只能进行节点交换）。\n示例 1：\n\n输入：head = [1,2,3,4]\n输出：[2,1,4,3]\n\n示例 2：\n输入：head = []\n输出：[]\n\n示例 3：\n输入：head = [1]\n输出：[1]\n\n提示：\n\n链表中节点的数目在范围 [0, 100] 内\n0 &lt;= Node.val &lt;= 100\n\n方法一：递归\n我们可以通过递归的方式实现两两交换链表中的节点。\n递归的终止条件是链表中没有节点，或者链表中只有一个节点，此时无法进行交换，直接返回该节点。\n否则，我们递归交换链表 head.next.next，记交换后的头节点为 t，然后我们记 head 的下一个节点为 p，然后令 p 指向 head，而 head 指向 t，最后返回 p。\n时间复杂度 O(n)，空间复杂度 O(n)，其中 n 是链表的长度。\nfunction swapPairs(head: ListNode | null): ListNode | null {\n    if(!head || !head.next){\n        return head; \n    }\n    let t = swapPairs(head.next.next)\n    let p = head.next\n    p.next = head;\n    head.next = t;\n    return p;\n};\n方法二：迭代\n我们设置一个虚拟头节点 dummy ，初始时指向 head，然后设置两个指针 pre 和 cur，初始时   pre 指向 dummy，而 cur 指向 head。\n接下来，我们遍历链表，每次需要交换 pre 后面的两个节点，因此我们先判断 cur 和  cur.next为空，若不为空，则进行交换，否则终止循环。\n时间复杂度 O(n)，空间复杂度 O(1)，其中 n 是链表的长度。\nfunction swapPairs(head: ListNode | null): ListNode | null {\n    const dummy = new ListNode(0, head);\n    let cur = head, pre = dummy;\n    while (cur &amp;&amp; cur.next) {\n        let next = cur.next;\n        // 交换\n        cur.next = next.next;\n        next.next = cur;\n        pre.next = next;\n        // 更新双指针状态\n        pre = cur;\n        cur = cur.next;\n    }\n    return dummy.next;\n};"},"algorithm/3":{"title":"3","links":[],"tags":[],"content":"3. 无重复字符的最长子串\n题目描述\n给定一个字符串 s ，请你找出其中不含有重复字符的 最长子串 的长度。\n示例 1:\n输入: s = &quot;abcabcbb&quot;\n输出: 3 \n解释: 因为无重复字符的最长子串是 &quot;abc&quot;，所以其长度为 3。\n\n示例 2:\n输入: s = &quot;bbbbb&quot;\n输出: 1\n解释: 因为无重复字符的最长子串是 &quot;b&quot;，所以其长度为 1。\n\n示例 3:\n输入: s = &quot;pwwkew&quot;\n输出: 3\n解释: 因为无重复字符的最长子串是 &quot;wke&quot;，所以其长度为 3。\n     请注意，你的答案必须是 子串 的长度，&quot;pwke&quot; 是一个子序列，不是子串。\n\n提示：\n\n0 &lt;= s.length &lt;= 5 * 104\ns 由英文字母、数字、符号和空格组成\n\n\n这道题，为什么是输出最长子串的长度呢，因为最长子串可能有多个；这是一个思考上的误区。\n\n解法一：暴力穷举\n找一个最长子串，那么我们用两个循环穷举所有子串，然后再用一个函数判断该子串中有没有重复的字符：\nfunction lengthOfLongestSubstring(s: string): number {\n    let n = s.length;\n    let ans = 0;    // 保存当前得到满足条件的子串的最大值\n    for (let i = 0; i &lt; n; i++) {\n        for (let j = i + 1; j &lt;= n; j++) {\n            // 之所以 j &lt;= n，是因为我们子串是 s[i,j)，左闭右开\n            if (allUnique(s, i, j)) {\n                ans = Math.max(ans, j - i); // 更新 ans\n            }\n        }\n    }\n    return ans;\n};\n \nfunction allUnique(s: string,  start: number, end: number) {\n    const set = new Set&lt;String&gt;(); // 初始化 set\n    for (let i = start; i &lt; end; i++) { // 遍历每个字符\n        const ch = s.charAt(i);\n        if (set.has(ch)) return false; // 判断字符在不在 set 中\n        set.add(ch); // 不在的话将该字符添加到 set 里边\n    }\n    return true;\n}\n \n// 在 js 中使用对象判断更高效\nfunction allUnique(s: string, start: number, end: number) {\n    const charMap: Record&lt;string, boolean&gt; = {}; // 使用对象来存储字符是否出现过的信息\n    for (let i = start; i &lt; end; i++) {\n        const ch = s.charAt(i);\n        if (charMap[ch]) return false; // 如果字符已经出现过，则返回false\n        charMap[ch] = true; // 标记字符已经出现过\n    }\n    return true;\n}\n时间复杂度：两个循环，加上判断子串是否满足条件的函数中的循环，O(n³)。\n空间复杂度：使用了一个 Set，判断子串中有没有重复的字符。由于 Set 中没有重复的字符，所以最长就是整个字符集，假设字符集的大小为 m ，那么 Set 最长就是 m 。另一方面，如果字符串的长度小于 m ，是 n 。那么 set 最长也就是 n 了。综上，空间复杂度为 O(min(m，n))。\n解法二：滑动窗口\n遗憾的是上边的算法没有通过 LeetCode，时间复杂度太大，造成了超时。我们怎么来优化一下呢？\n上边的算法中，我们假设当 i 取 0 的时候，\n\nj 取 1，判断字符串 str[0,1) 中有没有重复的字符。\nj 取 2，判断字符串 str[0,2) 中有没有重复的字符。\nj 取 3，判断字符串 str[0,3) 中有没有重复的字符。\nj 取 4，判断字符串 str[0,4) 中有没有重复的字符。\n\n做了很多重复的工作，因为如果 str[0,3) 中没有重复的字符，我们不需要再判断整个字符串 str[0,4) 中有没有重复的字符，而只需要判断 str[3] 在不在 str[0,3) 中，不在的话，就表明 str[0,4) 中没有重复的字符。\n如果在的话，那么 str[0,5) ，str[0,6) ，str[0,7) 一定有重复的字符，所以此时后边的  j 也不需要继续增加了。\ni ++ 进入下次的循环就可以了。\n\ni++，即这个起始位置的子串后续肯定都会有重复字符了，需要切换下一个起始位置，一下没反应过来。\n\n此外，我们的 j 也不需要取 j + 1，而只需要从当前的 j 开始就可以了。\n综上，其实整个关于 j 的循环我们完全可以去掉了，此时可以理解变成了一个「滑动窗口」。\n\n滑动窗口，即 [i, j] 区域的窗口，在 str 字符串上进行连续移动（i++，j++）。\n\n判断一个字符在不在字符串中，我们需要可以遍历整个字符串，遍历需要的时间复杂度就是 O（n），加上最外层的 i 的循环，总体复杂度就是 O（n²）。\n我们可以继续优化，判断字符在不在一个字符串，我们可以将已有的字符串存到 Hash 里，这样的时间复杂度是 O（1），总的时间复杂度就变成了 O（n）。\nfunction lengthOfLongestSubstring(s: string): number {\n        const n = s.length;\n        const set = new Set&lt;string&gt;();\n        let ans = 0, i = 0, j = 0;\n        while (i &lt; n &amp;&amp; j &lt; n) {\n            if (!set.has(s[j])){\n                set.add(s[j++]);\n                ans = Math.max(ans, j - i);\n            } else {\n                set.delete(s[i++]);\n            }\n        }\n        return ans;\n};\n时间复杂度：在最坏的情况下，while 循环中的语句会执行 2n 次，例如 abcdefgg，开始的时候 j 一直后移直到到达第二个 g 的时候固定不变 ，然后 i 开始一直后移直到 n ，所以总共执行了 2n 次，时间复杂度为 O（n）。\n空间复杂度：和上边的类似，需要一个 Hash 保存子串，所以是 O（min（m，n））。\n解法三：优化\n继续优化，我们看【解法二】算法中的一种情况：\n┌───┬───┬───┬───┬───┬───┬───┐\n│ a │ b │ c │ d │ c │ c │ a │\n├───┼───┼───┼───┼───┼───┼───┤\n│ i │   │   │   │ j │   │   │\n└───┴───┴───┴───┴───┴───┴───┘\n\t\t\t  ↓ \n┌───┬───┬───┬───┬───┬───┬───┐\n│ a │ b │ c │ d │ c │ c │ a │\n├───┼───┼───┼───┼───┼───┼───┤\n│   │ i │   │   │ j │   │   │\n└───┴───┴───┴───┴───┴───┴───┘\n\n当 j 指向的 c 存在于前边的子串 abcd 中，此时 i 向前移到 b ,此时子串中仍然含有 c，还得继续移动，所以这里其实可以优化。我们可以一步到位，直接移动到子串 c 的位置的下一位！\n┌───┬───┬───┬───┬───┬───┬───┐\n│ a │ b │ c │ d │ c │ c │ a │\n├───┼───┼───┼───┼───┼───┼───┤\n│   │   │   │ i │ j │   │   │\n└───┴───┴───┴───┴───┴───┴───┘\n\n实现这样的话，我们将 set 改为 map ，将字符作为 key 存储，将对应的下标存到 value 里就实现了。\nfunction lengthOfLongestSubstring(s: string): number {\n    const n = s.length\n    let ans = 0;\n    const map = new Map&lt;string, number&gt;(); \n    for (let j = 0, i = 0; j &lt; n; j++) {\n        if (map.has(s[j])) {\n            i = Math.max(map.get(s[j]), i); \n        }\n        ans = Math.max(ans, j - i + 1);\n        map.set(s[j], j + 1); // 下标 + 1 代表 i 要移动的下个位置\n    }\n    return ans;\n};\n与解法二相比：\n由于采取了 i 跳跃的形式，所以 map 之前存的字符没有进行 remove ，所以 if 语句中进行了 Math.max(map.get(s[ j ]), i)，要确认得到的下标不是 i 前边的。\n还有个不同之处是 j 每次循环都进行了自加 1 ，因为 i 的跳跃已经保证了 str[ i , j] 内没有重复的字符串，所以 j 直接可以加 1 。而解法二中，要保持 j 的位置不变，因为不知道和 j 重复的字符在哪个位置。\n最后个不同之处是， ans 在每次循环中都进行更新，因为 ans 更新前 i 都进行了更新，已经保证了当前的子串符合条件，所以可以更新 ans 。而解法二中，只有当当前的子串不包含当前的字符时，才进行更新。\n时间复杂度：我们将 2n 优化到了 n ，但最终还是和之前一样，O（n）。\n空间复杂度：也是一样的，O（min（m，n)）。\n解法四：优化++\n和解法三思路一样，区别的地方在于，我们不用 Hash ，而是直接用数组，字符的 ASCII 码值作为数组的下标，数组存储该字符所在字符串的位置。适用于字符集比较小的情况，因为我们会直接开辟和字符集等大的数组。\nfunction lengthOfLongestSubstring(s: string): number {\n    const n = s.length\n    let ans = 0;\n    const index = new Array(128).fill(0);   \n    for (let j = 0, i = 0; j &lt; n; j++) {\n        i = Math.max(index[s[j].charCodeAt(0)], i);\n        ans = Math.max(ans, j - i + 1);\n        index[s[j].charCodeAt(0)] = j + 1;//（下标 + 1） 代表 i 要移动的下个位置\n    }\n    return ans;\n};\n和解法 3 不同的地方在于，没有了 if 的判断，因为如果 index[s[j].charCodeAt(0)] 不存在的话，它的值会是 0 ，对最终结果不会影响。\n时间复杂度：O（n）。\n空间复杂度：O（m），m 代表字符集的大小。这次不论原字符串多小，都会利用这么大的空间。"},"algorithm/4":{"title":"4","links":[],"tags":[],"content":"寻找两个正序数组的中位数\n题目描述\n给定两个大小分别为 m 和 n 的正序（从小到大）数组 nums1 和 nums2。请你找出并返回这两个正序数组的 中位数 。\n算法的时间复杂度应该为 O(log (m+n)) 。\n示例 1：\n输入：nums1 = [1,3], nums2 = [2]\n输出：2.00000\n解释：合并数组 = [1,2,3] ，中位数 2\n\n示例 2：\n输入：nums1 = [1,2], nums2 = [3,4]\n输出：2.50000\n解释：合并数组 = [1,2,3,4] ，中位数 (2 + 3) / 2 = 2.5\n\n提示：\n\nnums1.length == m\nnums2.length == n\n0 &lt;= m &lt;= 1000\n0 &lt;= n &lt;= 1000\n1 &lt;= m + n &lt;= 2000\n-106 &lt;= nums1[i], nums2[i] &lt;= 106\n\n解法一\n简单粗暴，先将两个数组合并，两个有序数组的合并也是归并排序中的一部分。然后根据奇数，还是偶数，返回中位数。\nfunction findMedianSortedArrays(nums1, nums2) {\n  let nums = [];\n  let m = nums1.length;\n  let n = nums2.length;\n  if (m == 0) {\n      if (n % 2 == 0) {\n          return (nums2[n / 2 - 1] + nums2[n / 2]) / 2.0;\n      } else {\n \n          return nums2[Math.floor(n / 2)];\n      }\n  }\n  if (n == 0) {\n      if (m % 2 == 0) {\n          return (nums1[m / 2 - 1] + nums1[m / 2]) / 2.0;\n      } else {\n          return nums1[Math.floor(m / 2)];\n      }\n  }\n \n  let count = 0;\n  let i = 0, j = 0;\n  while (count != (m + n)) {\n      if (i == m) {\n          while (j != n) {\n              nums[count++] = nums2[j++];\n          }\n          break;\n      }\n      if (j == n) {\n          while (i != m) {\n              nums[count++] = nums1[i++];\n          }\n          break;\n      }\n \n      if (nums1[i] &lt; nums2[j]) {\n          nums[count++] = nums1[i++];\n      } else {\n          nums[count++] = nums2[j++];\n      }\n  }\n \n  if (count % 2 == 0) {\n      return (nums[count / 2 - 1] + nums[count / 2]) / 2.0;\n  } else {\n      return nums[Math.floor(count / 2)];\n  }  \n};\n时间复杂度：遍历全部数组，O（m + n）\n空间复杂度：开辟了一个数组，保存合并后的两个数组，O（m + n）\n解法二\n其实，我们不需要将两个数组真的合并，我们只需要找到中位数在哪里就可以了。\n首先是怎么将奇数和偶数的情况合并一下。用 len 表示合并后数组的长度，如果是奇数，我们需要知道第 （len + 1）/ 2 个数就可以了，如果遍历的话需要遍历 int ( len / 2 ) + 1 次。如果是偶数，我们需要知道第 len / 2 和 len / 2 + 1 个数，也是需要遍历 len / 2 + 1 次。所以遍历的话，奇数和偶数都是 len / 2 + 1 次。\n返回中位数的话，奇数需要最后一次遍历的结果就可以了，偶数需要最后一次和上一次遍历的结果。所以我们用两个变量 left 和 right ，right 保存当前循环的结果，在每次循环前将 right 的值赋给 left 。这样在最后一次循环的时候，left 将得到 right 的值，也就是上一次循环的结果，接下来 right 更新为最后一次的结果。\n循环中该怎么写，什么时候 A 数组后移，什么时候 B 数组后移。用 aStart 和 bStart 分别表示当前指向 A 数组和 B 数组的位置。如果 aStart 还没有到最后并且此时 A 位置的数字小于 B 位置的数组，那么就可以后移了。也就是aStart ＜ m &amp;&amp; A[aStart] &lt; B[bStart]。\n但如果 B 数组此刻已经没有数字了，继续取数字B [ bStart ]，则会越界，所以判断下 bStart 是否大于数组长度了，这样 || 后边的就不会执行了，也就不会导致错误了，所以增加为 aStart ＜ m &amp;&amp; ( bStart &gt;= n || A [ aStart ] &lt; B [ bStart ] ) 。\nfunction findMedianSortedArrays(A: number[], B: number[]) {\n    const m = A.length;\n    const n = B.length;\n    const len = m + n;\n    let left = -1, right = -1;\n    let aStart = 0, bStart = 0;\n    for (let i = 0; i &lt;= len / 2; i++) {\n        left = right;\n        if (aStart &lt; m &amp;&amp; (bStart &gt;= n || A[aStart] &lt; B[bStart])) {\n            right = A[aStart++];\n        } else {\n            right = B[bStart++];\n        }\n    }\n    if ((len &amp; 1) == 0)\n        return (left + right) / 2.0;\n    else\n        return right;\n \n};\n时间复杂度：遍历 len / 2 + 1 次，len = m + n ，所以时间复杂度依旧是 O（m + n）。\n空间复杂度：我们申请了常数个变量，也就是 m，n，len，left，right，aStart，bStart 以及 i 。\n总共 8 个变量，所以空间复杂度是 O（1）。\n解法三\n上边的两种思路，时间复杂度都达不到题目的要求 O ( log ( m + n ) )。看到 log ，很明显，我们只有用到二分的方法才能达到。我们不妨用另一种思路，题目是求中位数，其实就是求第 k 小数的一种特殊情况，而求第 k 小数有一种算法。\n解法二中，我们一次遍历就相当于去掉不可能是中位数的一个值，也就是一个一个排除。由于数列是有序的，其实我们完全可以一半儿一半儿的排除。假设我们要找第 k 小数，我们可以每次循环排除掉 k / 2 个数。看下边一个例子。\n假设我们要找第 7 小的数字。"},"algorithm/README":{"title":"README","links":[],"tags":[],"content":"\nLeetCode Wiki (doocs.github.io)\n小浩算法 (geekxh.com)\nlabuladong 的算法笔记 \nwang· leetcode\n图解 Java 数据结构和算法 | 数据结构与算法 系列教程（笔记） (zq99299.github.io)\n"},"algorithm/learning/1":{"title":"1","links":[],"tags":[],"content":"开篇\n\n[主定理](主定理 - 维基百科，自由的百科全书 (wikipedia.org))（Master theorem）提供了用渐近符号（大O符号）表示许多由分治法得到的递推关系式的方法。\n"},"algorithm/other/fisher-yates-shuffle":{"title":"fisher-yates-shuffle","links":[],"tags":[],"content":"洗牌算法 | Fisher–Yates shuffle\n费雪耶茨算法（Fisher-Yates shuffle），用来将一个集合随机排列，常用在扑克洗牌，打乱抽奖奖池等场景中。\nFisher-Yates 洗牌算法是由 Ronald A.Fisher 和 Frank Yates 于1938年发明的，后来被Knuth在书中介绍，很多人直接称Knuth洗牌算法， Knuth大家应该比较熟悉，《The Art of Computer Programming》作者，算法理论的创始人。\n使用 Fisher-Yates 算法打乱顺序，得到的每种排列都是等概率的。Fisher-Yates 算法运行时不占用额外的存储空间，消耗的时间正比于需要打乱的数的数量，改良后的算法时间复杂度仅有O(n)。\n等概率：洗牌算法有些人也称等概率洗牌算法，其实发牌的过程和我们抽签一样的，大学概率论讲过抽签是等概率的，同样洗牌算法选中每个元素是等概率的。\n用洗牌算法思路从1、2、3、4、5这5个数中，随机取一个数\n\n第一次随机抽取到4这个元素，4被抽中的概率是1/5\n第二次随机抽取到5这个元素，5被抽中的概率是1/4 * 4/5 = 1/5\n第三次随机抽取到2这个元素，2被抽中的概率是1/3 * 3/4  * 4/5 = 1/5\n第四次随机抽取到1这个元素，1被抽中的概率是1/2 * 1/3 * 3/4 * 4/5 = 1/5\n第五次随机抽取到3这个元素，3被抽中的概率是1/2 * 1/3 * 3/4 * 4/5 = 1/5\n\n时间复杂度为O(n*n),空间复杂度为O(n)。\n在上面的介绍的发牌过程中， Knuth 和 Durstenfeld 在Fisher 等人的基础上对算法进行了改进，在原始数组上对数字进行交互，省去了额外O(n)的空间。\n该算法的基本思想和 Fisher 类似，每次从未处理的数据中随机取出一个数字，然后把该数字放在数组的尾部，即数组尾部存放的是已经处理过的数字。\n\n在54张牌中随机选一张，将这张牌与第一张交换顺序\n在剩下的53张中继续随机选取一张与第二张牌进行交换\n往复上述过程，直至最后一张；\n\n时间复杂度为O(n)，空间复杂度为O(1)，缺点必须知道数组长度n。\n打乱一维数组\nfunction shuffle(arr) {\n  for(let i = arr.length - 1; i &gt; 0; i--){\n    let j = Math.floor(Math.random() * (i + 1));\n    [arr[j], arr[i]] = [arr[i], arr[j]];\n  }\n}\n生成雷区"},"algorithm/sort/quick":{"title":"quick","links":[],"tags":[],"content":"快速排序\n快速排序（英语：Quicksort），又称分区交换排序（partition-exchange sort），最早由图灵奖获得者东尼·霍尔于1960 年提出。在平均状况下，排序 n 个项目要 O(n\\log n) 次比较，在最坏状况下则需要 O(n^2) 次比较。\n快速排序是从冒泡排序算法演变而来的，实际上是在冒泡排基础上，使用分治法策略来把一个序列分为较小和较大的2个子序列，然后递归地排序两个子序列，整个排序过程只需要三步：\n\n挑选基准值：从数列中挑出一个元素，称为“基准”（pivot）；\n分割：所有小于基准值的元素，都移到基准值的左边；所有大于基准值的元素，都移到基准值的右边；\n递归排序子序列：递归地将小于基准值元素的子序列和大于基准值元素的子序列排序。\n\n递归到最底部的结束判断条件是数列的大小是零或一，此时该数列显然已经有序。\n选取基准值有数种具体方法，此选取方法对排序的时间性能有决定性影响。\n非原地排序\nconst quickSort = function (arr) { \n\t// 递归结束条件 \n\tif(arr.length &lt; 2) \n\t\treturn arr; \n\t// 基准 \n\tconst pivot = arr.splice(0, 1); \n\t// 左区 \n\tconst left = []; \n\t// 右区 \n\tconst right = []; \n\t// 将剩余元素按照一定规则，分配到左区、右区。 \n\tfor(let i = 0; i &lt; arr.length; i++) { \n\t\t// 大于基准值的分配到右区，小于基准值的分配到左区 \n\t\tif(arr[i] &gt; pivot[0]) { \n\t\t\tright.push(arr[i]) \n\t\t} else { \n\t\t\tleft.push(arr[i]) } \n\t\t}\n\t}\n\t// 返回 左区 拼 基准 拼 右区， 再对左区、右区分别重选基准分区 \n\treturn quickSort(left).concat(pivot).concat(quickSort(right));\n}"},"android/jetpack-compose/android-build":{"title":"android-build","links":[],"tags":[],"content":"配置 build\n\ndeveloper.android.google.cn/studio/build\n"},"android/jetpack-compose/getting-started":{"title":"getting-started","links":[],"tags":[],"content":"入门学习\nJetpack compose 使用可组合函数，来描述 UI：\n@Composable\nfun SimpleComposable() {\n    Text(&quot;Hello World&quot;)\n}\n函数添加 @Composable 注释即为一个可组合函数，此注释可告知 Compose 编译器：此函数旨在将数据转换为界面。\n可组合函数不会也不需要返回任何内容，因为它们描述所需的屏幕状态，而不是构造界面 widget。\n启用预览，可再添加 @Preview 注解，该注解可免依赖于 Android Studio 中的模拟器，直接在 IDE 中进行预览。这里需要回顾下 Kotlin 中的注解。\nKotlin 注解\n注解是将元数据附加到代码中，而不会影响程序的运行时逻辑。要声明注解，请将 annotation 修饰符放在类的前面：\nannotation class Preview\n注解的附加属性可以通过用元注解标注注解类来指定：\n\n@Target 指定可以用该注解标注的元素的可能的类型（类、函数、属性与表达式）；\n@Retention 指定该注解是否存储在编译后的 class 文件中，以及它在运行时能否通过反射可见 （默认都是 true）；\n@Repeatable 允许在单个元素上多次使用相同的该注解；\n@MustBeDocumented 指定该注解是公有 API 的一部分，并且应该包含在生成的 API 文档中显示的类或方法的签名中。\n\n@Repeatable\nannotation class Preview(\n    val name: String = &quot;&quot;, \n    val group: String = &quot;&quot;, // 分组，可在 IDE 根据分组进行预览 \n    @IntRange(from = 1) val apiLevel: Int = -1,\n    val widthDp: Int = -1,\t// 设置显示宽度\n    val heightDp: Int = -1,\n    val locale: String = &quot;&quot;,\n    @FloatRange(from = 0.01) val fontScale: Float = 1f,\n    val showDecoration: Boolean = false,\n    val showBackground: Boolean = false,\n    val backgroundColor: Long = 0,\n    @UiMode val uiMode: Int = 0,\n    @Device val device: String = Devices.DEFAULT\n)\n通过@Preview注解，我们可以自定义预览时的一些参数：\n@Preview(\n    name = &quot;My Preview&quot;,\n    showBackground = true,\n    backgroundColor = 0x989a82\n)\n@Composable\nfun DefaultPreview() {\n    Text(text = &quot;Hello Compose!&quot;)\n}\n可组合函数\n修饰符\n大多数 Compose 界面元素（例如 Surface 和 Text）都接受可选的 modifier 参数。修饰符会指示界面元素如何在其父布局中放置、显示或表现。\n例如，padding 修饰符会在其修饰的元素周围应用一定的空间。您可以使用 Modifier.padding() 创建内边距修饰符。\n@Composable\nprivate fun Greeting(name: String) {\n    Surface(color = MaterialTheme.colorScheme.primary) {\n        Text(text = &quot;Hello $name!&quot;, modifier = Modifier.padding(24.dp))\n    }\n}\n有数十种修饰符可用于实现对齐、添加动画、设置布局、使可点击或可滚动以及转换等效果。完整列表请查看 Compose 修饰符列表。\n\n修饰符可以包含重载，因而具有相应的优势，如可以指定不同的方式来创建内边距。\n若要向一个元素添加多个修饰符，只需要将它们链接起来即可。\n\n内部状态\n向可组合项添加内部状态，可以使用 mutableStateOf 函数，该函数可让 Compose 重组读取该 State 的函数。\n\nState 和 MutableState 是两个接口，它们具有特定的值，每当该值发生变化时，它们就会触发界面更新（重组）。\n\n@Composable\nfun Greeting() {\n    val expanded1 = mutableStateOf(false) // Don&#039;t do this!\n    val expanded2 = remember { mutableStateOf(false) }\n}\n但是，不能只是将 mutableStateOf 分配给可组合项中的某个变量。重组可能会随时发生，这会再次调用可组合项，从而将状态重置为值为 false 的新可变状态。在重组后保留状态，可使用 remember 记住可变状态。\n可组合函数是可能会被并行调用，创建不同的界面元素，且每个元素都会拥有自己的状态版本。您可以将内部状态视为类中的私有变量。\n可组合函数会自动“订阅”状态。如果状态发生变化，读取这些字段的可组合项将会重组以显示更新。\n状态提升\n在可组合函数中，被多个函数读取或修改的状态应位于共同祖先实体中，此过程称为状态提升。“提升”意为“提高”或“升级”。【这个概念等同于 React 框架中提到了，算是声明式 UI 中通用概念】\n保留状态\nremember 函数仅在可组合项包含在组合中时起作用。例如当旋转屏幕后，整个 activity 都会重启，所有状态都将丢失。当发生任何配置更改或者进程终止时，也会出现这种情况。\n此时应当使用 rememberSaveable，而不使用 remember。这会保存每个在配置更改（如旋转）和进程终止后保留下来的状态。\n重组\n当用户与界面交互时，界面会发起 onClick 等事件。这些事件应通知应用逻辑，应用逻辑随后可以改变应用的状态。当状态发生变化时，系统会使用新数据再次调用可组合函数。这会导致重新绘制界面元素，此过程称为“重组”。\n@Composable\nfun ClickCounter(clicks: Int, onClick: () -&gt; Unit) {\n    Button(onClick = onClick) {\n        Text(&quot;I&#039;ve been clicked $clicks times&quot;)\n    }\n}\n重组整个界面树在计算上成本高昂，因为会消耗计算能力并缩短电池续航时间。Compose 使用智能重组来解决此问题。\n重组是指在输入更改时再次调用可组合函数的过程。当函数的输入更改时，Compose 可以通过跳过所有未更改参数的函数或  lambda，实现高效地重组。\n切勿依赖于执行可组合函数所产生的附带效应，因为可能会跳过函数的重组。附带效应是指对应用的其余部分可见的任何更改，如下：\n\n写入共享对象的属性；\n更新 ViewModel 中的可观察项；\n更新共享偏好设置；\n\n例如在呈现动画时，可组合函数可能会像每一帧一样频繁地重新执行，其应快速执行，以避免在播放动画期间出现卡顿。\n如果需要执行成本高昂的操作（例如从共享偏好设置读取数据），请在后台协程中执行，并将值结果作为参数传递给可组合函数。\n\n可组合函数可以按任何顺序执行：Compose 可以选择识别出某些界面元素的优先级高于其他界面元素，因而首先绘制这些元素。\n可组合函数可以并行运行：Compose 可以利用多个核心，并以较低的优先级运行可组合函数（不在屏幕上），意味着可组合函数可能会在后台线程池中执行。调用某个可组合函数时，调用可能发生在与调用方不同的线程上。这意味着，应避免使用修改可组合 lambda 中的变量的代码，既因为此类代码并非线程安全代码，又因为它是可组合 lambda 不允许的附带效应。【?】\n重组会跳过尽可能多的内容：Compose 可以跳过某些内容以重新运行单个按钮的可组合项，而不执行界面树中在其上面或下面的任何可组合项。【根据组合函数参数进行重组】\n重组是乐观的操作：只要 Compose 认为某个可组合项的参数可能已更改，就会开始重组。Compose 预计会在参数再次更改之前完成重组。如果某个参数在重组完成之前发生更改，Compose 可能会取消重组，并使用新参数重新开始。取消重组后，Compose 会从重组中舍弃界面树。则即使取消了组合操作，也会应用该附带效应。这可能会导致应用状态不一致。确保所有可组合函数和 lambda 都幂等且没有附带效应，以处理乐观的重组。\n可组合函数可能会非常频繁地运行：在某些情况下，可能会针对界面动画的每一帧运行一个可组合函数。如果您的可组合函数需要数据，它应为相应的数据定义参数。然后，您可以将成本高昂的工作移至组成操作线程之外的其他线程，并使用 mutableStateOf 或 LiveData 将相应的数据传递给 Compose。\n\n主题样式\n在ui/theme/Theme.kt 文件中，根据模板创建工程时，会默认生成一个主题定义的可组合函数，内部对 MaterialTheme 这个可组合函数做了自定义：\nMaterialTheme(\n    colorScheme = colorScheme,\n    typography = typography,\n    content = content\n)\nMaterialTheme 是一个可组合函数，体现了 Material Design 规范 中的样式设置原则。样式设置信息会逐级向下传递到位于其 content 内的组件，这些组件会读取该信息来设置自身的样式。即从任何后代可组合项中都可以检索 MaterialTheme 的三个属性：colorScheme、typography 和 shapes。\nText(text = name, style = MaterialTheme.typography.headlineMedium)\n还可以基于现有的颜色或样式进行设置，使用 copy 函数修改预定义的样式将数字加粗：\nText(\n    text = name,\n    style = MaterialTheme.typography.headlineMedium.copy(\n    \tfontWeight = FontWeight.ExtraBold\n    )\n)\n学习资料\n\ndeveloper.android.com/jetpack/compose/mental-model\ndeveloper.android.com/courses/pathways/compose\ndeveloper.android.com/codelabs/jetpack-compose-basics\n"},"android/jetpack-compose/gradle":{"title":"gradle","links":[],"tags":[],"content":"Basic Gradle\n\nGradle core concepts\nProjects（项目）\nGradle Projects（项目）是一个可以构建的软件，比如一个应用程序或一个库，通常分为两种：\n\nSingle project：单体工程包含一个 project，称为 root project；\nMulti-project：包含一个 root project 和多个 subproject；\n\nBuild Scripts （构建脚本）\nBuild scripts 描述了Gradle 该如何一步步构建当前 Project。\n每个 project 都能包含一个或多个 build script。\nDependency Management（依赖管理）\n一项用于声明和解析当前 project 依赖的外部资源的自动化技术。\nTasks（任务）\nTask 是工作的基本单元，如编译代码或运行测试。\n每个 project 都包含一个或多个定义在 build script 中或 plugin 中的 task。\nPlugins（插件）\nPlugin 是可用于扩展 Gradle 的能力，和向 project 中添加 task。\nGradle project structure\n一个使用了 Gradle 的 project 的一个清晰的标识是其根目录包含 gradlew and gradle.bat。可能看起来像这样：\nproject\n├── gradle\n│   ├── libs.versions.toml              \n│   └── wrapper\n│       ├── gradle-wrapper.jar\n│       └── gradle-wrapper.properties\n├── gradlew\n├── gradlew.bat\n├── settings.gradle(.kts)               \n├── subproject-a\n│   ├── build.gradle(.kts)              \n│   └── src                             \n└── subproject-b\n    ├── build.gradle(.kts)              \n    └── src               \n\n\ngradle：放置 wrapper 文件或一些其他配置；\ngradlew &amp; gradle.bat：wrapper 脚本；\nsettings.gradle：定义了根项目 root project 名称和 子项目 subprojects；\nsubproject-a/b\n\nbuild.gradle：子项目的 build scripts 构建脚本；\n\n\n\nInvoking Gradle\n大多数 IDE 都内置了 Gradle 的调用方法，安装了 Gradle 后可通过命令行运行：\n$ gradle build\n但是大多数项目都不会使用安装的 Gradle。\nGradle Wrapper\nWrapper 是一个的脚本，可调用 Gradle 声明版本，这是执行Gradle构建的推荐方式：\n$ gradlew build     # Linux or OSX\n$ gradle.bat build  # Windows\nGradle Wrapper Basics\n使用 Wrapper 有如下优点：\n\n在给定的 gradle 版本上标准化 project；\n为不同用户，提供相同版本的 Gradle；\n为 Gradle 提供不同的运行环境；\n\nUsing the Gradle Wrapper\n$ ./gradlew build\n$ .\\gradlew.bat build\n该命令在 Wrapper 所在的同一目录中运行，否则需要基于 Wrapper 的相对路径。\nCommand-Line Interface Basics\n$ gradle [taskName...] [--option-name...]\n$ gradle [taskName1 taskName2...] [--option-name...]\n \n$ gradle :taskName\n$ gradle taskName --exampleOption=exampleValue\nSettings File Basics\n设置文件是 Gradle 项目的入口点，其主要目的是添加需要构建的子项目：\n\n对于单项目，设置文件是可选的；\n对于多项目的构建，设置文件是强制的，它声明了所有的子项目；\n\nSettings script\n如其名，它是一个脚本文件，要么使用 Groovy 编写的settings.gradle 要么是 Kotlin 的 settings.gradle.kts，不出意外都位于项目根目录。\n// settings.gradle\n// Define the project name\nrootProject.name = &#039;root-project&#039;\t\n// Add subprojects.\ninclude(&#039;sub-project-a&#039;)            \ninclude(&#039;sub-project-b&#039;)\ninclude(&#039;sub-project-c&#039;)\n// settings.gradle.kts\nrootProject.name = &quot;root-project&quot;   \n \ninclude(&quot;sub-project-a&quot;)            \ninclude(&quot;sub-project-b&quot;)\ninclude(&quot;sub-project-c&quot;)\n\nsettings script 执行后会根据配置生成一个 Settings 对象，该对象有许多属性，例如上述的 rootProject 则是其一。上述的 name 的配置完整如下：\nsettings.rootProject.name = &quot;root&quot;\n\nStandard Settings properties\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNameDescriptionbuildCache构建的缓存配置pluginsThe container of plugins that have been applied to the settings.rootDirThe root directory of the build. The root directory is the project directory of the root project.rootProjectThe root project of the build.settingsReturns this settings object.\n以下是常用的函数：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNameDescriptioninclude()添加给定的项目到构建中includeBuild()Includes a build at the specified path to the composite build.\nSettings Script structure\nSettings script 是一组使用{ … } 调用 Gradle API 的函数，一个{ … }块在 Kotlin 中称为 lambda ，在 Groovy 中叫 closure 。\n函数中在执行时，依靠着 this 对象，在 Kotlin lambda 中称为 receiver，在 Groovy closure 中称 delegate。Gradle 确定正确的 this 对象并调用正确的相应方法。\n如下，id(&quot;plugin&quot;)对象函数调用的 this 类型为 PluginDependenciesSpec.\nplugins(function() {\n    id(&quot;plugin&quot;)\n})\nGradle 一行一行从上往下执行脚本，来看一个详细例子：\npluginManagement {                                          \n    repositories {\n        gradlePluginPortal()\n        google()\n    }\n}\n \nplugins {                                                   \n    id(&quot;org.gradle.toolchains.fake&quot;) version &quot;0.6.0&quot;\n}\n \nrootProject.name = &quot;root-project&quot;                           \n \ndependencyResolutionManagement {                            \n    repositories {\n        mavenCentral()\n    }\n}\n \ninclude(&quot;sub-project-a&quot;)                                    \ninclude(&quot;sub-project-b&quot;)\ninclude(&quot;sub-project-c&quot;)\npluginManagement 可为项目定义插件，引入像 Gradle Plugin Portal 如此的二进制仓库或使用 includeBuild 通过路径引入其他的 Gradle 构建插件。\nplugins 声明将使用的插件，其配置能在多个构建/子项目中共享。插件只影响生成的 Settings 对象。\ndependencyResolutionManagement 为项目的组件依赖，提供了一个集中的本地声明仓库，可使用repositories 声明二进制仓库如 Maven Central 。\ninclude 语句定义了添加到项目的子项目。脚本中的每一项本质上都是调用了 Settings 对象的方法：\ninclude(&quot;app&quot;)\nsettings.include(&quot;app&quot;)\n\ninclude &#039;:app&#039; 和 include &quot;app&quot; 的区别\n添加了:表示该子模块在根目录下，否则只是表示其为当前项目的子模块。\n\nBuild File Basics\n每个 build file 都至少包含一个 build script，其中能添加两种类型的依赖：\n\nGradle 和 build script 依赖的库和/或插件；\n项目资源（源代码）依赖的库；\n\nBuild scripts\nBuild script 是 Groovy  写的 build.gradle 或是 Kotlin 写的 build.gradle.kts。\n// build.gradle\nplugins {\n    id &#039;application&#039;                \n}\n \napplication {\n    mainClass = &#039;com.example.Main&#039;  \n}\n// build.gradle.kts\nplugins {\n    id(&quot;application&quot;)               \n}\n \napplication {\n    mainClass = &quot;com.example.Main&quot;  \n}\n\nplugins：添加插件，插件能扩展 Gradle 的功能，并添加任务到项目中。如 application插件，可方便创建一个 可执行的 JVM 程序，此插件还隐式地引入了 Java 插件（包含了编译测试打包等功能）。\napplication ：添加一些约定属性，插件的引入也会添加属性和函数到项目中。如 application插件定义了程序的打包和分发方式，即 run任务，即需要定义 Java 程序的主类。\n\nDependency Management Basics\n依赖管理，是一项用于声明和解析项目所需的外部资源的自动给化技术。\nBuild scripts 定义了构建可能需要外部依赖项目的步骤，外部依赖涉及到 jars，插件，库或者源代码，以支持构建项目。\nVersion Catalog\n版本目录提供了一种在 libs.versions.toml文件中集中控制依赖声明的方式。\n该目录简化了在多个子项目中依赖共享和版本配置，也允许团队在大项目中强制库和插件的版本。\n通常在 catalog 包含以下几个节点：\n\n[versions] 声明引入的依赖和插件的版本号；\n[libraries] 定义在 build files 中的库；\n[bundles] 定义一组依赖；\n[plugins] 定义插件；\n\n[versions]\nandroidGradlePlugin = &quot;7.4.1&quot;\nmockito = &quot;2.16.0&quot;\n \n[libraries]\ngoogle-material = { group = &quot;com.google.android.material&quot;, name = &quot;material&quot;, version = &quot;1.1.0-alpha05&quot; }\nmockito-core = { module = &quot;org.mockito:mockito-core&quot;, version.ref = &quot;mockito&quot; }\n \n[plugins]\nandroid-application = { id = &quot;com.android.application&quot;, version.ref = &quot;androidGradlePlugin&quot; }\n该文件为于 gradle 路径下，可被 IDE 和 Gradle 自动使用，也应该加入到版本管理中。\nDeclaring Your Dependencies\n下面的 build.gradle.kts 文件使用上述的版本目录添加了插件和依赖：\nplugins {\n   alias(libs.plugins.android.application)  \n}\n \ndependencies {\n    // Dependency on a remote binary to compile and run the code\n    implementation(libs.google.material)    \n \n    // Dependency on a remote binary to compile and run the test code\n    testImplementation(libs.mockito.core)   \n}\n\ncom.android.application：该插件添加了多个用于构建 Android apps 的功能；\ncom.google.android.material：该库提供在 Android apps 中创建 UI 的组件，该库将在项目被用于编译和运行源代码；\norg.mockito:mockito-core：该库是一个用于测试 java 代码 mock 框架，该依赖用于编译和测试源代码。\n\nViewing Project Dependencies\n在命令行中使用./gradlew :app:dependencies可查看依赖。\nTask Basics\n使用命令行调用 Gradle Wrapper  运行 build 任务：\n$ ./gradlew build\nAvailable tasks\n所有的可用的任务来源于 Gradle 插件和 build scripts，使用 tasks 任务能够列出所有的任务：\n$ ./gradlew tasks\nRunning tasks\n如何运行任务，使用 ./gradlew  /  ./gradlew.bat 加上任务名。\nTask dependency\n大多情况下，某个任务需要其他任务先行运行。\n例如，对于 Gradle 执行 build 任务时，java 代码首先必须编译。因此，build 任务依赖于 compileJava 任务，意味着 compileJava 任务在 build 任务之前被执行。\nBuild scripts 能选择性定义任务依赖，Gradle 会自动确定任务执行次序。\nPlugin Basics\n大多数的功能，像编译 java 代码的能力，都来源于插件。\n使用插件是主要的组织构建逻辑的机制，插件能提供像运行代码，创建文档，设置源文件，发布归档等这样的有用的任务，例如：\n\nSpringBoot 的 org.springframework.boot插件；\nGoogle Services 的 com.google.gms:google-services，提供 Google API 和 Firebase 服务。\n\nPlugin distribution\n插件的分发主要有以下三种方式：\n\nCore plugins - Gradle 开发和维护的一组核心插件；\nCommunity plugins - Gradle 社区通过 Gradle Plugin Portal 共享的插件；\nLocal plugins - Gradle 运行用户使用 APIs 创建自定义插件；\n\n使用一个全局唯一的标识和或一个名字构成的 plugin id，在 build scripts 引入插件：\nplugins {\n    id «plugin id» version «plugin version» [apply «false»]\n}\nCore plugins\n核心插件都是独一无二的短小名字，如 java 即为 JavaPlugin：\nplugins {\n    id(&quot;java&quot;)\n}\nCommunity plugins\nTo apply the org.springframework.boot plugin to a project:\nplugins {\n    id(&quot;org.springframework.boot&quot;) version &quot;3.1.5&quot;\n}\nPlugin tasks\nJib 是一个构建 java 程序的 docker 和 OCI 镜像的插件：\nplugins {\n  id(&quot;com.google.cloud.tools.jib&quot;) version &quot;3.4.0&quot;\n}\n引入该插件后，将 jib，jibBuildTar 和 jibDockerBuild 三个任务添加到当前项目。\nGradle Incremental Builds and Build Caching\nGradle 使用两个主要的功能来减少构建时间：增量构建和构建缓存。\nIncremental builds\n增量构建是指避免运行那些输入在上一次构建前没有改变的任务，如果这些任务再次运行产生通用的输出，那么再次执行是没有必要的。\n对于增量构建的工作，任务必须定义输入和输出。Gradle 将在构建时确定输入和输出是否改变。如果有改动，Gradle 将执行；反之，则跳过执行。\n增量构建是默认开启的，在操作中查看的方式是开启 verbose 模式，在该模式下，构件中每一个任务状态都会被标记。\n$ ./gradlew compileJava --console=verbose\n当执行之前执行过且未改变的任务时，UP-TO-DATE 则会打印在该任务后。\n\n如果想每次都开启 verbose mode，可在gradle.properties文件中设置 org.gradle.console=verbose。\n\nBuild caching\n如果一个开发者切换到上周创建的一个分支，将会发什么呢？文件将被重新构建，即使开发者正在构建以前就被构建过的东西。\n这就是 build caching 有用的地方了。\n构建缓存存储上一次构建结果，并将其在需要的时候恢复。它能防止冗余的工作，执行时间的消耗和费力的处理。\n当构建缓存被用来重新填充本地目录时，任务被标记为FROM-CACHE。\nBuild Scans\nBuild scan 是运行构建时捕获的元数据的表示形式。\nGradle 捕获构建元数据，并将其发送到 Build Scan Service，该服务将其转换为分析和共享的信息。\n当出现故障，协作，或优化构建性能时，扫描收集到的信息则是宝贵的资源。\n例如，有了构建扫描，在 Stack Overflow 等社区询问时，没必要每一次复制粘贴报错信息或关于环境细节等。相反，只需要复制最近一次构建的链接。\nEnable Build Scans\n开始构建扫描，只需要一个命令行参数：\n$ ./gradlew build --scans\nAuthoring Gradle"},"android/jetpack-compose/layout":{"title":"layout","links":[],"tags":[],"content":"Column\nRow\nBox\nLazyRow\nLazyColumn"},"android/kotlin/异步编程/README":{"title":"README","links":[],"tags":[],"content":"\nhuanle19891345.github.io/en/kotlin/coroutine/kotlin%E5%8D%8F%E7%A8%8B/\n\n"},"android/kotlin/面向对象/Kotlin-object-关键字":{"title":"Kotlin-object 关键字","links":[],"tags":[],"content":"object 关键字\nKotlin 中有一个重要的关键字 object，其主要使用场景有以下三种：\n对象表达式\n对象表达式用于生成匿名类的对象，该匿名类可以直接从Any开始创建，也可以继承自某一父类，或者实现某一接口。\nval helloWorld = object {\n    val hello = &quot;Hello&quot;\n    val world = &quot;World&quot;\n    // object expressions extend Any, so `override` is required on `toString()`\n    override fun toString() = &quot;$hello $world&quot;\n}\n伴生对象\ncompanion object 是一个对象，在类初始化时被实例化。 伴生对象不是类的 static 方法，而是类的实例化对象，所以在其内部可以声明接口，方法也可以被重写，具备面向对象的所有特点。\nclass MyClass {\n    companion object Factory {\n        fun create(): MyClass = MyClass()\n    }\n}\n \nval instance = MyClass.create()\n诞生原因\n伴生对象 (companion object) 的出现是为了解决 Java 静态方法 (static) 的反面向对象（Anti-OOP）的问题。我们知道 Java中，static 方法是无法声明为接口，无法被重写的。\n用学术性话语来说，static 方法没有面向对象的 消息传递 和 延迟绑定 特性（参考）。而为了满足Kotlin 一切皆对象的特性，以及提升与 Java 的兼容性，提出了伴生对象来代替 static 方法。\n\n另外，如果想使用Java中的静态成员和静态方法的话，我们可以用：\n\n@JvmField 注解：生成与该属性相同的静态字段\n@JvmStatic 注解：在单例对象和伴生对象中生成对应的静态方法\n\n\n对象声明\nKotlin 中没有静态属性和方法，但是也提供了实现类似单例的功能，使用object关键字声明一个object 对象。\nobject StringUtils{  \n    val separator: String = &quot;&quot;&quot;\\&quot;&quot;&quot;  \n    fun isDigit(value: String): Boolean{  \n        for (c in value) {  \n            if (!c.isDigit()) {  \n                return false  \n            }  \n        }  \n        return true  \n    }  \n}\n总结\n\n对象表达式 (Object expressions)，在它们使用的地方，是立即（immediately）执行（或初始化）\n对象声明 (Object declarations)，会延迟（lazily）初始化；但第一次访问该对象时才执行\n伴生对象（Companion Objects），当外部类被加载时初始化，跟 Java 静态代码框初始化相似\n"},"android/kotlin/面向对象/Kotlin-内部类":{"title":"Kotlin-内部类","links":[],"tags":[],"content":"内部类\n内部类就是定义在类内部的类，Kotlin 中的内部类大致分为 2 种：\n\n静态内部类\n非静态内部类\n\n静态内部类\n在某个类中像普通类一样声明即可，可以认为静态内部类与外部类没有关系，只是定义在了外部类”体内”而已，在使用静态内部类时需要”带上”外部类：\nclass Outer {\n    val a: Int = 0\n \n    class Inner {\n        val a: Int = 5\n    }\n}\n \nfun main() {\n    val outer = Outer()\n    println(outer.a)\n    val inner = Outer.Inner()\n    println(inner.a)\n}\n非静态内部类\n声明一个非静态内部类使用inner关键字，非静态内部类与静态内部类有的区别有：\n\n非静态内部类会持有外部类的引用，而 静态内部类不会(可以认为两者没有关系)。\n非静态内部类使用时需要基于外部类对象（Outer().Inner()），而 静态内部类则是基于外部类（Outer.Inner()）。\n\n因为非静态内部类会持有外部类的引用，所以内部类可以直接使用外部类成员；当非静态内部类与外部类存在同名成员时，可以使用 @ 来解决歧义：\nclass Outer {\n    val b: Int = 3\n    val a: Int = 0\n \n    inner class Inner {\n        val a: Int = 5\n        fun test() {\n            println(&quot;Outer b = $b&quot;) \n            // 3，因为持有外部类的引用，所以直接使用外部类成员\n            println(&quot;Outer a = ${this@Outer.a}&quot;) \n            // 0，使用 @Outer 指定this是外部类对象\n            println(&quot;Inner a = ${this@Inner.a}&quot;) \n            // 5，使用 @Inner 指定this是内部类对象\n            println(&quot;Inner a = ${this.a}&quot;) \n            // 5，不使用 @标记 默认this就是内部类对象\n        }\n    }\n}\n \nfun main() {\n    val inner = Outer().Inner()\n    inner.test()\n}\n匿名内部类\n匿名内部类就是没有定义名字的内部类，一般格式为 object : 接口或(和)类，实际开发中，方法的回调接口(即 callback)一般不会专门声明一个类再创建对象来使用，而是直接使用匿名内部类：\nval textArea = TextArea()\ntextArea.addTextListener(object : TextListener {\n    override fun textValueChanged(e: TextEvent?) {...}\n})\nKotlin 的匿名内部类很强大，在使用时，可以有多个接口或父类，如：\nval textArea = TextArea()\ntextArea.addTextListener(object : TextField(), TextListener {\n    override fun textValueChanged(e: TextEvent?) {...}\n})\n这个匿名内部类既是 TextField 的子类，也是 TextListener 的实现类，不过可能实际应用场景会比较少，了解即可。"},"android/kotlin/面向对象/Kotlin-密封类":{"title":"Kotlin-密封类","links":[],"tags":[],"content":"密封类\n密封类是用来表示受限的类继承结构， 使用关键字sealed进行声明：\nsealed class BaseSealed {\n    data class People(val name: String) : BaseSealed()\n    object Student : BaseSealed()\n}\n一个密封类可以有子类，但是所有子类都必须在同一个文件中声明，作为密封类的本身，扩展密封类（间接继承）的子类的类可以放在任何地方，而不一定是在同一个文件中。\n密封类是不能被实例化的，即本身是抽象的，但可有抽象成员。\n受限的类继承结构\n所谓受限的类继承结构，即当类中的一个值只能是有限的几种类型，而不能是其他的任何类型。这种受限的类继承结构从某种意义上讲，它相当于是枚举类的扩展。\n但是，我们知道Kotlin的枚举类中的枚举常量是受限的，因为每一个枚举常量只能存在一个实例。和枚举类不同的地方在于，密封类的一个子类可以有可包含状态的多个实例。\n也可以说成，密封类是包含了一组受限的类集合，因为里面的类都是继承自这个密封类的。但是其和其他继承类（open）的区别在，密封类可以不被此文件外被继承，有效保护代码。\n密封类的使用\n创建一个名为Operation的密封类，它包含四种操作：加法，减法，乘法和除法：\nsealed class Operation {\n\tclass Add(val value: Int) : Operation()\n    class Substract(val value: Int) : Operation()\n    class Multiply(val value: Int) : Operation()\n    class Divide(val value: Int) : Operation()\n}\n密封类的一个好处，在于使用when表达式 的时候，如果能够验证语句覆盖了所有情况，就不需要为该语句再添加一个else子句了：\nfun execute(x: Int, op: Operation) = when (op) {\n\tis Operation.Add -&gt; x + op.value\n\tis Operation.Substract -&gt; x - op.value\n\tis Operation.Multiply -&gt; x * op.value\n\tis Operation.Divide -&gt; x / op.value\n}"},"android/kotlin/面向对象/Kotlin-抽象类":{"title":"Kotlin-抽象类","links":[],"tags":[],"content":"抽象类\n抽象类需要用abstract修饰，其中有抽象方法，也可以包含抽象属性：\n \nabstract class Person(var name: String, var age: Int){  \n\tabstract var addr: String\n\tabstract val weight: Float\n\t\n\tabstract fun doEat()\n\tabstract fun doWalk()\n\t\n\tfun doSwim() {\n\t\tprintln(&quot;I am Swimming ... &quot;)\n\t}\n\topen fun doSleep() {\n\t\tprintln(&quot;I am Sleeping ... &quot;)\n\t}\n}\n\n抽象类或者抽象函数不用手动添加open关键字，默认就是open类型；\n抽象类可以有具体实现的函数，这样的函数默认是final的（不能被覆盖）。如果想要被覆盖，需要手工加上open关键字；\n"},"android/kotlin/面向对象/Kotlin-接口":{"title":"Kotlin-接口","links":[],"tags":[],"content":"接口\n使用interface作为接口的关键词，\n和继承一样，也是使用冒号:来实现一个接口，如果要实现多个接口，使用逗号,分开。\n接口中的属性\n在接口中申明属性。接口中的属性要么是抽象的，要么提供访问器的实现。接口属性不可以有后备字段。而且访问器不可以引用它们。\n作为抽象\n即在实现类的类参数中重写属性：\ninterface InterfaceDemo {\n\tval num1: Int\n\tval num2: Int \n}\n作为访问器\n即手动方式去实现重写，并提供get()方法：\ninterface InterfaceDemo {     \n\t// 声明变量并提供默认值     \n\t// 注意： val num3: Int = 3  这种方式不提供，直接报错\n\tval num3: Int get() = 3\n\tval num4: Int\n}\n \nclass Demo(override val num1: Int, override val num2: Int) : InterfaceDemo {  \n  \n    // 提供访问器实现  \n    override val num3: Int get() = super.num3  \n  \n    // 手动赋值  \n    override var num4: Int = 4  \n  \n    fun result() : Int{  \n        return num3 + num4  \n    }  \n}\n接口中的函数\n不带函数体的函数可以省略大括号，且不用强制重写带函数体的函数就可以直接调用。"},"android/kotlin/面向对象/Kotlin-数据类":{"title":"Kotlin-数据类","links":[],"tags":[],"content":"数据类\n在class关键字之前，使用 data 关键字声明数据类：\ndata class Preson(var name : String,val sex : Int, var age : Int)\n\n构造函数中必须存在至少一个参数，并且必须使用val或var修饰；\n数据类不能是抽象、开放、密封或者内部的；\n数据类是可以实现接口的，如(序列化接口)，同时也是可以继承其他类的，如继承自一个密封类。\n\n解构声明"},"android/kotlin/面向对象/Kotlin-枚举类":{"title":"Kotlin-枚举类","links":[],"tags":[],"content":"枚举类\n使用 enum关键字在类头中的class关键字进行标识，枚举类中的每一个枚举常量都是一个对象，并且它们之间用逗号分隔：\nenum class State {  \n    NORMAL,\n    NO_DATA,\n    NO_INTERNET,\n    ERROR,\n    OTHER  \n}\n枚举常量\n每一个枚举都是枚举类的实例，它们都是需要被初始化的：\nenum class Color(var argb : Int){    \n\tRED(0xFF0000),\n\tWHITE(0xFFFFFF),\n\tBLACK(0x000000),\n\tGREEN(0x00FF00)\n}\n匿名类\n要实现枚举常量的匿名类，则必须提供一个抽象方法。且该方法定义在枚举类内部。而且必须在枚举变量的后面。\n枚举变量之间使用逗号（,）分割开。但是最后一个枚举变量必须使用分号结束。不然定义不了抽象方法。\nenum class ConsoleColor(var argb : Int){    \n\tRED(0xFF0000) {        \n\t\toverride fun print() {            \n\t\t\tprintln(&quot;我是枚举常量 RED &quot;)        \n\t\t}    \n\t},    \n\tWHITE(0xFFFFFF){        \n\t\toverride fun print() {\n\t\t\tprintln(&quot;我是枚举常量 WHITE &quot;)\n\t\t}\n\t};    \n\tabstract fun print()\n}\n枚举类的使用\n每个枚举常量都包含两个属性：name（枚举常量名）和ordinal（枚举常量位置），且提供了values()和valueOf()方法来检测指定的名称与枚举类中定义的任何枚举常量是否匹配。"},"android/kotlin/面向对象/Kotlin-继承类":{"title":"Kotlin-继承类","links":[],"tags":[],"content":"继承类\n超类(Any)\n在Kotlin中，所有的类都是继承于Any类，这是个没有父类型的类。即当我们定义各类时，它默认是继承于Any这个超类的。\n因为Any这个类只是给我们提供了equals()、hashCode()、toString()这三个方法。我们可以看看Any这个类的源码实现：\npackage kotlin  \n \npublic open class Any {  \n \n    public open operator fun equals(other: Any?): Boolean  \n  \n    public open fun hashCode(): Int  \n  \n    public open fun toString(): String  \n}\n除了抽象类和接口默认是可被继承外，其他类默认是不可以被继承的（相当于默认都带有final修饰符）。而类中的方法也是默认不可以被继承的。\n\n如果要继承一个类，需要使用open关键字修饰这个类;\n如果要重写一个类的某个方法，这个方法也需要使用open关键字修饰；\n\n构造函数\n在 Kotlin 中可以有一个主构造函数，一个或者多个次构造函数。\n主构造函数\n主构造函数直接跟在类名后面，如下：\nopen class Person constructor(var name: String, var age: Int) : Any() {\n\t//...\n}\n主构造函数中的属性可以是可变的（var）也可以是不变的（val）。如果主构造函数没有任何注解或者可见性修饰符，可以省略constructor关键字（属性默认是 val），而且 Koltin 中的类默认就是继承超类Any的，也可以省略。所以可以简化成如下：\nopen class Person(name: String, age: Int) {\n\t//...\n}\n主构造函数不能包括任何代码。初始化代码可以放到以init关键字作为前缀的初始化块中：\nopen class Person constructor(var name: String, var age: Int){  \n    init {  \n        println(&quot;Student(name = $name, age = $age) created&quot;)  \n    }  \n}\n主构造函数的参数可以在初始化块中使用，也可以在类体内申明的属性初始化器中使用。\n次构造函数\n我们也可以在类体中使用constructor申明次构造函数，次构造函数的参数不能使用 val 或者 var 申明。\nclass Student public constructor(name: String, age: Int) : Person(name, age) {  \n    var grade: Int = 1  \n  \n    init {  \n        println(&quot;Student(name = $name, age = $age) created&quot;)  \n    }  \n  \n    constructor(name: String, age: Int, grade: Int) : this(name, age){  \n        this.grade = grade  \n    }  \n}\n重载与重写\n当基类中的函数，没有用open修饰符修饰的时候，实现类中出现的函数的函数名不能与基类中没有用open修饰符修饰的函数的函数名相同，不管实现类中的该函数有无override修饰符修饰。\n当一个类不是用open修饰符修饰时，这个类默认是final的。\n继承时不想覆盖掉第一个基类的方法时，第二个基类的该方法可使用final修饰符修饰。\n\n在基类中声明的属性，然后在其基类的实现类中重写该属性，该属性必须以override关键字修饰，并且其属性具有和基类中属性一样的类型。且可以重写该属性的值（Getter）。\n当基类中属性的变量修饰符为val的使用，其实现类可以用重写属性可以用var去修饰。反之则不能。"},"android/system/AB分区":{"title":"AB分区","links":[],"tags":[],"content":""},"android/system/Android-启动过程":{"title":"Android 启动过程","links":[],"tags":[],"content":"\n\n\n第一阶段：Android设备上电后，首先会从处理器片上ROM的启动引导代码开始执行，片上ROM会寻找Bootloader代码，并加载到内存（这一步由“芯片厂商”负责设计和实现）。\n\n\n第二阶段：Bootloader开始执行，首先负责完成硬件的初始化，然后找到Linux内核代码，并加载到内存（这一步由“设备厂商”负责设计和实现）。\n\n\n第三阶段：Linux内核开始启动，初始化各种软硬件环境，加载驱动程序，挂载根文件系统，并执行init程序，由此开启Android的世界（这一步则是Android内核开发过程中需要涉及的地方）。\n\n\nAndroid系统以及各大Linux的发行版，他们的Linux内核部分启动过程都是差不多的，他们之间最大的区别就在于init程序的不同，因为init程序决定了系统在启动过程中，究竟会启动哪些守护进程和服务，以及呈现出怎样的一个用户UI界面。\n因此，init 程序是分析Android启动过程中最核心的程序，其工作主要有3点：\n\n创建和挂载一些系统目录/设备节点，设置权限，如：/dev, /proc, 和 /sys；\n解析 init.rc 和 init.&lt;hardware&gt;.rc，并启动属性服务，以及一系列的服务和进程。\n显示 boot logo；\n\n其中，最重要的步骤是第二步，一系列的Android服务在这时被启动起来，其实Android系统的启动最重要的过程也就是各个系统服务的启动，因为系统所有的功能都是依赖这些服务来完成的，比如启动应用程序，拨打电话，使用WIFI或者蓝牙，播放音视频等等，只要这些服务都能正常地启动起来并且正常工作，整个Android系统也就完成了自己的启动。\n本地服务\n本地服务是指运行在C++层的系统守护进程，一部分本地服务是init进程直接启动的，它们定义在init.rc脚本和init.&lt;hardware&gt;.rc中，如 ueventd、servicemanager、debuggerd、rild、mediaserver等。还有一部分本地服务，是由这些本地服务进一步创建的，如mediaserver服务会启动AudioFlinger, MediaPlayerService， 以及 CameraService 等本地服务。\n\n注意，每一个由init直接启动的本地服务都是一个独立的Linux进程，在系统启动以后，我们通过adb shell命令进入手机后，输入top命令就可以查看到这些本地进程的存在。\n\nAndroid服务\nAndroid服务是指运行在Dalvik虚拟机进程中的服务，这些服务的创建过程描述如下：\n\ninit进程会执行app_process程序，创建Zygote进程，它是Android系统最重要的进程，所有后续的Android应用程序都是由它fork出来的。\nZygote进程会首先fork出”SystemServer”进程，“SystemServer”进程的全部任务就是将所有的Android核心服务启动起来。\n\n部分 Android 核心服务：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nServiceDescriptionActivity ManagerManages activities life cycle and new servicesPackage ManagerManages application package handling (install, uninstall, upgrade, permissions)Window ManagerManages all the window manipulations (like input events, orientation).AppWidget ServiceHandles Android widgetsBackup ManagerManages backup scheduling and transferStatus BarShows software/hardware status. It works with other managers like Notification, Network Status, Battery StatusPower ManagerHandles power management while Android’s different modes (lock mode, sleep mode, Adjust brightness)NetworkManagement ServiceDeals with network related activitiesNotification ManagerManage all notifications (Toasts)Location ManagerManages location providersEntropy MixerHandles (load &amp; save periodically) kernel randomnessDisplay ManagerManages display propertiesTelephony RegistryProvides telephony informationScheduling PolicyManages the process schedulingAccount ManagerHandles the users account credential of different online servicesContent ManagerHandles all the data’s on a deviceBattery ServiceManages battery level and charging statesAlarm ManagerUsed to schedule the user applications to be run at future.Input ManagerHandles input devices and key layoutsDevice PolicyEnforces security policies for the deviceClipboard ServiceProvides Clipboard based copy/past operations.NetworkStats ServiceMonitors Network connection StatusNetworkPolicy ServiceEnforces network security policies.Wi-Fi P2pServiceHandles WiFi peer to peer connectionEthernet ServiceManages Ethernet connectivity.Wi-Fi ServiceManage WiFi connectivityConnectivity ServiceMonitors and handles network connection state changesNetwork Service Discovery ServiceUsed to find local network devices to share app data当所有的服务都启动完毕后，SystemServer 会打印出“Making services ready”，然后通过ActivityManager 启动 Home 界面，并发送“ACTION_BOOT_COMPLETED”广播消息。\n\n注意，这些Android服务并没有各种运行在独立的进程中，它们由SystemServer以线程的方式创建，所以都运行在同一个进程中，即SystemServer进程中。\n\nPackage Manager 服务启动后，会解析所有位于 “/system/app” and “/system/vendor/app” 路径下的 “.apk” 文件，并验证其 AndroidManifest.xml。"},"android/system/Android-签名校验机制":{"title":"Android 签名校验机制","links":[],"tags":[],"content":"Android 签名校验机制\n概述\nAndroid 支持以下三种应用签名方案：\n\nv1：基于 JAR 签名\nv2：APK 签名方案 v2（在 Android 7.0 引入）\nv3：APK 签名方案 v3（在 Android 9 引入）\n\n为了最大限度地提高兼容性，请按照 v1、v2、v3 的先后顺序采用所有方案对应用进行签名。与只通过 v1 方案签名的应用相比，还通过 v2+ 方案签名的应用能够更快的安装到 Android 7.0 及更高版本的设备上。更低版本的 Android 平台会忽略 v2+ 签名，这就需要应用包含 v1 签名。\nv1 方案-JAR 签名\nv1 利用的是 jarsigner 工具，它是 JDK 自带的。它会对所有的文件（包括 META-INF 中与签名不相关的文件）都会被签名。\n在 APK 的 META-INF 目录下一般有三个文件：.MF、.SF 和 .RSA 三个文件。\n\n.MF 文件：APK 当中的原始文件信息用摘要算法如 SHA1 计算得到的摘要信息并用 base64 编码保存，以及对应采用的摘要算法如 SHA1。\n.SF 文件：.MF 文件的摘要信息以及 .MF 文件当中每个条目在用摘要算法计算得到的摘要信息并用 base64 编码保存。\n.RSA 文件：存放证书信息，公钥信息，以及用私钥对 .SF 文件的加密数据即签名信息，这段数据是无法伪造的，除非有私钥，另外，.RSA 文件还记录了所用的签名算法等信息。\n\nAPK 包在安装的时候，是按照从 3 到 1 到顺序依次校验的。先用公钥还原签名信息，然后和 .SF 文件中的信息对比，然后用同样的摘要算法对 .MF 文件里面的每一个条目计算对应的摘要信息，然后对比 .MF 文件是否一致。\n在这个过程中，我们发现有两点：\n\n在校验的过程中需要解压，因为 .MF 文件的摘要信息是基于原始未压缩文件内存，因此在校验的时候就需要解压出原始数据，而这个解压操作无疑是耗时操作。\nAPK 包的完整性校验不够强。这里我们可以看到，如果我们在 APK 签名后，对 APK 包中没有涉及到原始文件的数据块做改变，那么这层校验机制就会失效。所以，在美团的打包工具 Walle 的做法就是在 META-INF 中添加空文件作为标识来实现多渠道打包，因为在 META-INF 中添加新文件是不需要重新签名的。这也同时说明了，其实存在过度签名的问题。\n\n为了解决这些问题，Android 7.0 中引入了 APK 签名方案 v2。\nv2 方案\nAPK 签名方案 v2 是一种全文件签名方案，该方案能够发现对 APK 受保护部分进行的所有更改，从而有助于加快验证速度并增强完整性保证。\n使用 APK 签名方案 v2 进行签名时，会在 APK 文件中插入一个 APK 签名分块，该分块位于 ” ZIP 中央目录” 部分之前并紧邻该部分。在 “APK 签名分块” 内，v2 签名和签名者身份信息会存储在其中。\n\nv2 签名机制不存在解压原始数据，签名校验时间显著减少，因此安装时间也相应减少。同时，它是基于 APK 的二进制内存做的签名信息（APK Signing Block 签名块本身不参与加密校验），因此打包后改变 APK 的其他三部分的任何字节都会导致签名校验不通过。这也说明了，zipalign 是要在 apksigner 之前的。\nAPK Signing Bolck 由这几个部分组成：两个用来标示这个区块长度的八字节 + 这个区块的魔数（APK Sig Bolck 42）+ 这个区块所承载数据（ID-value）。\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n偏移字节数描述@08这个 Block 的长度（本字段的长度不计算在内）@8n一组 ID-value@-248这个 Bolck 的长度（和第一个字段一样值）@-1616魔数 “APK Sig Block 42”\nv2 的签名信息是以 ID（0x7109871a）的 ID-value 来保存在这个区块中，这是一组 ID-value，但是在验证的时候，只是通过 ID 为 0x7109871a 的来获取 APK Signature Scheme v2 Block，对这个区块中其他的 ID-value 选择了忽略。所以 Walle 提供一个自定义的 ID-value 并写入该区域，从而为快速生成渠道包服务。\n想要了解是如何做的，请参考：新一代开源Android渠道包生成工具Walle\n在 APK 签名分块内，也就是 ID 为 0x7109871a，它里面有一个叫做 signed data 的数据结构。APK 签名方案 v2 负责保护第1、3、4 部分的完整性，以及第二部分包含的 APK 签名方案 v2 分块中的 signed data 分块的完整性。\n第1、3、4 部分的完整性通过其内容的一个或多个摘要来保护，这些摘要存储在 signed data 分块中，而这些分块则通过一个或多个签名保护。第1、3、4 部分都会被拆分为多个大小为 1MB 的连续块分段计算摘要，摘要以分段方式计算，以便通过并行处理来加快计算速度。\nAPK 签名方案 v2 是在 Android 7.0 中引入的，为了使 APK 可在 Android 6.0 及更低版本的设备上安装，应先使用 JAR 签名功能对 APK 进行签名，然后再使用 v2 方案对其进行签名。\nv3 方案\nAndroid 9 支持 APK 密钥轮转，这使得应用能够在 APK 更新过程中更改签名密钥。为了实现轮转，APK 必须指示新旧签名密钥之间的信任级别。为了支持密钥轮转，我们将 APK 签名方案从 v2 更新为 v3，以允许使用新旧密钥。v3 在 APK 签名分块中添加了有关受支持的 SDK 版本和 proof-of-rotation 结构的信息。\nv3 APK 签名分块的格式与 v2 相同，APK 的 v3 签名会存储为一个 ID 为 0xf05368c0 的 ID-value。看来 Google 给自己留了后路，以后再增加版本，肯定又是增加新的 ID-value，在高版本的 SDK 设备上解析即可。\n更多请参考：Android 文档 APK 签名方案 v3\n参考\nOracle Signed_JAR_File\nsource.android.com/security/apksigning\n分析Android V2新签名打包机制\n新一代开源Android渠道包生成工具Walle"},"android/system/Android-系统架构":{"title":"Android 系统架构","links":[],"tags":[],"content":"Android 系统架构\n概述\nAndroid 底层内核空间以 Linux Kernal 作为基石，上层用户空间由 Native 系统库、虚拟机运行环境、框架层组成，通过系统调用（Syscall）连通系统的内核空间与用户空间。对于用户空间主要采用 C++ 和 Java 代码编写，通过 JNI 打通用户空间的 Java 层 和 Native 层，从而连通整个系统。\n\nLinux 内核层\nAndroid 平台的基础是 Linux 内核。例如，ART 依靠 Linux 内核来执行底层功能。Linux 内核的安全机制为 Android 提供了相应的保障，也允许设备制造商为内核开发硬件驱动程序。\n硬件抽象层 HAL\n硬件抽象层提供标准界面，向更高级别的 Java Framework 层显示设备硬件功能。HAL 包含多个库模块，其中每个模块都为特定类型的硬件组件实现一个界面，例如相机和蓝牙模块。当框架 API 要求访问设备硬件时，Android 系统将为该硬件组件加载库模块。\nNative C/C++ 库 &amp; Android Runtime\n每个应用都在其自己的进程中运行，都有自己的虚拟机实例。ART 通过执行 DEX 文件可在设备上运行多个虚拟机，DEX 文件是一种专为 Android 设计的字节码格式，经过优化，使用内存很少。ART 主要功能包括：AOT 和 JIT 编译，优化的 GC，以及调试相关的支持。\nNative C/C++ 库主要包括 init 孵化来的用户空间的守护进程、HAL 层以及开机动画等。启动 init 进程，是 Linux 系统的用户进程，init 进程是所有用户进程的父进程。\nJava Framework 层\nZygote 进程 是由 init 进程通过解析 init.rc 文件后 fork 生成的，Zygote 进程主要包括：\n\n加载 ZygoteInit 类，注册 Zygote Socket 服务端套接字\n加载虚拟机\n提前加载类 preloadClasses\n提前加载资源 preloadResources\n\nSystem Server 进程 是由 Zygote 进程 fork 而来，System Server 是 Zygote 孵化的第一个进程，System Server 负责启动和管理整个 Java Framework，包括 ActivityManager、WindowManager、PackageManager、PowerManager 等服务。\nMedia Server 进程 是由 init 进程 fork 而来，负责启动和管理整个 C++ Framework，包括 AudioFlinger、Camera Service 等服务。\nSystem Apps 层\nZygote 进程孵化出第一个 App 进程是 Launcher，这是用户看到的桌面 App；\nZygote 进程还会创建 Browser、Phone、Email 等 App 进程，每个 App 至少运行在一个进程上。\n所有的 App 进程都是由 Zygote 进程 fork 生成的。\n系统内置的应用程序以及非系统级的应用程序都属于应用层，负责与用户进行直接交互。"},"android/system/Android-设备分区":{"title":"Android 设备分区","links":[],"tags":[],"content":"Android 设备分区\nAndroid 设备包含两类分区：一类是启动分区，对启动过程至关重要，另一类是用户分区，用于存储与启动无关的信息。\n启动分区\n\n\nboot：此分区包含一个使用 mkbootimg 创建的内核映像，此分区还包含在 Android 13 之前发布的设备中的通用 ramdisk：\n\nkernel 虚拟分区：通过将新内核映像写入旧内核映像来覆盖内核（zImage、zImage-dtb、Image.gz-dtb）。\nramdisk 虚拟分区：通过将新 ramdisk 映像写入旧 ramdisk 映像来覆盖 ramdisk。\n\n\n\ninit_boot：此分区包含发布时搭载 Android 13 及更高版本的设备的通用 ramdisk。\n\n\n标准分区\n\nsystem：此分区包含 Android 框架。\nodm：此分区包含原始设计制造商 (ODM) 对系统芯片 (SoC) 供应商板级支持包 (BSP) 的自定义设置。利用此类自定义设置，ODM 可以替换或自定义 SoC 组件，并在硬件抽象层 (HAL) 上为板级组件、守护程序和 ODM 特定的功能实现内核模块。\nodm_dlkm：此分区专门用于存储 ODM 内核模块。将 ODM 内核模块存储在 odm_dlkm 分区（而不是 odm 分区）中后，无需更新 odm 分区即可更新 ODM 内核模块。\nrecovery：此分区会存储在 OTA 过程中启动的恢复映像。支持 A/B 无缝更新的设备可以将恢复映像存储为 boot 或 init_boot 映像中包含的 ramdisk（而不是单独的映像）。\ncache：此分区会存储临时数据，如果设备使用无缝更新，则此分区是可选的。cache 分区并非必须可从引导加载程序写入，但必须可清空。\nmisc：此分区供 recovery 分区使用，大小为 4 KB 或更大。\nuserdata：此分区包含用户安装的应用和数据，包括自定义数据。\n\n\nmetadata ：此分区用于在设备使用元数据加密时存储元数据加密密钥。大小为 16 MB 或更大。此分区未经加密，且系统不会对其数据拍摄快照。数据会在设备恢复出厂设置时被清空。此分区的使用受到严格限制。\nvendor：此分区包含所有无法分发给 AOSP 的二进制文件。如果设备不包含专有信息，则可以忽略此分区。\nvendor_dlkm：此分区专门用于存储供应商内核模块。将供应商内核模块存储在vendor_dlkm 分区（而不是 vendor 分区）中后，无需更新 vendor 分区即可更新内核模块。\nradio：此分区包含无线装置映像，只有包含无线装置且在专用分区中存储无线装置专用软件的设备才需要此分区。\n\n动态分区\n搭载 Android 11 及更高版本的设备可以支持动态分区，此类分区属于 Android 的用户空间分区系统，支持在 OTA 更新期间创建和销毁分区以及调整分区大小。\n借助动态分区，供应商无需担心各个分区（例如 system、vendor 和 product）的大小。取而代之的是，设备会分配一个 super 分区，其中的子分区可动态调整大小。各个分区映像不再需要为将来的 OTA 预留空间。相反，super 中剩余的可用空间还可用于所有动态分区。"},"android/system/README":{"title":"README","links":[],"tags":[],"content":"\ngithub.com/Omooo/Android-Notes\n\n"},"cant/hot-code":{"title":"hot code","links":[],"tags":[],"content":"Hot code (or hot code path) are execution paths in your application / compiler in which most of the execution time is spent, and thus which are potentially executed very often. For example, a game application may contain ECS (Entity-Component-System) alongside a game loop: thus, that application’s update() and draw() methods have the most amount of execution time. This term may come up when talking about data locality or performance optimization.\nA “hot path” is a code path that is perf-critical, either because it’s something that is really perf-intensive, or because it’s latency-sensitive. An example of the former is a long for loop, or large nested iteration that does some core computation and takes a long time. An example of the latter is the measure/layout/draw logic for your UI, which must be as fast as possible to avoid dropping frames. In general, these are code paths you want that to take the least amount of time possible, for one reason or another."},"code-learing/lz-string/DOC":{"title":"DOC","links":[],"tags":[],"content":"一个简单的例子\nLZW编码 (Encoding) 的核心思想其实比较简单，就是把出现过的字符串映射到记号上，这样就可能用较短的编码来表示长的字符串，实现压缩，例如对于字符串：\nABABAB\n可以看到子串AB在后面重复出现了，这样我们可以用一个特殊记号表示AB，例如数字2，这样原来的字符串就可以表示为：\nAB22\n这里我们称2是字串AB的记号(Symbol)。那么A和B有没有记号来表示？当然有，例如我们规定数字0表示A，数字1表示B。实际上最后得到的压缩后的数据应该是一个记号流 (Symbol Stream) :\n0122\n这样我们就有一个记号和字符串的映射表，即字典 (Dictionary) ：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSymbolString0A1B2AB\n有了压缩后的编码0122，结合字典，就能够很轻松地解码 (Decoding) 原字符串ABABAB。\n当然在真正的LZW中A和B不会用数字0和1表示，而是它们的ASCII值。实际上LZW初始会有一个默认的字典，包含了所有256个8bit字符，单个字符的记号就是它自身，用数字表示就是ASCII值。在此基础上，编码过程中加入的新的记号的映射，从256开始，称为扩展表(Extended Dictionary)。在这个例子里是为了简单起见，只有两个基础字符，所以规定0表示A，1表示B，从记号2开始就是扩展项了。\n字典的生成\n这里有一个问题：为什么第一个AB不也用2表示？即表示为222，这样不又节省了一个记号？这个问题实际上引出的是LZW的一个核心思想，即压缩后的编码是自解释 (self-explaining) 的。什么意思？即字典是不会被写进压缩文件的，在解压缩的时候，一开始字典里除了默认的0→A和1→B之外并没有其它映射，2→AB是在解压缩的过程中一边加入的。这就要求压缩后的数据自己能告诉解码器，完整的字典，例如2→AB是如何生成的，在解码的过程中还原出编码时用的字典。\n用上面的例子来说明，我们可以想象ABABAB编码的过程：\n\n遇到A，用0表示，编码为0。\n遇到B，用1表示，编码为1。\n发现了一个子串AB，添加映射2→AB到字典里。\n后面又出现了AB子串，都用2来编码。\n\n以上过程只是一个概述，并非真正LZW编码过程，只是为了表示它的思想。可以看出最前面的A和B是用来生成表项2→AB的，所以它们必须被保留在压缩编码里，作为表项2→AB生成的“第一现场”。这样在解码0122的时候，解码器首先通过01直接解析出最前面A和B，并且生成表项2→AB，这样才能将后面出现的2都解析为AB。实际上解码器是自己还原出了编码时2→AB生成的过程。\n编码和解码都是从前往后步步推进的，同时生成字典，所以解码的过程也是一个不断还原编码字典的过程。解码器一边解码，向后推进，一边在之前已经解出的原始数据上重现编码的过程，构建出编码时用的字典。\nLZW算法详解\n下面给出完整的LZW编码和解码的过程，结合一个稍微复杂一点的例子，来说明LZW的原理，重点是理解解码中的每一步是如何对应和还原编码中的步骤，并恢复编码字典的。\n编码算法\n编码器从原字符串不断地读入新的字符，并试图将单个字符或字符串编码为记号 (Symbol)。这里我们维护两个变量，一个是P (Previous)，表示手头已有的，还没有被编码的字符串，一个是C (current)，表示当前新读进来的字符。\n 1. 初始状态，字典里只有所有的默认项，例如0-&gt;a，1-&gt;b，2-&gt;c。此时P和C都是空的。\n 2. 读入新的字符C，与P合并形成字符串P+C。\n 3. 在字典里查找P+C，如果:\n    - P+C在字典里，P=P+C。\n    - P+C不在字典里，将P的记号输出；在字典中为P+C建立一个记号映射；更新P=C。\n 4. 返回步骤2重复，直至读完原字符串中所有字符。\n\n以上表示的是编码中间的一般过程，在收尾的时候有一些特殊的处理，即步骤2中，如果到达字符串尾部，没有新的C读入了，则将手头的P对应的记号输出，结束。\n编码过程的核心就在于第3步，我们需要理解P究竟是什么。P是当前维护的，可以被编码为记号的子串。注意P是可以被编码为记号，但还并未输出。新的字符C不断被读入并添加到P的尾部，只要P+C仍然能在字典里找到，就不断增长更新P=P+C，这样就能将一个尽可能长的字串P编码为一个记号，这就是压缩的实现。当新的P+C无法在字典里找到时，我们没有办法，输出已有的P的编码记号，并为新子串P+C建立字典表项。然后新的P从单字符C开始，重新增长，重复上述过程。\n这里用一个例子来说明编码的过程，之所以用小写的字符串是为了和P，C区分。\nababcababac\n初始状态字典里有三个默认的映射：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSymbolString0a1b2c\n开始编码：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStepPCP+CP+C in Dict ？ActionOutput1-aaYes更新P=a-2ababNo添加3→ab，更新P=b03babaNo添加4→ba，更新P=a14ababYes更新P=ab-5abcabcNo添加5→abc，更新P=c36cacaNo添加6→ca，更新P=a27ababYes更新P=ab-8abaabaNo添加7→aba，更新P=a39ababYes更新P=ab-10abaabaYes更新P=aba-11abacabacNo添加8→abac，更新P=c712c----2\n注意编码过程中的第3-4步，第7-8步以及8-10步，子串P发生了增长，直到新的P+C无法在字典中找到，则将当前的P输出，P则更新为单字符C，重新开始增长。\n输出的结果为0132372，完整的字典为：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSymbolString0a1b2c3ab4ba5abc6ca7aba8abac\n这里用一个图来展示原字符串是如何对应到压缩后的编码的:\n\n—\n解码算法\n解码的过程比编码复杂，其核心思想在于解码需要还原出编码时的用的字典。因此要理解解码的原理，必须分析它是如何对应编码的过程的。下面首先给出算法：\n解码器的输入是压缩后的数据，即记号流 (Symbol Stream)。类似于编码，我们仍然维护两个变量pW (previous word) 和cW (current word)，后缀W的含义是word，实际上就是记号 (Symbol)，一个记号就代表一个word，或者说子串。pW表示之前刚刚解码的记号；cW表示当前新读进来的记号。\n注意cW和pW都是记号，我们用Str(cW)和Str(pW)表示它们解码出来的原字符串。\n1. 初始状态，字典里只有所有的默认项，例如0-&gt;a，1-&gt;b，2-&gt;c。此时pW和cW都是空的。\n2. 读入第一个的符号cW，解码输出。注意第一个cW肯定是能直接解码的，而且一定是单个字符。\n3. 赋值pW=cW。\n4. 读入下一个符号cW。\n5. 在字典里查找cW，如果:\n   a. cW在字典里：\n     (1) 解码cW，即输出 Str(cW)。\n     (2) 令P=Str(pW)，C=Str(cW)的**第一个字符**。\n     (3) 在字典中为P+C添加新的记号映射。\n   b. cW不在字典里:\n     (1) 令P=Str(pW)，C=Str(pW)的**第一个字符**。\n     (2) 在字典中为P+C添加新的记号映射，这个新的记号一定就是cW。\n     (3) 输出P+C。\n6. 返回步骤3重复，直至读完所有记号。\n\n显然，最重要的是第5步，也是最难理解的。在这一步中解码器不断地在已经破译出来的数据上，模拟编码的过程，还原出字典。我们还是结合之前的例子来说明，我们需要从记号流\n0 1 3 2 3 7 2\n\n解码出：\na b ab c ab aba c\n\n这里我用空格表示出了记号是如何依次对应解码出来的子串的，当然在解码开始时我们根本不知道这些，我们手里的字典只有默认项，即：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSymbolString0a1b2c\n解码开始：\n首先读取第一个记号cW=0，解码为a，输出，赋值pW=cW=0。然后开始循环，依此读取后面的记号：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSteppWcWcW in Dict ？ActionOutput101YesP=a，C=b，P+C=ab，添加3→abb213YesP=b，C=a，P+C=ba，添加4→baab332YesP=ab，C=c，P+C=abc，添加5→abcc\n好，先解码到这里，我们已经解出了前5个字符 a b ab c。一步一步走下来我们可以看出解码的思想。首先直接解码最前面的a和b，然后生成了3→ab这一映射，也就是说解码器利用前面已经解出的字符，如实还原了编码过程中字典的生成。这也是为什么第一个a和b必须保留下来，而不能直接用3来编码，因为解码器一开始根本不知道3表示ab。而第二个以及以后的ab就可以用记号3破译出来，因为此时我们已经建立了3→ab的关系。\n仔细观察添加新映射的过程，就可以看出它是如何还原编码过程的。解码步骤5.a中，P=Str(pW)，C=Str(cW)的第一个字符，我们可以用下图来说明：\n\n注意P+C构成的方式，取前一个符号pW，加上当前最新符号cW的第一个字符。这正好对应了编码过程中遇到P+C不在字典中的情况：将P编码为pW输出，并更新P=C，P从单字符C开始重新增长。\n到目前为止，我们只用到了解码步骤5.a的情况，即每次新读入的cW都能在字典里找到，只有这样我们才能直接解码cW输出，并拿到cW的第一个字符C，与P组成P+C。但实际上还有一种可能就是5.b中的cW不在字典里。为什么cW会不在字典里？回到例子，我们此时已经解出了5个字符，继续往下走：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSteppWcWcW in Dict ？ActionOutput423YesP=c，C=a，P+C=ca，添加6→caab537NoP=ab，C=a，P+C=aba，添加7→abaaba672YesP=aba，C=c，P+C=abac，添加8→abacc\n好到此为止，后面的 ab aba c 也解码出来了，解码过程结束。这里最重要的就是Step-5，新读入一个cW为7，可7此时并不在字典里。当然我们事实上知道7最终应该对应aba，可是解码器应该如何反推出来？\n为什么解码进行到这一步7→aba还没有被编入字典？因为解码比编码有一步的延迟，实际上aba正是由当前的P=ab，和那个还未知的cw=7的第一个字符C组成的，所以cW映射的就是这个即将新加入的子串P+C，也因此cW的第一个字符就是pW的第一个字符a，cW就是aba。\n我们看到解码器在这里做了一个推理，既然cW到目前为止还没有被加入字典，可解码却偏偏遇到了，说明cW的映射并不是很早之前加入的，而是就在当前这一步。对应到编码的过程，就是新的cW映射，即7→aba刚被写进字典，紧接着后面的一个字串就用到了它。读者可以对照后半部分 ab aba c 编码的过程，对比解码过程反推，理解它的原理。这也是解码算法中最难的部分。\n总结\n好了，LZW的编码和解码过程到此就讲解完毕了。其实它的思想本身是简单的，就是将原始数据中的子串用记号表示，类似于编一部字典。编码过程中如何切割子串，建立映射的方式，其实并不是唯一的，但是LZW算法的严格之处在于，它提供了一种方式，使得压缩后的编码能够唯一地反推出编码过程中建立的字典，从而不必将字典本身写入压缩文件。试想，如果字典也需要写入压缩文件，那它占据的体积本身就会很大，可能到最后起不到压缩的效果。下一章我会讲解另一种压缩算法，算数编码。"},"code-learing/ts-ast-viewer/docs/about":{"title":"about","links":[],"tags":[],"content":"About\nTypeScript AST Viewer provides a way to view the TypeScript AST, symbols, types, and signatures.\nInteracting with Compiler Objects\nIf you open up the developer console it will provide some compiler objects that can be interacted with:\n\nAdditional Resources\n\nTypeScript Architectual Overview\nUsing the Compiler API\n"},"code-learing/ts-ast-viewer/readme":{"title":"readme","links":[],"tags":[],"content":"TypeScript AST Viewer\n\nSource code for ts-ast-viewer.com\nDeveloping\n# install and setup\nyarn setup\n\n# run locally\nyarn start\n\n# run unit tests\nyarn test\n\n# run cypress\nyarn cypress\n\nFactory Code Generation\nThe code that code generates the factory code is automatically maintained by ts-factory-code-generator-generator."},"code-learing/ts-ast-viewer/shared/README":{"title":"README","links":[],"tags":[],"content":"shared\nCode shared between the e2e tests and the web application."},"computer/User-space-与-Kernel-space":{"title":"User space 与 Kernel space","links":[],"tags":[],"content":"简单说，Kernel space 是 Linux 内核的运行空间，User space 是用户程序的运行空间。为了安全，它们是隔离的，即使用户的程序崩溃了，内核也不受影响。\n\n在一个32位系统中，一个程序的虚拟空间最大可以是4GB，那么最直接的做法就是，把内核也看作是一个程序，使它和其他程序一样也具有4GB空间。但是这种做法会使系统不断的切换用户程序的页表和内核页表，以致影响计算机的效率。解决这个问题的最好做法就是把4GB空间分成两个部分：一部分为用户空间，另一部分为内核空间，这样就可以保证内核空间固定不变，而当程序切换时，改变的仅是程序的页表。这种做法的唯一缺点便是内核空间和用户空间均变小了。\n例如：在i386这种32位的硬件平台上，Linux 在文件page.h中定义了一个常量PAGE_OFFSET：\n#ifdef CONFIG_MMU  \n#define __PAGE_OFFSET  (0xC0000000)        //0xC0000000为3GB  \n#else  \n#define __PAGE_OFFSET  (0x00000000)  \n#endif  \n#define PAGE_OFFSET\t\t((unsigned long)__PAGE_OFFSET)\nLinux以PAGE_OFFSET为界将4GB的虚拟内存空间分成了两部分：地址0GB-3GB这段低地址空间为用户空间，大小为3GB；地址3GB-4GB这段高地址空间为内核空间，大小为1GB。\nKernel space 可以执行任意命令，调用系统的一切资源；User space 只能执行简单的运算，不能直接调用系统资源，必须通过系统接口（又称 system call），才能向内核发出指令。\nstr = &quot;my string&quot; // 用户空间\nx = x + 2\nfile.write(str) // 切换到内核空间\n \ny = x + 4 // 切换回用户空间\n上面代码中，第一行和第二行都是简单的赋值运算，在 User space 执行。第三行需要写入文件，就要切换到 Kernel space，因为用户不能直接写文件，必须通过内核安排。第四行又是赋值运算，就切换回 User space。\n查看 CPU 时间在 User space 与 Kernel Space 之间的分配情况，可以使用top命令。它的第三行输出就是 CPU 时间分配统计。\n这一行有 8 项统计指标：\n\n%Cpu(s): 24.8 us, 0.5 sy, 0.0 ni, 73.6 id, 0.4 wa, 0.0 hi, 0.2 si, 0.0 st\n\n其中，第一项24.8 us（user 的缩写）就是 CPU 消耗在 User space 的时间百分比，第二项0.5 sy（system 的缩写）是消耗在 Kernel space 的时间百分比。\n\n\nni：niceness 的缩写，CPU 消耗在 nice 进程（低优先级）的时间百分比\nid：idle 的缩写，CPU 消耗在闲置进程的时间百分比，这个值越低，表示 CPU 越忙\nwa：wait 的缩写，CPU 等待外部 I/O 的时间百分比，这段时间 CPU 不能干其他事，但是也没有执行运算，这个值太高就说明外部设备有问题\nhi：hardware interrupt 的缩写，CPU 响应硬件中断请求的时间百分比\nsi：software interrupt 的缩写，CPU 响应软件中断请求的时间百分比\nst：stole time 的缩写，该项指标只对虚拟机有效，表示分配给当前虚拟机的 CPU 时间之中，被同一台物理机上的其他虚拟机偷走的时间百分比\n\n\n如果想查看单个程序的耗时，一般使用time命令：\n$ time ping bilibili.com\n \n正在 Ping bilibili.com [47.103.24.173] 具有 32 字节的数据:\n来自 47.103.24.173 的回复: 字节=32 时间=13ms TTL=88\n来自 47.103.24.173 的回复: 字节=32 时间=12ms TTL=88\n来自 47.103.24.173 的回复: 字节=32 时间=56ms TTL=88\n来自 47.103.24.173 的回复: 字节=32 时间=15ms TTL=88\n \n47.103.24.173 的 Ping 统计信息:\n    数据包: 已发送 = 4，已接收 = 4，丢失 = 0 (0% 丢失)，\n往返行程的估计时间(以毫秒为单位):\n    最短 = 12ms，最长 = 56ms，平均 = 24ms\n \nreal    0m3.122s\nuser    0m0.015s\nsys     0m0.000s\n程序名之前加上time命令，会在程序执行完毕以后，默认显示三行统计。\n\n\nreal：程序从开始运行到结束的全部时间，这是用户能感知到的时间，包括 CPU 切换去执行其他任务的时间。\nuser：程序在 User space 执行的时间\nsys：程序在 Kernel space 执行的时间\n\n\nuser和sys之和，一般情况下，应该小于real。但如果是多核 CPU，这两个指标反映的是所有 CPU 的总耗时，所以它们之和可能大于real。"},"data-structure/AVL/README":{"title":"AVL 树","links":[],"tags":[],"content":"基本概念\nAVL 是最早发明的自平衡二叉搜索树之一，名称来源于 G. M. Adelson-Velsky 和 E. M. Landis (两位来自苏联的科学家)；\n平衡因子：某节点的左右子树的高度差；\n而在 AVL 树中每个节点的平衡因子只能是 1，0，-1；\n即绝对值 ≤ 1，大于 1 则称之为失衡；也就是说每个节点的左右子树高度差不超过 1；搜索、添加、删除的时间复杂度是 O(logn)；\n添加的失衡\n当在二叉搜索树中添加一个元素时，最坏的情况可能会导致所有祖先都失衡，父节点其他的非祖先节点不会失衡；\n添加导致的失衡可以通过旋转节点进行调整高度，达到重新平衡，有四种情况：\nLL - 右旋转\n\n首先解释一下这个分类名称，LL 表示新添加的节点 n 是在由其导致失衡的最近的祖先节点即 g 节点的 left 的 left 处；而有右旋转是将这种失衡状态重新平衡的方法，即：\n\ng.left = p.right\np.right = g\n让 p 成为该子树的根节点\n维护 parent 以及更新节点高度\n\n经过旋转之后，仍然是一颗二叉搜索树：T0 &lt; n &lt; T1 &lt; p &lt; T2 &lt; g &lt; T3；\nRR - 左旋转\n\n\ng.right= p.left\np.left= g\n让 p 成为该子树的根节点；\n维护 parent 以及更新节点高度；\n\nLR - 左旋转，右旋转\n\n经过两次旋转：先将 p 节点左旋，即形成 LL 情况，再右旋 g 节点；\nRL - 右旋转，左旋转\n\n经过两次旋转：先将 p 节点右旋，即形成 RR 情况，再左旋 g 节点；\n失衡调整\n我们在BinarySearchTree内部添加一个空方法afterAdd，每次添加后调用该方法：\npublic void add(E element) {\n    if(root == null) {\n        size++;\n        afterAdd(root);\n        return;\n    }\n    //...\n    size++;\n    afterAdd(newNode);\n}\n然后让AVL继承BinarySearchTree，重写afterAdd方法，即可完成失衡调整逻辑；\n失衡调整逻辑如下：\n\n沿着添加的节点的parent属性，往上找；\n找到最近的失衡节点，进行旋转调整；\n\n那么如何判断一个节点是否失衡呢，当然是检测其平衡因子了，即需要一个方法返回检测结果：\nprivate static class AVLNode&lt;E&gt; extends Node&lt;E&gt; {\n    int height = 1;\n    public AVLNode(E element, Node&lt;E&gt; parent) {\n        super(element, parent);\n    }\n    public int balanceFactor() {\n        int leftHeight = left == null ? 0 : ((AVLNode&lt;E&gt;)left).height;\n        int rightHeight = right == null ? 0 : ((AVLNode&lt;E&gt;)right).height;\n        return leftHeight - rightHeight;\n    }\n}\n \nprivate boolean isBanlance(Node&lt;E&gt; node) {\n    return Math.abs(((AVLNode&lt;E&gt;)node).balanceFactor()) &lt;= 1; \n}\n因此，在 AVL 树中也定义了一个 AVL 节点类继承自二叉树的节点类，还需要修改搜索二叉树中创建逻辑（创建的是默认的节点）：\n// BinaryTree.java\nprotected Node&lt;E&gt; createNode(E element, Node&lt;E&gt; parent){\n    return new Node&lt;E&gt;(element, parent); \n}\n// BinarySearchTree.java\npublic void add(E element) {\n    // root = new Node&lt;E&gt;(element, null); \n    root = createNode(element, null); \n}\n// AVLTree.java\n@Override\nprotected Node&lt;E&gt; createNode(E element, Node&lt;E&gt; parent) {\n    return new AVLNode&lt;&gt;(element, parent);\n}\n更新高度\n每次添加的新节点，高度是 1，即在AVLNode中的初始值为 1；之后沿着parent属性往上遍历，主要情况有三种：\n\n祖先节点的高度平衡的，那么更新高度；\n祖先节点的高度不平衡，即调整失衡；\n遍历到祖先节点为 null，停止；\n\n由此，需要编写一个更新高度的私有方法：\nprivate void updateHeight(Node&lt;E&gt; node){\n    ((AVLNode&lt;E&gt;)node).updateHeight();\n}\nprivate static class AVLNode&lt;E&gt; extends Node&lt;E&gt; {\n\tpublic void updateHeight() {\n\t\tint leftHeight = left == null ? 0 : ((AVLNode&lt;E&gt;)left).height;\n\t\tint rightHeight = right == null ? 0 : ((AVLNode&lt;E&gt;)right).height;\n\t\theight = 1 + Math.max(leftHeight, rightHeight);\n\t}\n}\n恢复平衡\n当往上遍历时，检测到失衡节点，即需要进行调整，那么就需要对几种类型（RR，LL等）进行判断，那么还需要几个简单的方法：\n// BinaryTree.java\nprotected static class Node&lt;E&gt;{\n    public boolean isLeftChild() {\n        return parent != null &amp;&amp; this == parent.left;\n    }\n    public boolean isRightChild() {\n        return parent != null &amp;&amp; this == parent.right;\n    }\n}\n为了调整失衡节点 g ，我们还需要获取到构成结构的 p 节点和 n 节点，通过上述的结构图，不难观察到 p 是 g 的高度较大的子节点，同样 n 也如出一辙，即还需要一个获取高度更高的子节点的方法：\nprivate static class AVLNode&lt;E&gt; extends Node&lt;E&gt; {\n    public Node&lt;E&gt; tallerChild(){\n        int leftHeight = left == null ? 0 : ((AVLNode&lt;E&gt;)left).height;\n        int rightHeight = right == null ? 0 : ((AVLNode&lt;E&gt;)right).height;\n        if(leftHeight &gt; rightHeight) return left;\n        if(rightHeight &gt; leftHeight) return right;\n        return isLeftChild() ? left : right;\n    }\n}\n那么恢复平衡的方法也就很自然的写出来了：\n@Override\nprotected void afterAdd(Node&lt;E&gt; node) {\n    while((node = node.parent) != null) {\n        if(isBanlance(node)) {\n            updateHeight(node); // 更新高度\n        }else {\n            rebalance(node); // 恢复平衡\n            break;\n        }\n    }\n}\n旋转方向判断\n有了上述的基本判断方法和逻辑框架，那么就可以编写失衡调整的方法了，其中主要涉及的是结构的旋转方向的判断，根据节点之间的连线，也就是isLeftChild或isRightChild方法即可：\nprivate void rebalance(Node&lt;E&gt; grand) {\n    Node&lt;E&gt; parent = ((AVLNode&lt;E&gt;)grand).tallerChild();\n    Node&lt;E&gt; node = ((AVLNode&lt;E&gt;)parent).tallerChild();\n    if(parent.isLeftChild()) { // L\n        if(node.isLeftChild()) { // LL\n            rotateRight(grand);\n        }else { // LR\n            rotateLeft(parent);\n            rotateRight(grand);\n        }\n    }else {\t// R\n        if(node.isLeftChild()) { // RL\n            rotateRight(parent);\n            rotateLeft(grand);\n        }else { //RR\n            rotateLeft(grand);\n        }\n    }\n}\n左旋实现\nprivate void rotateLeft(Node&lt;E&gt; grand){\n    Node&lt;E&gt; parent = grand.right;\n    Node&lt;E&gt; child = parent.left;\n    // 旋转\n    grand.right = child;\n    parent.left = grand;\n    afterRotate(grand, parent, child);\n}\n右旋实现\nprivate void rotateRight(Node&lt;E&gt; grand){\n    Node&lt;E&gt; parent = grand.left;\n    Node&lt;E&gt; child = parent.right;\n    // 旋转\n    grand.left = child;\n    parent.right = grand;\n    afterRotate(grand, parent, child);\n}\n因为无论是左旋还是右旋，后序的维护 parent 和更新高度的代码都是一样的，所以抽离到了一个函数中：\nprivate void afterRotate(Node&lt;E&gt; grand,Node&lt;E&gt; parent,Node&lt;E&gt; child) {\n    // 维护 parent --&gt; grand.parent, parent 成为子树根节点 \n    parent.parent = grand.parent;\n    if(grand.isLeftChild()) {\n        grand.parent.left = parent;\n    }else if(grand.isRightChild()){\n        grand.parent.right = parent;\n    }else {\n        root = parent;\n    }\n    // 维护 grand --&gt; parent\n    grand.parent = parent;\n \n    // 维护 child --&gt; grand\n    if(child != null) {\n        child.parent = grand;\n    }\n    // 更新高度\n    updateHeight(grand);\n    updateHeight(parent);\n}\n统一旋转操作\n删除的失衡\n\n只可能会导致父节点或祖先节点失衡，其他节点都不可能失衡；\n删除节点进行一次失衡调整后，更高层的祖先节点也可能失衡，需要再次调整，往复……\n\n那么只需要将添加失衡调整代码中的一次调整后的break语句删除即可，其他的操作一致：\n@Override\nprotected void afterRemove(Node&lt;E&gt; node) {\n    while((node = node.parent) != null) {\n        if(isBanlance(node)) {\n            updateHeight(node); // 更新高度\n        }else {\n            rebalance(node); // 恢复平衡\n        }\n    }\n}\n总结\n添加节点\n\n可能会导致所有祖先节点都失衡\n只要让高度最低的失衡节点恢复平衡，整棵树就恢复平衡【仅需O(1)次调整】\n\n删除节点\n\n只可能会导致父节点或祖先节点失衡，让父节点恢复平衡后，可能会导致更高层的祖先节点失衡【最多需要O(logn)次调整】\n\n平均时间复杂度\n\n\n搜索：O(logn)\n\n\n添加：O(logn)，仅需O(1)次的旋转操作\n\n\n删除：O(logn)，最多需要 O(logn)次的旋转操作\n\n"},"data-structure/B-tree":{"title":"B-tree","links":[],"tags":[],"content":"基本概念\nB树（英语：B-tree）是一种自平衡多路搜索树，能够保持数据有序。这种资料结构能够让查找数据、顺序访问、插入数据及删除的动作，都在对数时间内完成；\n与自平衡二叉查找树不同，B树适用于读写相对大的数据块的存储系统，例如磁盘。B树减少定位记录时所经历的中间过程，从而加快存取速度。\nB树这种数据结构可以用来描述外部存储。这种资料结构常被应用在数据库和文件系统的实现上常用于文件系统和数据库的实现中；\n\n不同于二叉树，每个B树的节点都可以存储两个以上的元素，每个节点都可以至多有 m 个子节点，我们称 m 为树的阶（order）。\n性质\n假设一个节点存储的元素为 x：\n\n根节点：1 ≤ x ≤ m - 1\n非根节点：⌈m/2⌉ - 1 ≤ x ≤ m - 1\n节点具有子节点，那么子节点个数为 y = x + 1\n\n根节点：2 ≤ y ≤ m\n非根节点：⌈m/2⌉ ≤ y ≤ m\n\n\n\n例如，m = 3 时，所有节点都满足 2 ≤ y ≤ 3，常称为 (2, 3) 树，2-3树。\n\nB树和二叉搜索树，在逻辑上是等价的多代节点合并，可以获得一个超级节点\n\n2代合并的超级节点，最多拥有4个子节点(至少是4阶B树)\n3代合并的超级节点，最多拥有8个子节点(至少是8阶B树)\nn代合并的超级节点，最多拥有2”个子节点(至少是2阶B树)\n\nm 阶的 B 树，最多需要 log2m 代合并；\n搜索节点\n与二叉搜索树的搜索类似：\n\n先在节点内部从小到大开始搜索元素；\n如果命中，搜索结束；\n如果未命中，再去对应的子节点中搜索元素，重复步骤 1；\n\n添加节点\n\n新添加的元素必定是添加到叶子节点；\n针对m阶高度h的B树，首先在B树中是否存在，如果不存在，即在叶子结点处插入；\n\n若该节点元素个数小于 m - 1，直接插入；\n若该节点元素个数等于 m - 1，引起节点分裂上溢；以该节点中间元素为分界，取中间元素（偶数个数，中间两个随机选取）插入到父节点中；\n重复上面动作，直到所有节点符合B树的规则；最坏的情况一直分裂到根节点，生成新的根节点，高度增加 1；\n\n\n\n分裂上溢\n在添加时，如果待添加节点元素个数为 m - 1，会引起该节点的上溢，因为 m 阶 B 树每个节点至多存储 m - 1 个元素：\n\n上溢节点的元素个数必然是 m 个；\n取上溢节点最中间元素的位置为 k，将 k 位置的元素向上与父节点合并；\n再将 [0, k - 1] 和 [K + 1, m - 1]位置的元素分割成 2 个子节点；\n\n分裂后的两个节点的元素个数，必然都不会低于最低限制（- 1）\n\n\n一次分裂完毕后，有可能导致父节点上溢，依旧同样的步骤进行；\n\n删除节点\n\n待删除的是叶子节点的话，直接删除即可；\n待删除的节点是非叶子节点：（非叶子节点的前驱或者后继元素，必定在叶子节点中）\n先找到前驱或者后继节点，覆盖掉待删除的元素的值；\n再把前驱或后继节点删除，真正的删除都是发生在叶子节点中的；\n\n下溢合并\n若删除后节点中元素数目小于 ⌈m/2⌉ -1，则需要看其相邻兄弟节点是否丰满（元素个数大于⌈m/2⌉ - 1）；\n\n如果丰满，则向父节点借一个元素，让其兄弟节点还一个元素来满足条件；\n如果相邻兄弟都刚脱贫，即借了之后其结点数目小于⌈m/2⌉ - 1\n则将父节点中的元素，与该节及其其相邻的兄弟节点进行“合并”成一个节点，以此来满足条件。\n合并后的节点元素个数为  ⌈m/2⌉ + ⌈m/2⌉ - 2，不超过 m - 1；\n该操作会导致父节点下溢，依然按照上述方法解决，下溢现象可能会一直往上传播；\n"},"data-structure/binary-search-tree/README":{"title":"搜索二叉树","links":[],"tags":["数据结构与算法"],"content":"思考\n如何在 n 个动态的整数中搜索某个整数？（检测其是否存在）\nⅠ. 考虑使用动态数组存放元素，从第 0 个位置开始遍历搜索，平均时间复杂度：O(n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n012345678933661828165295458671\nⅡ. 如果是一个有序的动态数组，使用二分搜索，最坏的时间复杂度：O(logn)；添加和删除的平均时间复杂度是O(n)；\n\n数据规模不断减半，时间复杂度一般为 O(logn)；\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n012345678915172028314657688594\n针对这个需求是否有更好的办法？\n使用二叉搜索树，添加、删除、搜索额最坏时间复杂度均可优化至：O(logn)；\n二叉搜索树\n二叉搜索树是二叉树的一种,是应用非常广泛的一种二叉树，英文简称为BST，又被称为二叉查找树、二叉排序；\n\n树任意一个节点的值都大于其左子树所有节点的值；\n任意一个节点的值都小于其右子树所有节点的值；\n它的左右子树也是一棵二叉搜索树；\n二叉搜索树存储的元素必须具有可比较性；\n\n接口设计\nint size()\t\t\t\t\t\t// 元素的数量\nboolean isEmpty()\t\t\t\t// 是否为空\nvoid clean() \t\t\t\t\t// 清空所有元素\nvoid add(E element) \t\t\t// 添加元素\nvoid remove (E element) \t\t// 删除元素\nboolean contains (E element)\t// 是否包含某元素\n通过接口可以看出，对于目前这个二叉树来说，元素是没有索引的概念的；\n结构设计\n首先，新建的二叉搜索树 BinarySearchTree 类，在其中需要有几个基础的属性：\n\nsize：保存节点的变量；\nroot：根节点的变量，二叉搜索树的操作都需要从根节点开始；\nelementNotNullCheck：检查节点元素是否为空的方法；\n\nprivate int size;\nprivate Node&lt;E&gt; root;\n \nprivate void elementNotNullCheck(E e) {\n    if(e == null) {\n        throw new IllegalArgumentException(&quot;element must not be null&quot;);\n    }\n}\n节点设计\n在 BinarySearchTree 类中，需要创建一个内部类进行节点的维护，内部包括左右节点和父节点，以及存储的元素，以及后序所需要的两个方法，在构造时只需传入元素值和父节点即可：\nprivate static class Node&lt;E&gt;{\n    E element;\n    Node&lt;E&gt; left;\n    Node&lt;E&gt; right;\n    Node&lt;E&gt; parent;\n \n    public Node(E e, Node&lt;E&gt; n) {\n        this.element = e;\n        this.parent = n;\n    }\n    public boolean isLeaf() {\n        return left == null &amp;&amp; right == null;\n    }\n \n    public boolean isTwoChildren() {\n        return left != null &amp;&amp; right != null;\n    }\n}\n比较逻辑\nComparable 接口\n所有传入二叉搜索树的元素都必须实现 Comparable 接口：\npublic interface Comparable&lt;E&gt; {\n    int compareTo(E e);\n}\n \npublic class BinarySearchTree&lt;E extends Comparable&gt; {\n    int compare(E e1, E e2) {\n        return e1.compareTo(e2);\n    }\n}\n但是传入的对象实现了 Comparable  接口后，其比较逻辑其实是被限制无法改变了，如需要针对同一个对象根据其他属性进行比较是无法实现的；\nComparator 接口\n要求在构造二叉搜索树时，必须传入一个 Comparator  比较器，\npublic interface Comparator&lt;E&gt; {\n    int compare(E e1, E e2);\n}\n \npublic class BinarySearchTree&lt;E&gt; {\n    private Comparator&lt;E&gt; comparator;\n \n    public BinarySearchTree3(Comparator&lt;E&gt; comparator){\n        this.comparator = comparator;\n    }\n   int compare(E e1,E e2) {\n\t\treturn comparator.compare(e1, e2);\n\t}\n}\n通过比较器虽然可以自定义比较逻辑，但是这样未免过于激进，不应该强制传入比较器，而应有其默认的比较逻辑；综上，结合二者的方法即是比较合理的实现：\npublic class BinarySearchTree&lt;E&gt; {\n    private Comparator&lt;E&gt; comparator;\n \n    public BinarySearchTree(){\n        this(null);\n    }\n \n    public BinarySearchTree(Comparator&lt;E&gt; comparator){\n        this.comparator = comparator;\n    }\n    private int compare(E e1, E e2) {\n        if(comparator != null) {\n            return comparator.compare(e1, e2);\n        }\n        return ((Comparable&lt;E&gt;) e1).compareTo(e2);\n    }\n}\n需要注意的是，上述代码中没有要求传入的元素必须实现 Comparable 接口，因为 BinarySearchTree 类默认当作元素已经实现了该接口；\n添加逻辑\n基本思路：\n\n先判断是否存在根节点，无则赋值为根节点；\n根据根节点，通过与插入元素比较，找到对应的父节点；\n创建新节点，通过 parent.left = node 或者 parent.right = node\n相同的值，如何处理？\n\n直接返回；\n覆盖原有的值（推荐）；\n\n\n\nvoid add(E element) {\n    elementNotNullCheck(element);\t// 检查 null\n    if(root == null) {\t// 判断是为空二叉树\n        root = new Node&lt;E&gt;(element, null); \n        return;\n    }\n \n    Node&lt;E&gt; node = root;\t// 寻找临时节点\n    Node&lt;E&gt; parent = root;\t// 父节点\n    int cmp = 0;\t\t\t// 比较结果\n \n    while(node != null) {\t// 判断条件：直到找到元素位置为 null 时\n        parent = node;\t\t// 保存父节点，在构造节点插入时需要\n        cmp = compare(element, node.element);\n        if(cmp &gt; 0) {\n            node = node.right;\n        }else if(cmp &lt; 0) {\n            node = node.left;\n        }else {\n            node.element = element;\n            return;\t\t// 相等\n        }\n    }\n    Node&lt;E&gt; newNode = new Node&lt;&gt;(element, parent);\n    if(cmp &gt; 0) {\t// 判断插入左支还是右支\n        parent.right = newNode;\n    }else {\n        parent.left = newNode;\n    }\n    size++;\n}\n遍历逻辑\n根据节点的访问顺序的不同，可分为四种：\n\n前序遍历 (Preorder Traversal)：根节点，前序左子树，再前序右子树；\n中序遍历 (Inorder Traversal)：中序左子树，根节点，中序右子树，可选为升序或降序；\n后序遍历 (Postorder Traversal)：后序左子树，后序右子树，根节点；\n层序遍历 (Level Order Traversal)：从上往下，从左往右，以此访问每一个节点；\n\n前序遍历\n递归方法：\nprivate void preorderTraversal(Node&lt;E&gt; node) {\n    if(node == null) return;\n    System.out.println(node.element);\n    preorderTraversal(node.left);\n    preorderTraversal(node.right);\n}\n中序遍历\n递归方法：\nprivate void inorderTraversal(Node&lt;E&gt; node) {\n    if(node == null) return;\n    inorderTraversal(node.left);\n    System.out.println(node.element);\n    inorderTraversal(node.right);\n}\n后序遍历\n递归方法：\nprivate void postorderTraversal(Node&lt;E&gt; node) {\n    if(node == null) return;\n    postorderTraversal(node.left);\n    postorderTraversal(node.right);\n    System.out.println(node.element);\n}\n层序遍历\n实现思路：使用队列\n\n将根节点入队\n循环执行以下操作，直到队列为空\n\n将队头节点出队，进行访问\n将头节点的左子节点入队；\n将头节点的右子节点入队；\n\n\n\npublic void levelOrderTraversal() {\n    if(root == null) return;\n \n    Queue&lt;Node&lt;E&gt;&gt; queue = new LinkedList&lt;&gt;();\n \n    queue.offer(root);\n \n    while(!queue.isEmpty()) {\n        Node&lt;E&gt; node = queue.poll();\n        System.out.println(node.element);\n \n        if(node.left != null) {\n            queue.offer(node.left);\n        }\n \n        if(node.right != null) {\n            queue.offer(node.right);\n        }\n    }\n}\n遍历接口设计\n使用一个 Visitor 抽象类，将用户对二叉搜索树遍历时的访问逻辑包裹传入；为什么不使用接口呢，因为需要一个 flag 进行存储是否继续遍历：\npublic static abstract class Visitor&lt;E&gt; {\n    boolean stop;\n    abstract boolean visit(E element);\n}\n在层序遍历中，我们可以很简单地实现自定义遍历过程：\npublic void levelOrder(Visitor&lt;E&gt; visitor) {\n    if(root == null) return;\n    Queue&lt;Node&lt;E&gt;&gt; queue = new LinkedList&lt;&gt;();\n    queue.offer(root);\n    while(!queue.isEmpty()) {\n        Node&lt;E&gt; node = queue.poll();\n        boolean stop = visitor.visit(node.element);\n        // 在完成一个元素操作后，根据返回值判断是否继续\n        if(stop) return ;\n        if(node.left != null) {\n            queue.offer(node.left);\n        }\n        if(node.right != null) {\n            queue.offer(node.right);\n        }\n    }\n}\n而在其他几种遍历中，需要借助于抽象类存储的 flag，需要注意的是进行判断的位置：\nprivate void preorder(Node&lt;E&gt; node, Visitor&lt;E&gt; visitor) {\n    if(node == null || visitor.stop) return;\n \n    visitor.stop = visitor.visit(node.element);\n \n    preorder(node.left, visitor);\n    preorder(node.right, visitor);\n}\n \nprivate void postorder(Node&lt;E&gt; node, Visitor&lt;E&gt; visitor) {\n    if(node == null || visitor.stop) return;\n \n    preorder(node.left, visitor);\n    preorder(node.right, visitor);\n    \n    if(visitor.stop) return;\n    visitor.stop = visitor.visit(node.element);\n}\n \nprivate void inorder(Node&lt;E&gt; node, Visitor&lt;E&gt; visitor) {\n    if(node == null || visitor.stop) return;\n \n    preorder(node.left, visitor);\n    if(visitor.stop) return;\n    visitor.stop = visitor.visit(node.element);\n    preorder(node.right, visitor);\n}\n遍历的应用\n\n前序遍历：树状结构展示(注意左右子树的顺序)\n中序遍历：二叉搜索树的中序遍历按升序或者降序处理节点\n后序遍历：适用于一些先子后父的操作\n层序遍历：计算二叉树的高度；判断是否一个完全二叉树\n\n练习\n计算二叉树的层数\n递归方法：\n每一次函数调用，返回该节点左右子节点层数中最大值加一，递归停止条件为，传入的子节点为null 时，说明已经是叶子节点，层数返回 0；\nprivate int height(Node&lt;E&gt; node) {\n    if(node == null) return 0;\n    return 1 + Math.max(height(node.left),height(node.right));\n}\n迭代方法（层序遍历）：\n使用 height 存储层数， levelSize 存储每一层元素个数，初始值为 1，当出队一次减一，每次迭代节点入队时检测是否为零，为零则说明该层已经迭代完毕，可将下一层元素数量赋值给 levelSize，层数 height 加一，层序遍历完毕后，返回层数；\npublic int height() {\n\t\tif(root == null) return 0;\n \n\t\tQueue&lt;Node&lt;E&gt;&gt; queue = new LinkedList&lt;&gt;();\n\t\tint height = 0;\n\t\tqueue.offer(root);\n\t\tint levelSize = 1;\n \n\t\twhile(!queue.isEmpty()) {\n\t\t\tNode&lt;E&gt; node = queue.poll();\n\t\t\t\n\t\t\tlevelSize--;\n\t\t\t\n\t\t\tif(node.left != null) {\n\t\t\t\tqueue.offer(node.left);\n\t\t\t}\n\t\t\tif(node.right != null) {\n\t\t\t\tqueue.offer(node.right);\n\t\t\t}\n\t\t\tif(levelSize == 0) {\n\t\t\t\tlevelSize = queue.size();\n\t\t\t\theight++;\n\t\t\t}\n\t\t}\n\t\treturn height;\n\t}\n完全二叉树的判断\n根据完全二叉树的特点（从上到下，从左到右，依次排列），我们可以很自然地可以想到，利用层序遍历对其判断，遍历节点时，共有四种情况，分别是：\n\n\n树为空，返回 false\n\n\nnode.left != null &amp;&amp; node.right != null，将 node.left，node.right 按顺序入队\n\n\nnode.left == null &amp;&amp; node.right != null，返回 false\n\n\nnode.left != null &amp;&amp; node.right == null 或者 node.left == null &amp;&amp; node.right == null\n\n\n最后一种情况较为特殊，这种情况下，说明该节点是一个分水岭节点，之前的节点都是度为 2 的节点，之后的节点都必须是度为 1，即叶子节点，才满足完全二叉树的条件；\n此时需要设置一个 flag 对之后遍历的节点进行判断，是否为叶子节点；\npublic boolean isComplete() {\n    if(root == null) return false;\n    Queue&lt;Node&lt;E&gt;&gt; queue = new LinkedList&lt;&gt;();\n    boolean leaf = false;\n    queue.offer(root);\n \n    while(!queue.isEmpty()) {\n        Node&lt;E&gt; node = queue.poll();\n \n        if(leaf &amp;&amp; !node.isLeaf()) return false;\n \n        if(node.left != null &amp;&amp; node.right != null) {\n            queue.offer(node.left);\n            queue.offer(node.right);\n        }else if(node.left == null &amp;&amp; node.right != null) {\n            return false;\n        }else {\n            leaf = true;\n            if(node.left != null) {\n                queue.offer(node.left);\n            }\n        }\n    }\n    return true;\n}\n这样其实是偏离了层序遍历的内在逻辑的，可以重构一下，减少代码量和重复判断 ：\n\n如果树为空，返回 false ；\n如果 node.left != null，将 node.left 入队\n如果 node.left == null &amp;&amp; node.right!=null，返回 false\n如果 node.right != null，将 node.right 入队\n如果 node.right == null，分界点，设置 flag\n\nif(node.left != null) {\n    queue.offer(node.left);\n}else if (node.right != null){\n    return false;\n}\n \nif(node.right != null) {\n    queue.offer(node.right);\n}else {\t// node.right == null\n    leaf = true;\n}\n二叉树的翻转\n问题核心在于，二叉树的遍历，只要在二叉树的每一个节点上，对左右子树进行交换即可：\nTreeNode temp = node.left;\nnode.left = node.right;\nnode.right = temp;\n而对于中序遍历来说，交换当前节点发生于左右子树递归之间，左右子树的引用已发生更换，两次需要递归同一个变量；\n其他概念\n前驱节点\n中序遍历中的前一个节点；\n如果是二叉搜索树，前驱节点则是前一个比它小的节点，而且是左子树中的最大节点；\n通过观察，可发现，针对任意的二叉树， 任意节点的前驱节点可分为四种情况：\n\n左子节点不为空，前驱节点为其左子树的最右侧的节点；\n左子节点为空且父节点不为空，前驱节点为其父节点上溯到父节点的右子树位置，即该父节点；\n在第二种情况基础上，上溯父节点直到为空，则无前驱节点；\n左子节点为空，且父节点也为空，无前驱节点；\n\nprivate Node&lt;E&gt; predecessor(Node&lt;E&gt; node){\n    if(node == null) return null;\n    Node&lt;E&gt; p = node.left;\n    if(p != null) {\n        while(p.right != null) {\n            p = p.right;\n        }\n        return p;\n    }\n    while(node.parent != null &amp;&amp; node == node.parent.left) {\n        node = node.parent;\n    }\n    return node.parent;\n}\n后继节点\n后继节点：中序遍历时的后一个节点；\n如果是二叉搜索树，后继节点就是后一个比它大的节点，且是右子树中最小的节点；\n其中，后继节点于前驱节点基本相反，实现类似，只需更改方向：\nprivate Node&lt;E&gt; successor(Node&lt;E&gt; node){\n    if(node == null) return null;\n    Node&lt;E&gt; p = node.right;\n    if(p != null) {\n        while(p.left != null) {\n            p = p.left;\n        }\n        return p;\n    }\n    while(node.parent != null &amp;&amp; node == node.parent.right) {\n        node = node.parent;\n    }\n    return node.parent;\n}\n删除逻辑\n度为 0 节点\n叶子节点，直接删除；具体直接将父节点的左/右子节点设置为 null ；\n度为 1 节点\n用子节点替代待删除节点的位置：具体操作将待删除节点的父节点的左/右子节点直线待删除节点的左/右子节点；\n如果待删除节点是根节点，即直接将 root 变量指向根节点的左/右子节点；\n度为 2 节点\n常见的做法是，使用待删除节点和前驱节点或后继节点，覆盖待删除的结点，再删除相应的前驱/后继节点；\n因为若一个节点的度为 2，那么它的前驱或者后继节点的度只能是 0 或 1；原因在于，前驱和后继节点的查找特点；\n具体实现\nprivate void remove(Node&lt;E&gt; node) {\n    if(node == null) return ;\n    if(node.isTwoChildren()) {\t// 度为 2 的节点\n        Node&lt;E&gt; s = successor(node);\n        node.element = s.element;\t// 覆盖值\n        node = s;\t// 把后继节点赋给待删除节点，做统一处理\n    }\n    Node&lt;E&gt; replace = node.left == null ? node.right : node.left;\n \n    if(replace != null) {\t// 度为 1\n        replace.parent = node.parent;\t// 统一处理\n        if(node.parent == null) {\t// 根节点\n            root = replace;\n        } else if(node == node.parent.left) {\n            node.parent.left = replace;\n        } else {\n            node.parent.right = replace;\n        }\n    } else if (node.parent == null){\t// 根节点\n        root = null;\n    } else {\t// 度为0，叶子节点\n        if(node == node.parent.left) {\n            node.parent.left = null;\n        }else {\n            node.parent.right = null;\n        }\n    }\n}\n其中包含一个查找元素的方法：\nprivate Node&lt;E&gt; node(E element){\n    Node&lt;E&gt; node = root;\n    while(node != null) {\n        int cmp = compare(element, node.element);\n        if(cmp == 0) return node;\n        if(cmp &gt; 0) {\n            node = node.right;\n        }else {\n            node = node.left;\n        }\n    }\n    return null;\n}\n复杂度分析\n查找、添加，删除的时间复杂度都是 O(h) = O(logn)，也就是跟树的高度有关；\n如果是，从小到大添加元素，，那么二叉搜索树会退化成链表，那么时间复杂度会变成 O(h) = O(n)；\n二者的性能会造成显著差距；此外，删除节点也会造成二叉树退化成链表；\n有什么方法可以防止二叉树退化成链表呢？\n平衡二叉树\n平衡：当节点数量固定时，左右子树的高度越接近，这棵二叉树就越平衡（高度越低）；\n理想平衡：即类似于完全二叉树和满二叉树，高度差是最小的；\n改进二叉树\n首先，节点的添加、删除顺序是无法限制的，可以认为是随机的；\n所以改进方案是：在节点的添加、删除操作之后，想办法让二叉搜索树恢复平衡(减小树的高度)；\n如果接着继续调整节点的位置，完全可以达到理想平衡，但是付出的代价可能会比较大口比如调整的次数会比较多，反而增加了时间复杂度；\n总结来说，比较合理的改进方案是：用尽量少的调整次数达到适度平衡即可\n一棵达到适度平衡的二叉搜索树，可以称之为：平衡二叉搜索树，简称为BBST。\n常见的平衡二叉树有：AVL 树（在 Windows 内核中广泛使用）、红黑树（C++ STL，Linux 的进程调度等）\n一般也称它们为：自平衡的二叉搜索树（Self-balance Binary Search Tree）。"},"data-structure/binary-tree":{"title":"二叉树","links":[],"tags":["数据结构与算法"],"content":"树介绍\n在计算机科学中，树（英语：tree）是一种抽象数据类型（ADT）或是实现这种抽象数据类型的数据结构，用来模拟具有树状结构性质的数据集合。\n它是由 n（n&gt;0）个有限节点组成一个具有层次关系的集合。它具有以下的特点：\n\n每个节点都只有有限个子节点或无子节点；\n没有父节点的节点称为根节点；\n每一个非根节点有且只有一个父节点；\n除了根节点外，每个子节点可以分为多个不相交的子树；\n树里面没有环路(cycle)\n\n树的分类\n\n无序树：树中任意节点的子节点之间没有顺序关系，称为无序树，也称为自由树。\n有序树：树中任意节点的子节点之间有顺序关系，为有序树：\n\n二叉树\n霍夫曼树\nB树\n\n\n\n一些术语概念\n\n结点：树上包含的一个数据元素；\n根节点：树的开端的节点；\n父节点：若一个节点含有子节点，则这个节点称为其子节点的父节点；\n子节点：一个节点含有的子树的根节点称为该节点的子节点；\n兄弟节点：具有相同父节点的节点互称为兄弟节点；\n\n\n\n节点的度：一个节点含有的子树的个数；\n树的度：一棵树中，所有节点中度最大的称为树的度；\n叶节点或终端节点：度  为零的节点；\n非终端节点或分支节点：度不为零的节点；\n\n\n\n节点的层次：从根开始定义起，根为第1层，根的子节点为第2层，以此类推；\n深度：对于任意节点n，其深度为从根到n的唯一路径的长度，根的深度为0；\n高度：对于任意节点n，其高度为从n到一叶子节点的最长路径长，所有叶子节点的高度为0；\n树的深度：所有节点深度中的最大值；\n树的高度：所有节点高度中的最大值；\n\n\n\n一棵树可以没有任何阶段，则成为空树；\n一棵树也可以只有一个节点，即根节点；\n\n左右子树只在二叉树中有意义，因为二叉树非左即右：\n\n左子树：以当前节点看，它的左子节点那一分支的子树，该子树以当前节点左子节点为根；\n右子树：以当前节点看，它的右子节点那一分支的子树，该子树以当前节点右子节点为根；\n\n二叉树\n二元树（英语：Binary tree）是每个节点最多只有两个分支（即不存在分支度大于2的节点）的树结构；\n\n每个节点的度最大为 2 （最多拥有两颗子树）；\n左子树和右子树是有顺序的，即是某节点只有一个子树也要区分左右子树；\n\n二叉树的性质\n\n\n非空二叉树的第 i 层，最多有 2^i-1^ 个节点 (i ≥ 1)；\n\n\n在高度为 h 的二叉树上最多有 2^h^ - 1 个节点 (h ≥ 1)；\n\n\n对于任何一棵非空二叉树，如果叶子节点个数为n0，度为 2 的节点个数为n2，则有：n0 = n2  + 1；\n设度为 1 的节点个数为 n1，那么二叉树的节点总数 n = n0 + n1 + n2，\n叉树的边数 T= n1 + 2 * n2 = n - 1 = n0 + n1 + n2 - 1\n\n\n真二叉树\n真二叉树的所有节点的度要么为 0，要么为 2；\n满二叉树\n满二叉树的所有节点的度要么为 0，要么为 2，且所有叶子节点都在同一层；\n\n\n在同样高度的二叉树中，满二叉树的叶子节点数量最多、总节点数量最多\n\n\n满二叉树一定是真二叉树，真二叉树不一定是满二叉树；\n\n\n假设满二叉树的高度为 h (h ≥ 1)，则有\n\n第 i 层的节点数量为 2^i-1^\n叶子节点数量为 2^h-1^\n总节点数量 n = 2^h^ - 1 = 2^0^ + 2^1^ + 2^2^ + … + 2^h-1^\n\n完全二叉树\n完全二叉树的叶子节点只会出现在最后 2 层，且最后一层的叶子节点都靠左对齐；\n也就是说，除最后一层外的其馀层都是满的，最后一层要么是满的，要么在右边缺少连续若干节点；\n\n完全二叉树从根节点到倒数第二层是一棵满二叉树；\n满二叉树一定是完全二叉树，完全二叉树不一定是满二叉树；\n\n完全二叉树的性质\n\n度为 1 的节点只有左子树；\n度为 1 的节点要么是 1 个，要么是 0 个；\n同样节点数量的二叉树，完全二叉树的高度最小；\n\n假设完全二叉树的高度为 h ( h &gt; 1 )，那么：\n\n\n至少有 2^h-1^ 个节点( 2^0^ + 2^1^ + 2^2^ + … + 2^h-2^ + 1 )\n\n\n最多有 2^h^ - 1 个节点(2^0^ + 2^1^ + 2^2^ + … + 2^h-1^，满二叉树)\n\n\n总节点数量为 n，\n\n2^h-1^  &lt; n &lt; 2^h^\nh - 1 &lt; log2n &lt; h\nh = floor(log2n) + 1\n\n\n\n\n一棵有 n 个节点的完全二叉树 (n&gt;0)，从上到下、从左到右对节点从 1 开始进行编号，对任意第 i 个节点：\n\n如果 i = 1，它是根节点；\n如果 i &gt; 1，它的父节点编号为 floor(i/2)；\n如果 2i ≤ n，它的左子节点编号为 2i；\n如果 2i &gt; n，它无左子节点；\n如果 2i + 1 ≤ n，它的右子节点编号为 2i + 1；\n如果 2i + 1 &gt; n，它无右子节点；\n\n\n若从 0 开始编号：\n\n如果 i = 0，它是根节点；\n如果 i &gt; 0，它的父节点编号为 floor((i - 1)/2)；\n如果 2i + 1 ≤ n - 1，它的左子节点编号为 2i + 1；\n如果 2i + 1  &gt; n - 1，它无左子节点；\n如果 2i + 2 ≤ n - 1，它的右子节点编号为 2i + 2；\n如果 2i + 2 &gt; n - 1，它无右子节点；\n\n测试题\n如果一棵完全二叉树有768个节点，求叶子节点的个数\n\n假设叶子节点个数为n0，度为1的节点个数为n1，度为2的节点个数为n2\n总结点个数n = n0 + n1 + n2，而且n0 = n2 +1\nn = 2 * n0 + n1 - 1\n完全二叉树的 n1 要么为 0，要么为1\n\nn1为1时， n = 2* n0， n 必然是偶数；叶子节点个数n0= n/2，非叶子节点个数 n1 +n2 = n/2\nn1为0时， n=2 * n0 - 1， n 必然是奇数；叶子节点个数n0 = (n + 1)/2，非叶子节点个数 n1 + n2 = (n - 1) /2\n\n"},"front-end/babel/toolchain/1":{"title":"1","links":[],"tags":[],"content":"带你玩转 babel 工具链（一）@babel/parser\n一、前言\n@babel/parser作为 babel 最核心的库，是我们学习 babel 最重要的一部分，对于后面插件的学习都很有帮助。本文将通过各种示例，帮大家理解 babel-loader 在 babel 工具链中的作用。\n二、基础示例\n首先我们先学习下如何使用@babel/parser，下面是一个简单用法：\nrequire(&quot;@babel/parser&quot;).parse(&quot;let a = 1&quot;, {\n  sourceType: &quot;module&quot;,\n});\n上面的代码执行后，就会返回 ast 节点，我们可以通过 AST explorer 这个站点查看 AST：\n{\n  &quot;type&quot;: &quot;File&quot;,\n  &quot;start&quot;: 0,\n  &quot;end&quot;: 10,\n  &quot;loc&quot;: {\n    &quot;start&quot;: {\n      &quot;line&quot;: 1,\n      &quot;column&quot;: 0,\n      &quot;index&quot;: 0\n    },\n    &quot;end&quot;: {\n      &quot;line&quot;: 1,\n      &quot;column&quot;: 10,\n      &quot;index&quot;: 10\n    }\n  },\n  &quot;errors&quot;: [],\n  &quot;program&quot;: {\n    &quot;type&quot;: &quot;Program&quot;,\n    &quot;start&quot;: 0,\n    &quot;end&quot;: 10,\n    &quot;loc&quot;: {\n      &quot;start&quot;: {\n        &quot;line&quot;: 1,\n        &quot;column&quot;: 0,\n        &quot;index&quot;: 0\n      },\n      &quot;end&quot;: {\n        &quot;line&quot;: 1,\n        &quot;column&quot;: 10,\n        &quot;index&quot;: 10\n      }\n    },\n    &quot;sourceType&quot;: &quot;module&quot;,\n    &quot;interpreter&quot;: null,\n    &quot;body&quot;: [\n      {\n        &quot;type&quot;: &quot;VariableDeclaration&quot;,\n        &quot;start&quot;: 0,\n        &quot;end&quot;: 10,\n        &quot;loc&quot;: {\n          &quot;start&quot;: {\n            &quot;line&quot;: 1,\n            &quot;column&quot;: 0,\n            &quot;index&quot;: 0\n          },\n          &quot;end&quot;: {\n            &quot;line&quot;: 1,\n            &quot;column&quot;: 10,\n            &quot;index&quot;: 10\n          }\n        },\n        &quot;declarations&quot;: [\n          {\n            &quot;type&quot;: &quot;VariableDeclarator&quot;,\n            &quot;start&quot;: 4,\n            &quot;end&quot;: 9,\n            &quot;loc&quot;: {\n              &quot;start&quot;: {\n                &quot;line&quot;: 1,\n                &quot;column&quot;: 4,\n                &quot;index&quot;: 4\n              },\n              &quot;end&quot;: {\n                &quot;line&quot;: 1,\n                &quot;column&quot;: 9,\n                &quot;index&quot;: 9\n              }\n            },\n            &quot;id&quot;: {\n              &quot;type&quot;: &quot;Identifier&quot;,\n              &quot;start&quot;: 4,\n              &quot;end&quot;: 5,\n              &quot;loc&quot;: {\n                &quot;start&quot;: {\n                  &quot;line&quot;: 1,\n                  &quot;column&quot;: 4,\n                  &quot;index&quot;: 4\n                },\n                &quot;end&quot;: {\n                  &quot;line&quot;: 1,\n                  &quot;column&quot;: 5,\n                  &quot;index&quot;: 5\n                },\n                &quot;identifierName&quot;: &quot;a&quot;\n              },\n              &quot;name&quot;: &quot;a&quot;\n            },\n            &quot;init&quot;: {\n              &quot;type&quot;: &quot;NumericLiteral&quot;,\n              &quot;start&quot;: 8,\n              &quot;end&quot;: 9,\n              &quot;loc&quot;: {\n                &quot;start&quot;: {\n                  &quot;line&quot;: 1,\n                  &quot;column&quot;: 8,\n                  &quot;index&quot;: 8\n                },\n                &quot;end&quot;: {\n                  &quot;line&quot;: 1,\n                  &quot;column&quot;: 9,\n                  &quot;index&quot;: 9\n                }\n              },\n              &quot;extra&quot;: {\n                &quot;rawValue&quot;: 1,\n                &quot;raw&quot;: &quot;1&quot;\n              },\n              &quot;value&quot;: 1\n            }\n          }\n        ],\n        &quot;kind&quot;: &quot;let&quot;\n      }\n    ],\n    &quot;directives&quot;: []\n  },\n  &quot;comments&quot;: []\n}\n三、选项配置\n那 parser 除了上面的sourceType还有哪些参数呢？\n下面我列出了所有的参数说明，方便大家理解：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n选项说明简介allowImportExportEverywhere默认情况下，导入和导出声明只能出现在程序的顶层。如果将此选项设置为 true，则可以在允许语句的任何位置使用它们允许任何地方写 importallowAwaitOutsideFunction默认情况下，仅允许在异步函数内部或在启用 topLevelAwait 插件时，在模块的顶级范围内使用 await，可以将该值设置为 true允许顶层 awaitallowReturnOutsideFunction默认情况下，函数外的 return 语句会引发错误。将此设置为 true，不会报错允许函数外面写 returnallowSuperOutsideMethod默认情况下，在类和方法之外不允许使用。将此设置为 true，不会报错允许其他地方写 superallowUndeclaredExports默认情况下，导出未在当前模块作用域中声明的标识符将引发错误。设置为 true 后将不会报错允许导出一个未声明的变量attachComment默认情况下，Babel 将注释附加到相邻的 AST 节点。如果此选项设置为 false，则不会附加注释。当输入代码有许多注释时，它可以提供高达 30%的性能改进@babel/eslint 解析器将为您设置它。不建议在 Babel transform 中使用 attachComment:false，因为这样做会删除输出代码中的所有注释是否保留注释createParenthesizedExpressions当此选项设置为 true 时，如果给表达式节点包了一层圆括号，会被保留，如果设置为 false，表达式的括号不会保留是否保留包裹表达式的圆括号errorRecovery默认情况下，Babel 在发现一些无效代码时总是抛出错误。当此选项设置为 true 时，它将存储解析错误并尝试继续解析无效的输入文件。生成的 AST 将具有一个 errors 属性，表示所有解析错误的数组。请注意，即使启用此选项，@babel/parser 也可能抛出不可恢复的错误是否出现错误后，不停止解析plugins包含要启用的插件的数组插件数组sourceType指示应在其中解析代码的模式。可以是“script”、“module”或“unambiguous”之一。默认为“script”。“unambiguous”将使@babel/parser 根据 ES6 导入或导出语句的存在尝试猜测。带有 ES6 导入和导出的文件被视为“module”，否则为“script”。解析代码模式，推荐 unambiguoussourceFilename将输出 AST 节点与其源文件名关联。从多个输入文件的 AST 生成代码和源映射时非常有用ast 节点携带当前解析的文件名称startColumn默认情况下，解析的代码被视为从第 1 行第 0 列开始。您可以提供一个列编号，以供选择。用于与其他源工具集成。可以选择从哪一列开始解析startLine默认情况下，解析的代码被视为从第 1 行第 0 列开始。您可以提供一个行号，以供选择。用于与其他源工具集成。可以选择从哪一行开始解析strictMode默认情况下，ECMAScript 代码仅在“use strict”时解析为 strict；指令存在，或者如果解析的文件是 ECMAScript 模块。将此选项设置为 true 以始终在严格模式下解析文件解析的文件都会加上 use strictranges向每个节点添加范围属性：[node.start，node.end]给 ast 节点添加 rangetokens将所有已解析的令牌添加到文件节点上的令牌属性为 File Ast 节点上的 tokens 属性，添加所有 token\n其中，大家注意一下plugins这个属性配置，babel 语法插件很多都通过这个字段实现。\n四、babel 是如何按需支持不同语法的？\n\n@babel/parser 内部实现了所有可配置的语法，例如 typescript、top-level-await，本文只讨论如何配置并支持各种语法。\n\n首先我们有如下代码, 我们写了一段typescript 代码，并用 parser 编译：\nconst parser = require(&quot;@babel/parser&quot;);\n \nconst ast = parser.parse(\n  `\n  const a: number = 1\n`,\n  {}\n);\nf;\nconsole.log(ast);\n但是结果并不是我们想要的那样，而是报了语法错误：\nSyntaxError: Missing initializer in const declaration.\n然后我们再加一个配置：\nconst parser = require(&#039;@babel/parser&#039;)\n \nconst ast = parser.parse(`\n  const a: number = 1\n`, {\n+  plugins: [&#039;typescript&#039;]\n})\n \nconsole.log(ast);\n发现可以正常打印结果了，其实@babel/parser在支持不同语法时，需要我们手动添加plugins来进行支持，但是我们开发项目并不会去添加各种语法插件，那 babel 是如何帮我们添加的呢？\n在node_modules/@babel目录，可以发现里面有一部分插件命名形如 plugin-syntax-xxx，我们简单看一下plugin-syntax-top-level-await 的实现：\nvar _helperPluginUtils = require(&quot;@babel/helper-plugin-utils&quot;);\n \nvar _default = (0, _helperPluginUtils.declare)(api =&gt; {\n  api.assertVersion(7);\n  return {\n    name: &quot;syntax-top-level-await&quot;,\n    manipulateOptions(opts, parserOpts) {\n      parserOpts.plugins.push(&quot;topLevelAwait&quot;);\n    }\n  };\n});\n \nexports.default = _default;\n源码实现非常简单，只是在 parser 选项添加了一个topLevelAwait，用于开启top-level-await。\n然后，我们再来安装下@babel/preset-typescript, 发现它竟然帮助我们安装了一个plugin-syntax-typescript插件：\nvar _default = exports.default = (0, _helperPluginUtils.declare)((api, opts) =&gt; {\n  api.assertVersion(7);\n  const {\n    disallowAmbiguousJSXLike,\n    dts\n  } = opts;\n  {\n    var {\n      isTSX\n    } = opts;\n  }\n  return {\n    name: &quot;syntax-typescript&quot;,\n    manipulateOptions(opts, parserOpts) {\n      {\n        const {\n          plugins\n        } = parserOpts;\n        removePlugin(plugins, &quot;flow&quot;);\n        removePlugin(plugins, &quot;jsx&quot;);\n        plugins.push(&quot;objectRestSpread&quot;, &quot;classProperties&quot;);\n        if (isTSX) {\n          plugins.push(&quot;jsx&quot;);\n        }\n      }\n      parserOpts.plugins.push([&quot;typescript&quot;, {\n        disallowAmbiguousJSXLike,\n        dts\n      }]);\n    }\n  };\n});\n源码一样非常简单，同时删除了 flow 和 jsx 语法支持。\n总结\n\n@babel/parser基于 acron 做了进一步扩展，实现了很多语法；\n@babel/parser提供了语法支持；\nplugin-syntax-xxx 语法插件增加了@babel/parser的plugins配置；\n"},"front-end/babel/toolchain/2":{"title":"2","links":[],"tags":[],"content":"带你玩转 babel 工具链（二）@babel/traverse\n一、前言\n本文将继续学习另一个babel非常核心的库@babel/traverse。 目前大多数的 babel 插件都是基于这个库，做了很多代码转换，所以本文将通过手写一个@babel/traverse来了解其原理。\n下面我们先看一个简单的示例，了解下如何使用。\n二、例子\nimport * as parser from &quot;@babel/parser&quot;;\nimport traverse from &quot;@babel/traverse&quot;;\n \nconst code = `function square(n) {\n  return n * n;\n}`;\n \nconst ast = parser.parse(code);\n \ntraverse(ast, {\n  enter(path) {\n    if (path.isIdentifier({ name: &quot;n&quot; })) {\n      path.node.name = &quot;x&quot;;\n    }\n  },\n});\n通过 parser 解析除了 ast，然后调用traverse对 ast 做了进一步的转换：\nlet n = 1;\n// 转换后\nlet x = 1;\n以上就是一个简单的例子，下面了解下 traverse 的写法。\n三、traverse 的写法\ntraverse 支持三种写法\n第一种：\ntraverse(ast, {\n  enter(path) {},\n  exit(path) {},\n});\n上面这种方式比较常用，那enter, exit在遍历 ast 节点的时候是如何执行的呢？可以看下伪代码：\nfunction traverse(path) {\n  // 递归子孙节点之前执行\n  enter(path);\n \n  traverse(child);\n \n  // 子孙节点遍历完后，回溯时执行\n  exit(path);\n}\n第二种\ntraverse(ast, {\n  FunctionDeclaration(path) {},\n  xxx(path) {},\n  // xxx\n});\n可以直接通过节点的类型操作 AST 节点。大概的实现如下\nfunction traverse(path) {\n  // 获取当前节点类型\n  const type = path.node.type;\n  // 传入的配置，并执行对应节点的回调\n  visitor[type](path);\n \n  traverse(child);\n}\n第三种\ntraverse(ast, {\n  &quot;FunctionDeclaration|VariableDeclaration&quot;(path) {},\n  xxx(path) {},\n  // xxx\n});\n这种写法比较特殊，用|分割不同的节点类型，可以同时命中多个，原理同上。\n四、path\n从上面的用法可以发现，有很多地方都会用到 path，那path上到底有哪些属性和方法呢？\npath 的属性\npath 中的属性并不是很多，但是都很关键，可以看到有如下属性：\npath {\n    // 属性：\n    node // 当前 AST 节点\n    parent // 父 AST 节点\n    parentPath // 父 AST 节点的 path\n    scope // 作用域\n    hub // 可以通过 path.hub.file 拿到最外层 File 对象， path.hub.getScope 拿到最外层作用域，path.hub.getCode 拿到源码字符串\n    container // 当前 AST 节点所在的父节点属性的属性值\n    key // 当前 AST 节点所在父节点属性的属性名或所在数组的下标\n    listKey // 当前 AST 节点所在父节点属性的属性值为数组时 listkey 为该属性名，否则为 undefined\n}\n我们常用的主要有node, parentPath, parent, 那scope、hub又是什么呢？\npath 的特殊属性：scope\n举个例子，有如下代码，声明了两个变量：\n// 变量v1\nlet v1 = 1;\nfunction fn() {\n  // 变量v2\n  let v2 = 2;\n  console.log(v2);\n}\n \nfn();\n如果我想要在遍历到v2的时候访问父作用域下的v1，就可以通过path.scope.parent.bindings.v1获取到：\ntraverse(ast2, {\n  Identifier(path) {\n    if (path.node.name === &quot;v2&quot;) {\n      console.log(path.scope)\n      console.log(path.scope.parent)\n    }\n  },\n});\n那么 scope 有哪些属性呢？\n\nscope.bindings 当前作用域内声明的所有变量\nscope.block 生成作用域的 block，例如FunctionDeclaration, Program等 AST 节点\nscope.path 生成作用域的节点对应的 path，例如FunctionDeclaration, Program等 AST 节点的path\nscope.references 所有 binding 的引用对应的 path，详见下文\nscope.dump() 打印作用域链的所有 binding 到控制台\nscope.parentBlock() 父级作用域的 block\ngetAllBindings() 从当前作用域到根作用域的所有 binding 的合并\ngetBinding(name) 查找某个 binding，从当前作用域一直查找到根作用域\ngetOwnBinding(name) 从当前作用域查找 binding\nparentHasBinding(name, noGlobals) 查找某个 binding，从父作用域查到根作用域，不包括当前作用域。可以通过 noGlobals 参数指定是否算上全局变量（比如 console，不需要声明就可用），默认是 false\nremoveBinding(name) 删除某个 binding\nhasBinding(name, noGlobals) 从当前作用域查找 binding，可以指定是否算上全局变量，默认是 false\nmoveBindingTo(name, scope) 把当前作用域中的某个 binding 移动到其他作用域\ngenerateUid(name) 生成作用域内唯一的名字，根据 name 添加下划线，比如 name 为 a，会尝试生成 _a，如果被占用就会生成 __a，直到生成没有被使用的名字。\n\n上面的方法和属性有很多，就不一个个说明了，我们能通过 scope 很方便的操作作用域中的某个变量。完全不需要我们手动去获取对应的 AST 了！\npath 的特殊属性：hub\nhub 上面挂载了很多方法，其实都是 file 对象上的方法，推荐大家直接通过path.hub.file直接使用：\nhub {\n  file: File,\n  getCode: () =&gt; file.code,\n  getScope: () =&gt; file.scope,\n  addHelper: file.addHelper.bind(this), // 为代码添加运行时的helper\n  buildError: file.buildCodeFrameError.bind(this)\n}\n其实 hub 的属性，主要依赖了 file 类的实例对象, 我们定位到 File 的源码位置 node_modules\\@babel\\core\\lib\\transformation\\file\\file.js：\nclass File {\n  constructor(options, { code, ast, inputMap }) {\n    this.hub = {\n      file: this,\n      getCode: () =&gt; this.code,\n      getScope: () =&gt; this.scope,\n      addHelper: this.addHelper.bind(this),\n      buildError: this.buildCodeFrameError.bind(this),\n    };\n    this.code = code;\n    this.ast = ast;\n    this.scope = this.path.scope;\n    // 省略..\n  }\n  set(key, val) {}\n \n  get(key) {}\n \n  has(key) {}\n \n  getModuleName() {}\n \n  addHelper(name) {}\n \n  // 省略..\n}\nFile 对象是@babel/core中声明的类，其中有几个重要的属性和方法\n\ncode：源代码\nast: ast 对象\nscope：根作用域\npath: path 对象\nset, get: 可以在 file 上设置和获取自定义的属性值。\ngetModuleName：获取模块的路径\naddHelper： 通过 AST 操作，注入运行时代码\n\n关于addHelper是干嘛的，后续文章将逐步展开，大家敬请期待。\npath 的方法\n\ninList() 判断节点是否在数组中，如果 container 为数组，也就是有 listkey 的时候，返回 true\nget(key) 获取某个属性的 path\nset(key, node) 设置某个属性的值\ngetSibling(key) 获取某个下标的兄弟节点\ngetNextSibling() 获取下一个兄弟节点\ngetPrevSibling() 获取上一个兄弟节点\ngetAllPrevSiblings() 获取之前的所有兄弟节点\ngetAllNextSiblings() 获取之后的所有兄弟节点\nfind(callback) 从当前节点到根节点来查找节点（包括当前节点），调用 callback（传入 path）来决定是否终止查找\nfindParent(callback) 从当前节点到根节点来查找节点（不包括当前节点），调用 callback（传入 path）来决定是否终止查找\nisXxx(opts) 判断当前节点是否是某个类型，可以传入属性和属性值进一步判断，比如 path.isIdentifier({name: ‘a’})\nassertXxx(opts) 同 isXxx，但是不返回布尔值，而是抛出异常\ninsertBefore(nodes) 在之前插入节点，可以是单个节点或者节点数组\ninsertAfter(nodes) 在之后插入节点，可以是单个节点或者节点数组\nreplaceWith(replacement) 用某个节点替换当前节点\nreplaceWithMultiple(nodes) 用多个节点替换当前节点\nreplaceWithSourceString(replacement) 解析源码成 AST，然后替换当前节点\nremove() 删除当前节点\ntraverse(visitor, state) 遍历当前节点的子节点，传入 visitor 和 state（state 是不同节点间传递数据的方式）\nskip() 跳过当前节点的子节点的遍历\nstop() 结束所有遍历\n\n具体用法，大家可以逐个尝试，就不一一展开了。\n五、实现@babel/traverse\n通过上面的学习，相信大家对@babel/traverse有个大概的认识，下面我们来一块手写@babel/traverse来加深对源码的理解。"},"front-end/css/basic-css-animation/README":{"title":"README","links":[],"tags":[],"content":"深入浅出 CSS 动画\n\n原文链接：深入浅出 CSS 动画 - iCSS前端趣闻\n\n动画介绍及语法\nCSS 动画用于实现元素从一个 CSS 样式配置转换到另一个 CSS 样式配置；\n动画包括两个部分：\n\n描述动画的样式规则；\n用于指定动画开始、结束以及中间点样式的关键帧；\n\n简单例子：\ndiv {\n    animation: change 3s;\n}\n \n@keyframes change {\n    0% {\n        color: #f00;\n    }\n    100% {\n        color: #000;\n    }\n}\n\n\nanimation: change 1s 部分就是动画的第一部分，用于描述动画的各个规则；\n\n\n@keyframes change {} 部分就是动画的第二部分，用于指定动画开始、结束以及中间点样式的关键帧；\n\n\n动画的语法详解\nanimation 的子属性有：\n\nanimation-name：指定由 @keyframes 描述的关键帧名称；\nanimation-duration：设置动画一个周期的时长；\nanimation-delay：设置延时，即从元素加载完成之后到动画序列开始执行的这段时间；\nanimation-direction：设置动画在每次运行完后是反向运行还是重新回到开始位置重复运行；\nanimation-iteration-count：设置动画重复次数， 可以指定 infinite 无限次重复动画；\nanimation-play-state：允许暂停和恢复动画；\nanimation-timing-function：设置动画速度， 即通过建立加速度曲线，设置动画在关键帧之间是如何变化；\nanimation-fill-mode：指定动画执行前后如何为目标元素应用样式；\n@keyframes 规则，当然，一个动画想要运行，还应该包括 @keyframes 规则，在内部设定动画关键帧；\n\n其中，对于一个动画，必须项：animation-name、animation-duration 和 @keyframes规则，其余都有默认值。\nname / duration 详解\n\nanimation-name 命名和 CSS 规则命名一样，如支持 emoji 表情；\n\ndelay 详解\n\n设置动画延时，即从元素加载完成之后到动画序列开始执行的这段时间；\n延时可为负值，这样可以让动画提前进行；\n\nduration 和 delay 构建随机效果\n利用一定范围内随机的 animation-duration 和一定范围内随机的 animation-delay，可以有效的构建更为随机的动画效果，让动画更加的自然；\n@for $i from 1 to 11 {\n    li:nth-child(#{$i}) {\n        animation-duration: #{random(2000)/1000 + 2}s;\n        animation-delay: #{random(1000)/1000 + 1}s;\n    }\n}\n\nHuaWei Battery Charging Animation (codepen.io)\n\ntiming-function 缓动函数\n\n定义CSS动画在每一动画周期中执行的节奏；\n\ncubic-bezier-timing-function\nstep-timing-function\n\n\ncubic-bezier()连续动画：linear、ease、ease-in、ease-out、ease-in-out；\nsteps()功能符可以让动画不连续：step-start、step-end；\nsteps()更像是楼梯坡道，cubic-bezier()更像是无障碍坡道；\n\nplay-state 详解\n控制动画的状态——运行或者暂停：\n{\n    animation-play-state: paused | running;\n}\nfill-mode 详解\n控制元素在各个阶段的状态：\n\nnone：默认值，当动画未执行状态，动画将不会将任何样式应用于目标，而是使用赋予给该元素的 CSS 规则来显示该元素的状态；\nbackwards：动画将在应用于目标时立即应用第一个关键帧中定义的值，并在 animation-delay 期间保留此值；\nforwards：目标将保留由执行期间遇到的最后一个关键帧计算值。 最后一个关键帧取决于 animation-direction 和 animation-iteration-count；\nboth：动画将遵循 forwards 和 backwards 的规则，从而在两个方向上扩展动画属性；\n\niteration-count /direction 详解\n\nanimation-iteration-count 控制动画运行的次数，可以是数字或者 infinite，注意，数字可以是小数；\nanimation-direction 控制动画的方向，正向、反向、正向交替与反向交替；\n\n动画运行的第一帧和最后一帧的实际状态会受到动画运行方向 animation-direction 和 animation-iteration-count 的影响：\n\n\n动画运行的第一帧由 animation-direction 决定\n\n\n动画运行的最后一帧由 animation-iteration-count 和 animation-direction 决定；\n\n\n动画的分治与复用\nanimation 是可以接收多个动画的，这样做的目的不仅仅只是为了复用，同时也是为了分治，我们对每一个属性层面的动画能够有着更为精确的控制：\ndiv {\n    width: 100px;\n    height: 100px;\n    background: #000;\n    animation: combine 2s;\n}\n/* 下落的同时产生透明度的变化 */\n@keyframes combine {\n    100% {\n        transform: translate(0, 150px);\n        opacity: 0;\n    }\n}\n动画状态的高优先级性\n在 CSS 中，优先级还需要考虑选择器的层叠（级联）顺序。只有在层叠顺序相等时，使用哪个值才取决于样式的优先级；\n根据 CSS Cascading 4 最新标准：\nCSS Cascading and Inheritance Level 5(Current Work)\n定义的当前规范下申明的层叠顺序优先级如下（越往下的优先级越高，下面的规则按升序排列）：\n\nNormal user agent declarations\nNormal user declarations\nNormal author declarations\nAnimation declarations\nImportant author declarations\nImportant user declarations\nImportant user agent declarations\nTransition declarations\n\n按照上述算法，大概是这样：\n过渡动画过程中每一帧的样式 &gt; 用户代理、用户、页面作者设置的!important样式 &gt; 动画过程中每一帧的样式优先级 &gt; 页面作者、用户、用户代理普通样式；\n举个例子，我们可以通过这个特性，覆盖掉行内样式中的 !important 样式：\n&lt;p class=&quot;txt&quot; style=&quot;color:red!important&quot;&gt;123456789&lt;/p&gt;\n.txt {\n    animation: colorGreen 2s infinite;\n}\n@keyframes colorGreen {\n    0%,\n    100% {\n        color: green;\n    }\n}\n动画的优化\n1. 动画元素生成独立的 GraphicsLayer，强制开始 GPU 加速；\nWeb 动画很大一部分开销在于层的重绘，以层为基础的复合模型对渲染性能有着深远的影响。当不需要绘制时，复合操作的开销可以忽略不计，因此在试着调试渲染性能问题时，首要目标就是要避免层的重绘。那么这就给动画的性能优化提供了方向，减少元素的重绘与回流。\n这其中，如何减少页面的回流与重绘呢，这里就会运用到我们常说的 GPU 加速。\nGPU 加速的本质其实是减少浏览器渲染页面每一帧过程中的 reflow 和 repaint，其根本，就是让需要进行动画的元素，生成自己的 GraphicsLayer。\n在 Chrome 中，存在有不同类型的层： RenderLayer(负责 DOM 子树)，GraphicsLayer(负责 RenderLayer 的子树)。\nGraphicsLayer ，它对于我们的 Web 动画而言非常重要，通常，Chrome 会将一个层的内容在作为纹理上传到 GPU 前先绘制(paint)进一个位图中。如果内容不会改变，那么就没有必要重绘(repaint)层。\n而当元素生成了自己的 GraphicsLayer 之后，在动画过程中，Chrome 并不会始终重绘整个层，它会尝试智能地去重绘 DOM 中失效的部分，也就是发生动画的部分，在 Composite 之前，页面是处于一种分层状态，借助 GPU，浏览器仅仅在每一帧对生成了自己独立 GraphicsLayer 元素层进行重绘，如此，大大的降低了整个页面重排重绘的开销，提升了页面渲染的效率。\n生成自己的独立的 GraphicsLayer，不仅仅只有 transform3d api，还有非常多的方式。在 CSS 中，包括但不限于（找了很多文档，没有很全面的，需要一个一个去尝试，通过开启 Chrome 的 Layer border 选项）：\n\n3D 或透视变换(perspective、transform) CSS 属性\n使用加速视频解码的\n拥有 3D (WebGL) 上下文或加速的 2D 上下文的 元素\n混合插件(如 Flash)\n对自己的 opacity 做 CSS 动画或使用一个动画变换的元素\n拥有加速 CSS 过滤器的元素\n元素有一个包含复合层的后代节点(换句话说，就是一个元素拥有一个子元素，该子元素在自己的层里)\n元素有一个 z-index 较低且包含一个复合层的兄弟元素(换句话说就是该元素在复合层上面渲染)\n\n对于上述一大段非常绕的内容，你可以再看看这几篇文章：\n\n【Web动画】CSS3 3D 行星运转 &amp;&amp; 浏览器渲染原理\nAccelerated Rendering in Chrome\n\n2. 减少使用耗性能样式\n不同样式在消耗性能方面是不同的，改变一些属性的开销比改变其他属性要多，因此更可能使动画卡顿。\n\nbox-shadow 属性，从渲染角度来讲十分耗性能，原因是与其他样式相比，它们的绘制代码执行时间过长；\n类似的还有 CSS 3D 变换、mix-blend-mode、filter；\n需要针对每一起卡顿的例子，借助开发工具来分辨出性能瓶颈所在，然后设法减少浏览器的工作量；\n\n3. 使用 will-change 提高页面滚动、动画等渲染性能\nwill-change 为 Web 开发者提供了一种告知浏览器该元素会有哪些变化的方法，这样浏览器可以在元素属性真正发生变化之前提前做好对应的优化准备工作。 这种优化可以将一部分复杂的计算工作提前准备好，使页面的反应更为快速灵敏。\n\n不要将 will-change 应用到太多元素上；\n有节制地使用：最佳实践是当元素变化前后通过脚本来切换 will-change 的值。；\n不要过早应用 will-change 优化：不应该被用来预防性能问题；\n给它足够的工作时间：尝试找到一些方法提前获知元素可能发生的变化，然后为它加上 will-change 属性；\n"},"front-end/css/basic-css-cursor/cursor":{"title":"cursor","links":[],"tags":[],"content":"修改鼠标样式\n在 CSS 中，我们可以通过 cursor 样式，对鼠标指针形状进行修改\ncursor: auto;\ncursor: pointer;\n...\ncursor: zoom-out;\n \n/* 使用图片 */\ncursor: url(hand.cur)\n \n/* 使用图片，并且设置 fallback 兜底 */\ncursor: url(hand.cur), pointer;\n隐藏鼠标光标\n可通过 cursor: none 隐藏页面的鼠标指针：\nbody {\n    cursor: none;\n}\n\n首先实现一个 10px x 10px 的圆形 div，设置为基于 &lt;body&gt; 绝对定位：\n&lt;div id=&quot;g-pointer&quot;&gt;&lt;/div&gt;\n\n#g-pointer {\n    position: absolute;\n    top: 0;\n    left: 0;\n    width: 10px;\n    height: 10px;\n    background: #000;\n    border-radius: 50%;\n}\n\n那么，在页面上，我们就得到了一个圆形黑点，再通过事件监听，监听 body 上的 mousemove，将小圆形的位置与实时鼠标指针位置重合：\nconst body = document.querySelector(&quot;body&quot;);\nconst element = document.getElementById(&quot;g-pointer-1&quot;);\nconst element2 = document.getElementById(&quot;g-pointer-2&quot;);\n \n// offsetWidth 只读属性，返回一个元素的布局宽度\nconst halfAlementWidth = element.offsetWidth / 2;\nconst halfAlementWidth2 = element2.offsetWidth / 2;\n// 做一个相对的位移\nfunction setPosition(x, y) { \n    element.style.transform  = `translate(${x - halfAlementWidth}px, ${y - halfAlementWidth}px)`;       \n    element2.style.transform  = `translate(${x - halfAlementWidth2}px, ${y - halfAlementWidth2}px)`;\n}\n \nbody.addEventListener(&#039;mousemove&#039;, (e) =&gt; {\n  // 告诉浏览器——你希望执行一个动画，并且要求浏览器在下次重绘之前调用指定的回调函数更新动画。\n  // 该方法需要传入一个回调函数作为参数，该回调函数会在浏览器下一次重绘之前执行\n  window.requestAnimationFrame(function(){\n    setPosition(e.clientX, e.clientY);\n  });\n});\n之后可以借助混合模式 mix-blend-mode: exclusion，能够实现让模拟的鼠标指针能够智能地在不同背景色下改变自己的颜色；\n{\n    background: #999;\n    background-color: #fff;\n    mix-blend-mode: exclusion;\n    z-index: 1;\n}"},"front-end/css/basic-css-cursor/mouse":{"title":"mouse","links":[],"tags":[],"content":"纯 CSS 实现鼠标跟随\n如何实时监测到当前鼠标处于何处？\n要监测到当前鼠标处于何处，我们只需要在页面上铺满元素即可：\n我们使用 100 个元素，将整个页面铺满，hover 的时，展示颜色，核心 SCSS 代码如下：\n&lt;div class=&quot;g-container&quot;&gt;\n  &lt;div class=&quot;position&quot;&gt;&lt;/div&gt;\n  &lt;div class=&quot;position&quot;&gt;&lt;/div&gt;\n  &lt;div class=&quot;position&quot;&gt;&lt;/div&gt;\n  &lt;div class=&quot;position&quot;&gt;&lt;/div&gt;\n  ... // 100个\n&lt;/div&gt;\n.g-container {\n    position: relative;\n    width: 100vw;\n    height: 100vh;\n}\n \n.position {\n    position: absolute;\n    width: 10vw;\n    height: 10vh;\n}\n \n@for $i from 0 through 100 { \n    \n    $x: $i % 10;\n    $y: ($i - $x) / 10;\n    \n    .position:nth-child(#{$i + 1}) {\n        top: #{$y * 10}vh;\n        left: #{$x * 10}vw;\n    }\n \n    .position:nth-child(#{$i + 1}):hover {\n        background: rgba(255, 155, 10, .5)\n    }\n}\n可以得到一片跟随的鼠标的色块，当鼠标位于某个色块上时触发其 hover 效果；\n继续，我们再给页面添加一个元素（圆形小球），将它绝对定位到页面中间：\n&lt;div class=&quot;g-ball&quot;&gt;&lt;/div&gt;\n.ball {\n    position: absolute;\n    top: 50%;\n    left: 50%;\n    width: 10vmax;\n    height: 10vmax;\n    border-radius: 50%;\n    transform: translate(-50%, -50%);\n}\n最后，借助 ~ 兄弟元素选择器，在 hover 页面的时候（其实是 hover 一百个隐藏的 div），通过当前 hover 到的 div，去控制小球元素的位置：\n@for $i from 0 through 100{ \n    \n    $x: $i % 10;\n    $y: ($i - $x) / 10;\n    \n    .position:nth-child(#{$i + 1}):hover ~ .ball {\n        top: #{$y * 10}vh;\n        left: #{$x * 10}vw;\n    }\n}\n存在的问题\n就上面的 Demo 来看，还是有很多瑕疵的，譬如\n精度太差\n只能控制元素运动到 div 所在空间，而不是精确的鼠标所在位置，针对这一点，我们可以通过增加隐藏的 div 的数量来优化。譬如将 100 个平铺 div 增加到 1000 个平铺 div。\n运动不够丝滑\n效果看起来不够丝滑，这个可能需要通过合理的缓动函数，适当的动画延时来优化。\n鼠标跟随指示\n\n默认的铺满背景的 div 的 transition-duration: 0.5s\n当 hover 到元素背景 div 的时候，改变当前 hover 到的 div 的 transition-duration: 0s，并且 hover 的时候赋予背景色，这样当前 hover 到的 div 会立即展示\n当鼠标离开 div，div 的 transition-duration 变回默认状态，也就是 transition-duration: 0.5s，同时背景色消失，这样被离开的 div 的背景色将慢慢过渡到透明，造成虚影的效果\n\n.box {\n    position: relative;\n    float: left;\n    width: 30px;\n    height: 30px;\n    margin: 4px;\n    border: 1px solid red;\n    \n    &amp;::before {\n        content: &quot;&quot;;\n        position: absolute;\n        border-radius: 50%;  \n        transform: scale3d(0.1, 0.1, 1);\n        background-color: transparent;\n        transition: .5s transform ease-in,\n            .5s background ease-in;\n    }\n}\n \n.box:hover {\n    &amp;::before {\n        transform: scale3d(1.8, 1.8, 1.8);\n        transition: 0s transform;\n    }\n}\n "},"front-end/css/basic-css-filter/README":{"title":"README","links":[],"tags":[],"content":"基本用法\nCSS 属性 filter 将模糊或颜色偏移等图形效果应用于元素。滤镜通常用于调整图像、背景和边框的渲染；\n本文所描述的滤镜，指的是 CSS3 出来后的滤镜，不是 IE 系列时代的滤镜，语法如下：\n/* URL to SVG filter */\nfilter: url(&quot;filters.svg#filter-id&quot;);\n \n/* &lt;filter-function&gt; values */\nfilter: blur(5px);\nfilter: brightness(0.4);\nfilter: contrast(200%);\nfilter: drop-shadow(16px 16px 20px blue);\nfilter: grayscale(50%);\nfilter: hue-rotate(90deg);\nfilter: invert(75%);\nfilter: opacity(25%);\nfilter: saturate(30%);\nfilter: sepia(60%);\n \n/* Multiple filters */\nfilter: contrast(175%) brightness(3%);\n \n/* Use no filter */\nfilter: none;\n \n/* Global values */\nfilter: inherit;\nfilter: initial;\nfilter: revert;\nfilter: unset;\n \ncontrast/brightness — hover 增亮图片\n通常页面上的按钮，都会有 hover/active 的颜色变化，以增强与用户的交互。但是一些图片展示，则很少有 hover 的交互，运用 filter: contrast() 或者 filter: brightness() 可以在 hover 图片的时候，调整图片的对比图或者亮度，达到聚焦用户视野的目的。\n当然，这个方法同样适用于按钮，简单的 CSS 代码如下：\n.btn:hover,\n.img:hover {\n    transition: filter .3s;\n    filter: brightness(1.1) contrast(110%);\n}\nblur — 生成图像阴影\n通常而言，我们生成阴影的方式大多是 box-shadow 、filter: drop-shadow() 、text-shadow 。但是，使用它们生成阴影是阴影只能是单色的；\n通过巧妙的利用 filter: blur 模糊滤镜，我们可以假装生成渐变色或者说是颜色丰富的阴影效果：\n.avator {\n    position: relative;\n    background: url($img) no-repeat center center;\n    background-size: 100% 100%;\n    \n    &amp;::after {\n        content: &quot;&quot;;\n        position: absolute;\n        top: 10%;\n        width: 100%;\n        height: 100%;\n        background: inherit;\n        background-size: 100% 100%;\n        filter: blur(10px) brightness(80%) opacity(.8);\n        z-index: -1;\n    }\n}\n简单的原理就是，利用伪元素，生成一个与原图一样大小的新图叠加在原图之下，然后利用滤镜模糊 filter: blur() 配合其他的亮度/对比度，透明度等滤镜，制作出一个虚幻的影子，伪装成原图的阴影效果。\n嗯，最重要的就是这一句 filter: blur(10px) brightness(80%) opacity(.8);\nblur 混合 contrast 产生融合效果\n模糊滤镜叠加对比度滤镜产生的融合效果。让你知道什么是 CSS 黑科技：\n单独将两个滤镜拿出来，它们的作用分别是：\n\nfilter: blur()： 给图像设置高斯模糊效果；\nfilter: contrast()： 调整图像的对比度；\n\n但是，当他们“合体”的时候，产生了奇妙的融合现象：\n两圆相交时，在边与边接触的时候，会产生一种边界融合的效果，通过对比度滤镜把高斯模糊的模糊边缘给干掉，利用高斯模糊实现融合效果；\n上述效果的实现基于两点：\n\n图形是在被设置了 filter: contrast() 的画布背景上进行动画的\n进行动画的图形被设置了 filter: blur()（ 进行动画的图形的父元素需要是被设置了 filter: contrast() 的画布）\n\n意思是，两圆相融的背后，其实是叠加了一张设置了 filter: contrast() 的大白色背景，而两个圆形则被设置了 filter: blur() ，两个条件缺一不可。\n文字融合动画\n可以在动画的过程中，动态改变元素滤镜的 filter: blur() 的值。\n利用这个方法，还可以设计一些文字融合的效果：\nh2 {\n    color: grey;\n    font-size: 4rem;\n    text-transform: uppercase;\n    line-height: 1;\n    animation: letterspacing 5s infinite alternate ease-in-out;\n    display: block;\n    letter-spacing: -2.2rem;\n}\n \n@keyframes letterspacing {\n    0% {\n        letter-spacing: -2.2rem;\n        filter: blur(.3rem);\n    }\n \n    50% {\n        filter: blur(.5rem);\n    }\n \n    100% {\n        letter-spacing: .5rem;\n        filter: blur(0rem);\n        color: grey;\n    }\n}\n主要是通过动画同时改变文字的间距和模糊度；\n总结\n\n\nCSS 滤镜可以给同个元素同时定义多个，例如 filter: contrast(150%) brightness(1.5) ，但是滤镜的先后顺序不同产生的效果也是不一样的；\n\n也就是说，使用 filter: contrast(150%) brightness(1.5) 和 filter: brightness(1.5) contrast(150%) 处理同一张图片，得到的效果是不一样的，原因在于滤镜的色值处理算法对图片处理的先后顺序。\n\n\n\n滤镜动画需要大量的计算，不断的重绘页面，属于非常消耗性能的动画，使用时要注意使用场景。记得开启硬件加速及合理使用分层技术；\n\n\nblur() 混合 contrast() 滤镜效果，设置不同的颜色会产生不同的效果，这个颜色叠加的具体算法本文作者暂时也不是很清楚，使用时比较好的方法是多尝试不同颜色，观察取最好的效果；\n\n\nSS3 filter 兼容性不算太好，但是在移动端已经可以比较正常的使用，更为精确的兼容性列表，查询 Can i Use。\n\n"},"front-end/css/basic-css-gradient/basci-gradient":{"title":"basci-gradient","links":[],"tags":[],"content":"linear-gradient 线性渐变\n线性渐变由一个轴 (梯度线) 定义，其上的每个点具有两种或多种的颜色，且轴上的每个点都具有独立的颜色。\n渐变线由包含渐变图形的容器的中心点和一个角度来定义的，默认 0 度为竖轴，顺时针旋转；\n渐变线上的颜色值是由不同的点来定义，包括起始点，终点，以及两者之间的可选的中间点（中间点可以有多个）；\n默认情况下，从一个颜色的终止点平滑的过渡到另一个颜色的终止点，颜色之间的中点是两个颜色颜色转换的中点；\n可以将中点移动到这两个颜色之间的任意位置，方法是在两个颜色之间未添加颜色标记的 %，以指示颜色的中转位置；\n颜色终止列表中颜色的终止点应该是依次递增的。如果后面的颜色终止点小于前面颜色的终止点，则后面的会被覆盖，从而创建一个硬转换。\n允许多个包含颜色终止位置。通过在 CSS 声明中包含两个位置，可以将一个颜色声明为两个相邻的颜色终止。\n.demo {\n    /* 渐变轴为45度，从蓝色渐变到红色 */\n    background: linear-gradient(45deg, blue, red);\n}\n.demo {\n    /* 从右下到左上、从蓝色渐变到红色 */\n    background: linear-gradient(to left top, blue, red);\n  }\n.demo{\n    background: repeating-linear-gradient(45deg, blue, red);\n}\nradial-gradient 径向渐变\n径向渐变 (Radial gradients) 由其中心点、边缘形状轮廓、*两个或多个色值结束点（color stops）*定义而成。\n在不指定渐变类型以及位置的情况下，其渐变距离和位置是由容器的尺寸决定的；若指定渐变的形状是一个圆形，形状不受外部容器尺寸影响，可以使用circle关键字；\n当渐变的 &lt;ending-shape&gt; 被指定为circle时，可以为其指定渐变范围的大小（即渐变圆形的半径）：\n.demo {\n    background: radial-gradient(50px circle, yellow, red);\n}\n如果没有指定circle关键字，那么渐变的范围可有四个关键字指定：\n\nclosest-side    渐变中心距离容器最近的边作为终止位置；\nclosest-corner：渐变中心距离容器最近的角作为终止位置；\nfarthest-side ：渐变中心距离容器最远的边作为终止位置；\nfarthest-corner： 渐变中心距离容器最远的角作为终止位置；\n\n起始点位置可以通过at来指定，例如：\n.demo{\n    background: radial-gradient(circle at 50px 50px, yellow, red);\n}\n.demo{   \n    background: radial-gradient(circle at top, yellow, red);\n}\n如果指定多个颜色，但未指定具体断点的位置，则这些颜色会均匀分配 0%~100% 的渐变区域：\n.demo {\n    background: radial-gradient(circle, yellow, red,green, orange);\n}\n除了circle关键字，还有椭圆 ellipse，区别在于，椭圆需要指定横轴和纵轴，而不是一个半径了；\n且在指定颜色的终止点和中间点时，指定的长度则是以横轴为基准的：\n.demo {\n    background: radial-gradient(50px 30px ellipse, yellow 10px,30px, black);\n}\n/* 二者效果一致 */\n.demo {\n    background: radial-gradient(50px 30px ellipse, yellow 20%,60%, black);\n}\n可以把多个径向渐变累加在一起实现某些效果，配合background-size的尺寸控制和背景重复特性，还可以实现渐变式的复杂纹理效果，例如：\n.demo{\n    background: \n        radial-gradient(25% 25% at 25% 25%,red 80%,#0000 81%),\n        radial-gradient(25% 25% at 75% 75%,red 80%,#0000 81%);\n}\n.demo{\n    background: \n        radial-gradient(10px circle at 25% 25%,red 80%,#0000 81%),\n        radial-gradient(10px 10px at 75% 75%,red 80%,#0000 81%);\n    background-size: 35px 35px;\n}\nrepeating-radial-gradient()会在所有方向上重复颜色，以覆盖整个容器：\n.demo{\n    background-image: repeating-radial-gradient(#0000 0% 12%,#c39f76 13% 26% );\n}\n.demo{\n    background-image: repeating-radial-gradient(#0000 0% 12%,#c39f76 13% 26% );\n    background-size:20px 20px;\n}\nconic-gradient 角向渐变\n锥形渐变定义一个围绕一个中心点旋转颜色渐变图像；\n.demo {\n    background: conic-gradient(deeppink, yellowgreen);\n}\n\nlinear-gradient 线性渐变的方向是一条直线，可以是任何角度\nradial-gradient径向渐变是从圆心点以椭圆形状向外扩散\n而conic-gradient是以图形中心为起始点，然后以顺时针方向绕中心实现渐变效果；\n\n实现一个取色板：\n{\n    width: 200px;\n    height: 200px;\n    border-radius: 50%;\n    background: conic-gradient(red, orange, yellow, green, teal, blue, purple);\n}\n\n但这样处理，一是颜色不够丰富不够明亮，二是起始处与结尾处衔接不够自然：\n\nhsl() 被定义为色相-饱和度-明度（Hue-saturation-lightness）\n\n\n色相（H）是色彩的基本属性，就是平常所说的颜色名称，如红色、黄色等。\n饱和度（S）是指色彩的纯度，越高色彩越纯，低则逐渐变灰，取0-100%的数值。\n明度（V），亮度（L），取0-100%。\n\n$colors: ();\n$totalStops:20;\n \n@for $i from 0 through $totalStops{\n    $colors: append($colors, hsl($i *(360deg/$totalStops), 100%, 50%), comma);\n}\n \n.colors {\n    width: 200px;\n    height: 200px;\n    background: conic-gradient($colors);\n    border-radius: 50%;\n}\n我们可以更加具体的指定角向渐变每一段的比例，配合百分比，可以很轻松的实现饼图。\n假设我们有如下 CSS：\n{\n    width: 200px;\n    height: 200px;\n    background: conic-gradient(deeppink 0, deeppink 30%, yellowgreen 30%, yellowgreen 70%, teal 70%, teal 100%);\n    border-radius: 50%;\n}\n当然，上面只是百分比的第一种写法，还有另一种写法也能实现：\n{\n    background: conic-gradient(deeppink 0 30%, yellowgreen 0 70%, teal 0 100%);\n}\n\n这里表示 ：\n\n0-30% 的区间使用 deeppink\n0-70% 的区间使用 yellowgreen\n0-100% 的区间使用 teal\n\n而且，先定义的颜色的层叠在后定义的颜色之上。\n使用了百分比控制了区间，再配合使用 background-size 就可以实现各种贴图啦。\n我们首先实现一个基础角向渐变图形如下：\nbackground: conic-gradient(#000 12.5%, #fff 0 37.5%, #000 0 62.5%, #fff 0 87.5%, #000 0);\n与线性渐变及径向渐变一样，角向渐变也是存在重复角向渐变 repaet-conic-gradient 的。\n我们假设希望不断重复的片段是 0~30° 的一个片段，它的 CSS 代码是 conic-gradient(deeppink 0 15deg, yellowgreen 0 30deg) ：\nbackground: repeating-conic-gradient(deeppink 0 15deg, yellowgreen 0 30deg);"},"front-end/css/basic-css-gradient/repeating-gradient":{"title":"repeating-gradient","links":[],"tags":[],"content":"数量级对背景图形的影响\n什么是数量级对背景图形呢？我们来看这样一种有意思的现象：\n我们使用 repeating-conic-gradient 多重角向渐变实现一个图形，代码非常的简单：\n&lt;div&gt;&lt;/div&gt;\ndiv {\n    width: 100vw;\n    height: 100vh;\n    background: repeating-conic-gradient(#fff, #000, #fff 30deg);\n}\n然后，我们用一个非常小的值去替换上述代码中的 30deg，不可思议，出现了一个很特别的图像。这里 0.1deg 非常关键，这里的角度越小（小于 1deg 为佳），图形越酷炫，也就是我们说的数量级对背景图形的影响。\n借助 CSS @Property 观察变化过程\n如果我们编写如下的过度代码，是无法得到补间过渡动画的，只有逐帧过渡动画：\ndiv{\n    background: repeating-conic-gradient(#fff, #000, #fff 0.1deg);\n    transition: background 1s;\n}\n \ndiv:hover {\n    background: repeating-conic-gradient(#fff, #000, #fff 30deg);\n}\n原因在于 CSS 不支持对这种复杂的渐变进行直接的过渡动画；\n运用  CSS @property 自定义属性，可观察一下它们两种状态变化的过程：\n@property --angle {\n  syntax: &#039;&lt;angle&gt;&#039;;\n  inherits: false;\n  initial-value: 0.1deg;\n}\ndiv{\n    background: repeating-conic-gradient(#fff, #000, #fff var(--angle));\n    transition: --angle 2s;\n}\nhtml:hover {\n    --angle: 30deg;\n}\n通过 CSS @property 实现的补间过渡动画，看到从 30deg 到 0.1deg 的变化过程，我们大致可以看出小单位 0.1deg 是如何去影响图形的；\n多重径向渐变 &amp; 多重角向渐变\n利用上述的一些小技巧，我们利用多重径向渐变(repeating-radial-gradient)、多重角向渐变(repeating-conic-gradient)就可以生成一些非常有意思的背景图片：\n.demo {\n    width: 30vw;\n    height: 30vh;\n    background-image: repeating-radial-gradient(\n        circle at center center,\n        rgb(241, 43, 239),\n        rgb(239, 246, 244) 3px\n    );\n}\n最小可以小到什么程度？\n以下述代码为例子，其中的单次绘制图形的终止点 1px，也就是本文的重点，它究竟可以小到什么程度呢？\n:root {\n    --length: 1px\n}\n{\n    background-image: repeating-radial-gradient(\n        circle at 17% 32%,\n        rgb(4, 4, 0),\n        rgb(52, 72, 197),\n        rgb(115, 252, 224),\n        rgb(116, 71, 5),\n        rgb(223, 46, 169),\n        rgb(0, 160, 56),\n        rgb(234, 255, 0) var(--length)\n    );\n}\n在 0.001px 到 0.0001px 这个区间段，基本上图形已经退化为粒子图形，见不到径向渐变的轮廓了，而到了 0.00001px 这个级别，居然退化为了一张纯色图片！\n使用 repeating-radial-gradient 实现电视雪花噪声动画\n在上述 DEMO 中，我们发现，当在 0.001px 到 0.0001px 这个区间段，repeating-radial-gradient 基本退化为了粒子图形：\n@property --snow-length {\n  syntax: &#039;&lt;length&gt;&#039;;\n  inherits: false;\n  initial-value: 0.0085px;\n}\n.demo {\n    background-image: repeating-radial-gradient(\n        circle at 17% 32%,\n        rgb(4, 4, 0),\n        rgb(52, 72, 197),\n        rgb(115, 252, 224),\n        rgb(116, 71, 5),\n        rgb(223, 46, 169),\n        rgb(0, 160, 56),\n        rgb(234, 255, 0) var(--snow-length)\n    );\n    animation: change 1s infinite alternate;\n}\n@keyframes change {\n    100% {\n      --snow-length: 0.009px;\n    }\n}"},"front-end/css/basic-css-layout/Masonry/README":{"title":"README","links":[],"tags":[],"content":"CSS 多列布局\n定义了多栏布局的模块，可支持在布局中建立列（column）的数量，以及内容如何在列之间流动（flow）、列之间的间距（gap）大小，以及列的分隔线（column rules）。\ncolumn-count\n描述元素的列数，类似的，还有 column-width 使用宽度代替具体列数；\ncolumn-gap\n设置元素列之间的间隔大小，Flexible Box以及 Grid layouts 都可以使用；\ncolumn-rule\n规定了列与列之间的直线，该包括三个属性：width，style 和 color，可单独设置；\ncolumn-span\n其值被设置为all时，可以让一个元素跨越所有的列；\nCSS 计数器\ncounter-increment\n将计数器增加给定值\ncounter-reset\n用于将计数器重置为给定值\n读取计数器\n\n不包含父级上下文的编号使用 counter();\n包含父级上下文和嵌套内容的编号时，则使用 counters();\n\n反向计数器\n在 counter-reset 属性中将计数器的名称使用 reversed() 函数包裹来创建"},"front-end/css/basic-css-layout/stickily-layout":{"title":"stickily-layout","links":[],"tags":[],"content":"\n谈谈一些有趣的CSS题目（18）— 使用 position:sticky 实现粘性布局 · Issue #8 · chokcoco/iCSS (github.com)\n\n初窥  position:sticky\n这是一个结合了 position:relative 和 position:fixed 两种定位功能于一体的特殊定位，适用于一些特殊场景。\n什么是结合两种定位功能于一体呢？\n元素先按照普通文档流定位，然后相对于该元素在流中的 flow root（BFC）和 containing block（最近的块级祖先元素）定位。\n而后，元素定位表现为在跨越特定阈值前为相对定位，之后为固定定位。\n这个特定阈值指的是 top, right, bottom 或 left 之一，换言之，指定 top, right, bottom 或 left 四个阈值其中之一，才可使粘性定位生效。否则其行为与相对定位相同。\nposition:sticky 示例\n例如，有如下的 HTML 结构和 CSS 代码：\n&lt;div class=&quot;container&quot;&gt;\n    &lt;div class=&quot;sticky-box&quot;&gt;内容1&lt;/div&gt;\n    &lt;div class=&quot;sticky-box&quot;&gt;内容2&lt;/div&gt;\n    &lt;div class=&quot;sticky-box&quot;&gt;内容3&lt;/div&gt;\n    &lt;div class=&quot;sticky-box&quot;&gt;内容4&lt;/div&gt;\n&lt;/div&gt;\n.container {\n    background: #eee;\n    width: 600px;\n    height: 1000px;\n    margin: 100px auto;\n}\n \n.sticky-box {\n    position: -webkit-sticky;\n    position: sticky;\n    height: 60px;\n    margin-bottom: 30px;\n    background: #ff7300;\n    top: 80px;\n}\n \ndiv {\n    font-size: 30px;\n    text-align: center;\n    color: #fff;\n    line-height: 60px;\n}\n简单描述下生效过程，因为设定的阈值是 top: 0 ，这个值表示当元素距离页面视口（Viewport，也就是fixed定位的参照）顶部距离大于 0px 时，元素以 relative 定位表现，而当元素距离页面视口小于 0px 时，元素表现为 fixed 定位，也就会固定在顶部。\n生效规则\nposition:sticky 的生效是有一定的限制的，总结如下：\n\n须指定 top, right, bottom 或 left 四个阈值其中之一，才可使粘性定位生效。否则其行为与相对定位相同。\n\n并且 top 和 bottom 同时设置时，top 生效的优先级高，left 和 right 同时设置时，left 的优先级高。\n\n\n设定为 position:sticky 元素的任意父节点的 overflow 属性必须是 visible，否则 position:sticky 不会生效。这里需要解释一下：\n\n如果 position:sticky 元素的任意父节点设置为 overflow: hidden，则父容器无法进行滚动，所以 position:sticky 元素也不会有滚动然后固定的情况。\n\n\n在满足上述情况下，设定了 position: sticky 的元素的父容器的高度必须大于当前元素，否则也会失效。（当然，此时，sticky 吸附的基准元素就会变成父元素）\n"},"front-end/css/basic-css-scroll/scroll-snap/README":{"title":"README","links":[],"tags":[],"content":"根据 CSS Scroll Snap Module Level 1 规范，CSS 新增了一批能够控制滚动的属性，让滚动能够在仅仅通过 CSS 的控制下，得到许多原本需要 JS 脚本介入才能实现的美好交互。\nsroll-snap-type\n首先看看 sroll-snap-type 可能算得上是新的滚动规范里面最核心的一个属性样式。\nscroll-snap-type：属性定义在滚动容器中的一个临时点（snap point）如何被严格的执行。\n简单而言，这个属性规定了一个容器是否对内部滚动动作进行捕捉，并且规定了如何去处理滚动结束状态。\n语法\n{\n    scroll-snap-type: none | [ x | y | block | inline | both ] [ mandatory | proximity ]?\n}\n举个例子，假设，我们希望一个横向可滚动容器，每次滚动之后，子元素最终的停留位置不是尴尬的被分割，而是完整的呈现在容器内，可以这样写：\n&lt;div class=&quot;container&quot;&gt;\n  &lt;div class=&quot;child&quot;&gt;&lt;/div&gt;\n  &lt;div class=&quot;child&quot;&gt;&lt;/div&gt;\n  &lt;div class=&quot;child&quot;&gt;&lt;/div&gt;\n&lt;/div&gt;\n.container {\n  scroll-snap-type: x mandatory;\n}\n \n.child {\n  scroll-snap-align: start;\n}\n上面 scroll-snap-type: y mandatory 中:\n\ny 表示捕捉 y 轴方向上的滚动；\nmandatory 表示强制将滚动结束后元素的停留位置设置到我们规定的地方。\n\nmandatory 与 proximity\n\nmandatory： 通常在 CSS 代码中我们都会使用这个，mandatory 的英文意思是强制性的，表示滚动结束后，滚动停止点一定会强制停在我们指定的地方；\nproximity： 意思是接近、临近、大约，在这个属性中的意思是滚动结束后，滚动停止点可能就是滚动停止的地方，也可能会再进行额外移动，停在我们指定的地方；\n\nboth mandatory\n当然，还有一种比较特殊的情况是，scroll-snap-type: both mandatory，表示横向与竖向的滚动，都会同时进行捕捉，也是可以的；\nscroll-snap-align\n使用 scroll-snap-align 可以简单的控制将要聚焦的当前滚动子元素在滚动方向上相对于父容器的对齐方式。\n其需要作用在父元素上，可选值有三个：\n{\n    scroll-snap-align: start | center | end;\n}\n如果子元素大小不一，也能有非常好的表现，使用 scroll-snap-align: center，使得不规则子元素在每次滚动后居于容器中间；\nscroll-margin / scroll-padding\n上述的 scroll-snap-align 很好用，可以控制滚动子元素与父容器的对齐方式。然而可选的值只有三个，有的时候我们希望进行一些更精细的控制时，可以使用 scroll-margin 或者 scroll-padding\n其中：\n\nscroll-padding 是作用于滚动父容器，类似于盒子的 padding\nscroll-margin 是作用于滚动子元素，每个子元素的 scroll-margin 可以设置为不一样的值，类似于盒子的 margin\n\n废弃的 scroll-snap-points-x / scroll-snap-points-y\n标准的发展过程，早年间的规范如今废除，这个了解一下即可，新标准现在是这几个，并且大部分浏览器已经兼容：\n\nscroll-snap-type\nscroll-snap-align\nscroll-margin / scroll-padding\nscroll-snap-stop\n\nscroll-snap-stop\n默认情况下，scroll snapping 只在用户滚动停止时才生效，这意味着可以一直滚动，而跳过一些停靠点（snap point）；\n而通过在某些子元素上设置 scroll-snap-stop: always 可保证容器滚到该子元素时，总是触发 scroll snapping 效果；\n目前还没有主流的浏览器支持该属性，尽管在 Chrome 上有一个tracking bug ；"},"front-end/css/basic-css-selector/attribute-selector":{"title":"attribute-selector","links":[],"tags":[],"content":"属性选择器的深入挖掘\n\nCSS 属性选择器的深入挖掘 · Issue #65 · chokcoco/iCSS (github.com)\n\nCSS 属性选择器，可以通过已经存在的属性名或属性值匹配元素\n简单的语法介绍\n\n[attr]：该选择器选择包含 attr 属性的所有元素，不论 attr 的值为何；\n[attr=val]：该选择器仅选择 attr 属性被赋值为 val 的所有元素；\n[attr~=val]：该选择器仅选择具有 attr 属性的元素，而且要求 val 值是 attr 值包含的被空格分隔的取值列表里中的一个；\n\n子串值（Substring value）属性选择器\n下面几个属于 CSS3 新增语法，也被称为“伪正则选择器”，因为它们提供类似正则表达式的灵活匹配方式：\n\n[attr|=val] ：选择attr属性的值是 val 或值以 val- 开头的元素（注意，这里的 “-” 不是一个错误，这是用来处理语言编码的）；\n[attr^=val] : 选择attr属性的值以 val 开头（包括 val）的元素。\n[attr$=val] : 选择attr属性的值以 val 结尾（包括 val）的元素。\n[attr*=val] : 选择attr属性的值中包含子字符串 val 的元素（一个子字符串就是一个字符串的一部分而已，例如，”cat“ 是 字符串 ”caterpillar“ 的子字符串\n\n基本用法\n[href] {\n    color: red;\n}\n \n/* 层叠选择 */\ndiv [href]{\n\t/* 选择 div 存在 href 属性的子元素 */\n}\n \n/* 多条件复合选择 */\nimg[title][class~=logo]{\n\t/* 选择一个 img 标签，它含有 title 属性，并且包含类名为 logo 的元素 */\n}\n伪正则写法\ni 参数\n忽略类名的大小写限制，也就是正则表达式里的 ignore，例如：\np[class*=&quot;text&quot; i] {\n\t...\n}\n该选择器可以选中类似这样的目标元素：\n&lt;p class=&quot;text&quot;&gt;&lt;/p&gt;\n&lt;p class=&quot;nameText&quot;&gt;&lt;/p&gt;\n&lt;p class=&quot;desc textarea&quot;&gt;&lt;/p&gt;\ng 参数\n与正则表达式不一样，参数 g 在这里表示大小写敏感（case-sensitively）。然而，这个属性当前仍未纳入标准，支持的浏览器不多。\n配合 :not() 伪类\n搭配:not() 伪类，完成一些判断检测性的功能；\n譬如下面这个选择器，就可以选取所有没有 [href] 属性的 a 标签，添加一个红色边框：\na:not([href]){\n    border: 1px solid red;\n}\n复杂一点， :not()伪类可以叠加；如选择一个 href, target, rel 属性都没有的 a 标签：\na:not([href]):not([target]):not([rel]){\n    border: 1px solid blue;\n}\n重写行内样式\n如果有这种场景，我们还可以覆盖掉行内样式，像这样:\n&lt;p style=&quot;height: 24px; color: red;&quot;&gt;xxxxxx&lt;/p&gt;\n我们可以使用属性选择器强制覆盖掉上述样式：\n[style*=&quot;color: red&quot;] {\n    color: blue !important;\n}\n伪元素组合搭配用法\n属性选择器不一定只是单单的进行标签的选择；配合上伪元素，我们可以实现很多有助提升用户体验的功能。\n角标功能\n伪元素的 content 属性，通过 attr(xxx)，可以读取到对应 DOM 元素标签名为 xxx 的属性的值；\n所以，配合属性选择器，我们可以很容易的实现一些角标功能：\n&lt;div count=“5“&gt;Message&lt;/div&gt;\n \ndiv {\n    position: relative;\n    width: 200px;\n    height: 64px;\n}\n \ndiv::before {\n    content: attr(count);\n    ...\n}\n这里右上角的数字 5 提示角标，就是使用属性选择器配合伪元素实现，可以适应各种长度，以及中英文，能够节省一些标签；\n类 title 功能\n我们都知道，如果给一个图片添加一个 title 属性，当 hover 到图片上面的时，会展示 title 属性里面附加的内容，类似这样：\n&lt;img src=&quot;xxxxxxxxx&quot; title=&quot;风景图片&quot;&gt;\n这里不一定是 img 标签，其他标签添加 title 属性都能有类似的效果。但是这里会有两个问题：\n\n响应太慢，通常鼠标 hover 上去要隔 1s 左右才会出现这个 title 框；\n框体结构无法自定义，弹出框的样式无法自定义；\n\n如果我们希望有一些自己能够控制样式的可快速响应的浮层，可以自定义一个类 title 属性，我们把它称作 popTitle，那么可以这样操作：\n&lt;p class=&quot;title&quot; popTitle=&quot;文字弹出&quot;&gt;这是一段描述性文字&lt;/p&gt;\n&lt;p class=&quot;title&quot; popTitle=&quot;标题A&quot;&gt;这是一段描述性文字&lt;/p&gt;\n \np[popTitle]:hover::before {\n    content: attr(popTitle);\n    position: absolute;\n    color: red;\n    border: 1px solid #000;\n    ...\n}\n\n浏览器自带的 title 属性延迟响应是添加一层防抖保护，避免频繁触发，这里也可以通过对伪元素添加一个100毫秒级的 transition-delay 实现延迟展示。\n\n商品展示提示效果\n在实际业务中，是有很多用武之地的。譬如说，通过属性选择器给图片添加标签，类似一些电商网站会用到的一个效果。\n给图片添加一些标签，在 hover 图片的时候展示出来；当然，CSS 中，诸如 &lt;img&gt; 、&lt;input&gt;、&lt;iframe&gt;，这几个标签是不支持伪元素的。\n所以在输出 DOM 的时候，给 img 的父元素带上部分图片描述标签。通过 CSS 去控制这些标签的展示：\n&lt;div class=&quot;g-wrap&quot; desc1=&quot;商品描述AAA&quot; desc2=&quot;商品描述BBB&quot;&gt;\n    &lt;img src=&quot;xx.baidu.com/timg &gt;    \n&lt;/div&gt;\n[desc1]::before,\n[desc2]::after {\n    position: absolute;\n    opacity: 0;\n}\n \n[desc1]::before {\n    content: attr(desc1);\n}\n \n[desc2]::after {\n    content: attr(desc2);\n}\n \n[desc1]:hover::before,\n[desc2]:hover::after{\n    opacity: 1;\n}\n实现下载提示\nHTML5 对标签新增了一个 download 属性，此属性指示浏览器下载 URL 而不是导航到它；那么，我们可以利用属性选择器对所有带此类标签的元素进行提示。像这样：\n&lt;a href=&quot;www.xxx.com/logo.png&quot; download=&quot;logo&quot;&gt;logo&lt;/a&gt;\n[download] {\n    position: relative;\n    color: hotpink;\n}\n \n[download]:hover::before {\n    content: &quot;点击可下载此资源！&quot;;\n    position: absolute;\n    ...\n}\n链接协议进行提示(http/https)\na[href^=&quot;http:&quot;]:hover::before {\n    content: &quot;这是一个http链接&quot;;\n}\n \na[href^=&quot;https:&quot;]:hover::before {\n    content: &quot;这是一个https链接&quot;;\n}\n或者在连接前方插入图标：\na[href^=&quot;https:&quot;]:hover::before {\n    content: &quot;&quot;;\n    padding-left: 16px;\n    background: url(&quot;data:image/png;base64,iVBO...&quot;);\n    ...\n}\n对文件类型的处理\n可以对一些可下载资源进行视觉上 icon 的提示：\n&lt;ul&gt;\n    &lt;li&gt;&lt;a href=&quot;xxx.doc&quot;&gt;Word File&lt;/a&gt;&lt;/li&gt;\n    &lt;li&gt;&lt;a href=&quot;xxx.ppt&quot;&gt;PPT File&lt;/a&gt;&lt;/li&gt;\n    &lt;li&gt;&lt;a href=&quot;xxx.PDF&quot;&gt;PDF File&lt;/a&gt;&lt;/li&gt;\n    &lt;li&gt;&lt;a href=&quot;xxx.MP3&quot;&gt;MP3 File&lt;/a&gt;&lt;/li&gt;\n    &lt;li&gt;&lt;a href=&quot;xxx.avi&quot;&gt;AVI File&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\na[href$=&quot;.doc&quot; i]::before {\n    content: &quot;doc&quot;;\n    background: #a9c4f5;\n}\na[href$=&quot;.ppt&quot; i]::before {\n    content: &quot;ppt&quot;;\n    background: #f8e94f;\n}\na[href$=&quot;.pdf&quot; i]::before {\n    content: &quot;pdf&quot;;\n    background: #fb807a;\n}\na[href$=&quot;.mp3&quot; i]::before {\n    content: &quot;mp3&quot;;\n    background: #cb5cf5;\n}\na[href$=&quot;.avi&quot; i]::before {\n    content: &quot;avi&quot;;\n    background: #5f8ffc;\n}\n对 input 类型的处理\n因为 input 常用，且经常搭配很多不同功能的属性值；\n只不过，由于 input 类型无法添加伪元素。所以搭配属性选择器更多的通过属性的各种状态改变自身的样式；\n&lt;input type=&quot;text&quot;&gt;\n&lt;input type=&quot;text&quot; disabled&gt;\ninput[type=text][disabled] { \n    border: 1px solid #aaa;\n    background: #ccc; \n}\n如上例，选择了 type=text 并且拥有 disabled 属性的 input 元素，将它的背景色和边框色设置为灰色。给与用户更好的视觉提示。\n值得注意的点\n注意选择器优先级 ，.class 与 [class=xxx] 是否等价\n.header {\n    color: red;\n}\n \n[class~=&quot;header&quot;] {\n    color: blue;\n}\n上述两个选择器，作用完全一致。然而，如果是下面这种情况，两者就不一样了：\n#header{\n    color: red;\n}\n \n[id=&quot;header&quot;] {\n    color: blue;\n}\nID 选择器#header比属性选择器[id=&quot;header&quot;]的权重更高，虽然两者能够选择同样的元素，但是两者并不完全等价；\n是否需要引号\n虑下面三种情况，是否一致？\n[class=&quot;header&quot;]{ ... }\n \n[class=&#039;header&#039;]{ ... }\n \n[class=header]{ ... }\n事实上，从 HTML2 开始，不添加引号的写法就已经得到支持，所以上述三种写法都是正确的。\n能够不使用引号也是有限制的，再看看下面这种写法：\na[href=bar] { ... }\n\na[href^=http://] {... }\n\n第二个选择器是个无效选择器，:// 不引起来的话会识别错误，必须使用引号引起来像这样a[href^=&quot;http://&quot;] \n具体的原因可以看看这篇文章：Unquoted attribute value validator。\n所以保险起见，建议都加上引号。\nCSS 语义化\n编写”具有语义的HTML”原则是现代、专业前端开发的一个基础。当然，我们经常谈论到的都是 HTML 语义化。\n那么，CSS 需要语义化吗？CSS 有语义化吗？例如上述的例子，使用特定的类名或者 id 选择器皆可完成。那么使用属性选择器的理由是什么？\n我的理解是，属性（attribute）本身已经具有一定的语义，表达了元素的某些特征或者功能，利用属性选取元素再进行对该属性值的特定操作，一定程度上也可以辅助提升代码的语义化。至少的提升了 CSS 代码的可读性。但是 CSS 是否需要语义化这个问题就见仁见智了。"},"front-end/css/basic-css-selector/complex-selector":{"title":"complex-selector","links":[],"tags":[],"content":"复杂选择器\n五花八门的伪类叠加\n在单个选择器中，叠加各种伪元素，例如：\na:not(main *:not(:is(h2, h3) &gt; *)) {\n    color: red;\n}\n其中混入了比较新的两个伪类选择器：\n\n:not()：用来匹配不符合一组选择器的元素。由于它的作用是防止特定的元素被选中，它也被称为反选伪类（negation pseudo-class）\n:is()：将选择器列表作为参数，并选择该列表中任意一个选择器可以选择的元素。\n\n对于它的拆解：\n\na:not(main *)：选择不是 &lt;main&gt; 标签下的所有 a 标签\nmain *:not(:is(h2, h3) &gt; *)：选择 &lt;main&gt; 标签下所有不是 &lt;h2&gt;、&lt;h3&gt; 子元素的元素\n\n\n\n&gt; 组合器选择前一个元素的直接子代的节点；\n~ 组合器选择兄弟元素，即后一个节点在前一个节点后面的任意位置，并且共享同一个父节点；\n+ 组合器选择相邻元素，即后一个元素紧跟在前一个之后，并且共享同一个父节点；\n (Space)组合器选择前一个元素的后代节点，即前一个节点内的任意位置的后一个节点；\n\n\n所以合起来就是：选择所有不是 &lt;main&gt; 标签下的 &lt;a&gt; 标签以及所有 &lt;main&gt; 下面不是 &lt;h2&gt;、&lt;h3&gt; 下的子 &lt;a&gt; 以外的所有 &lt;a&gt; 标签。\n若有以下 html 代码：\n&lt;main&gt;\n    &lt;a href=&quot;&quot;&gt;1. main&gt;a&lt;/a&gt;\n    &lt;h1&gt;&lt;a href=&quot;&quot;&gt;2. main&gt;h1&gt;a&lt;/a&gt;&lt;/h1&gt;\n    &lt;h2&gt;&lt;a href=&quot;&quot;&gt;3. main&gt;h2&gt;a&lt;/a&gt;&lt;/h2&gt;\n    &lt;h2&gt;&lt;p&gt;&lt;a href=&quot;&quot;&gt;4. main&gt;h2&gt;p&gt;a&lt;/a&gt;&lt;/p&gt;&lt;/h2&gt;\n    &lt;h3&gt;&lt;a href=&quot;&quot;&gt;5. main&gt;h3&gt;a&lt;/a&gt;&lt;/h3&gt;\n&lt;/main&gt;\n&lt;h1&gt;&lt;a href=&quot;&quot;&gt;6. h1&gt;a&lt;/a&gt;&lt;/h1&gt;\n&lt;h2&gt;&lt;a href=&quot;&quot;&gt;7. h2&gt;a&lt;/a&gt;&lt;/h2&gt;\n&lt;h3&gt;&lt;a href=&quot;&quot;&gt;8. h3&gt;a&lt;/a&gt;&lt;/h3&gt;\n&lt;a href=&quot;&quot;&gt;9. a&lt;/a&gt;\n那么只有 1，2，4 项没被选中，其余呈现红色；\n神奇的特殊字符\n#\\~\\!\\@\\$\\%\\^\\&amp;\\*\\(\\)\\_\\+-\\=\\,\\.\\/\\&#039;\\;\\:\\?\\&gt;\\&lt;\\\\\\[\\]\\{\\}\\|\\`\\# {\n    color: red;\n}\n它还真能生效，CSS 中的 CSS 类名中允许使用除 NUL 之外的任何字符，\n\n感兴趣可以看看这个：Which characters are valid in CSS class names/selectors?\n\n所以，上述的选择器，是可以匹配这样的标签的：\n&lt;div id=&quot;~!@$%^&amp;*()_+-=,./&#039;;:?&gt;&lt;\\[]{}|`#&quot;&gt;Lorem&lt;/div&gt;\n\n那么可以有如下牛啤的操作：\n&lt;style&gt;\n#💉💧🐂🍺 {\n    padding: 10px;\n    color: red;\n}\n&lt;/style&gt;\n \n&lt;div id=&quot;💉💧🐂🍺&quot;&gt;真滴牛啤&lt;/div&gt;\n自身的多重重叠\ndiv.g-text-color.g-text-color.g-text-color.g-text-color.g-text-color {\n    color: red;\n}\n这类选择器大部分情况是为了提升优先级；例如，引入了组件库后，使用了其中一个按钮，但想改变其中的某些样式。给它加了一个类名，在对应类名新增了覆盖样式后发现没有生效。\n原因就在于定义样式的选择器优先级不够高；\n此时就可以通过自己叠加自己的方式，提升选择器的权重。\ndiv.g-text-color.g-text-color.g-text-color 的权重，就会比 div.g-text-color.g-text-color 更高。所以某些极端情况下，就出现了上述的选择器。"},"front-end/css/basic-css-selector/nth-child":{"title":"nth-child","links":[],"tags":[],"content":"对于 p:nth-child(2) 表示这个元素要是 p 标签，且是第二个子元素，是两个必须满足的条件;\n而 ·p:nth-of-type(2) 表示父标签下的第二个 p 元素，显然，被选中的元素之前有多少其他元素，都不影响选中第二个 p 元素。\n\np:nth-child(-n+3)：匹配子元素中前三个 p 标签；\np:nth-child(0n+1)：子元素中第一个 p 标签，等价于与 :first-child；\np:nth-child(2n)：匹配子元素中的偶数位的 p 元素，等价于 :nth-child(even)；\np:nth-child(2n + 1)：匹配子元素中的奇数位的 p 元素，等价于 :nth-child(odd)；\n3n+4 匹配位置为 4、7、10、13…的元素\n"},"front-end/css/basic-css-selector/pseudo-class-selector":{"title":"pseudo-class-selector","links":[],"tags":[],"content":"几个特殊且实用的伪类选择器\n以下是 4 个基本的结构性伪类选择器，结构性伪类选择器的共同特征是允许开发者根据文档树中的结构来指定元素的样式；\n:root 伪类\n:root 伪类匹配文档树的根元素。应用到HTML，:root 即表示为&lt;html&gt;元素，除了优先级更高外，相当于html标签选择器：\n:root { 样式属性 }\n由于属于 CSS3 新增的伪类，所以也可以作为一种 HACK 元素，只对 IE9+ 生效；声明全局 CSS 自定义属性时 :root 很有用。\n:empty 伪类\n:empty 伪类，代表没有子元素的元素；\n这里说的子元素，只计算元素结点及文本（包括空格），注释、运行指令不考虑在内。\ndiv{\n  height:20px;\n  background:#ffcc00;\n}\ndiv:empty{\n  display:none;\n}\n \n&lt;div&gt;1&lt;/div&gt;\n&lt;div&gt; &lt;/div&gt;\n&lt;div&gt;&lt;/div&gt;\n如上述的例子，第三个 div会被隐藏；\n:not 伪类\nCSS 否定伪类，:not(X)，可以选择除某个元素之外的所有元素；X 中不能包含另外一个否定选择器；\n\n\n:not 伪类不像其它伪类，它不会增加选择器的优先级。它的优先级即为它参数选择器的优先级。\n\n伪类选择的权重与类选择器（class selectors，例如 .example），属性选择器（attributes selectors，例如 [type=&quot;radio&quot;]）的权重相同；\n:not()是个特例：其在优先级计算中不会被看作是伪类，但是在计算选择器数量时还是会把其中的选择器当做普通选择器进行计数；\n\n\n\n提高规则的优先级；例如， #foo:not(#bar) 和 #foo 会匹配相同的元素，但是前者优先级更高；\n\n\n使用 :not(*) 将匹配任何非元素的元素，因此这个规则将永远不会被应用；\n\n\n这个选择器只会应用在一个元素上，无法用它来排除所有父元素。比如， body :not(table) a 依旧会应用到 table 内部的 a 上，因为 将会被 :not(table) 这部分选择器匹配。\n\n\n:target 伪类\n:target 代表一个特殊的元素，指定那些包含片段标识符的 URI 的目标元素；\nURL 末尾带有锚名称 #，就可以指向文档内某个具体的元素。这个被链接的元素就是目标元素(target element)。它需要一个 id 去匹配文档中的 target ；\n:target 选择器的出现，让 CSS 也能够接受到用户的点击事件，并进行反馈。（另一个可以接收点击事件的 CSS 选择器是 :checked）。\n&lt;style&gt;\n  :target {\n    font-size: 60px;\n  }\n  h1:target{\n    color: red;\n  }\n&lt;/style&gt;\n \n&lt;body&gt;\n  &lt;h1 id=&quot;one&quot;&gt;First&lt;/h1&gt;\n  &lt;h2 id=&quot;two&quot;&gt;Second&lt;/h2&gt;\n  &lt;h3 id=&quot;three&quot;&gt;Third&lt;/h3&gt;\n \n  &lt;a href=&quot;#one&quot;&gt;First&lt;/a&gt;\n  &lt;a href=&quot;#two&quot;&gt;Second&lt;/a&gt;\n  &lt;a href=&quot;#three&quot;&gt;Third&lt;/a&gt;\n&lt;/body&gt;\n如上面的例子中，点击每一个链接都会激活一个锚点，锚点绑定的元素字体大小将会变为 60px；而当 id 为 #one的 h1 元素活动时，字体还会变成红色；"},"front-end/css/basic-css-shape/button":{"title":"button","links":[],"tags":[],"content":"CSS 实现奇形怪状按钮\n矩形与圆角按钮\n实现简单，宽高和圆角和背景色：\n&lt;div class=&#039;btn rect&#039;&gt;rect&lt;/div&gt;\n&lt;div class=&#039;btn circle&#039;&gt;circle&lt;/div&gt;\n.btn {\n    margin: 8px auto;\n    flex-shrink: 0;\n    width: 160px;\n    height: 64px;\n}\n.rect {\n    background: #f6ed8d;\n}\n \n.circle {\n    border-radius: 64px;\n    background: #7de3c8;\n}\n梯形与平行四边形\n基于矩形的变形，经常会出现梯形与平行四边形的按钮，实现它们主要使用 transform 即可；\n但是要注意一点，使用了 transform 之后，标签内的文字也会同样的变形；\n所以，通常使用元素的伪元素去实现造型，这样可以做到不影响按钮内的文字。\n平行四边形\n使用 transform: skewX() 即可，注意上述说的，利用元素的伪元素实现平行四边形，做到不影响内部的文字，并且设置伪元素层级为负，防止遮挡文字：\n&lt;div class=&#039;btn parallelogram&#039;&gt;Parallelogram&lt;/div&gt;\n.parallelogram {\n    position: relative;\n    width: 160px;\n    height: 64px;\n}\n \n.parallelogram::after {\n    content: &quot;&quot;;\n    position: absolute;\n    top: 0;\n    left: 0;\n    bottom: 0;\n    right: 0;\n    z-index: -1;\n    background: #03f463;\n    transform: skewX(10deg);\n}\n除了使用伪元素还可以使用平行四边形渐变：\n.parallelogram{\n    background: linear-gradient(80deg, transparent 12%, \n        #04e6fb 12%, #3f3dcf 30%, #bd73e2 90%, transparent 0);\n}\n梯形\n梯形比平行四边形稍微复杂一点，它多借助了 perspective，其实是利用了一定的 3D 变换。\n原理就是一个矩形，绕着 X 轴旋转，使用 perspective 和 transform: rotateX() 即可：\n&lt;div class=&#039;btn trapezoid&#039;&gt;Trapezoid&lt;/div&gt;\n.trapezoid {\n    position: relative;\n    width: 160px;\n    height: 64px;\n \n    &amp;::after {\n        content:&quot;&quot;;\n        position: absolute;\n        z-index: -1;\n        top: 0; right: 0; bottom: 0; left: 0;\n        transform: perspective(40px) rotateX(10deg);\n        transform-origin: bottom;\n        background: #ff9800;\n    }\n}\n\n**perspective**指定了观察者与 z=0 平面的距离，使具有三维位置变换的元素产生透视效果。z&gt;0 的三维元素比正常大，而 z&lt;0 时则比正常小，大小程度由该属性的值决定。\n\n切角 — 纯色背景与渐变色背景\n切角图形，最常见的方法主要是借助渐变 linear-gradient 实现，来看这样一个图形：\n&lt;div id=“notching-demo”&gt;&lt;/div&gt;\n#notching-demo {\n    background: linear-gradient(45deg,  #ff1493 20px,transparent 20px,#1a2d98);\n    background-repeat: no-repeat;\n}\n基于此，我们只需要利用多重渐变，实现 4 个这样的图形即可，并且，利用 background-position 定位到四个角：\n&lt;div class=&quot;notching&quot;&gt;notching&lt;/div&gt;\n.notching {\n    background: \n        linear-gradient(135deg, transparent 10px, #ff1493 0) top left,\n        linear-gradient(-135deg, transparent 10px, #ff1493 0) top right,\n        linear-gradient(-45deg, transparent 10px, #ff1493 0) bottom right,\n        linear-gradient(45deg, transparent 10px, #ff1493 0) bottom left;\n    background-size: 50% 50%;\n    background-repeat: no-repeat;\n}\nclip-path 实现渐变背景的切角图形\n使用渐变技巧制作切角时，若要求底色是渐变色的时候，这个方法就比较笨拙了；\n好在，我们还有另外一种方式，借助 clip-path 切出一个切角图形，这样，背景色可以是任意定制的颜色，无论是渐变还是纯色都不在话下：\n&lt;div class=&quot;clip-notching&quot;&gt;notching&lt;/div&gt;\n.clip-notching {\n    background: linear-gradient(\n        45deg,\n        #f9d9e7,\n        #ff1493\n    );\n    clip-path: polygon(\n        15px 0,\n        calc(100% - 15px) 0,\n        100% 15px,\n        100% calc(100% - 15px),\n        calc(100% - 15px) 100%,\n        15px 100%,\n        0 calc(100% - 15px),\n        0 15px\n    );\n}\n简单的实现一个渐变背景，接着核心就是，在渐变矩形图形的基础上，利用 clip-path: polygon() 切出我们想要的形状（一个 8 边形）；\n箭头按钮\n我们可以利用两重渐变，实现一个单箭头按钮：\n&lt;div class=&quot;arrow&quot;&gt;arrow&lt;/div&gt;\narrow {\n    background: linear-gradient(\n        -135deg,\n        transparent 22px,\n        #04e6fb 22px,\n        #65ff9a 100%\n    )\n        top right,\n        linear-gradient(\n            -45deg,\n            transparent 22px,\n            #04e6fb 22px,\n            #65ff9a 100%\n        )\n        bottom right;\n    background-size: 100% 50%;\n    background-repeat: no-repeat;\n}\n稍微复杂一点的燕尾箭头，也可以是两个渐变的叠加，渐变的颜色是透明 ⇒ 颜色A ⇒ 颜色B ⇒ 透明。简便点，可以使用clip-path实现：\n{\n    background: linear-gradient(45deg, #04e6fb, #65ff9a);\n    clip-path: polygon(\n        0 0,\n        30px 50%,\n        0 100%,\n        calc(100% - 30px) 100%,\n        100% 50%,\n        calc(100% - 30px) 0\n    );\n}\n内切圆角\n多出现于优惠券，最常见的解法，也是使用渐变，当然，与切角不同，这里使用的径向渐变：\ninset-circle {\n    background-size: 70% 70%;\n    background-image: radial-gradient(\n            circle at 100% 100%,\n            transparent 0,\n            transparent 12px,\n            #2179f5 13px\n        ),\n        radial-gradient(\n            circle at 0 0,\n            transparent 0,\n            transparent 12px,\n            #2179f5 13px\n        ),\n        radial-gradient(\n            circle at 100% 0,\n            transparent 0,\n            transparent 12px,\n            #2179f5 13px\n        ),\n        radial-gradient(\n            circle at 0 100%,\n            transparent 0,\n            transparent 12px,\n            #2179f5 13px\n        );\n    background-repeat: no-repeat;\n    background-position: right bottom, left top, right top, left bottom;\n}\n渐变的内切圆角\n如果背景色要求渐变怎么办呢？\n假设我们有一张矩形背景图案，我们只需要使用 mask 实现一层遮罩，利用 mask 的特性，把 4 个角给遮住即可。\nmask 的代码和上述的圆角切角代码非常类似，简单改造下即可得到渐变的内切圆角按钮：\n&lt;div class=&quot;mask-inset-circle&quot;&gt;inset-circle&lt;/div&gt;\n.mask-inset-circle {\n    background: linear-gradient(45deg, #2179f5, #e91e63);\n    mask: radial-gradient(\n        circle at 100% 100%,\n        transparent 0,\n        transparent 12px,\n        #2179f5 13px\n    ),\n        radial-gradient(\n            circle at 0 0,\n            transparent 0,\n            transparent 12px,\n            #2179f5 13px\n        ),\n        radial-gradient(\n            circle at 100% 0,\n            transparent 0,\n            transparent 12px,\n            #2179f5 13px\n        ),\n        radial-gradient(\n            circle at 0 100%,\n            transparent 0,\n            transparent 12px,\n            #2179f5 13px\n        );\n    mask-repeat: no-repeat;\n    mask-position: right bottom, left top, right top, left bottom;\n    mask-size: 70% 70%;\n}\n圆角不规则矩形\n一侧是规则的带圆角直角，另外一侧则是带圆角的斜边；其实，它就是由圆角矩形 + 圆角平行四边形组成；\n所以，借助两个伪元素，可以轻松的实现它们：\n&lt;div class=&quot;skew&quot;&gt;Skew&lt;/div&gt;\n.skew {\n    position: relative;\n    width: 120px;\n \n    &amp;::after {\n        content: &quot;&quot;;\n        position: absolute;\n        top: 0;\n        left: 0;\n        right: 0;\n        bottom: 0;\n        border-radius: 10px;\n        background: orange;\n        transform: skewX(15deg);\n    }\n    &amp;::before {\n        content: &quot;&quot;;\n        position: absolute;\n        top: 0;\n        right: -13px;\n        width: 100px;\n        height: 64px;\n        border-radius: 10px;\n        background: orange;\n    }\n}\n外圆角按钮\n常见于 Tab 页上，对这个按钮形状拆解一下，这里其实是 3 块的叠加：\n\n中间的上圆角矩形\n两侧的矩形切弧形成的弧形三角\n\n主要难点是两侧的三角，可用径向渐变实现：\n&lt;div class=&quot;outside-circle&quot;&gt;outside-circle&lt;/div&gt;\n.outside-circle {\n    position: relative;\n    background: #e91e63;\n    border-radius: 10px 10px 0 0;\n \n    &amp;::before {\n        content: &quot;&quot;;\n        position: absolute;\n        width: 20px;\n        height: 20px;\n        left: -20px;\n        bottom: 0;\n        background: #000;\n        background:radial-gradient(circle at 0 0, transparent 20px, #e91e63 21px);\n    }\n    &amp;::after {\n        content: &quot;&quot;;\n        position: absolute;\n        width: 20px;\n        height: 20px;\n        right: -20px;\n        bottom: 0;\n        background: #000;\n        background:radial-gradient(circle at 100% 0, transparent 20px, #e91e63 21px);\n    }\n}\n总结一下\n基于上述的实现，我们不难发现，一些稍微特殊的按钮，无非都通过拼接、障眼法、遮罩等方式实现。\n而在其中：\n\n渐变（线性渐变 linear-gradient、径向渐变 radial-gradient、多重渐变）\n遮罩 mask\n裁剪 clip-path\n变形 transform\n\n发挥了重要的作用，熟练使用它们，我们对于这些图形就可以信手拈来，基于它们的变形也能从容面对。\n上述的图形，再配合 filter: drop-shadow()，基本都能实现不规则阴影。"},"front-end/css/basic-css-text/animation/README":{"title":"README","links":[],"tags":[],"content":"Google Font\n在写各种 DEMO 的时候，有的时候一些特殊的字体能更好的体现动画的效果。这里讲一个快速引入不同格式字体的小技巧。\n就是 Google Font 这个网站，上面有非常多的不同的开源字体；\n当我们相中了一个我们喜欢的字体，它也提供了非常快速的便捷的引入方式。选中对应的字体，选择 +Select this style，便可以通过 link 和 @import 两种方式引入：\n使用 link 标签引入：\n&lt;link rel=&quot;preconnect&quot; href=&quot;fonts.gstatic.com&quot;&gt;\n&lt;link href=&quot;fonts.googleapis.com/css2+Code+Pro:wght@200&amp;display=swap&quot; rel=&quot;stylesheet&quot;&gt;\nOR，在 CSS 代码中，使用 @import 引入：\n&lt;style&gt;\n@import url(&#039;fonts.googleapis.com/css2+Code+Pro:wght@200&amp;display=swap&#039;);\n&lt;/style&gt;\n上述两种方式内部其实都是使用的 @font-face 进行了字体的定义。\n我们可以通过 @font-face 快速声明指定一个自定义字体。类似这样：\n@font-face {\n  font-family: &quot;Open Sans&quot;;\n  src: url(&quot;/fonts/OpenSans-Regular-webfont.woff2&quot;) format(&quot;woff2&quot;),\n       url(&quot;/fonts/OpenSans-Regular-webfont.woff&quot;) format(&quot;woff&quot;);\n}\n这样，利用 Google Font，我们就可以便捷的享受各种字体了。接下来，就会分门别类的看看，文字在 CSS 中，和不同属性相结合，能够鼓捣出什么样的效果。\n长阴影文字效果\n通过多层次，颜色逐渐变化（透明）的阴影变化，可以生成长阴影：\ndiv {\n  text-shadow: 0px 0px #992400, 1px 1px rgba(152, 36, 1, 0.98), 2px 2px rgba(151, 37, 2, 0.96), 3px 3px rgba(151, 37, 2, 0.94), 4px 4px rgba(150, 37, 3, 0.92), 5px 5px rgba(149, 38, 4, 0.9), 6px 6px rgba(148, 38, 5, 0.88), 7px 7px rgba(148, 39, 5, 0.86), 8px 8px rgba(147, 39, 6, 0.84), 9px 9px rgba(146, 39, 7, 0.82), 10px 10px rgba(145, 40, 8, 0.8), 11px 11px rgba(145, 40, 8, 0.78), 12px 12px rgba(144, 41, 9, 0.76), 13px 13px rgba(143, 41, 10, 0.74), 14px 14px rgba(142, 41, 11, 0.72), 15px 15px rgba(142, 42, 11, 0.7), 16px 16px rgba(141, 42, 12, 0.68), 17px 17px rgba(140, 43, 13, 0.66), 18px 18px rgba(139, 43, 14, 0.64), 19px 19px rgba(138, 43, 15, 0.62), 20px 20px rgba(138, 44, 15, 0.6), 21px 21px rgba(137, 44, 16, 0.58), 22px 22px rgba(136, 45, 17, 0.56), 23px 23px rgba(135, 45, 18, 0.54), 24px 24px rgba(135, 45, 18, 0.52), 25px 25px rgba(134, 46, 19, 0.5), 26px 26px rgba(133, 46, 20, 0.48), 27px 27px rgba(132, 47, 21, 0.46), 28px 28px rgba(132, 47, 21, 0.44), 29px 29px rgba(131, 48, 22, 0.42), 30px 30px rgba(130, 48, 23, 0.4), 31px 31px rgba(129, 48, 24, 0.38), 32px 32px rgba(129, 49, 24, 0.36), 33px 33px rgba(128, 49, 25, 0.34), 34px 34px rgba(127, 50, 26, 0.32), 35px 35px rgba(126, 50, 27, 0.3), 36px 36px rgba(125, 50, 28, 0.28), 37px 37px rgba(125, 51, 28, 0.26), 38px 38px rgba(124, 51, 29, 0.24), 39px 39px rgba(123, 52, 30, 0.22), 40px 40px rgba(122, 52, 31, 0.2), 41px 41px rgba(122, 52, 31, 0.18), 42px 42px rgba(121, 53, 32, 0.16), 43px 43px rgba(120, 53, 33, 0.14), 44px 44px rgba(119, 54, 34, 0.12), 45px 45px rgba(119, 54, 34, 0.1), 46px 46px rgba(118, 54, 35, 0.08), 47px 47px rgba(117, 55, 36, 0.06), 48px 48px rgba(116, 55, 37, 0.04), 49px 49px rgba(116, 56, 37, 0.02), 50px 50px rgba(115, 56, 38, 0);\n}\n当然，多重阴影以及每重的颜色我们很难一个一个手动去写，在写长阴影的时候通常需要借助 SASS、LESS 去帮助节省时间：\n@function makelongrightshadow($color) {\n    $val: 0px 0px $color;\n \n    @for $i from 1 through 50 {\n        $color: fade-out(desaturate($color, 1%), .02);\n        $val: #{$val}, #{$i}px #{$i}px #{$color};\n    }\n \n    @return $val;\n}\ndiv {\n    text-shadow: makeLongShadow(hsl(14, 100%, 30%));\n}\n内嵌阴影文字效果\n合理的阴影颜色和背景底色搭配，搭配，可以实现类似内嵌效果的阴影。\ndiv {\n  color: #202020;\n  background-color: #2d2d2d;\n  letter-spacing: .1em;\n  text-shadow: -1px -1px 1px #111111, 2px 2px 1px #363636;\n}\n氖光效果（Neon）\n氖光效果，英文名叫 Neon，是我在 Codepen 上看到的最多的效果之一。它的原理非常简单，却可以产生非常酷炫的效果。\n我们只需要设置 3~n 层阴影效果，每一层的模糊半径（文字阴影的第三个参数）间隔较大，并且每一层的阴影颜色相同即可。\np {\n    color: #fff;\n    text-shadow: \n        0 0 10px #0ebeff,\n        0 0 20px #0ebeff,\n        0 0 50px #0ebeff,\n        0 0 100px #0ebeff,\n        0 0 200px #0ebeff\n}\n合理运用 Neon 效果，就可以制作非常多有意思的动效。譬如作用于鼠标 hover 上去的效果：\np {\n    transition: .2s;\n    &amp;:hover {\n        text-shadow: \n            0 0 10px #0ebeff, \n            0 0 20px #0ebeff, \n            0 0 50px #0ebeff, \n            0 0 100px #0ebeff, \n            0 0 200px #0ebeff;\n    }\n}\n文字与背景\nCSS 中的背景 background，也提供了一些属性用于增强文字的效果。\nbackground-clip 与文字\n背景中有个属性为 background-clip， 其作用就是设置元素的背景（背景图片或颜色）的填充规则。\n与 box-sizing 的取值非常类似，通常而言，它有 3 个取值，border-box，padding-box，content-box，后面规范新增了一个 background-clip。时至今日，部分浏览器仍需要添加前缀 webkit 进行使用 -webkit-background-clip。\n使用了这个属性的意思是，以区块内的文字作为裁剪区域向外裁剪，文字的背景即为区块的背景，文字之外的区域都将被裁剪掉。\n看个最简单的 Demo ，没有使用 background-clip:text :\n&lt;div&gt;Clip&lt;/div&gt;\n \n&lt;style&gt;\ndiv {\n  font-size: 180px;\n  font-weight: bold;\n  color: deeppink;\n  background: url($img) no-repeat center center;\n  background-size: cover;\n}\n&lt;/style&gt;\n看到这里，可能有人就纳闷了，这不就是文字设置 color 属性嘛。\n别急，由于文字设置了颜色，挡住了 div 块的背景，如果将文字设置为透明呢？文字是可以设置为透明的 color: transparent 。\ndiv {\n  color: transparent;\n  background-clip: text;\n}\n通过将文字设置为透明，原本 div 的背景就显现出来了，而文字以外的区域全部被裁剪了，这就是 background-clip:text 的作用。\n利用 background-clip 实现渐变文字\n再者，利用这个属性，也可以轻松的实现渐变色的文字：\n{\n    background: linear-gradient(45deg, #009688, yellowgreen, pink, #03a9f4, #9c27b0, #8bc34a);\n    background-clip: text;\n}\n配合 background-position 或者 filter: hue-rotate()，让渐变动起来：\n{\n    background: linear-gradient(45deg, #009688, yellowgreen, pink, #03a9f4, #9c27b0, #8bc34a);\n    background-clip: text;\n    animation: huerotate 5s infinite;\n}\n \n@keyframes huerotate {\n    100% {\n        filter: hue-rotate(360deg);\n    }\n}\n利用 background-clip 给文字增加高光动画\n利用 background-clip， 我们还可以轻松的给文字增加高光动画。\n其本质也是利用了 background-clip，伪代码如下：\n&lt;p data-text=&quot;Lorem ipsum dolor&quot;&gt; Lorem ipsum dolor &lt;/p&gt;\np {\n    position: relative;\n    color: transparent;\n    background-color: #E8A95B;\n    background-clip: text;\n}\np::after {\n    content: attr(data-text);\n    position: absolute;\n    left: 0;\n    top: 0;\n    width: 100%;\n    height: 100%;\n    background-image: linear-gradient(120deg, transparent 0%, transparent 6rem, white 11rem, transparent 11.15rem, transparent 15rem, rgba(255, 255, 255, 0.3) 20rem, transparent 25rem, transparent 27rem, rgba(255, 255, 255, 0.6) 32rem, white 33rem, rgba(255, 255, 255, 0.3) 33.15rem, transparent 38rem, transparent 40rem, rgba(255, 255, 255, 0.3) 45rem, transparent 50rem, transparent 100%);\n    background-clip: text;\n    background-size: 150% 100%;\n    background-repeat: no-repeat;\n    animation: shine 5s infinite linear;\n}\n@keyframes shine {\n\t0% {\n\t\tbackground-position: 50% 0;\n\t}\n\t100% {\n\t\tbackground-position: -190% 0;\n\t}\n}\n去掉伪元素的 background-clip: text，就能看懂原理；\nmask 与文字\n还有一个与背景相关的属性 — mask 。\n只需要记住核心的，使用 mask 最重要结论就是：添加了 mask 属性的元素，其内容会与 mask 表示的渐变的 transparent 的重叠部分，并且重叠部分将会变得透明。\n利用 mask，我们可以实现各种文字的出场特效：\n&lt;div&gt;\n    &lt;p&gt;Hello MASK&lt;/p&gt;\n&lt;/div&gt;\n核心的 CSS 代码：\ndiv {\n    mask: radial-gradient(circle at 50% 0%, #000, transparent 30%);\n    animation: scale 6s infinite;\n}\n@keyframes scale {\n    0% {\n        mask-size: 100% 100%;\n    }\n    60%,\n    100% {\n        mask-size: 150% 800%;\n    }\n}\n文字与混合模式(mix-blend-mode)及滤镜(filter)\n接下来，就到了非常有意思的混合模式及滤镜了。这两个属性给 CSS 世界增添了非常多的趣味性，活灵活用，会感叹 CSS 居然如此的强大美妙。\n之前有多非常多篇关于混合模式及滤镜的文章，一些基础的用法就不再赘述。\n给文字添加边框，生成镂空文字\n在 CSS 中，我们可以利用 -webkit-text-stroke，给文字快速的添加边框，利用这个，可以快速生成镂空型的文字：\np {\n    -webkit-text-stroke: 3px #373750;\n}\n当然，我们看到，用到的属性 -webkit-text-stroke 带了 webkit 前缀，存在一定的兼容性问题。\n所以，在更早的时候，我们还会使用 text-shadow，生成镂空文字。\np {\n    text-shadow: 0 0 5px #fff;\n}\n可以看到，因为使用的是阴影，所以有很明显的虚化的感觉，存在一定的瑕疵。\n还有一种非常绕的方法，利用混合模式加上滤镜，也能生成镂空文字。\np {\n    position: relative;\n    color: #fff;\n \n    &amp;::after {\n        content: &#039;Magic Text&#039;;\n        position: absolute;\n        left: 0;\n        top: 0;\n        color: #fff;\n        mix-blend-mode: difference;\n        filter: blur(1px);\n    }\n}\n这里利用 filter: blur(1px) 生成了一个比原字体稍微大一点点的字体覆盖在原字体之上，再利用 mix-blend-mode: difference 消除掉了同色的部分，只留下了利用模糊滤镜多出来的那一部分。\n\nmix-blend-mode: difference: 差值模式（Difference），作用是查看每个通道中的颜色信息，比较底色和绘图色，用较亮的像素点的像素值减去较暗的像素点的像素值。与白色混合将使底色反相；与黑色混合则不产生变化。\n\n利用混合模式，生成渐变色镂空文字\n好，回到上面的 -webkit-text-stroke，拿到了镂空文字后，我们还可以利用混合模式 mix-blend-mode: multiply 生成渐变色的文字。\n\nmix-blend-mode: multiply: 正片叠底（multiply），将两个颜色的像素值相乘，然后除以255得到的结果就是最终色的像素值。通常执行正片叠底模式后的颜色比原来两种颜色都深。任何颜色和黑色正片叠底得到的仍然是黑色，任何颜色和白色执行正片叠底则保持原来的颜色不变，而与其他颜色执行此模式会产生暗室中以此种颜色照明的效果。\n\np {\n    position: relative;\n    -webkit-text-stroke: 3px #9a9acc;\n \n    &amp;::before{\n\t\tcontent: &#039; &#039;;\n\t\twidth: 100%;\n\t\theight: 100%;\n\t\tposition: absolute;\n\t\tleft: 0;\n\t\ttop: 0;\n\t\tbackground-image: linear-gradient(45deg, #ff269b, #2ab5f5, #ffbf00);\n\t\tmix-blend-mode: multiply;\n\t}\n}\n在这里，mix-blend-mode: multiply 发挥的作用和 mask 非常的类似，我们其实是生成了一幅渐变图案，但是只有在文字轮廓内，渐变颜色才会显现。\n利用混合模式，生成光影效果文字\nOK，在上述的基础上，我们可以继续叠加混合模式，这次我们利用剩余的一个 ::after 伪类，再添加一个 mix-blend-mode: color-dodge 混合模式，给文字加上最后的点缀，实现美妙的光影效果。\n\nmix-blend-mode: color-dodge: 颜色减淡模式（Color Dodge），查看每个通道的颜色信息，通过降低“对比度”使底色的颜色变亮来反映绘图色，和黑色混合没变化。。\n\n核心的伪代码：\np {\n    position: relative;\n    -webkit-text-stroke: 3px #7272a5;\n \n    &amp;::before {\n\t\tcontent: &#039; &#039;;\n\t\tbackground-image: linear-gradient(45deg, #ff269b, #2ab5f5, #ffbf00);\n\t\tmix-blend-mode: multiply;\n    }\n \n    &amp;::after {\n        content: &quot;&quot;;\n        position: absolute;\n        background: radial-gradient(circle, #fff, #000 50%);\n        background-size: 25% 25%;\n        mix-blend-mode: color-dodge;\n        animation: mix 8s linear infinite;\n    }\n}\n \n@keyframes mix {\n    to {\n        transform: translate(50%, 50%);\n    }\n}\n利用混合模式实现文字与底色反色的效果\n这里还是利用 mix-blend-mode: difference 差值模式，实现一种文字与底色反色的 Title 效果。\n\nmix-blend-mode: difference: 差值模式（Difference），作用是查看每个通道中的颜色信息，比较底色和绘图色，用较亮的像素点的像素值减去较暗的像素点的像素值。与白色混合将使底色反相；与黑色混合则不产生变化。\n\n代码非常的简单，我们实现一个黑白相间的背景，文本的颜色为白色，配合上差值模式，即可实现黑底上的文字为白色，白底上的文字为黑色的效果。\np  {\n    background: repeating-radial-gradient(circle at 200% 200%, #000 0, #000 150px, #fff 150px, #fff 300px);\n \n    &amp;::before {\n        content: &quot;LOREM IPSUM&quot;;\n        color: #fff;\n        mix-blend-mode: difference;\n    }\n}\n利用混合模式实现动态类抖音风格 Glitch 效果\nOK，接下来，我们再尝试下其他混合模式的搭配。在 CSS 故障艺术 一文中，提到了一种故障艺术。\n什么是故障艺术？我们熟知的抖音的 LOGO 正是故障艺术其中一种表现形式。它有一种魔幻的感觉，看起来具有闪烁、震动的效果，很吸引人眼球。\n关键点\n\n利用 mix-blend-mode: lighten 混合模式实现两段文字结构重叠部分为白色\n利用元素位移完成错位移动动画，形成视觉上的冲击效果\n\n本文篇幅有点长，代码就不上了，完整 DEMO 在这里：\n类抖音 LOGO 文字故障效果\n当然，我们也不是一定要使用混合模式去使得融合部分为白色，可以仅仅是使用这个配色效果，基于上面效果的另外一个版本，没有使用混合模式。\n关键点\n\n利用了伪元素生成了文字的两个副本\n视觉效果由位移、遮罩、混合模式完成\n配色借鉴了抖音 LOGO 的风格\n\nGlitch Art 风格的 404 效果\n稍微替换一下文本文案为 404，再添加上一些滤镜效果（hue-rotate()、blur()）嘿嘿，找到了一个可能实际可用的场景，两个 404 效果的 Demo 如下：\n\nCodePen — CSS 404故障效果\nCodePen — 404故障效果\n\n\n小技巧，在使用混合模式的时，有的时候，效果不希望和背景混合在一起，可以使用 isolation: isolate 进行隔离。\n\n使用滤镜生成文字融合效果\n在 你所不知道的 CSS 滤镜技巧与细节 一文中，介绍了利用滤镜实现的一种融合效果。\n利用了模糊滤镜叠加文字与 SVG\n最后，我们再来看看文字与 SVG。\n在 SVG 与 CSS 的搭配中，有一类非常适合拿来做动画的属性，也就是 stroke-* 相关的几个属性，利用它们，我们只需要掌握简单的 SVG 语法，就可以快速制作相关的线条动画。\n我们利用 SVG 中几个和边框、线条相关的属性，来实现文字的线条动画，下面罗列一下，其实大部分和 CSS 对比一下非常好理解，只是换了个名字：\n\nstroke-width：类比 css 中的 border-width，给 svg 图形设定边框宽度；\nstroke：类比 css 中的 border-color，给 svg 图形设定边框颜色；\nstroke-linejoin | stroke-linecap：设定线段连接处的样式；\nstroke-dasharray：值是一组数组，没数量上限，每个数字交替表示划线与间隔的宽度；\nstroke-dashoffset：则是虚线的偏移量\n\n\n具体的更深入的介绍，可以看看这篇：【Web动画】SVG 线条动画入门\n\n线条文字动画\n接下来，我们利用 stroke-* 相关属性，实现一个简单的线条文字动画。\n&lt;svg viewBox=&quot;0 0 400 200&quot;&gt;\n\t&lt;text x=&quot;0&quot; y=&quot;70%&quot;&gt; Lorem &lt;/text&gt;\n&lt;/svg&gt;\t\nsvg text {\n\tanimation: stroke 5s infinite alternate;\n\tletter-spacing: 10px;\n\tfont-size: 150px;\n}\n@keyframes stroke {\n\t0% {\n\t\tfill: rgba(72, 138, 20, 0);\n\t\tstroke: rgba(54, 95, 160, 1);\n\t\tstroke-dashoffset: 25%;\n\t\tstroke-dasharray: 0 50%;\n\t\tstroke-width: 1;\n\t}\n\t70% {\n\t\tfill: rgba(72, 138, 20, 0);\n\t\tstroke: rgba(54, 95, 160, 1);\n\t\tstroke-width: 3;\n\t}\n\t90%,\n\t100% {\n\t\tfill: rgba(72, 138, 204, 1);\n\t\tstroke: rgba(54, 95, 160, 0);\n\t\tstroke-dashoffset: -25%;\n\t\tstroke-dasharray: 50% 0;\n\t\tstroke-width: 0;\n\t}\n}\n\n动画的核心就是，利用动态变化文字的 stroke-dasharray 和 stroke-dashoffset 形成视觉上的线条变换，动画的最后再给文字上色。看看效果：对比度滤镜产生的融合效果。\n单独将两个滤镜拿出来，它们的作用分别是：\n\nfilter: blur()： 给图像设置高斯模糊效果。\nfilter: contrast()： 调整图像的对比度。\n\n但是，当他们“合体”的时候，产生了奇妙的融合现象。\n文字与 SVG\n最后，我们再来看看文字与 SVG。\n在 SVG 与 CSS 的搭配中，有一类非常适合拿来做动画的属性，也就是 stroke-* 相关的几个属性，利用它们，我们只需要掌握简单的 SVG 语法，就可以快速制作相关的线条动画。\n我们利用 SVG 中几个和边框、线条相关的属性，来实现文字的线条动画，下面罗列一下，其实大部分和 CSS 对比一下非常好理解，只是换了个名字：\n\nstroke-width：类比 css 中的 border-width，给 svg 图形设定边框宽度；\nstroke：类比 css 中的 border-color，给 svg 图形设定边框颜色；\nstroke-linejoin | stroke-linecap：设定线段连接处的样式；\nstroke-dasharray：值是一组数组，没数量上限，每个数字交替表示划线与间隔的宽度；\nstroke-dashoffset：则是虚线的偏移量\n\n\n具体的更深入的介绍，可以看看这篇：【Web动画】SVG 线条动画入门\n\n线条文字动画\n接下来，我们利用 stroke-* 相关属性，实现一个简单的线条文字动画。\n&lt;svg viewBox=&quot;0 0 400 200&quot;&gt;\n\t&lt;text x=&quot;0&quot; y=&quot;70%&quot;&gt; Lorem &lt;/text&gt;\n&lt;/svg&gt;\t\nsvg text {\n\tanimation: stroke 5s infinite alternate;\n\tletter-spacing: 10px;\n\tfont-size: 150px;\n}\n@keyframes stroke {\n\t0% {\n\t\tfill: rgba(72, 138, 20, 0);\n\t\tstroke: rgba(54, 95, 160, 1);\n\t\tstroke-dashoffset: 25%;\n\t\tstroke-dasharray: 0 50%;\n\t\tstroke-width: 1;\n\t}\n\t70% {\n\t\tfill: rgba(72, 138, 20, 0);\n\t\tstroke: rgba(54, 95, 160, 1);\n\t\tstroke-width: 3;\n\t}\n\t90%,\n\t100% {\n\t\tfill: rgba(72, 138, 204, 1);\n\t\tstroke: rgba(54, 95, 160, 0);\n\t\tstroke-dashoffset: -25%;\n\t\tstroke-dasharray: 50% 0;\n\t\tstroke-width: 0;\n\t}\n}\n动画的核心就是，利用动态变化文字的 stroke-dasharray 和 stroke-dashoffset 形成视觉上的线条变换，动画的最后再给文字上色。\nCodePen Demo — SVG Text Line Effect"},"front-end/css/basic-css-text/baseline/index":{"title":"index","links":[],"tags":[],"content":"基本介绍\nvertical-align用来指定行内元素（inline）或表格单元格（table-cell）元素的垂直对齐方式，且支持很多属性值：\n/* 关键字值 */\nvertical-align: baseline;\nvertical-align: sub;\nvertical-align: super;\nvertical-align: text-top;\nvertical-align: text-bottom;\nvertical-align: middle;\nvertical-align: top;\nvertical-align: bottom;\n \n/* &lt;长度&gt; 值 */\nvertical-align: 10em;\nvertical-align: 4px;\n \n/* &lt;百分比&gt; 值 */\nvertical-align: 10%;\n\n常见的内联元素有a、span、em、br、strong、i、img、input 等；\n\n断背基友\nvertical-align的百分比值不是相对于字体大小或者其他什么属性计算的，而是相对于line-height计算的。\n基本现象\n举个例子：\n{\n  line-height: 30px;\n  vertical-align: -10%;\n}\n/* 实际上，等价于 */\n{\n  line-height: 30px;\n  vertical-align: -3px;    /* = 30px * -10% */  \n}\n我们不妨从一个极其简单的现象入手。假设，我们有一个&lt;div&gt;标签，然后，里面有一张&lt;img&gt;图片：\n&lt;div&gt;&lt;img src=&quot;img/mahoo.png&quot;&gt;&lt;/div&gt;\n如果我们给这个&lt;div&gt;元素增加一个背景色，例如淡蓝色：\n&lt;div style=&quot;background-color:#e5edff;&quot;&gt;&lt;img src=&quot;img/mahoo.png&quot;&gt;&lt;/div&gt;\n会发现图片下面有一段空白空间，实际上，这段空白间隙就是vertical-align和line-height携手搞的鬼！\n首先，大家一定要意识到这么一点：对于内联元素，vertical-align与line-height虽然看不见，但实际上「到处都是」！\n因此，对于内联元素各种想得通或者想不通的行为表现，基本上都可以用vertical-align和line-height来解释。\n幽灵空白节点\n原作者自命名，学习原则： 1.情感化认知；2. 具象化思维。\n「幽灵空白节点」是个什么意思呢？\n在HTML5文档声明下，块状元素内部的内联元素的行为表现，就好像块状元素内部还有一个（更有可能两个-前后）看不见摸不着没有宽度没有实体的空白节点，这个假想又似乎存在的空白节点，我称之为“幽灵空白节点”。\n抽象了这个概念，绝对定位与text-align的一些行为表现，以及这里的行为表现，就好理解了。\n上述的图片下的间隙的例子，实际上，这种行为表现，就跟图片前面或者后面有一个宽度为0的空格元素表现是一致的。但是，空格是透明的，为了便于大家理解，我就直接使用很明显的匿名 inline box, 也就是字符代替。如下，大家会发现，图片下面的间隙，依旧是那个间隙。\n&lt;div style=&quot;background-color: #e5edff&quot;&gt;\n    &lt;img src=&quot;img/mahoo.png&quot; /&gt;mahoo\n&lt;/div&gt;\n下面要解释这个间隙就好解释了。下面，我们让新增的文本inline-block化，然后弄个白色背景，显示其占据的高度。\n会发现，图片下面的间隙，依旧是那个间隙。但是，我们的理解就好理解了。回答下面几个问题，我们就知道表现的原因了：\n\nvertical-align默认的对齐方式是？\n后面文字的高度从何而来？\n\n\nvertical-align默认值是baseline, 也就是基线对齐。而基线是什么，基线就是字母X的下边缘；所以图片的下边缘就和后面文字中的字母x下边缘对齐。而字符本身是有高度的，对吧，于是，图片下面就留空了。\n文字的高度是由行高决定的。\n\n因此，简单的图片下面留白行为表现，本质上，就是vertical-align和line-height背地里搞基造成的。\n知道了问题的原因，我们就可以对症下药，准确搞定图片下面我们不希望看到的间隙。怎么搞呢？一对基友，vertical-align和line-height我们随便搞定一个就可以了。\n1. 让vertical-align失效\n图片默认是inline水平的，而vertical-align对块状水平的元素无感。因此，我们只要让图片display水平为block就可以了，我们可以直接设置display或者浮动、绝对定位等（如果布局允许）。例如：\nimg { display: block; }\n2. 使用其他vertical-align值\n告别baseline, 取用其他属性值，比方说bottom/middle/top都是可以的。\n3. 直接修改line-height值\n下面的空隙高度，实际上是文字计算后的行高值和字母x下边缘的距离。因此，只要行高足够小，实际文字占据的高度的底部就会在x的上面，下面没有了高度区域支撑，自然，图片就会有容器底边贴合在一起了。比方说，我们设置行高5像素：\ndiv { line-height: 5px; }\n4. line-height为相对单位，font-size间接控制\n如果line-height是相对单位，例如line-height:1.6或者line-height:160%之类，也可以使用font-size间接控制，比方说来个狠的，font-size设为大鸡蛋0, 本质上还是改变line-height值.\ndiv { font-size: 0; }\n5. 基本现象衍生：垂直居中\n由于「幽灵空白节点」的存在，因此，我们可以进一步衍生，实现其他更实用的效果，比方说任意尺寸的图片（或者内联块状化的多行文字）的垂直居中效果。就是借助本文的两位男主角，vertical-align和line-height。\n你想啊，图片后面（前面）有个类似空格字符的节点，然后就能响应line-height形成高度，此时，图片再来个vertical-align:middle，就可以和这个被行高撑高的「幽灵空白节点」(近似)垂直对齐了。\n而这样只是近似居中，那是因为「幽灵空白节点」高度行高撑开，其垂直中心是字符 content area 的中心，而对于字符x而言，都是比绝对中心位置要下沉的（不同字体下沉幅度不一样），换句更易懂的描述就是x的中心位置都是在字符内容区域高度中心点的下方，而这上下的偏差就是这里图片上下间距的偏差。\n换句更简单的话说就是：middle中线位置(字符x的中心)并不是字符内容的绝对居中位置。两个位置的偏差就是图片近似居中的偏差。\n因此，要想完全垂直居中，最先想到的方法就是让后面的“幽灵字符”也是vertical-align:middle，然而，呵呵，既然称之为“幽灵”就表示不会受非继承特性的属性影响，所以，根本没法设置vertical-align:middle，除非你自己创建一个显示的内联元素。\n我们就没有办法了吗？当然不是，“幽灵字符”可以受具有继承特性的CSS属性影响，于是，我们可以通过其他东西来做调整，让字符的中线和字符内容中心线在一起，或者说在一个位置上就可以了。有人可能要疑问了，这能行吗？啊，是可以的。\n怎么搞？很简单，font-size:0, 因此此时 content area 高度是0，各种乱七八糟的线都在高度为 0 的这条线上，绝对中心线和中线重合，自然全垂直居中。\ndiv { line-height: 240px; font-size: 0; }\nimg { vertical-align: middle; }\ninline-block 和 baseline\nCSS2的可视化格式模型文档中有一么一段话：\n\nThe baseline of an ‘inline-block’ is the baseline of its last line box in the normal flow, unless it has either no in-flow line boxes or if its ‘overflow’ property has a computed value other than ‘visible’, in which case the baseline is the bottom margin edge.\n\n英文看得眼睛大，于是我中文直译了下：\n\n‘inline-block’的基线是正常流中最后一个line box的基线, 除非，这个line box里面既没有line boxes或者本身’overflow’属性的计算值而不是’visible’, 这种情况下基线是margin底边缘。\n\n这段文档中出现了很多专有名词line box, line boxes等，这些是内联盒子模型中的概念，是CSS进阶必备知识。"},"front-end/css/basic-css-text/font/README":{"title":"README","links":[],"tags":[],"content":"\nWeb 字体 font-family 再探秘 · Issue #69 · chokcoco/iCSS (github.com)\n谈谈一些有趣的CSS题目（16）— 你该知道的字体 font-family · Issue #6 · chokcoco/iCSS (github.com)\n\n各大网站最新 font-family\n作为前端的一个习惯，浏览各个网站的时候总是喜欢打开开发者工具时不时审查元素一下。看了一下一些比较出名的网站移动端的 font-family：\n\n天猫：font-family: &quot;PingFang SC&quot;,miui,system-ui,-apple-system,BlinkMacSystemFont,Helvetica Neue,Helvetica,sans-serif;\nGithub：font-family: -apple-system,BlinkMacSystemFont,Segoe UI,Helvetica,Arial,sans-serif,Apple Color Emoji,Segoe UI Emoji,Segoe UI Symbol;\nCSS-Tricks：font-family: system-ui,-apple-system,BlinkMacSystemFont,segoe ui,Roboto,Helvetica,Arial,sans-serif,apple color emoji,segoe ui emoji,segoe ui symbol;\n\n很有意思的是，类似 system-ui，-apple-system，BlinkMacSystemFont 等等早几年在 font-family 中几乎见不到的字体定义如今已经很普遍了。它们是什么呢？是一种特定的字体吗？\n字体的分类\n就 Web 常用的一些字体而言，经常听说的字体类型，大致可以分为这几种：\n\nserif(衬线)\nsans-serif(无衬线)\nmonospace(等宽)\nfantasy(梦幻)\ncuisive(草体)\n\n其实大体上分为衬线字体和无衬线字体，等宽字体中也有衬线等宽和无衬线等宽字体，这 5 个分类是 font-family 的 5 个可用字体系列取值。\n也就是说，上述 5 个名字，代表的并非某个特定字体，而是一系列字体，这些通用的名称允许用户代理（通常就是浏览器）从相应集合中选择一款字体。\n这也很好解释了，font-family 中的 family ，家庭的意思，也就是不单单指一个，而是可以指定多个，上述 5 个英文单词都是 font-family 的可用取值，下文还会详细讲到。\n下面详细了解一下每类字体。\nserif — 衬线字体\nserif，意为有衬线的字体，衬线的意思是在字符笔画末端有叫做衬线的小细节的额外装饰，而且笔画的粗细会有所不同，这些细节在大写字母中特别明显。\nOK，那么有哪些常用字体属于衬线字体呢？\n宋体（SimSun）\nWindows 下大部分浏览器的默认中文字体，是为适应印刷术而出现的一种汉字字体。笔画有粗细变化，是一种衬线字体，宋体在小字号下的显示效果还可以接受，但是字号一大体验就很差了，所以使用的时候要注意，不建议做标题字体使用。\nTimes New Roman\nMac 平台 Safari 下默认的英文字体，是最常见且广为人知的西文衬线字体之一，众多网页浏览器和文字处理软件都是用它作为默认字体。\nsans-serif — 无衬线字体\nsans 的意思是无，sans-serif 也就是无衬线的意思。专指西文中没有衬线的字体，与汉字字体中的黑体相对应。与衬线字体相反，该类字体通常是机械的和统一线条的，它们往往拥有相同的曲率，笔直的线条，锐利的转角。\n中文下，无衬线字体就是黑体，黑体字也就是又称方体或等线体，没有衬线装饰，字形端庄，笔画横平竖直，笔迹全部一样粗细。\n看看又有哪些常见的无衬线字体。\n微软雅黑（Microsoft Yahei）\n大名鼎鼎的微软雅黑相信都不陌生，从 windows Vista 开始，微软提供了这款新的字体，一款无衬线的黑体类字体，显著提高了字体的显示效果。现在这款字体已经成为 windows 浏览器最值得使用的中文字体。\n华文黑体（STHeiti）、华文细黑（STXihei）\n属于同一字体家族系列，MAC OS X 10.6 之前的简体中文系统界面的默认中文字体，正常粗细就是华文细黑，粗体下则是华文黑体。\n黑体-简（Heiti SC）\n从 MAC OS X 10.6 开始，黑体-简代替华文黑体用作简体中文系统界面默认字体，苹果生态最常用的字体之一，包括 iPhone、iPad 等设备用的也是这款字体。\n冬青黑体（Hiragino Sans GB）\n又叫苹果丽黑，Hiragino 是字游工房设计的系列字体名称。是一款清新的专业印刷字体，小字号时足够清晰，Mac OS X 10.6 开始自带有 W3 和 W6 。\nHelvetica、Helvetica Neue\n被广泛用于全世界使用拉丁字母和西里尔字母的国家。Helvetica 是苹果电脑的默认字体，微软常用的 Arial 字体也来自于它。\nArial\nWindows 平台上默认的无衬线西文字体，有多种变体，比例及字重（weight）和 Helvetica 极为相近。\nVerdana\n无衬线字体，优点在于它在小字上仍结构清晰端整、阅读辨识容易。\nTahoma\n十分常见的无衬线字体，字体结构和 Verdana 很相似，其字元间距较小，而且对 Unicode 字集的支持范围较大。许多不喜欢 Arial 字体的人常常会改用 Tahoma 来代替，除了是因为 Tahoma 很容易取得之外，也是因为 Tahoma 没有一些 Arial 为人诟病的缺点，例如大写“i”与小写“L”难以分辨等（这里故意反过来写）。\nmonospace — 等宽字体\n这系列字体程序员们其实都不陌生。我们用来敲代码的编辑器，字体的选择经常就是一类等宽字体。\n等宽字体是指字符宽度相同的电脑字体，常见于 IDE 或者编辑器中，每个字母的宽度相等，通常用于计算机相关书籍中排版代码块。\n除了 IDE ，我们看到的技术文章中的代码块中，经常也是使用等宽字体进行排版。\nConsolas\n这是一套等宽的字体，属无衬线字体。这个字体使用了微软的 ClearType 字型平滑技术，主要是设计做为代码的显示字型之用，特别之处是它的“0”字加入了一斜撇，以方便与字母“O”分辨。\n\nClearType：由微软在其操作系统中提供的屏幕亚像素微调字体平滑工具，让 Windows 字体更加漂亮。在 Windows XP 平台上，这项技术默认是关闭，到了Windows Vista 才默认为开启。\n\nGithub 代码区块的字体设置的默认字体就是 Consolas ，紧接着的几个都是其它等宽字体，如果用户的系统中都没有预装这些字体，则会匹配最后一个 monospace ，它表示等宽字体系列，会从用户系统中的等宽字体中选取一个展示。\nfantasy — 梦幻 和 cuisive — 草体\nfantasy 和 cuisive 字体在浏览器中不常用，在各个浏览器中有明显的差异。\nfont-family 关键字\n对于 CSS 中的 font-family 而言，它有两类取值。\n\n一类是类似这样的具体的字体族名定义：font-family: Arial 这里定义了一个具体的字体样式，字体族名为 Arial;\n一类是通用字体族名，它是一种备选机制，用于在指定的字体不可用时给出较好的字体，类似这样：font-family: sans-serif 。\n\n关于通用字体族名，在 CSS Fonts Module Level 3 — Basic Font Properties 中定义，也就是上文提到的那五个；\n新增通用字体族关键字\n而在 CSS Fonts Module Level 4 — Generic font families 中，新增了几个关键字：\n\nsystem-ui 系统默认字体\nemoji 用于兼容 emoji 表情符号字符\nmath 适用于数学表达式\nfangsong 此字体系列用于中文的（仿宋）字体。\n\n我们看看用的最多的 system-ui。\nsystem-ui\n简单而言，font-family: system-ui 的目的就是在不同的操作系统的 Web 页面下，自动选择本操作系统下的默认系统字体。\n默认使用特定操作系统的系统字体可以提高性能，因为浏览器或者 webview 不必去下载任何字体文件，而是使用已有的字体文件。 font-family: system-ui 字体设置的优势之处在于它与当前操作系统使用的字体相匹配，对于文本内容而言，它可以得到最恰当的展示。\nSan Francisco Fonts\nOK，简单了解了 system-ui 字体族。但是像 -apple-system、BlinkMacSystemFont 没有在最新的标准里出现。它们又代表什么意思呢？\n在此之前，先了解下 San Francisco Fonts 。\nSan Francisco Fonts 又叫旧金山字体，是一款西文字体。随着 iOS 9 更新面世，在 WatchOS 中随 Apple Watch 一起悄然发售，并且还将在 Apple TV 上的新 tvOS 中使用。\nSan Francisco Fonts 在 iOS 系统上用于替代升级另外一款西文字体 Helvetica Neue。Apple 做了一些重要的改变，使其成为平台上更好的， 甚至是完美的西文字体。\n-apple-system/BlinkMacSystemFont\n话说回来。正如每个前端开发人员都知道的那样，将一个功能纳入规范是一回事，将其纳入浏览器又是另一回事。\n幸运的是，system-ui 的普及很快。 Chrome 和 Safari 都可以在各种平台上完全支持它。只有 Mozilla 和 Windows 相对落后。\n而考虑到不同平台及向后兼容，在 macOS 和 iOS 上，我们需要使用 -apple-system 及 BlinkMacSystemFont 来兼容适配 system-ui 标准。\nSegoe UI\nSegoe UI 是 Windows 从 Vista 开始的默认西文字体族，只有西文，不支持汉字，属于无衬线体。\n它也表示一个系列而不是某一款单一字体。使用 font-family: Segoe UI 可以在 Windows 平台及 Windows Phone 上选取最佳的西文字体展示。\nRoboto\nRoboto 是为 Android 操作系统设计的一个无衬线字体家族。Google 描述该字体为“现代的、但平易近人”和“有感情”的。\n这个字体家族包含 Thin、Light、Regular、Medium、Bold、Black 六种粗细及相配的斜体。\n中文字体的兼容写法\n一些中文字体，例如font-family: &#039;宋体&#039;，由于字符编码的问题，少部分浏览器解释这个代码的时候，中文出现乱码，这个时候设定的字体无法正常显示；\n所以通常会转化成对应的英文写法或者是对应的 unicode 编码，font-family:&#039;宋体&#039; → font-family: &#039;\\5b8b\\4f53&#039;；\n\\5b8b\\4f53 是宋体两个中文字的 unicode 编码表示。类似的写法还有：\n\n黑体： \\9ED1\\4F53\n微软雅黑：\\5FAE\\8F6F\\96C5\\9ED1\n华文细黑：\\534E\\6587\\7EC6\\9ED1\n华文黑体：\\534E\\6587\\9ED1\\4F53\n\n\nUnicode编码： 人们希望在一套系统里面能够容纳所有字符，Unicode 编码解决传统的字符编码方案的局限性，每个字符占用 2 字节。这样理论上一共最多可以表示2^16（即65536）个字符。基本满足各种语言的使用。\n\n字体定义的细节\n其他一些小细节也很重要，譬如定义字体的时候，何时需要在字体两端添加引号？像这样：\np{\n    font-family: &#039;Microsoft YaHei&#039;, &#039;黑体-简&#039;, &#039;\\5b8b\\4f53&#039;;\n}\n当字体名字中间有空格，中文名字体及 Unicode 字符编码表示的中文字体，为了保证兼容性，都建议在字体两端添加单引号或者双引号。\n字体定义顺序\n字体定义顺序是一门学问，通常而言，我们定义字体的时候，会定义多个字体或字体系列。举个栗子：\nbody {\n    font-family: tahoma, arial, &#039;Hiragino Sans GB&#039;, &#039;\\5b8b\\4f53&#039;, sans-serif;\n}\n别看短短 5 个字体名，其实其中门道很深。解释一下：\n\n使用 tahoma 作为首选的西文字体，小字号下结构清晰端整、阅读辨识容易；\n用户电脑未预装 tohoma，则选择 arial 作为替代的西文字体，覆盖 windows 和 MAC OS；\nHiragino Sans GB 为冬青黑体，首选的中文字体，保证了 MAC 用户的观看体验；\nWindows 下没有预装冬青黑体，则使用 &#039;\\5b8b\\4f53&#039; 宋体为替代的中文字体方案，小字号下有着不错的效果；\n最后使用无衬线系列字体 sans-serif 结尾，保证旧版本操作系统用户能选中一款电脑预装的无衬线字体，向下兼容。\n\n嗯，其实上面的 font-family 就是淘宝首页 body 的字体定义，非常的规范，每一个字体的定义都有它的意义。\n再以 CSS-Tricks 网站的 font-family 定义为例子：\n{\n  font-family: \n    system-ui,-apple-system,BlinkMacSystemFont,segoe ui,Roboto,\n    Helvetica,Arial,\n    sans-serif,apple color emoji,segoe ui emoji,segoe ui symbol;\n}\n\n\nsystem-ui，使用各个支持平台上的默认系统字体\n-apple-system， 在一些稍低版本 Mac OS X 和 iOS 上，它针对旧版上的 Neue Helvetica 和 Lucida Grande 字体，升级使用更为合适的 San Francisco Fonts\nBlinkMacSystemFont，针对一些 Mac OS X 上的 Chrome 浏览器，使用系统默认字体\nsegoe ui，在 Windows 及 Windows Phone 上选取系统默认字体\nRoboto，面向 Android 和一些新版的的 Chrome OS\nHelvetica,Arial，在针对不同操作系统不同平台设定采用默认系统字体后，针对一些低版本浏览器的降级方案\nsans-serif，兜底方案，保证字体风格统一，至少也得是无衬线字体\n\n上述 5 个字体族定义，优先级由高到底，可以看到，它们 5 个都并非某个特定字体，基本的核心思想都是选择对应平台上的默认系统字体。\n涵盖了 iOS、MAC OS X、Android、Windows、Windows Phone 基本所有用户经常使用的主流操作系统。\n使用系统默认字体的主要原因是性能。字体通常是网站上加载的最大/最重的资源之一。如果我们可以使用用户机器上已有的字体，我们就完全不需要再去获取字体资源，从而使加载时间明显加快。\n并且系统字体的优点在于它与当前操作系统使用的相匹配，因此它的文本展示必然也是一个让人舒适展示效果。\n字体书写规则\n综上，总结一下，我觉得字体 font-family 定义的原则大概遵循：\n1、尽量使用系统默认字体\n使用系统默认字体的主要原因是性能，并且系统字体的优点在于它与当前操作系统使用的相匹配，因此它的文本展示必然也是一个让人舒适展示效果。\n2、兼顾中西、西文在前，中文在后\n中文或者西文（英文）都要考虑到。由于大部分中文字体也是带有英文部分的，但是英文部分又不怎么好看，同理英文字体中大多不包含中文。\n所以通常会先进行英文字体的声明，选择最优的英文字体，这样不会影响到中文字体的选择，中文字体声明则紧随其次。\n3、兼顾多操作系统\n选择字体的时候要考虑多操作系统。例如 MAC OS 下的很多中文字体在 Windows 都没有预装，为了保证 MAC 用户的体验，在定义中文字体的时候，先定义 MAC 用户的中文字体，再定义 Windows 用户的中文字体；\n4、兼顾旧操作系统，以字体族系列 serif 和 sans-serif 结尾\n当使用一些非常新的字体时，要考虑向下兼容，兼顾到一些极旧的操作系统，使用字体族系列 serif 和 sans-serif 结尾总归是不错的选择。"},"front-end/css/basic-css-variable/README":{"title":"README","links":[],"tags":[],"content":"CSS 自定义属性（CSS Variable）\n\n原文链接：谈谈一些有趣的CSS题目（13）— 引人瞩目的 CSS 自定义属性（CSS Variable） · Issue #58 · chokcoco/iCSS (github.com)\n\nCSS 自定义属性，顾名思义，也就是由网页的作者或用户定义的实体，用来指定文档中的特定变量；\n常称作CSS 变量，但是，更准确的说法，应该称之为 CSS 自定义属性；\n// 声明一个变量：\n:root{\n  --bgColor:#000;\n}\n\n:root 伪类匹配文档树的根元素；应用到HTML，:root 即表示为&lt;html&gt;元素，除了优先级更高外，相当于 html 标签选择器；\n\n可通过[“CSS Variables” | Can I use… Support tables for HTML5, CSS3, etc](caniuse.com/ Variables)查看浏览器具体支持；\nCSS 变量的层叠与作用域\nCSS 变量在局部定义的变量会覆盖祖先元素的定义，也就是作用域：\n\n在 CSS 中，一个元素的实际属性是由其自身属性以及其祖先元素的属性层叠得到的，CSS 变量也支持层叠的特性，当一个属性没有在当前元素定义，则会转而使用其祖先元素的属性。在当前元素定义的属性，将会覆盖祖先元素的同名属性。\n\n:root{\n  --mainColor:red;\n}\n \ndiv{\n  --mainColor:blue;\n  color:var(--mainColor);\n}\n\n注意的是 CSS 变量并不支持 !important 声明\n\nCSS 变量的组合\nCSS 变量也可以进行组合使用：\n:root{\n  --word:&quot;this&quot;;\n  --word-second:&quot;is&quot;;\n  --word-third:&quot;CSS Variable&quot;;\n}\n \ndiv::before{\n  content:var(--word)&#039; &#039;var(--word-second)&#039; &#039;var(--word-third);\n}\nCSS 变量与计算属性 calc( )\nCSS 变量可以结合 CSS3 新增的函数 calc( ) 一起使用：\n:root{\n  --margin: 10px;\n}\n \ndiv{\n  text-indent: calc(var(--margin)*10)\n}\nCSS 变量的用途\n1、代码更加符合 DRY（Don‘t repeat yourself）原则\n现在 CSS 也能像SASS，LESS中一样使用通过定义变量，避免重复定义属性：\n:root{\n  --mainColor:#fc0;\n}\n// 多个需要使用到的 --mainColor 的地方\n.div1{\n  color: var(--mainColor);\n}\n.div2{\n  color: var(--mainColor);\n}\n2、精简代码，减少冗余，响应式媒体查询的好帮手\n一般而言，使用媒体查询的时候，我们需要将要响应式改变的属性全部重新罗列一遍：\n.main {\n\twidth: 1000px;\n\tmargin-left: 100px;\n}\n@media screen and (min-width:1480px) {\n\t.main {\n\t\twidth: 800px;\n\t\tmargin-left: 50px;\n\t}\n}\nCSS 变量的出现让媒体查询更加的简单，只需改变修改变量定义即可：\n:root { \n  --mainWidth:1000px;\n  --leftMargin:100px;\n}\n \n.main {\n  width: var(--mainWidth);\n  margin-left: var(--leftMargin);\n}\n \n@media screen and (min-width:1480px) {\n\t:root { \n\t  --mainWidth:800px;\n\t  --leftMargin:50px;\n\t}\n}\n3、方便的从 JS 中读/写，统一修改\n:root{\n  --testMargin:75px;\n}\n \n//  读取\nvar root = getComputedStyle(document.documentElement);\nvar cssVariable = root.getPropertyValue(&#039;--testMargin&#039;).trim();\n \nconsole.log(cssVariable); // &#039;75px&#039;\n \n// 写入\ndocument.documentElement.style.setProperty(&#039;--testMargin&#039;, &#039;100px&#039;);\n与传统 LESS 、SASS 等预处理器变量比较\n相较于传统的 LESS 、SASS 等预处理器变量，CSS 变量的优点在于:\n\nCSS 变量的动态性，能在页面运行时更改，而传统预处理器变量编译后无法更改\nCSS 变量能够继承，能够组合使用，具有作用域\n配合 Javascript 使用，可以方便的从 JS 中读/写\n"},"front-end/css/basic-css-width/README":{"title":"README","links":[],"tags":[],"content":"理解 CSS3 max/min-content 及 fit-content 等 width 值\n一、为何要蹦出这些新玩意？\n在CSS3的世界里，width属性又多了几个关键字成员，fill-available, max-content, min-content, 以及fit-content。\n虽然，作为名词fill-available, max-content, min-content, 以及fit-content都是新鲜面孔，但是，实际上，在CSS2.1的时候，就有类似的尺寸概念……\n二、CSS2.1的尺寸体系\n在CSS2.1的世界中，常见的尺寸分为这几类：\n1. 充分利用可用空间\n例如，一些div元素默认宽度100%父元素，这种充分利用可用空间的行为就称为“fill-available”。\n2. 收缩与包裹\n典型代表就是浮动，绝对定位以及inline-block，英文称为“shrink-to-fit”，直译为“收缩到合适”，这种直译往往都是不准确的，这种行为表现确实很难描述，有些只可意会不能言传的感觉，而我自己一直以“包裹性”作为理解。在CSS3中有个专有的关键名称，fit-content。\n3. 收缩到最小\n这个基本上就出现在table-layout为auto的表格中，空间都不够的时候，文字能断的就断，中文是随便断的，英文单词不能断。于是乎，第一列被无情地每个字都断掉，形成一柱擎天。这种行为称之为“preferred minimum width”或者“minimum content width”。\n即本文的重点内容之一的min-content，换了一个更加规范好听的名字了。实际上，大家也看到了，min-content这种尺寸特性，display:table-cell实际上就有，但是，由于没有明确的名词或概念，大家都不知道，都是稀里糊涂有此表现，究其根本就不清楚了。\n4. 超出容器限制\n上面1~3情况，除非有明确的width相关设置，否则尺寸都不会主动超过容器宽度的，但是，存在一些特殊情况，例如，连续的英文数字，好长好长；或者内联元素被设置了white-space:nowrap，则会超出容器。\nmax-content的表现与之有些类似，具有收缩特性，同时最大内容宽度。\n至此，大家会发现，fill-available, max-content, min-content, 以及fit-content确实在CSS2.1的时候，就有类似概念。\n三、理解width:fill-available\nwidth:fill-available比较好理解，比方说，我们在页面中扔一个没有其他样式的&lt;div&gt;元素，则，此时，该&lt;div&gt;元素的width表现就是fill-available自动填满剩余的空间。也就是我们平常所说的盒模型的margin,border,padding的尺寸填充。\n出现fill-available关键字值的价值在于，我们可以让元素的100%自动填充特性不仅仅在block水平元素上，其他元素，例如，我们一直认为的包裹收缩的inline-block元素上：\ndiv { \n    display:inline-block; \n    width:fill-available; \n}\n四、理解width:max-content\n同样，从字面意思上理解max-content就是使用 最大的内容，实际上这样讲是远远不够的，max-content的真正定义是：采用子元素中最大空间尺寸的那个元素的尺寸大小。\n&lt;style&gt;\n.box {\n    background-color: #f0f3f9;\n    padding: 10px;\n    margin: 10px auto 20px;\n    overflow: hidden;\n}\n \n.inline-block {\n    display: inline-block;\n}\n.max-content {\n    width: -webkit-max-content;\n    width: -moz-max-content;\n    width: max-content;    \n}\n&lt;/style&gt;\n \n&lt;strong&gt;display:inline-block;&lt;/strong&gt;\n&lt;div class=&quot;box inline-block&quot;&gt;\n    &lt;p&gt;display:inline-block具有收缩特性&lt;/p&gt;\n    &lt;p&gt;display:inline-block具有收缩特性，但是，当（例如这里的）描述文字超过一行显示的时候，其会这行，不会让自身的宽度超过父级容器的可用空间的，但是，width:max-content就不是酱样子哦咯！表现得好像设置了white-space:nowrap一样，科科！&lt;/p&gt;\n&lt;/div&gt;\n \n&lt;strong&gt;width: max-content;&lt;/strong&gt;\n&lt;div class=&quot;box max-content&quot;&gt;\n    &lt;p&gt;display:inline-block具有收缩特性&lt;/p&gt;\n    &lt;p&gt;display:inline-block具有收缩特性，但是，当（例如这里的）描述文字超过一行显示的时候，其会这行，不会让自身的宽度超过父级容器的可用空间的，但是，width:max-content就不是酱样子哦咯！表现得好像设置了white-space:nowrap一样，科科！&lt;/p&gt;\n&lt;/div&gt;\n五、理解width:min-content\nmin-content宽度表示的并不是内部那个宽度小就是那个宽度，而是，采用内部元素最小宽度值最大的那个元素的宽度作为最终容器的宽度。\n首先，我们要明白这里的“最小宽度值”是什么意思。定义上为缩放到极限的最小宽度，例如图片的最小宽度值就是图片呈现的宽度，对于文本元素，如果全部是中文，则最小宽度值就是一个中文的宽度值；如果包含英文，因为默认英文单词不换行，所以，最小宽度可能就是里面最长的英文单词的宽度。\n&lt;style&gt;\n.box {\n    background-color: #f0f3f9;\n    padding: 10px;\n    margin: 10px 0 20px;\n    overflow: hidden;\n}\n \n.inline-block {\n    display: inline-block;\n}\n.min-content {\n    width: -webkit-min-content;\n    width: -moz-min-content;\n    width: min-content;    \n}\n&lt;/style&gt;\n&lt;strong&gt;display:inline-block;&lt;/strong&gt;\n&lt;div class=&quot;box inline-block&quot;&gt;\n    &lt;img src=&quot;mm1.jpg&quot;&gt;\n    &lt;p&gt;display:inline-block具有收缩特性，但这里宽度随文字。而width:min-content随图片。&lt;/p&gt;\n&lt;/div&gt;\n \n&lt;strong&gt;width: min-content;&lt;/strong&gt;\n&lt;div class=&quot;box min-content&quot;&gt;\n    &lt;img src=&quot;mm1.jpg&quot;&gt;\n    &lt;p&gt;display:inline-block具有收缩特性，但这里宽度随文字。而width:min-content随图片。&lt;/p&gt;\n&lt;/div&gt;\ndisplay:inline-block虽然也具有收缩特性，但宽度随最大长度长的那一个（同时不超过可用宽度），上例中，图片的宽度最小值是256像素，而文字的最小宽度值为 display:inline- 的宽度，显然是小于 256像素的，即在第一个 box 中取的是文字的宽度，第二个 box 取的图片的宽度；\n六、理解width:fit-content\nwidth:fit-content可以实现元素收缩效果的同时，保持原本的block水平状态，于是，就可以直接使用margin:auto实现元素向内自适应同时的居中效果了。\n&lt;style&gt;\n.box {\n    background-color: #f0f3f9;\n    padding: 10px;\n    /* 这里左右方向是auto */\n    margin: 10px auto 20px;\n    overflow: hidden;\n}\n \n.inline-block {\n    display: inline-block;\n}\n.fit-content {\n    width: -webkit-fit-content;\n    width: -moz-fit-content;\n    width: fit-content;    \n}\n&lt;/style&gt;\n&lt;strong&gt;display:inline-block;&lt;/strong&gt;\n&lt;div class=&quot;box inline-block&quot;&gt;\n    &lt;img src=&quot;mm1.jpg&quot;&gt;\n    &lt;p&gt;display:inline-block居中要靠父元素，而width:fit-content直接margin:auto.&lt;/p&gt;\n&lt;/div&gt;\n \n&lt;strong&gt;width: fit-content;&lt;/strong&gt;\n&lt;div class=&quot;box fit-content&quot;&gt;\n    &lt;img src=&quot;mm1.jpg&quot;&gt;\n    &lt;p&gt;display:inline-block居中要靠父元素，而width:fit-content直接margin:auto.&lt;/p&gt;\n&lt;/div&gt;\n取以下两种值中的较大值：\n\n固有的最小宽度\n固有首选宽度（max-content）和可用宽度（available）两者中的较小值\n\n可表示为：min(max-content, max(min-content, &lt;length-percentage&gt;))\n\nfill-available 外部尺寸\nmax-content 内部尺寸\nmin-content 内部尺寸\nfit-content 外部尺寸+内部尺寸\n"},"front-end/css/css-banner-without-js/readme":{"title":"readme","links":[],"tags":[],"content":"CSS 实现轮播效果，根本不需要 JS\n\n原文链接：文字轮播与图片轮播？CSS 不在话下 · Issue #184 · chokcoco/iCSS (github.com)\n\n实现原理： 巧用逐帧动画，配合补间动画实现一个无限循环的轮播效果\n难点：\n\n这是个无限轮播的效果，动画需要支持任意多个元素的无限轮播切换；\n因为是轮播，所以，运行到最后一个的时候，需要动画切到第一个元素；\n\n&lt;div class=&quot;g-container&quot;&gt;\n  &lt;ul&gt;\n    &lt;li&gt;Lorem ipsum 1111111&lt;/li&gt;\n    &lt;li&gt;Lorem ipsum 2222222&lt;/li&gt;\n    &lt;li&gt;Lorem ipsum 3333333&lt;/li&gt;\n    &lt;li&gt;Lorem ipsum 4444444&lt;/li&gt;\n    &lt;li&gt;Lorem ipsum 5555555&lt;/li&gt;\n    &lt;li&gt;Lorem ipsum 6666666&lt;/li&gt;\n  &lt;/ul&gt;\n&lt;/div&gt;\n逐帧动画控制整体切换\n逐帧动画效果，也被称为步骤缓动函数，即animation-timing-function：\n:root {\n  // 轮播的个数\n  --s: 6;\n  // 单个 li 容器的高度\n  --h: 36;\n  // 单次动画的时长\n  --speed: 1.5s;\n}\n.g-container {\n  width: 300px;\n  height: calc(var(--h) * 1px);\n  line-height: calc(var(--h) * 1px);\n}\nul {\n  display: flex;\n  flex-direction: column;\n  animation: move calc(var(--speed) * var(--s)) steps(var(--s)) infinite;\n}\nul li {\n  width: 100%;\n}\n@keyframes move {\n  0% {\n    transform: translate(0, 0);\n  }\n  100% {\n    transform: translate(0, calc(var(--s) * var(--h) * -1px));\n  }\n}\n在上述的move动画中，\n\ncalc(var(--speed) * var(--s))：单次动画的耗时 * 轮播的个数，也就是总动画时长\nsteps(var(--s)) 就是逐帧动画的帧数，这里也就是 steps(6)，很好理解\ncalc(var(--s) * var(--h) * -1px)) 单个 li 容器的高度 * 轮播的个数，其实就是 ul 的总体高度，用于设置逐帧动画的终点值\n\n最后，给容器添加overflow: hidden即有了基本的效果。\n利用补间动画实现两组数据间的切换\n利用补间动画，实现动态的切换效果，就是将一组数据，利用 transform，从状态 A 位移到状态 B；\nul li {\n  width: 100%;\n  animation: liMove calc(var(--speed)) infinite;\n}\n \n@keyframes liMove {\n  0% {\n    transform: translate(0, 0);\n  }\n  80%,\n  100%  {\n    transform: translate(0, calc(var(--h) * -1px));\n  }\n}\n末尾填充头部第一组数据\n有一点瑕疵，可以看到，最后一组数据，是从第六组数据 transform 移动向了一组空数据；\n实际开发过轮播的同学肯定知道，这里，其实也很好处理，我们只需要在末尾，补一组头部的第一个数据即可；\n横向轮播和图片轮播\n类似；\n总结\n\n利用 逐帧动画，实现整体的轮播的循环效果\n利用 补间动画，实现具体的 *状态A 向 状态B 的动画效果\n逐帧动画 配合 补间动画 构成整体轮播的效果\n通过向 HTML 结构末尾补充一组头部数据，实现整体动画的衔接\n通过 HTML 元素的 style 标签，利用 CSS 变量，填入实际的参与循环的 DOM 个数，可以实现 JavaScript 与 CSS 的打通\n"},"front-end/css/demo-css-frosted-glass/README":{"title":"README","links":[],"tags":[],"content":"全兼容的毛玻璃效果\n\nCSS 奇思妙想 | 全兼容的毛玻璃效果 · Issue #124 · chokcoco/iCSS (github.com)\n\n通过本文，你能了解到\n\n最基本的使用 CSS backdrop-filter 实现磨砂玻璃(毛玻璃)的效果\n在至今不兼容 backdrop-filter 的 firefox 浏览器，如何利用一些技巧性的操作，巧妙的同样实现毛玻璃效果，让这个效果真正能运用在业务当中\n\n什么是 backdrop-filter\nbackdrop-filter CSS 属性可以让你为一个元素后面区域添加图形效果（如模糊或颜色偏移）。\n因为它适用于元素背后的所有元素，为了看到效果，必须使元素或其背景至少部分透明。\nbackdrop-filter 与 filter 非常类似，可以取的值都是一样的，但是一个是只作用于元素后面的区域，一个是作用于整个元素。\nbackdrop-filter 与 filter 对比\n我们使用 backdrop-filter 与 filter 同时实现一个毛玻璃效果作为对比，代码如下：\n&lt;div class=&quot;bg&quot;&gt;\n&lt;div class=&quot;g-normal&quot;&gt;Normal&lt;/div&gt;\n&lt;div class=&quot;g-filter&quot;&gt;filter&lt;/div&gt;\n&lt;div class=&quot;g-backdrop-filter&quot;&gt;backdrop-filter&lt;/div&gt;\n&lt;/div&gt;\n.bg .g-filter {\n    filter: blur(6px);\n}\n \n.bg .g-backdrop-filter {\n    -webkit-backdrop-filter: blur(6px);\n    backdrop-filter: blur(6px);\n}\n在 backdrop-filter 之前，想实现上述的只给元素背景添加滤镜效果还是非常困难的，并且，对于静态画面还好，如果背景还是可以滚动的动态背景，通常 CSS 是无能为力的。\nbackdrop-filter 正是为了给元素后的内容添加滤镜而不影响元素本身而诞生的。使用它可以非常方便的实现磨砂玻璃效果（毛玻璃）！\nbackdrop-filter 在 Firefox 上 Polyfill\n如果在 firefox 上想使用毛玻璃效果。应用毛玻璃元素的背景只是一张静态背景图，其实方法是有很多的。\n使用 background-attachment: fixed 兼容静态背景图\n只需在元素的背后，叠加一张同样的图片，利用 background-attachment: fixed 将叠加在元素下面的图片定位到与背景相同的坐标，再使用 filter: blur() 对其进行模糊处理即可。\n&amp;::before{\n    content: &quot;&quot;;\n    position: absolute;\n    top: 0; left: 0; right: 0; bottom: 0;\n    background-image: url(&quot;&quot;);\n    background-repeat: no-repeat;\n    background-attachment: fixed;\n    background-size: cover;\n    filter: blur(10px);\n}\n不过这种方法也有两个缺点：\n\n由于使用了伪元素叠加了一层背景，因为层级关系，父元素的 background 是在最下层的，所以元素本身的背景色其实并没有被充分体现；\n\n解决方案是再通过另外一个伪元素再叠加一层背景色，这个背景色应该是原本赋值给父元素本身的：\n&amp;::after {\n    content: &quot;&quot;;\n    position: absolute;\n    top: 0;\n    left: 0;\n    right: 0;\n    bottom: 0;\n    background: rgba(255, 255, 255, 0.5);\n}\n\n上述效果已经非常接近了，硬要挑刺的话，就是应用了模糊滤镜的伪元素的边缘有白边瑕疵，这一点其实是滤镜本身的问题，也非常好解决，我们只需要将伪元素的范围扩大一点即可：\n\n{\n    overflow: hidden;\n    &amp;::before {\n        content: &quot;&quot;;\n        position: absolute;\n        top: -100px;\n        left: -100px;\n        right: -100px;\n        bottom: -100px;\n    }\n}\n使用 moz-element() 配合 filter: blur() 实现复杂背景毛玻璃效果\n毛玻璃背后通常都是整个页面复杂的结构，多层 DOM 的嵌套。\n那么通过叠加一张简单的图片，就无法奏效了，我们得想办法模拟整个 DOM 元素。\n而恰好，在 Firefox 中，有这么一个属性 — -moz-element()。\n何为 -moz-element()？MDN-element 的解释是，CSS 函数 element() 定义了一个从任意的 HTML 元素中生成的图像 &lt;image&gt; 值。该图像值是实时的，这意味着如果被指定的 HTML 元素被更改，应用了该属性的元素的背景也会相应更改。\n它其实是个草案规范，但是一直以来，只有 Firefox 支持它 — CAN I USE — CSS element()；\n-moz-element() 如何使用\n那么 -moz-element() 如何使用呢？简而言之，它能够复制一个元素内部渲染出来的 UI，并且能够实时同步变化。\n我们有这样一个简单的结构，元素背景和内容都在运动：\n&lt;div id=&quot;bg&quot; class=&quot;g-normal&quot;&gt;\n    &lt;p&gt;Content&lt;/p&gt;\n&lt;/div&gt;\n&lt;div class=&quot;g-element-copy&quot;&gt;&lt;/div&gt;\n \n.g-normal {\n    margin: auto;\n    width: 200px;\n    height: 200px;\n    animation: change 5s infinite;\n    background: linear-gradient(deeppink, yellowgreen);\n}\n \np {\n    font-size: 14px;\n    color: #fff;\n    animation: move 5s infinite;\n}\n \n@keyframes change {\n    0% {\n        filter: hue-rotate(0);\n    }\n    100% {\n        filter: hue-rotate(360deg);\n    }\n}\n \n@keyframes move {\n    0% {\n        transform: translate(0, 0);\n    }\n    100% {\n        transform: translate(150px, 150px);\n    }\n}\n \n.g-element-copy {\n    margin: auto;\n    width: 200px;\n    height: 200px;\n    background: -moz-element(#bg);\n}\n在 firefox 中使用 element 复制 UI，用作毛玻璃元素背景\n这样，有了上面的铺垫，下面的内容就比较好理解了。\n和上述的 background-attachment: fixed 方案对比，我们还是通过伪元素叠加一层背景，只不过背景内的内容由单纯一张图片，变成了由 -moz-element() 复制的整段 UI 内容。\n其次，上面的方案我们使用 background-attachment: fixed 使背景图和伪元素内叠加的图片的位置对齐，在这里，我们需要借助 Javascript 进行简单的运算，确定背景内容元素的相关位置，计算对齐量。\n来看这样一个 DEMO：\n&lt;div id=&quot;bg&quot; class=&quot;bg&quot;&gt;\n    &lt;div&gt;模拟真实 DOM&lt;/div&gt;\n    &lt;div&gt;模拟真实 DOM&lt;/div&gt;\n    &lt;div&gt;模拟真实 DOM&lt;/div&gt;\n    &lt;div&gt;模拟真实 DOM&lt;/div&gt;\n    &lt;div&gt;模拟真实 DOM&lt;/div&gt;\n    &lt;div&gt;模拟真实 DOM&lt;/div&gt;\n    &lt;div&gt;模拟真实 DOM&lt;/div&gt;\n    &lt;div&gt;模拟真实 DOM&lt;/div&gt;\n    &lt;div&gt;模拟真实 DOM&lt;/div&gt;\n&lt;/div&gt;\n&lt;div class=&quot;g-glossy&quot;&gt;frosted glass effect &lt;/div&gt;\n&lt;div class=&quot;g-glossy-firefox&quot;&gt;&lt;/div&gt;\n\n其中，.g-glossy 是在正常情况下 backdrop-filter 兼容时，我们的毛玻璃元素，而 .g-glossy-firefox 则是不兼容 backdrop-filter 时，我们需要模拟整个 DOM 背景 UI时候的元素，可以通过 CSS 特性检测 CSS @support 进行控制：\n核心 CSS 代码：\n.bg {\n    // 整个页面的 DOM 结构\n}\n\n.g-glossy {\n    position: fixed;\n    width: 600px;\n    height: 300px;\n    background-color: rgba(255, 255, 255, 0.5);\n    backdrop-filter: blur(10px);\n}\n\n.g-glossy-firefox {\n    display: none;\n}\n\n@supports (background: -moz-element(#bg)) {\n    .g-glossy-firefox {\n        display: block;\n        position: fixed;\n        width: 600px;\n        height: 300px;\n        background: -moz-element(#bg) no-repeat;\n        filter: blur(10px);\n    }\n}\n\n简单解读一下：\n\n对于兼容 backdrop-filter 的，.g-glossy 内的代码将直接生效，并且 .g-glossy-firefox 不会展示\n对于 Firefox 浏览器，因为 backdrop-filter 必然不兼容，所以 .g-glossy 内的 backdrop-filter: blur(10px) 不会生效，而 @supports (background: -moz-element(#bg)) 内的样式会生效，此时 .g-glossy-firefox 将会利用 background: -moz-element(#bg) no-repeat; 模拟 id 为 bg 的元素\n\n当然，这里我们需要借助一定的 JavaScript 代码，计算我们的模拟页面 UI 的元素 .g-glossy-firefox 相对它模拟的 #bg 元素，也就是页面布局的一个定位偏差：\n$(function() {\n        let blur = $(&#039;.g-glossy-firefox&#039;)[0].style;\n        let offset = $(&#039;.g-glossy&#039;).eq(0).offset();\n\n        function updateBlur() {\n            blur.backgroundPosition = \n                `${-window.scrollX - offset.left}px ` + \n                `${-window.scrollY - offset.top}px`;\n        }\n        document.addEventListener(&#039;scroll&#039;, updateBlur, false), updateBlur();\n});\n\nOK，至此，我们就能完美的在 Firefox 上也实现毛玻璃的效果了\n总结一下\n简单对上述内容进行一个总结：\n\n你可以使用 backdrop-filter 对兼容它的浏览器非常简单的实现毛玻璃（磨砂玻璃）效果\n对于不兼容 backdrop-filter 的浏览器，如果它只是简单背景，可以使用 background-attachment: fixed 配合 filter: blur() 进行模拟\n对于 firefox 浏览器，你还可以使用 moz-element() 配合 filter: blur() 实现复杂背景毛玻璃效果\n对于不兼容的上述 3 种效果的其他浏览器，设置了毛玻璃效果的元素，可以通过设置类似 background: rgba(255, 255, 255, 0.5) 的样式，使之回退到半透明效果，也算一种非常合理的降级效果，不会引起 Bug\n"},"front-end/css/demo-dynamic-linear-loading/README":{"title":"README","links":[],"tags":[],"content":"前言\n我们知道，使用 CSS，我们可以非常轻松的实现动态旋转的动画效果：\n&lt;div&gt;&lt;/div&gt;\ndiv {\n    width: 100px;\n    height: 100px;\n    border-radius: 50%;\n    border: 2px solid transparent;\n    border-top: 2px solid #000;\n    border-left: 2px solid #000;\n    animation: rotate 3s infinite linear;\n}\n@keyframes rotate {\n    100% {\n        transform: rotate(360deg);\n    }\n}\n与要求的线条 loading 动画相比，上述动画缺少了比较核心的一点在于：\n线条在旋转运动的过程中，长短是会发生变化的；\n所以，这里的的难点也就转变为了，如何动态的实现弧形线段的长短变化？解决了这个问题，也就基本上解决了上述的线条变换 Loading 动画。\n本文将介绍 CSS 当中，几种有意思的，可能可以动态改变弧形线条长短的方式：\n方法一：使用遮罩实现\n第一种方法，也是比较容易想到的方式，使用遮罩的方式实现。\n我们实现两个半圆线条，一个是实际能看到的颜色，另外一个则是和背景色相同的，相对更为粗一点的半圆线条，当两条线条运动的速率不一致时，我们从视觉上，也就能看到动态变化的弧形线条。\n&lt;div&gt;&lt;/div&gt;\ndiv {\n    width: 200px;\n    height: 200px;\n}\ndiv::before {\n    position: absolute;\n    content: &quot;&quot;;\n    top: 0px; left: 0px; right: 0px; bottom: 0px;\n    border-radius: 50%;\n    border: 3px solid transparent;\n    border-top: 3px solid #000;\n    border-left: 3px solid #000;\n    animation: rotate 3s infinite ease-out;\n}\ndiv::after {\n    position: absolute;\n    content: &quot;&quot;;\n    top: -2px; left: -2px; right: -2px; bottom: -2px;\n    border-radius: 50%;\n    border: 7px solid transparent;\n    border-bottom: 7px solid #fff;\n    border-right: 7px solid #fff;\n    animation: rotate 4s infinite ease-in-out;\n}\n@keyframes rotate {\n    100% {\n        transform: rotate(0deg);\n    }\n}\n核心就是实现两条半圆线条，一条黑色，一条背景色，两段线条以不同的速率运动（通过动画时间及缓动控制）\n上述方案最大的 2 个问题在于：\n\n如果背景色不是纯色，会露馅\n如果要求能展现的线段长度大于半个圆，无法完成\n\n基于此，我们只能另辟蹊径。\n方法二：借助 SVG 的 stroke-* 能力\n我们只需要一个简单的 SVG 标签 &lt;circle&gt;，配合其 CSS 样式 stroke-dasharray 和 stroke-dashoffset 即可轻松完成上述效果：\n&lt;svg class=&quot;circular&quot; viewbox=&quot;25 25 50 50&quot;&gt;\n  &lt;circle class=&quot;path&quot; cx=&quot;50&quot; cy=&quot;50&quot; r=&quot;20&quot; fill=&quot;none&quot; /&gt;\n&lt;/svg&gt;\n.circular {\n  width: 100px;\n  height: 100px;\n  animation: rotate 2s linear infinite;\n}\n.path {\n  stroke-dasharray: 1, 200;\n  stroke-dashoffset: 0;\n  stroke: #000;\n  animation: dash 1.5s ease-in-out infinite\n}\n@keyframes rotate {\n  100% {\n    transform: rotate(360deg);\n  }\n}\n@keyframes dash {\n  0% {\n    stroke-dasharray: 1, 200;\n    stroke-dashoffset: 0;\n  }\n  50% {\n    stroke-dasharray: 89, 200;\n    stroke-dashoffset: -35px;\n  }\n  100% {\n    stroke-dasharray: 89, 200;\n    stroke-dashoffset: -124px;\n  }\n}\n简单解释下：\n\nstroke：类比 css 中的 border-color，给 svg 图形设定边框颜色；\nstroke-dasharray：值是一组数组，没数量上限，每个数字交替表示划线与间隔的宽度;\nstroke-dashoffset：dash 模式到路径开始的距离。\n\n我们利用 stroke-dasharray 将原本完整的线条切割成多段，例如 stroke-dasharray: 10, 10 表示线段每段长 10px且间隔也是10px，\n而在动画中：\n\nstroke-dasharray: 1, 200;：则会显示为一个点；\nstroke-dasharray: 89, 200;：显示为 89px 长的圆弧；\n\n通过 animation，让线段在这两种状态之间补间变换。而 stroke-dashoffset 的作用则是将线段向前推移，配合父容器的 transform: rotate() 旋转动画，使得视觉效果，线段是在一直在向一个方向旋转。\nOK，还会有同学说了，我不想引入 SVG 标签，我只想使用纯 CSS 方案。这里，还有一种利用 CSS @Property 的纯 CSS 方案。\n方法三：使用 CSS @Property 让 conic-gradient 动起来\n这里我们需要借助 CSS @Property 的能力，使得本来无法实现动画效果的角向渐变，动起来。\n正常来说，渐变是无法进行动画效果的，如下所示：\n&lt;div&gt;&lt;/div&gt;\n \n.normal {\n    width: 200px;\n    height: 200px;\n    border-radius: 50%;\n    background: conic-gradient(\n        yellowgreen, yellowgreen 25%, \n        transparent 25%, transparent 100%\n    ); \n    transition: background 300ms;\n    \n    &amp;:hover {\n        background: conic-gradient(\n            yellowgreen, yellowgreen 60%, \n            transparent 60.1%, transparent 100%\n        ); \n    }\n \n}\n将会得到这样一种效果，由于 conic-gradient 是不支持过渡动画的，得到的是一帧向另外一帧的直接变化；\n好，使用 CSS @Property 自定义变量改造一下：\n@property --per {\n  syntax: &#039;&lt;percentage&gt;&#039;;\n  inherits: false;\n  initial-value: 25%;\n}\n \ndiv {\n    background: conic-gradient(\n        yellowgreen, yellowgreen var(--per), \n        transparent var(--per), transparent 100%\n    ); \n    transition: --per 300ms linear;\n    \n    &amp;:hover {\n        --per: 60%;\n    }\n}\n \n在这里，我们可以让渐变动态的动起来，赋予了动画的能力。\n我们只需要再引入 mask，将中间部分裁切掉，即可实现上述线条 Loading 动画，伪代码如下：\n&lt;div&gt;&lt;/div&gt;\n@property --per {\n    syntax: &quot;&lt;percentage&gt;&quot;;\n    inherits: false;\n    initial-value: 10%;\n}\n \ndiv {\n    position: relative;\n    width: 100px;\n    height: 100px;\n    border-radius: 50%;\n    animation: rotate 11s infinite ease-in-out;\n \n    &amp;::before {\n        content: &quot;&quot;;\n        position: absolute;\n        top: 0;\n        left: 0;\n        right: 0;\n        bottom: 0;\n        border-radius: 50%;\n        background: conic-gradient(transparent, transparent var(--per), #fa7 var(--per), #fa7);\n        mask: radial-gradient(transparent, transparent 47.5px, #000 48px, #000);\n        animation: change 3s infinite cubic-bezier(0.57, 0.29, 0.49, 0.76);\n    }\n}\n \n@keyframes change {\n    50% {\n        transform: rotate(270deg);\n        --per: 98%;\n    }\n    100% {\n        transform: rotate(720deg);\n    }\n}\n \n@keyframes rotate {\n    100% {\n        transform: rotate(360deg);\n        filter: hue-rotate(360deg);\n    }\n}\n \n这里，我顺便加上了 filter: hue-rotate()，让线条在旋转的同时，颜色也跟着变化，最终效果如下，这是一个纯 CSS 解决方案；"},"front-end/css/demo-happy-new-year/README":{"title":"README","links":[],"tags":[],"content":"CSS 实现 3D 新年快乐\n\n链接： www.youtube.com/watch\n\ntransform-style\n用于设置元素的子元素是位于 3D 空间中还是平面中；\n\nflat：设置元素的子元素位于该元素的平面中。\npreserve-3d：指示元素的子元素应位于 3D 空间中。\n\ntransform-origin\n属性让你更改一个元素变形的原点；\n什么是原点，举例子，rotate()函数的转换原点是旋转中心；默认的转换原点是 center；"},"front-end/css/demo-matte-gradient-bg/README":{"title":"README","links":[],"tags":[],"content":"实现渐变图\n磨砂玻璃渐变背景效果看似复杂，其实非常的简单。它就是：\n多块不规则渐变背景 + 高斯模糊蒙版\n在 CSS 中，也就是借助 background + backdrop-filter: blur() 即可实现。\n去掉叠在上方的 高斯模糊蒙版，背后的元素其实非常简单明了：其实就是几个彩色多边形的堆叠；\n这里简单列下代码，我们使用了 3 个 div 实现了 3 个渐变图，每个图形再使用 clip-path 随机裁剪成不规则的多边形：\n&lt;div class=&quot;g-bg&quot;&gt;\n    &lt;div class=&quot;g-polygon g-polygon-1&quot;&gt;&lt;/div&gt;\n    &lt;div class=&quot;g-polygon g-polygon-2&quot;&gt;&lt;/div&gt;\n    &lt;div class=&quot;g-polygon g-polygon-3&quot;&gt;&lt;/div&gt;\n&lt;/div&gt;\n.g-polygon {\n    position: absolute;\n    opacity: .5;\n}\n.g-polygon-1 {\n    // 定位代码，容器高宽随意\n    background: #ffee55;\n    clip-path: polygon(0 10%, 30% 0, 100% 40%, 70% 100%, 20% 90%);\n}\n \n.g-polygon-2 {\n    // 定位代码，容器高宽随意\n    background: #E950D1;\n    clip-path: polygon(10% 0, 100% 70%, 100% 100%, 20% 90%);\n}\n \n.g-polygon-3 {\n    // 定位代码，容器高宽随意\n    background: rgba(87, 80, 233);\n    clip-path: polygon(80% 0, 100% 70%, 100% 100%, 20% 90%);\n}\n使用 backdrop-filter 实现高斯模糊蒙版\n接下来，这一步最为关键，就是使用 backdrop-filter 实现高斯模糊蒙版。叠在上述几个元素上方即可，最关键的一行代码 backdrop-filter: blur(150px)：\n.g-bg::before {\n    content: &quot;&quot;;\n    position: fixed;\n    top: 0; left: 0; bottom: 0; right: 0;\n    backdrop-filter: blur(150px);\n    z-index: 1;\n}\n注意，这里使用的是 backdrop-filter: blur()，而不是 filter: blur()；\n借助 CSS-doodle 工具，批量产生该效果\n简单了解了原理之后，我们就可以借助 CSS-doodle 尝试批量来生成这个效果了。\n\nCSS-doodle 它是一个基于 Web-Component 的库。允许我们快速的创建基于 CSS Grid 布局的页面，并且提供各种便捷的指令及函数（随机、循环等等），让我们能通过一套规则，得到不同 CSS 效果。感兴趣的可以猛击官网了解 — CSS-doodle\n\n代码非常简单，也非常好理解，就是随机场景不同尺寸、不同定位、不同颜色、不同形式的几个图形：\n&lt;css-doodle&gt;\n    :doodle {\n        @grid: 1x8 / 100vmin;\n    }\n    @place-cell: center;\n    width: @rand(40vmin, 80vmin);\n    height: @rand(40vmin, 80vmin);\n    transform: translate(@rand(-200%, 200%), @rand(-60%, 60%)) scale(@rand(.8, 1.8)) skew(@rand(45deg));\n    clip-path: polygon(\n      @r(0, 30%) @r(0, 50%), \n      @r(30%, 60%) @r(0%, 30%), \n      @r(60%, 100%) @r(0%, 50%), \n      @r(60%, 100%) @r(50%, 100%), \n      @r(30%, 60%) @r(60%, 100%),\n      @r(0, 30%) @r(60%, 100%)\n    );\n    background: @pick(#f44336, #e91e63, #9c27b0, #673ab7, #3f51b5, #60569e, #e6437d, #ebbf4d, #00bcd4, #03a9f4, #2196f3, #009688, #5ee463, #f8e645, #ffc107, #ff5722, #43f8bf);\n    opacity: @rand(.3, .8);\n&lt;/css-doodle&gt;\n上述代码会随机生成这样的图案，配合上蒙版，能够批量的去生成上述的背景效果；\n如果需求，配合上 hue-rotate 及简单的位移，我们甚至可以让这个渐变背景动画动起来，更加生动些：\n&lt;css-doodle&gt;\n    // 同上...\n    position: relative;\n    top: @rand(-80%, 80%);\n    left: @rand(-80%, 80%);\n    animation: colorChange @rand(6.1s, 16.1s) infinite @rand(-.5s, -2.5s) linear alternate;\n  \n  @keyframes colorChange {\n    100% {\n      left: 0;\n      top: 0;\n      filter: hue-rotate(360deg);\n    }\n  }\n&lt;/css-doodle&gt;"},"front-end/css/new-scroll-timeline/README":{"title":"README","links":[],"tags":[],"content":"\n革命性创新，动画杀手锏 @scroll-timeline · Issue #166 · chokcoco/iCSS · GitHub\n\n在 CSS 规范 Scroll-linked Animations 中，推出了一个划时代的 CSS 功能。也就是 — The @scroll-timeline at-rule，直译过来就是滚动时间线。\n何为 @scroll-timeline 滚动时间线？\n什么是 @scroll-timeline 滚动时间线呢？\n@scroll-timeline 能够设定一个动画的开始和结束由滚动容器内的滚动进度决定，而不是由时间决定。\n意思是，我们可以定义一个动画效果，该动画的开始和结束可以通过容器的滚动来进行控制。\n\n@scroll-timeline 目前仍处于实验室特性时间，Chrome 从 85 版本开始支持，但是默认是关闭的。\n在最新的 chrome、Edge、Opera 可以通过浏览器配置开启该特性，Chrome 下开启该特性需要：\n\n浏览器 URL 框输入 chrome://flags\n开启 #enable-experimental-web-platform-features\n\n\n示意 DEMO\n再系统性学习语法之前，我们通过一个 DEMO，简单了解一下它的用法：\n我们首先实现一个简单的字体 F 旋转动画：\n&lt;div id=&quot;g-box&quot;&gt;F&lt;/div&gt;\n#g-box {\n    font-size: 150px;\n    margin: 40vh auto;\n    animation-name: rotate;\n    animation-duration: 3s;\n    animation-direction: alternate;\n    animation-easing-function: linear;\n}\n@keyframes rotate {\n    0% {\n        transform: rotate(0);\n    }\n    100% {\n        transform: rotate(360deg);\n    }\n}\n正常而言，它是这样一个大字号 F 的旋转动画；接下来，我们把这个动画和 @scroll-timeline 相结合，需要把它放置到一个可滚动的容器中：\n#g-container {\n    width: 200px;\n    height: 170vh;\n    margin: 0 auto;\n    background: #999;\n    display: flex;\n}\n@scroll-timeline box-rotate {\n    source: selector(&quot;#g-content&quot;);\n}\n#g-box {\n    animation-timeline: box-rotate;\n}\n如上设置之后，元素的旋转动画不会自动开始，只有当我们向下滚动的时候，动画才会开始进行\n@scroll-timeline 语法介绍\n接下来，我们先缓一缓，简单看一看 @scroll-timeline 的语法。\n使用 @scroll-timeline，最核心的就是需要定义一个 @scroll-timeline 规则：\n@scroll-timeline moveTimeline {\n  source: selector(&quot;#g-content&quot;);\n  orientation: vertical;\n  scroll-offsets: 0px, 500px;\n}\n其中：\n\nsource：绑定触发滚动动画的滚动容器\n\nsource: auto：绑定到 Document，也就是全局 Windows 对象\nsource: selector(&quot;id-selector&quot;)，通过 selector()，内置一个 #id 选择器，选取一个可滚动容器\nsource: none：不指的滚动容器\n\n\norientation：设定滚动时间线的方向\n\norientation: auto：默认为 vertical，也就是竖直方向的滚动\norientation: vertical：竖直方向的滚动\norientation: horizontal：水平方向的滚动\norientation: block：不太常用，使用沿块轴的滚动位置，符合书写模式和方向性\norientation: inline：不太常用，使用沿内联轴的滚动位置，符合书写模式和方向性\n\n\nscroll-offsets：滚动时间线的核心，设定在滚动的什么阶段，触发动画，可通过三种方式之一进行设置：\n\nscroll-offsets: none 这意味着没有 scroll-offset 指定。\n由逗号分隔的值列表确定。每个值都映射到animation-duration。例如，如果 ananimation-duration 设置为 2s 且滚动偏移量为 0px, 30px, 100px，则在 1s 时，滚动偏移量将为 30px。\n第三种确定滚动偏移量的方法是使用元素偏移量。这意味着可以指定页面内的元素，其位置决定了滚动时间线以及要使用这些元素的哪个边缘。指定元素是使用 selector() 函数完成的，该函数接收元素的 id。边缘由关键字 start 或确定 end。可选的阈值的 0–1 可用于表示元素滚动中预期可见的百分比。\n\n\n\nscroll-offsets 的理解会比较困难，我们稍后详述。\n在设定了一个 @scroll-timeline 之后，我们只需要将它和动画绑定起来即可，通过 animation-timeline：\n@scroll-timeline moveTimeline {\n  source: selector(&quot;#g-content&quot;);\n  orientation: vertical;\n  scroll-offsets: 0px, 500px;\n}\ndiv {\n    animation-name: move;\n    animation-duration: 3s;\n    animation-timeline: moveTimeline;\n}\n@keyframes move{\n    0% {\n        transform: translate(0, 0);\n    }\n    100% {\n        transform: translate(100%, 0);\n    }\n}\n使用 @scroll-timeline 实现滚动进度指示器\n有了 @scroll-timeline 之后，我们可以轻松将滚动和动画这两个元素绑定起来，实现滚动进度指示器：\n&lt;div id=&quot;g-container&quot;&gt;\n    &lt;p&gt;...文本内容...&lt;/p&gt;\n&lt;/div&gt;\n#g-container {\n    width: 100vw;\n}\n#g-container::before {\n    content: &quot;&quot;;\n    position: fixed;\n    height: 5px;\n    left: 0;\n    top: 0;\n    right: 0;\n    background: #ffc107;\n    animation-name: scale;\n    animation-duration: 1s;\n    animation-fill-mode: forwards;\n    animation-timeline: box-rotate;\n    transform-origin: 0 50%;\n}\n \n@keyframes scale {\n    0% {\n        transform: scaleX(0);\n    }\n    100% {\n        transform: scaleX(1);\n    }\n}\n@scroll-timeline box-rotate {\n    source: auto;\n    orientation: vertical;\n}\n使用 scroll-offsets 精确控制动画触发时机\n上述的例子都是根据滚动从头到尾完成动画的，如果需要更加精确的控制我们的动画，则需要借助 scroll-offsets了；\n在滚动过程中，我们可以将一个元素，划分为 3 个区域：\n\n滚动过程中，从上方视野盲区，进入视野\n滚动过程中，处于视野中\n滚动过程中，从视野中，进入下方视野盲区\n\n在这里，我们就可以得到两个边界，上方边界，下方边界；而对于边界，又会有两种状态。以上边界为例子，会有：\n\n元素刚刚开始进入可视区\n元素完全进入可视区\n\n对于这两种状态，我们用 start 0 和 start 1 表示，同理，下方的边界也可以用 end 0 和 end 1 表示；\n这里的 0 和 1 实际表示的是，元素滚动中预期可见的百分比。\n有了这些状态值，配合 scroll-offsets，我们就可以精确控制滚动动画的触发时间。\n我们设定一个从左向右并且伴随透明度变化的动画，的看看下面几种情况：\n1. 滚动动画在元素从下方开始出现时开始，完全出现后截止\n动画运行范围：end 0 ⇒ end 1：\n@keyframes move {\n    0% {\n        transform: translate(-100%, 0);\n        opacity: 0;\n    }\n    100% {\n        transform: translate(0, 0);\n        opacity: 1;\n    }\n}\n@scroll-timeline box-move {\n    source: auto;\n    orientation: &quot;vertical&quot;;\n    scroll-offsets: \n        selector(#g-box) end 0, \n        selector(#g-box) end 1;\n    /* Legacy Descriptors Below: */\n    start: selector(#g-box) end 0;\n    end: selector(#g-box) end 1;\n    time-range: 1s;\n}\n#g-box {\n    animation-name: move;\n    animation-duration: 3s;\n    animation-fill-mode: both;\n    animation-timeline: box-move;\n}\n2. 滚动动画在元素从下方完全出现时开始，在滚动到上方即将离开屏幕后截止\n动画运行范围：end 1 ⇒ start 1：\n@scroll-timeline box-move {\n    source: auto;\n    orientation: &quot;vertical&quot;;\n    scroll-offsets: \n        selector(#g-box) end 1, \n        selector(#g-box) start 1;\n    /* Legacy Descriptors Below: */\n    start: selector(#g-box) end 1;\n    end: selector(#g-box) start 1;\n    time-range: 1s;\n}\n以此类推，掌握 scroll-offsets 的用法是灵活运用滚动时间线的关键，当然，在上面你还会看到 start: selector(#g-box) start 1 和 end: selector(#g-box) start 0 这种写法，这是规范历史遗留问题；\n使用 @scroll-timeline 实现各类效果\n在能够掌握 @scroll-timeline 的各个语法之后，我们就可以开始使用它创造各种动画效果了。\n譬如如下的，滚动内容不断划入：\n\n代码较长，可以戳这里，来自 bramus 的 Codepen CodePen Demo — Fly-in Contact List (CSS @scroll-timeline version)\n甚至可以结合 scroll-snap-type 制作一些全屏滚动的大屏特效动画：\n\n要知道，这在以前，是完全不可能利用纯 CSS 实现的。完整的代码你可以戳这里：CodePen Demo — CSS Scroll-Timeline Split Screen Carousel\n简而言之，任何动画效果，如今，都可以和滚动相结合起来，甚至乎是配合 SVG 元素也不例外，这里我还简单改造了一下之前的一个 SVG 线条动画：\n\n完整的代码你可以戳这里：CodePen Demo — SVG Text Line Effect | Scroll Timeline\n@scroll-timeline 的实验室特性与特性检测\n基于目前的兼容性问题，我们可以通过浏览器的特性检测 @supports 语法，来渐进增强使用该功能。\n特性检测的语法也非常简单：\n@supports (animation-timeline: works) {\n    @scroll-timeline list-item-1 {\n\tsource: selector(#list-view);\n\tstart: selector(#list-item-1) end 0;\n\tend: selector(#list-item-1) end 1;\n        scroll-offsets:\n            selector(#list-item-1) end 0,\n            selector(#list-item-1) end 1\n        ;\n\ttime-range: 1s;\n    }\n    // ...\n}\n\n通过 @supports (animation-timeline: works) {} 可以判断浏览器是否支持 @scroll-timeline。"},"front-end/css/trick-css-extract-color/README":{"title":"README","links":[],"tags":[],"content":"利用 filter: blur() 及 transform: sacle() 获取图片主题色\n\n小技巧！CSS 提取图片主题色功能探索 · Issue #114 · chokcoco/iCSS (github.com)\n\n利用模糊滤镜以及放大效果，可以近似的拿到图片的主题色。例如，一张这样一张图片：\n\n利用模糊滤镜作用给图片：\ndiv {\n    background: url(&quot;i0.wp.com/airlinkalaska.com/wp-content/uploads//aurora-2.jpg%2C683&amp;ssl=1&quot;);\n    background-size: cover;\n    filter: blur(50px);\n}\n看看效果，我们通过比较大的一个模糊滤镜，将图片 blur(50px)，模糊之后的图片有点那感觉了，不过存在一些模糊边缘，尝试利用 overflow 进行裁剪。\n接下来，我们需要去掉模糊的边边，以及通过 transform: scale() 放大效果，将颜色再聚焦下，稍微改造下代码：\ndiv {\n    position: relative;\n    width: 320px;\n    height: 200px;\n    overflow: hidden;\n}\n \ndiv::before {\n    content: &quot;&quot;;\n    position: absolute;\n    top: 0;\n    left: 0;\n    right: 0;\n    bottom: 0;\n    background: url(&quot;i0.wp.com/airlinkalaska.com/wp-content/uploads//aurora-2.jpg%2C683&amp;ssl=1&quot;);\n    background-size: cover;\n    // 核心代码：\n    filter: blur(50px);\n    transform: scale(3);\n}\n这样，我们就利用 CSS，拿到了图片的主色调，并且效果还是不错的！\n当然，该方案也是存在一定的小问题的：\n\n只能是大致拿到图片的主色调，无法非常精确，并且 filter: blur(50px) 这个 50px 需要进行一定的调试\n模糊滤镜本身是比较消耗性能的，如果一个页面存在多个这种方法获取到的背景，可能对性能会造成一定的影响，实际使用的时候需要进行一定的取舍\n"},"front-end/css/trick-css-negative-value/README":{"title":"README","links":[],"tags":[],"content":"单侧投影\n关于 box-shadow，大部分时候，我们使用它都是用来生成一个两侧的投影，或者一个四侧的投影。如果要生成一个单侧的投影呢？\n我们来看看 box-shadow 的用法定义：\n{\n    box-shadow: none | [inset? &amp;&amp; [ &lt;offset-x&gt; &lt;offset-y&gt; &lt;blur-radius&gt;? &lt;spread-radius&gt;? &lt;color&gt;? ] ]#\n}\n\n以 box-shadow: 1px 2px 3px 4px #333 为例，4 个数值的含义分别是，x 方向偏移值、y 方向偏移值 、模糊半径、扩张半径。\n这里有一个小技巧，扩张半径可以为负值。\n继续，如果阴影的模糊半径，与负的扩张半径一致，那么我们将看不到任何阴影，因为生成的阴影将被包含在原来的元素之下，除非给它设定一个方向的偏移量。\n所以这个时候，我们给定一个方向的偏移值，即可实现单侧投影：\nbox-shadow: -7px 0 5px -5px #333;\t/* 左 */\n \nbox-shadow: 7px 0 5px -5px #333;\t/* 右 */\n \nbox-shadow: 0 -7px 5px -5px #333;\t/* 上 */\n\t\nbox-shadow: 0 7px 5px -5px #333;\t/* 下 */\n使用 scale(-1) 实现翻转\n要实现一个元素的 180° 翻转，我们会使用 transform: rotate(180deg)，这里有个小技巧，使用 transform: scale(-1) 可以达到同样的效果：\n&lt;p class=&quot;scale&quot;&gt;CSS Nagative Scale(-1)&lt;/p&gt;\n \n.scale {\n    transform: scale(1);\n    animation: scale 10s infinite linear;\n}\n \n@keyframes scale{\n    50% {\n        transform: scale(-1);\n    }  \n    100% {\n        transform: scale(-1);\n    }\n}\n使用负 letter-spacing 倒序排列文字\n与上面 scale(-1) 有异曲同工之妙的是负的 letter-spacing。\nletter-spacing 属性明确了文字的间距行为，通常而言，除了关键字 normal，我们还可以指定一个大小，表示文字的间距。像这样：\n&lt;p class=&quot;letter_spacing&quot;&gt;倒序排列文字&lt;/p&gt;\n \n.letter_spacing {\n    font-size: 36px;\n    letter-spacing: 0px;\n    animation: move 10s infinite;\n}\n \n@keyframes move {\n    40% {\n        letter-spacing: 36px;\n    }\n    80% {\n        letter-spacing: -72px;\n    }\n    100% {\n        letter-spacing: -72px;\n    }\n}\ntransition-delay 及 animation-delay 的负值使用，立刻开始动画\n我们知道，CSS 动画及过渡提供了一个 delay 属性，可以延迟动画的进行；\n简单的代码大概是这样：\n&lt;div class=&quot;g-container&quot;&gt;\n    &lt;div class=&quot;item&quot;&gt;&lt;/div&gt;\n    &lt;div class=&quot;item&quot;&gt;&lt;/div&gt;\n    &lt;div class=&quot;item&quot;&gt;&lt;/div&gt;\n&lt;/div&gt;\n.item {\n    transform: rotate(0) translate(-80px, 0) ;\n}\n \n.item:nth-child(1) {\n    animation: rotate 3s infinite linear;\n}\n \n.item:nth-child(2) {\n    animation: rotate 3s infinite 1s linear;\n}\n \n.item:nth-child(3) {\n    animation: rotate 3s infinite 2s linear;\n}\n \n \n@keyframes rotate {\n    100% {\n        transform: rotate(360deg) translate(-80px, 0) ;\n    }\n}\n如果，我们想去掉这个延迟，希望在一进入页面的时候，3 个球就是同时运动的。这个时候，只需要把正向的 animation-delay 改成负向的即可。\n.item:nth-child(1) {\n    animation: rotate 3s infinite linear;\n}\n \n.item:nth-child(2) {\n    animation: rotate 3s infinite -1s linear;\n}\n \n.item:nth-child(3) {\n    animation: rotate 3s infinite -2s linear;\n}\n这里，有个小技巧，被设置了 animation-dealy 为负值的动画会立刻执行，开始的位置是其动画阶段中的一个阶段。\n负值 margin\n负值 margin 在 CSS 中算是运用的比较多的，元素的外边距可以设置为负值。\n在 flexbox 布局规范还没流行之前，实现多行等高布局还是需要下一番功夫的。其中一种方法便是使用正 padding 负 margin 相消的方法。\n例如一个左右栏的布局分布，左右两栏的内容都是不确定的，也就是高度未知。但是希望无论左侧内容较多还是右侧内容较多，两栏的高度始终保持一致；\n其中一种 Hack 办法便是使用一个很大的正 padding 和相同的负 margin 相消的方法填充左右两栏：\n.g-left {\n  ...\n  padding-bottom: 9999px;\n  margin-bottom: -9999px;\n}\n \n.g-right {\n  ...\n  padding-bottom: 9999px;\n  margin-bottom: -9999px;\n}\n可以做到无论左右两栏高度如何变化，高度较低的那一栏都会随着另外一栏变化。\n总结一下\n另外，还有一些大家熟知的没有单独列出来的，譬如：\n\n使用负 marign 实现元素的水平垂直居中\n使用负 marign隐藏列表 li 首尾多余的边框\n使用负 text-indent 实现文字的隐藏\n使用负的 z-index 参与层叠上下文排序\n\n还有一些很深奥的，譬如张鑫旭大大在今年的 CSS 大会上分享的，利用负的 opacity 在 CSS 中实现了伪条件判断，配合 CSS 自定义属性，使用纯 CSS 实现 360° 的饼图效果：\n\n第五届CSS大会主题分享之CSS创意与视觉表现\n"},"front-end/gis/README":{"title":"README","links":[],"tags":[],"content":"Web GIS 开发入门\n坐标系\n总所周知，地球不是一个标准的球体，而是一个近似的椭球体，越靠近赤道则越宽。既然是一个三维物体，那么进行坐标系定位一般来说需要 x，y，z 一个三维坐标系来定义。但是为了更好的在球面上进行定位，所以就采取了使用经纬度的方式，在 GIS 开发中，以经度、维度以及相对高度所组成的坐标系将其称作为地理坐标系（Geographic Coordinate System， 简称 GCS） 。\n而在平时使用手机地图或者网页地图的时候，展现在我们面前的则是一个平面地图。如果说此时我们需要查询自己去某个饭店有多远，手机会告诉我们距离多少公里或者多少米，所以我们得到两个地点之间的距离是平面距离，使用米或者千米做单位。而此时的定位坐标系，就被称作为投影 坐标系（Projection Coordinate System，简称PCS） 。\n很显然，我们平时使用的平面地图，肯定是做了这样一件事情，那就是将地理坐标系转换成投影坐标系。但是，一个球面从直观上是无法展开成一个连续的，没有褶皱的平面的，因此我们需要一定的数学方法进行转换。\n其实从投影坐标系的名称也可以看出，坐标系转化的方法就是投影。可以想象一下，一个3D的物品被光照射之后的影子，是不是就是2D平面了。当然坐标系的转换肯定不是随便投影就行，为了让投影之后的坐标系有一定的使用价值，投影的方式一般都会具备一定的规律，比如投影后距离不变，或者角度不变等。\n墨卡托投影\n墨卡托投影（Mercator Projection） 是在1569年，当时的地理学家杰拉杜斯·墨卡托提出的一种角度不变的投影方式，又被称作为等角正切圆柱投影。我们可以想象一下，将地球置于一个空心圆柱体中，其中地球的赤道正切于圆柱体。然后假设地心有一个灯泡，灯泡的光线能够透过地表照射到圆柱体表面，那么地球球面上的绝大部分区域都会相应的被投影到圆柱体上。此时将圆柱体展开，以赤道的投影为横坐标，以本初子午线的投影的纵坐标，就得到了以墨卡托投影所构成的平面坐标系。\n\n我们可以看到该投影有以下特点：\n\n经线、纬线分别为平行直线，并且经纬线之间互相垂直\n纬度越高的地方，投影面积形变越大，而在纬度无限接近于极点的位置，面积则会无限大，因此纬度的上限和下限分别是北纬 89° 和南纬 89°。\n虽然在面积上有形变，但是是各个方向上的均等扩大，所以保证了地图方向、角度以及位置关系的正确性。\n\nWeb 墨卡托\nWeb墨卡托，也称伪墨卡托（Pseudo Mercator Projection） ，属于一种不严格的墨卡托投影方式，其被 Google Map 最先发明，后续又被 Bing，百度， OSM 等各个网络地图服务商使用，因此成为了互联网电子地图最常见的投影方式。\n其和墨卡托投影的最大区别在于，墨卡托投影是建立在地球是一个椭球体的基础上进行投影公式计算的，而 Web 墨卡托在其计算公式上直接将椭球体变成了球体，大大简化了投影转化的计算方法，其计算公式为：\n\\left\\{ {\\begin{array}{*{20}{c}}\n{x = \\alpha  \\times \\theta }\\\\\n{y = \\alpha \\times \\ln \\tan (\\frac{\\pi }{4} + \\frac{\\varphi }{2})}\n\\end{array}} \\right.\n其中 x, y 为投影坐标系中的坐标值， \\alpha 为赤道半径， \\theta 为经度， \\varphi 为纬度。\n此外，web 墨卡托投影一般默认为一个正方形。已知赤道半径为 6378137 米，则赤道的周长则为 2\\pi \\alpha = 40075016.68557849，所以投影坐标系中 X 轴的范围为 [-20037508.342789244, 20037508.342789244]，则 Y 轴的范围也为 [-20037508.342789244, 20037508.342789244]，可以通过上面公式反算出纬度被限制在了[-85.0511287， 85.0511287] 范围内。\n在日常地图使用中，使用 web 墨卡托投影的地图已经足够了。但是如果有一些其他的要求，比如说要精确描述区域面积，则一般使用圆锥投影，比如阿尔伯斯投影、兰伯特投影等，这里就不再具体展开，感兴趣的可以看一下 常见的地图投影方式[1]。\nEPSG\n上个小节提到了地理坐标系和投影坐标系，还提到了一些投影方法。就拿墨卡托和web墨卡托来说，前者是将地球看作一个椭球体，后者将地球看作了一个球体。所以说我们并没有一个严格的标准且统一的方式来表述某个点的位置。\n当没有统一标准的时候，就会存在很多体系标准，而当各种体系标准变得庞大且失去统一管理的时候，人们想将不同体系之间的坐标互相转化的话就会变得异常困难。EPSG[2] 就是来管理这些坐标体系的一个组织。\nEPSG 通过 WKID 来管理不同的坐标体系，WKID 简单理解就是 ID，每个坐标体系拥有独一无二的ID。拿一些常用的WKID 举例：\nWGS84 （WKID = 4326）\n在介绍 WGS84 之前，我们需要弄清楚一个概念：大地坐标系。大地坐标系是以参考椭球面为基准面而建立起来的坐标系，也可以简单理解成属于地理坐标系的一种。大地坐标系又分为参心大地坐标系和地心大地坐标系。其中参心坐标系是以椭球几何中心为原点构建的坐标系，一般用来对局部地区大地测绘使用（合适的参心坐标系可以使得某一地区的地图投影变形最小），而地心坐标系是以地球质心为原点构建的坐标系，一般用来对地球整体大地测绘使用。\nWGS84 则属于地心大地坐标系，是世界上第一个统一的大地坐标系，所以也被称为世界大地坐标系，而我们常说的 GPS 定位系统就是依据此坐标系建立的。除了中国地区以外，很多电子地图比如谷歌、Bing 等都是用的是 WGS84。\nCGCS2000（WKID = 4490）\n我国在上世纪50年代和80年代分别建立了北京54和西安80参心大地坐标系，之后随着社会经济，科学的发展，中国测绘、地震部门和科学院有关单位重新建立了中国新一代地心大地坐标系，也就是  CGCS2000，所以也被称为 2000 国家大地坐标系。\n和 WGS84 相比，两者本质上可以算是一致的，只是在计算过程中采用的参数有细微的差别。这个差别映射到地图上，也只会有 cm 级别的不同，因此如果在精度不需要严格到 cm 级别的应用中，两者可以默认相容。\nWeb 墨卡托 （WKID = 3857)\nWeb 墨卡托也在 EPSG 的管理范围下，可见 EPSG 管理的坐标系不仅仅只有地理坐标系，同样也包括投影坐标系。\n其实原本 EPSG 不准备将 web 墨卡托纳入 WKID，因为 web 墨卡托毕竟是采用了不严谨的假设，使得原本是等角投影的墨卡托变成了近似等角，从而直接影响到投影坐标的精度。但是随着 web 墨卡托在 web 领域被广泛使用从而名声大噪，EPSG 也只能将其接受。\nGCJ02 和 BD09\nGCJ02 是中国国家测绘局所制定的坐标系统，其本质就是在 WGS84 经纬度的基础上进行了一层加密。由于国家相关安全保密规定，我国所有对外的地图系统都需要进行加密。所以高德以及谷歌的中国地图都是使用 GCJ02 坐标系。所以，如果在 GCJ02 的坐标系下直接使用 GPS 的经纬度坐标，那么就会得到一个错误的定位地点。\n比如在手机上下载一个GPS定位软件（部分硬件设备获取的GPS信息是原始的GPS信息，而一般地图软件的定位信息都是GCJ02加密过后的），得到天安门的经纬度是 39.907375,116.391349。\n但是在高德地图上，使用该坐标点则定位到其他地方，所以 GCJ02 坐标系在业内也常常被称为火星坐标系。\n而百度在 GCJ02 的基础上又进行了一层加密，这就是 BD09。\n至于 GCJ02 的加密算法是不对外公开的，只有通过相关地图资质的审核，有关部门才会提供相应的加密算法。而国内一些拿到资质的厂商也提供了相应的 API 对外提供，可供用户将 WGS84的坐标转换成 GSJ02 的坐标。\n严格意义上并没有 GCJ02 转化成 WGS84 的反向转化算法。\n\n[1] 常见的地图投影方式: pro.arcgis.com/zh-cn/pro-app/latest/help/mapping/properties/list-of-supported-map-projections.htm\n[2] EPSG: epsg.io/\n[3] 高德API: lbs.amap.com/api/webservice/guide/api/convert/\n[4] 几种互联网地图服务背后的解读（WMS，WFS，WMTS，TMS）: zhuanlan.zhihu.com/p/398998331\n[5] 参心坐标系和地心坐标系: www.jianshu.com/p/7bbbd86dec82\n[6] 墨卡托投影‒ ArcGIS Pro | 文档: pro.arcgis.com/zh-cn/pro-app/latest/help/mapping/properties/mercator.htm\n[7] 聊聊GIS中的坐标系|再版: zhuanlan.zhihu.com/p/98839097\n数据服务\n通过了解坐标系原理，我们知道了如何将三维的地理坐标系转换成平面的投影坐标系。但是光有坐标系肯定是不行的，我们还是需要将对应的数据呈现在坐标系中才能有一个完整的地图，那么就不得不去了解地图常见的数据服务。\nOGC\nOGC （开放地理空间联盟 Open Geospatial Consortium）是一个制定空间信息和基于位置服务相关标准的国际化组织。严格来说，OGC 并不算是一个“官方”组织，但是由于 OGC 有着ESRI、Google、Oracle 等业界强势企业作为其成员，同时还和 W3C、ISO、IEEE 等协会或组织结成合作伙伴关系。因此在 GIS 开发领域，绝大部分开发者或者企业都会依据 OGC 标准来提供地图数据服务。\n在地图数据服务中最显而易见的肯定是图片服务，用图片来承载一个地理信息数据，这个理所应当很好理解。所以当地理信息数据被封装成了图片信息并且可以根据用户的请求而动态返回的服务就被称作 WMS (web map service) 。\n除了图片资源以外，地图上还会有道路信息，POI 信息等，而这些数据往往是灵活的，可编辑的，因此肯定不能通过图片信息进行传递，因此就有了矢量资源。而一般地图的矢量数据会包含空间数据和属性数据，拿常见的 GeoJSON 格式举例：\n{   \n    &quot;type&quot;: &quot;FeatureCollection&quot;,  \n    &quot;features&quot;: [  \n        {  \n            &quot;type&quot;: &quot;Feature&quot;,  \n            &quot;geometry&quot;: {  \n                &quot;type&quot;: &quot;Point&quot;,  \n                &quot;coordinates&quot;: [102.0, 0.5] // 空间数据  \n            },  \n            &quot;properties&quot;: { // 属性数据  \n                &quot;name&quot;: &quot;xx超市&quot;，  \n            }  \n        }  \n    ]  \n}\n这种提供给用户矢量数据并且支持增删改查的服务就被称作 WFS(web feature service)。\n在实际应用中 WMS 和 WFS 也不能够完全胜任要求，比如我打开一张世界地图，服务返回给我一张世界地图的图片，但是我想通过放大的方式来定位到我的家，那么要实现这个功能这个图片的分辨率就会高的不可思议。这种要求显然是不合理的，所以 OGC 在 WMS 服务端的基础上制定了 WMTS(web map tile service) ，也就是我们常说的瓦片服务。此外常见的瓦片服务还有 TMS(tiled map service) ，但是这个服务不是 OGC 创建的协议。\n瓦片\n不同于 WMS，瓦片服务提供的图片是提前制定好的静态图片，可以通过下面的示意图来理解瓦片。\n\n在上面的金字塔模型中，世界地图分成了多层级别的瓦片服务。这个层就对应着地图的放大级别。在最上层，也就是地图缩小到最小程度时，只提供一张图片来展示世界的全貌。用户如果进行放大操作提升地图的放大级别，那么世界地图相应的展示第二个层级的图片，而实际上展示的地理位置区域大小没有变化，只是原本一张图片展示世界全貌，变成了和原本图片同等大小的四张图片来展示世界全貌。和原本相比，就会更加清晰一些。\n同样，用户继续放大，用来展示的层级所拥有的图片数量就会越多，展示的细节就会越来越清晰。但是由于屏幕大小范围有限，所以可以只选择在屏幕范围之内的图片进行下载，这样就避免了下载一张超大的图片，从而减轻了服务压力提升了体验性能。而这种被分割的图片，就被叫做瓦片。\n拿高德地图举例，因为是使用的 web 墨卡托投影，所以呈现的地图是正方形的。其瓦片排布编码的规律如下，其中 z 为放大层级，每个瓦片大小默认为 256 * 256，第 z 层级的瓦片数量为 2^{2z}。\n\n高德地图瓦片链接为 webrd01.is.autonavi.com/appmaptile{x}&amp;y={y}&amp;z={z}，其中 z 为放大层级，x, y 为该瓦片在所在层级的编码。\n当然这种瓦片排布的规律不是通用的，不同厂商制定的瓦片服务都可能存在着一些差别，所以在使用瓦片服务的时候要注意一些。\n定位渲染\n在知道坐标系和地图数据服务之后，我们其实就可以简单的模拟一下地图上的点是如何渲染的了。\n\n\n已知初始条件\n\n定义 DOM container 大小为 1200 * 1000\n初始放大层级为 12\n中心定位点为天安门，也就是 GCJ02坐标系下的 116.397588,39.908775\nWeb 墨卡托投影正方形的边长为 l=40075016.68557849\n\n\n计算 container 要展示出的地图区域\n\n放大层级为 12，横轴或纵轴存在的瓦片个数为 2^{12}=4096\n像素长度比为 ratio = l \\div 4096 \\div 256 = {\\rm{38}}{\\rm{.2185141425881290435791015625}}\ncontainer 展示的地图面积为 area = \\left( {1200 \\times radio} \\right) \\times \\left( {1000 \\times radio} \\right) = 1,752,785,787.9206505990036522605952\n中心点的投影坐标点为\n\\left\\{ {\\begin{array}{*{20}{c}}\n{x = \\alpha  \\times \\theta =12957320.225725248}\\\\\n{y = \\alpha \\times \\ln \\tan (\\frac{\\pi }{4} + \\frac{\\varphi }{2}) = 4852694.552998661}\n\\end{array}} \\right.\n\ncontainer 展示的地图区域为\n\n所在横轴区间 [12934389.117239695, 12980251.334210802]\n所在纵轴区间 [4833585.295927367, 4871803.810069955]\n\n\n\n\n计算出要展示的瓦片\n\n瓦片编号计算公式\n\n\n\n\n\\begin{array}{l}\n{n_x} = \\left{ {\\begin{array}{{20}{l}}\n{  (x + l/2){\\rm{  }}\\ \\bmod \\  {\\rm{ }}(256 \\times ratio)}\\\n{{\\rm{       }}x{\\rm{        }}\\ \\bmod \\  {\\rm{ (}}256 \\times ratio{\\rm{)}}}\n\\end{array}{\\rm{  }}\\begin{array}{{20}{c}}\n\\ \\ \\ {x \\ge 0}\\\n\\ \\ \\ {x &lt; 0}\n\\end{array}} \\right.\\\\\n{n_y} = (l/2 - y){\\rm{ \\  mod \\  (256}} \\times {\\rm{ratio)}}\n\\end{array}\n$$\n+ 瓦片编号区间：\n\t+ 横轴瓦片编号区间 [3370, 3374]  \n\t+ 纵轴瓦片编号区间 [1550, 1553]\n\n那么屏幕可视区范围展示的瓦片分布就应该是：\n![](tiles-z12.png)\n\n4. 验证\n在 ID 编辑器上，将背景配置成高德瓦片，并将放大层级设定为12，中心定位到天安门，可以得到如下图所示内容，发现屏幕内瓦片展示和我们之前手动算出来的结构保持一致。"},"front-end/interview/baidu/1":{"title":"1","links":[],"tags":[],"content":"一维数组变二维数组\n题目：[1, 2, 3, 4, 5, 6, 7, 8, 9] ⇒ [[1, 2, 3],[4, 5, 6],[7, 8, 9]]\n在JavaScript中，可以使用数组的slice方法和一个循环来将一个一维数组转换为一个二维数组。下面是一个示例代码：\nfunction convertTo2DArray(arr, chunkSize) {\n  var result = [];\n  for (var i = 0; i &lt; arr.length; i += chunkSize) {\n    result.push(arr.slice(i, i + chunkSize));\n  }\n  return result;\n}\n \nvar inputArray = [1, 2, 3, 4, 5, 6, 7, 8, 9];\nvar outputArray = convertTo2DArray(inputArray, 3);\n \nconsole.log(outputArray);\n\nslice 不会修改原数组，只会返回一个浅复制了原数组中的元素的一个新数组。\n\n输出结果，为什么？\nconst obj3 = {a: 1};\nconst obj4 = {b: 2};\nconsole.log(obj3 == obj4);  // false\nconsole.log(obj3 === obj4); // false\n结果：\nfalse，false\n\n原因：\n在这段代码中，obj3和obj4分别是两个独立的对象，它们开辟的堆内存地址是完全不一样。==运算符用于比较两个操作数是否相等，而===运算符用于比较两个操作数是否严格相等。\n根据对象的比较规则，当使用==运算符比较两个对象时，它们将会进行类型转换后再进行比较。由于obj3和obj4是不同的对象，即使它们的属性值相同，它们的引用也不同，因此在进行类型转换后，它们会被视为不相等的对象。因此，console.log(obj3 == obj4);的输出结果将会是false。\n而在使用===运算符比较两个对象时，不会进行类型转换，而是直接比较两个操作数的值和类型是否完全相同。由于obj3和obj4是不同的对象，且类型也不同，即使它们的属性值相同，它们也不会被视为严格相等的对象。因此，console.log(obj3 === obj4);的输出结果同样会是false。\n\n总结起来，无论是使用运算符还是=运算符，obj3和obj4都不会被视为相等或严格相等的对象，因为它们是不同的对象。\n\nthis: 输出结果, 为什么?\nconst obj1 = {\n  fn: () =&gt; {\n    return this\n  }\n}\nconst obj2 = {\n  fn: function(){\n    return this\n  }\n}\n \nconsole.log(obj1.fn());\nconsole.log(obj2.fn());\n输出结果：\n\nwindow || undefined\nobj2\n\n原因是：\n在箭头函数 fn 中的 this 关键字指向的是定义该函数的上下文，而不是调用该函数的对象。因此，当 obj1.fn() 被调用时，由于箭头函数没有它自己的this，当你调用fn()函数时，this指向会向上寻找，因此箭头函数中的 this 指向的是全局对象（在浏览器环境下通常是 window 对象），因此返回的是 undefined。\n而在普通函数 fn 中的 this 关键字指向的是调用该函数的对象。在 obj2.fn() 中，函数 fn 是作为 obj2 的方法被调用的，所以其中的 this 指向的是 obj2 对象本身，因此返回的是 obj2。\n\n准确来说，不能说是被 obj2 调用，this 就是 obj2 而是 fn 函数在 obj2 内部，this 取决于位置，而不是调用者。\n\n需要注意的是，在严格模式下，普通函数中的 this 也会变为 undefined，因此即使是 obj2.fn() 也会返回 undefined。但在示例中没有明确指定使用严格模式，所以默认情况下运行在非严格模式下。\nPromise: 输出结果,为什么\nconsole.log(&#039;1&#039;);\nfunction promiseFn() {\n  return new Promise((resolve, reject) =&gt; {\n    setTimeout(()=&gt; {\n      console.log(&#039;2&#039;);\n    })\n    resolve(&#039;3&#039;);\n    console.log(&#039;4&#039;)\n  })\n}\n \npromiseFn().then(res =&gt; {\n  console.log(res);\n});\n输出结果： 1 4 3 2\n原因是：\n\n首先，代码从上往下执行，把console.log(&#039;1&#039;)放入同步任务\n再调用promiseFn()，因为new Promise是同步任务，所以放入同步任务，继续执行\n遇到setTimout这个宏任务，放入宏任务队列中\n遇到resolve(‘3’)，把res返回\n之后再执行.then()，因为promise.then是微任务，所以放入微任务队列\n代码是先执行同步任务，再执行微任务，之后再是宏任务\n所以输出结果为1 4 3 2\n\n\n这里涉及到了EventLoop的执行机制：\n\n执行同步代码。\n执行所有微任务。\n更新渲染（重绘页面）。\n执行下一个宏任务。\n重复步骤2~4。\n\n\n实现斐波那契的第N个值\n题目：实现斐波那契的第N个值（从0开始），要求时间复杂度为O(n)\n\n首先，说到斐波那契第一个想到的肯定是如下的算法，但这可是百度啊，如果只是这种程度的话如何能和同样面相同岗位的人竞争呢，所以我们得想到如下算法有什么缺点，然后如何优化。\n\nfunction fib(n) {\n  if (n == 0 || n === 1) return 1;\n  return fib(n - 1) + fib(n - 2);\n};\n \nconsole.log(fib(3)); // 5\nconsole.log(fib(5)); // 8\n单纯的使用递归看似没什么问题，也能运算出结果，但是里面有个致命的问题，首先，时间复杂度就不对，递归思想的复杂度为 O(2^n) ，它不为O(n)，然后还有会重复计算，比如计算 n=3 时，会计算fib(1) + fib(2)，再次计算 fib(4) 时，会先算fib(3) = fib(1) + fib(2)，然后再计算fib(4) = fib(1) + fib(2) + fib(3)，在这里，fib(1)和fib(2)重复计算了两次，对于性能损耗极大。此时的你如果对动态规划敏感的话，就会从中想到动态规划其中最关键的特征——重叠子问题\n\n因此，使用动态规划来规避重复计算问题，算是比较容易想到较优的一种解法，并且向面试官展现了你算法能力中有动态规划的思想，对于在面试中的你加分是极大的。\n\n以下是动态规划思路的算法，状态转移方程为dp[i] = dp[i-1] + dp[i-2]\nfunction fibonacci(n) { \n  if (n &lt;= 1) return n;\n  let fib = [0, 1]; // 保存斐波那契数列的结果 \n  for (let i = 2; i &lt;= n; i++) { \n      fib[i] = fib[i - 1] + fib[i - 2]; // 计算第i个斐波那契数 \n  } \n  return fib[n]; \n}\n\n当然，你可能会说，在面试中怎么可能一下子就能想到动态规划，所以在面试前你需要背一背相关的状态转移方程，当你对算法问题分析到一定程度时，就能够记忆起这些状态转移方程，提高你写算法的速度。\n\n在面试中，动态规划的常用状态转移方程可以根据问题的具体情况有所不同。以下是几个常见的动态规划问题和它们对应的状态转移方程示例：\n\n\n斐波那契数列（Fibonacci Sequence）：\n\n\n\ndp[i] = dp[i-1] + dp[i-2]，其中 dp[i] 表示第 i 个斐波那契数。\n\n\n\n爬楼梯问题（Climbing Stairs）：\n\n\n\ndp[i] = dp[i-1] + dp[i-2]，其中 dp[i] 表示爬到第 i 级楼梯的方法数。\n\n\n\n背包问题（Knapsack Problem）：\n\n\n\ndp[i][j] = max(dp[i-1][j], dp[i-1][j-weight[i]] + value[i])，其中 dp[i][j] 表示在前 i 个物品中选择总重量不超过 j 的最大价值，weight[i] 表示第 i 个物品的重量，value[i] 表示第 i 个物品的价值。\n\n\n\n最长递增子序列（Longest Increasing Subsequence）：\n\n\n\ndp[i] = max(dp[j] + 1, dp[i])，其中 dp[i] 表示以第 i 个元素结尾的最长递增子序列的长度，j 为 0 到 i-1 的索引，且 nums[i] &gt; nums[j]。\n\n\n\n最大子数组和（Maximum Subarray Sum）：\n\n\n\ndp[i] = max(nums[i], nums[i] + dp[i-1])，其中 dp[i] 表示以第 i 个元素结尾的最大子数组和。\n\n\n\n最长公共子序列（Longest Common Subsequence）：\n\n\n\n如果 str1[i] 等于 str2[j]，则 dp[i][j] = dp[i-1][j-1] + 1；\n否则，dp[i][j] = max(dp[i-1][j], dp[i][j-1])，其中 dp[i][j] 表示 str1 的前 i 个字符和 str2 的前 j 个字符的最长公共子序列的长度。\n\n\n\n编辑距离（Edit Distance）：\n\n\n\n如果 word1[i] 等于 word2[j]，则 dp[i][j] = dp[i-1][j-1]；\n否则，dp[i][j] = min(dp[i-1][j], dp[i][j-1], dp[i-1][j-1]) + 1，其中 dp[i][j] 表示将 word1 的前 i 个字符转换为 word2 的前 j 个字符所需的最少操作次数。\n\n\n\n打家劫舍（House Robber）：\n\n\n\ndp[i] = max(dp[i-1], dp[i-2] + nums[i])，其中 dp[i] 表示前 i 个房屋能够获得的最大金额，nums[i] 表示第 i 个房屋中的金额。\n\n\n\n最大正方形（Maximal Square）：\n\n\n\n如果 matrix[i][j] 等于 1，则 dp[i][j] = min(dp[i-1][j], dp[i][j-1], dp[i-1][j-1]) + 1；\n否则，dp[i][j] = 0，其中 dp[i][j] 表示以 matrix[i][j] 为右下角的最大正方形的边长。\n\n\n\n手写 Event Bus (事件总线)\n当需要手动实现一个简单的 EventBus 时，你可以创建一个全局的事件总线对象，并在该对象上定义事件的订阅和发布方法。\nclass EventBus {\n    constructor() {\n        this.events = {}; // 存储事件及其对应的回调函数列表\n    }\n \n    // 订阅事件\n    subscribe(eventName, callback) {\n        // 如果事件不存在，创建一个空的回调函数列表\n        this.events[eventName] = this.events[eventName] || [];\n        // 将回调函数添加到事件的回调函数列表中\n        this.events[eventName].push(callback); \n    }\n \n    // 发布事件\n    publish(eventName, data) {\n        if (this.events[eventName]) {\n            this.events[eventName].forEach(callback =&gt; {\n                // 执行回调函数，并传递数据作为参数\n                callback(data);\n            });\n        }\n    }\n \n    // 取消订阅事件\n    unsubscribe(eventName, callback) {\n        if (this.events[eventName]) {\n            // 过滤掉要取消的回调函数\n            this.events[eventName] = \n                this.events[eventName].filter(cb =&gt; cb !== callback); \n        }\n    }\n}\n使用上述 EventBus 类，你可以执行以下操作：\n// 创建全局事件总线对象\nconst eventBus = new EventBus();\n \nconst callback1 = data =&gt; {\n  console.log(&#039;Callback 1:&#039;, data);\n};\n \nconst callback2 = data =&gt; {\n  console.log(&#039;Callback 2:&#039;, data);\n};\n \n// 订阅事件\neventBus.subscribe(&#039;event1&#039;, callback1);\neventBus.subscribe(&#039;event1&#039;, callback2);\n \n// 发布事件\neventBus.publish(&#039;event1&#039;, &#039;Hello, world!&#039;);\n \n// 输出：\n// Callback 1: Hello, world!\n// Callback 2: Hello, world!\n \n// 取消订阅事件\neventBus.unsubscribe(&#039;event1&#039;, callback1);\n \n// 发布事件\neventBus.publish(&#039;event1&#039;, &#039;Goodbye!&#039;);\n \n// 输出：\n// Callback 2: Goodbye!\n在上述示例中，我们创建了一个 EventBus 类，该类具有 subscribe、publish 和 unsubscribe 方法。subscribe 方法用于订阅事件，publish 方法用于发布事件并触发相关的回调函数，unsubscribe 方法用于取消订阅事件。我们使用全局的 eventBus 对象来执行订阅和发布操作。\n这个简单的 EventBus 实现允许你在不同的组件或模块之间发布和订阅事件，以实现跨组件的事件通信和数据传递。你可以根据需要对 EventBus 类进行扩展，添加更多的功能，如命名空间、一次订阅多个事件等。\n\n当问到EventBus时，得预防面试官问到EvnetEmitter，不过当我在网上查找相关的资料时，发现很多人似乎都搞混了这两个概念，虽然我在这里的手写原理似乎也差不多，但在实际使用中，两者可能在细节上有所不同。因此，在具体场景中，你仍然需要根据需求和所选用的实现来查看相关文档或源码，以了解它们的具体实现和用法。\n\n下面是一个简单的 EventEmitter 类实现的基本示例：\nclass EventEmitter {\n  constructor() {\n    this.events = {}; // 用于存储事件及其对应的回调函数列表\n  }\n \n  // 订阅事件\n  on(eventName, callback) {\n    this.events[eventName] = this.events[eventName] || []; // 如果事件不存在，创建一个空的回调函数列表\n    this.events[eventName].push(callback); // 将回调函数添加到事件的回调函数列表中\n  }\n \n  // 发布事件\n  emit(eventName, data) {\n    if (this.events[eventName]) {\n      this.events[eventName].forEach(callback =&gt; {\n        callback(data); // 执行回调函数，并传递数据作为参数\n      });\n    }\n  }\n \n  // 取消订阅事件\n  off(eventName, callback) {\n    if (this.events[eventName]) {\n      this.events[eventName] = this.events[eventName].filter(cb =&gt; cb !== callback); // 过滤掉要取消的回调函数\n    }\n  }\n  \n  // 添加一次性的事件监听器 \n  once(eventName, callback) { \n      const onceCallback = data =&gt; { \n          callback(data); // 执行回调函数 \n          this.off(eventName, onceCallback); // 在执行后取消订阅该事件 \n      }; \n      this.on(eventName, onceCallback); \n  }\n}\n使用上述 EventEmitter 类，你可以执行以下操作：\nconst emitter = new EventEmitter();\n \nconst callback1 = data =&gt; {\n  console.log(&#039;Callback 1:&#039;, data);\n};\n \nconst callback2 = data =&gt; {\n  console.log(&#039;Callback 2:&#039;, data);\n};\n \n// 添加一次性事件监听器 \nconst onceCallback = data =&gt; { \n    console.log(&#039;Once Callback:&#039;, data); \n};\n \n// 订阅事件\nemitter.on(&#039;event1&#039;, callback1);\nemitter.on(&#039;event1&#039;, callback2);\nemitter.once(&#039;event1&#039;, onceCallback);\n \n// 发布事件\nemitter.emit(&#039;event1&#039;, &#039;Hello, world!&#039;);\n \n// 输出：\n// Callback 1: Hello, world!\n// Callback 2: Hello, world!\n// Once Callback: Hello, world!\n \n// 取消订阅事件\nemitter.off(&#039;event1&#039;, callback1);\n \n// 发布事件\nemitter.emit(&#039;event1&#039;, &#039;Goodbye!&#039;);\n \n// 输出：\n// Callback 2: Goodbye!\n在上述示例中，EventEmitter 类具有 on、emit 、 off和once 方法。on 方法用于订阅事件，emit 方法用于发布事件并触发相关的回调函数，off 方法用于取消订阅事件，once方法用于添加一次性的事件监听器。你可以根据需求对 EventEmitter 类进行扩展，添加更多的功能，比如一次订阅多个事件、取消所有事件订阅等。\neventBus,eventEmitter的区别\nEventBus 和 EventEmitter 都是用于实现事件发布-订阅模式的工具，但它们在实现和使用上有一些区别。\n\n\n实现方式：\n\n\n\nEventBus：EventBus 是一个全局的事件总线，通常是作为一个单例对象存在，用于在不同组件或模块之间传递事件和数据。在 Vue.js 中，Vue 实例可以充当 EventBus 的角色。\nEventEmitter：EventEmitter 是一个基于类的模块，通常是作为一个实例对象存在，用于在单个组件或模块内部实现事件的发布和订阅。\n\n\n\n使用范围：\n\n\n\nEventBus：EventBus 的作用范围更广泛，可以跨越不同组件、模块或文件进行事件的发布和订阅。它可以实现多个组件之间的通信和数据传递。\nEventEmitter：EventEmitter 主要用于单个组件或模块内部，用于实现内部事件的处理和通信。\n\n\n\n依赖关系：\n\n\n\nEventBus：EventBus 通常需要一个中央管理的实例，因此需要在应用程序的某个地方进行创建和管理。在 Vue.js 中，Vue 实例可以用作全局的 EventBus。\nEventEmitter：EventEmitter 可以在需要的地方创建实例对象，并将其用于内部事件的发布和订阅。\n\n\n\n命名空间：\n\n\n\nEventBus：EventBus 可以使用不同的事件名称来进行事件的区分和分类，可以使用命名空间来标识不同类型的事件。\nEventEmitter：EventEmitter 通常使用字符串作为事件的名称，没有直接支持命名空间的概念。\n\n\n\n\n总结起来，EventBus 主要用于实现跨组件或模块的事件通信和数据传递，适用于大型应用程序；而 EventEmitter 主要用于组件或模块内部的事件处理和通信，适用于小型应用程序或组件级别的事件管理。选择使用哪种工具取决于你的具体需求和应用场景。\n\n浏览器一天弹一个弹窗\n题目：（场景题）在浏览器中一天只能弹出一个弹窗，如何实现，说一下你的思路？\n要在浏览器中实现一天只能弹出一个弹窗的功能，可以使用本地存储（localStorage）来记录弹窗状态。下面是一种实现方案：\n\n当页面加载时，检查本地存储中是否已存在弹窗状态的标记。\n如果标记不存在或者标记表示上一次弹窗是在前一天，则显示弹窗并更新本地存储中的标记为当前日期。\n如果标记存在且表示上一次弹窗是在当天，则不显示弹窗。\n\n以下是示例代码：\n// 检查弹窗状态的函数\nfunction checkPopupStatus() {\n    // 获取当前日期\n    const currentDate = new Date().toDateString();\n \n    // 从本地存储中获取弹窗状态标记\n    const popupStatus = localStorage.getItem(&#039;popupStatus&#039;);\n \n    // 如果标记不存在或者标记表示上一次弹窗是在前一天\n    if (!popupStatus || popupStatus !== currentDate) {\n        // 显示弹窗\n        displayPopup();\n \n        // 更新本地存储中的标记为当前日期\n        localStorage.setItem(&#039;popupStatus&#039;, currentDate);\n    }\n}\n \n// 显示弹窗的函数\nfunction displayPopup() {\n    // 在这里编写显示弹窗的逻辑，可以是通过修改 DOM 元素显示弹窗，或者调用自定义的弹窗组件等\n    console.log(&#039;弹出弹窗&#039;);\n}\n \n// 在页面加载时调用检查弹窗状态的函数\ncheckPopupStatus();\n在这个实现中，checkPopupStatus 函数会在页面加载时被调用。它首先获取当前日期，并从本地存储中获取弹窗状态的标记。如果标记不存在或者表示上一次弹窗是在前一天，就会调用 displayPopup 函数显示弹窗，并更新本地存储中的标记为当前日期。\n通过这种方式，就可以确保在同一天只能弹出一个弹窗，而在后续的页面加载中不会重复弹窗。"},"front-end/interview/big-front-end/js-1-10":{"title":"js-1-10","links":[],"tags":[],"content":"1. implement curry()\nconst join = (a, b, c) =&gt; {\n   return `${a}_${b}_${c}`\n}\n \nconst curriedJoin = curry(join)\n \ncurriedJoin(1, 2, 3) // &#039;1_2_3&#039;\n \ncurriedJoin(1)(2, 3) // &#039;1_2_3&#039;\n \ncurriedJoin(1, 2)(3) // &#039;1_2_3&#039;\n \nfunction curry(fn) {\n  return function curried(...args) {\n    if (args.length &gt;= fn.length){\n      return fn.apply(this, args)\n    } else {\n      return (...other) =&gt; {\n        return curried.apply(this, args.concat(other))\n      }\n    }\n  }\n}\n\n\n\njavascript.info/currying-partials\n\n\nlodash.com/docs/4.17.15#curry\n\n\n\n2. implement curry() with placeholder support\nconst  join = (a, b, c) =&gt; {\n   return `${a}_${b}_${c}`\n}\n \nconst curriedJoin = curry(join)\nconst _ = curry.placeholder\n \ncurriedJoin(1, 2, 3) // &#039;1_2_3&#039;\n \ncurriedJoin(_, 2)(1, 3) // &#039;1_2_3&#039;\n \ncurriedJoin(_, _, _)(1)(_, 3)(2) // &#039;1_2_3&#039;\n第二题，相比于第一题，多了一个 placeholder 占位符的处理，根据样例，后来的参数需要放置在之前的placeholder的地方。 大概想法和第一问是一样的，除了在判断参数是否够用的时候，需要过滤掉 placeholder：\nconst expectedArgLength = func.length\nconst isArgsEnough = args.length &gt;= expectedArgLength &amp;&amp;\n  args.slice(0, expectedArgLength)\n    .every(arg =&gt; arg !== curry.placeholder)\n如果参数不够，和之前一样我们需要把参数和后来调用的参数合并在一起，再递归。 但是 这里不能简单的  concat，而需要寻找 placeholder 然后 merge：\nfunction curry(fn) {\n  return function curried(...args) {\n    const expectedArgLength = fn.length\n    const isArgsEnough = args.length &gt;= expectedArgLength &amp;&amp;\n      args.slice(0, expectedArgLength)\n        .every(arg =&gt; arg !== curry.placeholder)\n    if (isArgsEnough) {\n      return fn.apply(this, args)\n    } else {\n      return function (...newArgs) {\n        const finalArgs = []\n        let i = 0\n        let j = 0\n        while (i &lt; args.length &amp;&amp; j &lt; newArgs.length) {\n          if (args[i] === curry.placeholder) {\n            finalArgs.push(newArgs[j])\n            i += 1\n            j += 1\n          } else {\n            finalArgs.push(args[i])\n            i += 1\n          }\n        }\n \n        while (i &lt; args.length) {\n          finalArgs.push(args[i])\n          i += 1\n        }\n \n        while (j &lt; newArgs.length) {\n          finalArgs.push(newArgs[j])\n          j += 1\n        }\n        return curried(...finalArgs)\n      }\n    }\n  }\n}\n3. implement Array.prototype.flat()\nfunction flat(arr, depth = 1) {\n  return depth ? \n    arr.reduce((acc, curr) =&gt; {\n      return [...acc, ...(Array.isArray(curr) ? flat(curr, depth - 1) : [curr])]\n    }, []) : arr;\n}\n4. implement basic throttle()\n再次说明一下，throttle(func, delay)返回一个function，这个function无论多么频繁地调用，原始的 func 的调用也不会超过指定的频率。\n比如，这是throttle之前的调用\n─ A ─ B ─ C ─ ─ D ─ ─ ─ ─ ─ ─ E ─ ─ F ─ G\n按照3个单位进行throttle过后\n─ A ─ ─ ─ C ─ ─ ─D ─ ─ ─ ─ E ─ ─ ─ G \n注意到\n\nA 因为不在任何的冷却时间，所以立即被执行\nB 被跳过了，因为B和C都在A的冷却时间里。\n\n注意\n\n请按照以上 spec 完成代码。以上逻辑和lodash.throttle()并不完全一致\n因为 window.setTimeout 和 window.clearTimeout 并不精确。所以在test你写的代码的时候，这两个方法会被替换为静态的实现。不过不用担心，interface 是一样的。\n\nfunction throttle(func, wait) {\n    let waiting = false, lastArgs = null;\n    return function(...args) {\n        if(!waiting) {\n            func.apply(this, args)\n            waiting = true;\n            let timeout = () =&gt; setTimeout(() =&gt; {\n                waiting = false;\n                if(lastArgs){\n                    func.apply(this, lastArgs);\n                    waiting = true;\n                    lastArgs = null;\n                    timeout();\n                }\n            }, wait);\n            timeout();\n        } else {\n            lastArgs = args\n        }\n    }\n}\nthrottle 是一个很考验闭包功底的练习，两个变量维护在闭包内：\n\nwaiting：记录当前是否处理等待状态；\nlastArgs：记录上一次 throttle 调用的参数；\n\n\nflowchart TB\n    clause[&quot;waiting = false, lastArgs = null&quot;]\n    firstCall[&quot;func(0): called&quot;]\n    secondCall[&quot;func(1): wait&quot;]\n    alotof[&quot;many wait call...&quot;]\n    sixthCall[&quot;func(5): wait&quot;]\n    waitOver1[&quot;no func call: func(5) exec&quot;]\n    seventhCall[&quot;func(6): wait&quot;]\n    eighthCall[&quot;func(7): wait&quot;]\n    waitOver2[&quot;no func call: func(7) exec&quot;]\n    waiting[&quot;no func call, wait a moment...&quot;]\n    newCall[&quot;func(-1): called&quot;]\n    \n    clause --&gt; firstCall\n    firstCall --&gt; secondCall\n    secondCall --&gt; alotof\n    alotof --&gt; sixthCall\n    sixthCall --&gt; waitOver1\n    waitOver1 --&gt; seventhCall\n    seventhCall --&gt; eighthCall\n    eighthCall --&gt; waitOver2\n    waitOver2 --&gt; waiting\n    waiting --&gt; newCall\n    \n    subgraph &quot;first call (called)&quot;\n      direction LR\n      firstCall--&gt; clause1[&quot;waiting = true, lastArgs = null, args = 0&quot;]\n    end\n    \n    subgraph &quot;second call (timing)&quot;\n      direction RL\n      secondCall--&gt; clause2[&quot;waiting = true, lastArgs = 1, args = 0&quot;]\n    end\n    \n    subgraph &quot;sixth call  (timing)&quot;\n      direction RL\n      sixthCall--&gt; clause6[&quot;waiting = true, lastArgs = 5, args = 0&quot;]\n    end\n    \n    subgraph &quot;over call1  (time over)&quot;\n      direction RL\n      waitOver1--&gt; clause4[&quot;waiting = true, lastArgs = null, args = 0&quot;]\n    end\n\n    subgraph &quot;seventh call  (timing)&quot;\n      direction RL\n      seventhCall--&gt; clause7[&quot;waiting = true, lastArgs = 6, args = 0&quot;]\n    end\n    subgraph &quot;eighth call  (timing)&quot;\n      direction RL\n      eighthCall--&gt; clause8[&quot;waiting = true, lastArgs = 7, args = 0&quot;]\n    end\n    subgraph &quot;over call2  (time over)&quot;\n      direction RL\n      waitOver2--&gt; clause9[&quot;waiting = true, lastArgs = null, args = 0&quot;]\n    end\n    \n\n      waiting --&gt; clause10[&quot;waiting = false, lastArgs = null, args = 0&quot;]\n\n    \n    subgraph &quot;new call  (called)&quot;\n      newCall --&gt; clause11[&quot;waiting = false, lastArgs = null, args = -1&quot;]\n    end\n\n我们从上图，一步步分析其中闭包变量变化，以及 throttled func （throttle 函数返回的函数）的执行：\n\n根据题目要求，第一次调用  throttled func 时需要执行一次，然后进入 waiting 状态；\n进入 waiting 状态时，会执行一个 setTimeout，等待时间则是传入的 wait，在这个时间间隔内， throttled func 都不会执行，而是将其参数保存到闭包中；\n之后的 func(1) ~ func(5) 都在 wait 间隔中调用了，每次调用都会更新 lastArgs，args 并没有随着 func 调用而更新；\n之后没有 func 调用，直到 wait 时间 timeout 了，获取到最新的 lastArgs = 5，调用原函数，并置空 lastArgs；\n紧接着 func(6)，func(7) 调用，仍在 wait 时间间隔内，类似操作，更新 lastArgs；\n之后没有 func 调用，使用 lastArgs = 7 执行原函数，置空 lastArgs；\n等到 wait 时间间隔外后，仍没有 func 调用，waiting = true，状态复原，将开启新一轮 throttled；\nfunc(-1) 调用，首次直接执行，此时更新了 args；\n\n\n这里的一个疑惑点，在于为什么要保留使用 lastArgs 保留上一次的 args ？\n上述详细的分析可知，每次 timeout 闭包捕获的 args，其实都是 timeout 函数声明定义时观测到的作用域，也就是 timeout 的递归调用不结束，args 总是第一次执行时的值。\n这不是主要原因，重点是，在 wait timeout 前的 throttled  时间内，如何忽略掉多次频繁的调用？\n出于这个首要目的，我们首先要以 timeout 时间点为基准，之前的调用都不执行，只是记录调用的参数；\ntimeout 后，获取最后一次传参执行函数，并以该参数为判断依据，决定是否需要继续 wait。\n因为执行原函数后，仍会递归调用一次 timeout 函数，在内部判断是否存在 lastArgs，有值则继续 wait；\n为空则清空 waiting 状态，等待新的 throttle 。\n\n5. implement throttle() with leading &amp; trailing option\n该题目是4. 手写throttle()的后续，请先完成第4题。\n本题目中你需要实现一个增强的throttle()，使其支持第三个参数option: {leading: boolean, trailing: boolean}\n\nleading: 是否立即执行\ntrailing: 是否在冷却后执行\n\n\n手写throttle() 实际上是 {leading: true, trailing: true}的特殊情形。\n\n具体说明：\n同样地按照之前的3单位的throttle来举例。\n─ A ─ B ─ C ─ ─ D ─ ─ ─ ─ ─ ─ E ─ ─ F ─ G \n\n用{leading: true, trailing: true} 来 throttle 后，我们得到\n─ A ─ ─ ─ C ─ ─ ─ D ─ ─ ─ ─ E ─ ─ ─ G \n\n如果是 {leading: false, trailing: true}，A 和 E 被跳过了\n─ ─ ─ ─ C ─ ─ ─ D ─ ─ ─ ─ ─ ─ ─ G \n\n如果是 {leading: true, trailing: false}，只有 A D E 被保留\n─ A ─ ─ ─ ─ D ─ ─ ─ ─ ─ ─ E\n\n如果是 {leading: false, trailing: false}，显而易见，什么都不会发生\n这个难度没有增加，只是简单的扩展，代码如下：\nfunction throttle(func, wait, option = { leading: true, trailing: true }) {\n  let waiting = false, lastArgs = null;\n  const { leading, trailing } = option\n  return function (...args) {\n    if (!waiting) {\n      if (leading) {\n        func.apply(this, args)\n      }\n      waiting = true;\n      let timeout = () =&gt; setTimeout(() =&gt; {\n        waiting = false;\n        if (lastArgs &amp;&amp; trailing) {\n          func.apply(this, lastArgs);\n          waiting = true;\n          lastArgs = null;\n          timeout();\n        }\n      }, wait);\n      timeout();\n    } else {\n      lastArgs = args\n    }\n  }\n}\n6. implement basic debounce()\n你能够自己实现一个基本的debounce()吗？\n\n当事件触发时，相应的函数并不会立即触发，而是会等待一定的时间；\n当事件密集触发时，函数的触发会被频繁的推迟；\n只有等待了一段时间也没有事件触发，才会真正的执行响应函数；\n\nfunction debounce(func, wait) {\n  let cancel = null;\n  return (...args) =&gt; {\n    clearTimeout(cancel)\n    cancel = setTimeout(() =&gt; func(...args), wait)\n  }\n}\n7. implement debounce() with leading &amp; trailing option\n本题目中你需要实现一个增强的 debounce()，使其支持第三个参数 option: {leading: boolean, trailing: boolean}\n\nleading: 是否立即执行\ntrailing: 是否在冷却后执行\n\n\n手写 debounce() 实际上是 {leading: false, trailing: true}的特殊情形。\n\nfunction debounce(func, wait, option = {leading: false, trailing: true}) {\n  let cancel = null\n  return (...args) =&gt; {\n    let isCalled = false;\n    if(!cancel &amp;&amp; option.leading){\n      func(...args)\n      isCalled = true;   // 已经立即执行, 阻止下次触发的立即执行\n    }\n    clearTimeout(cancel)\n \n    cancel = setTimeout(()=&gt; {\n      cancel = null\n      if(!isCalled &amp;&amp; option.trailing){\n        func(...args)\n      }\n    }, wait)\n  }\n}\nwith cancel method\nfunction debounce(func, wait, option = {leading: false, trailing: true}) {\n  let timer = null\n  \n  _debounce(...args) =&gt; {\n    let isCalled = false;\n    if(!cancel &amp;&amp; option.leading){\n      func(...args)\n      isCalled = true;   // 已经立即执行, 阻止下次触发的立即执行\n    }\n    clearTimeout(cancel)\n \n    cancel = setTimeout(()=&gt; {\n      timer = null\n      if(!isCalled &amp;&amp; option.trailing){\n        func(...args)\n      }\n    }, wait)\n  }\n  _debounce.cancel = function() {\n    if (timer) clearTimeout(timer)\n    timer = null\n    isInvoke = false\n  }\n  return _debounce\n}\n8. can you shuffle() an array?\n能否手写一个shuffle() ?\n当传入一个数组的时候，shuffle() 需要更换元素的顺序，每一种最终的数列都需要被相等的概率生成。\n比如：\nconst arr = [1, 2, 3, 4]\n以上的数组共有 4! = 24 中不同的排列：\n[1, 2, 3, 4]\n[1, 2, 4, 3]\n[1, 3, 2, 4]\n[1, 3, 4, 2]\n[1, 4, 2, 3]\n[1, 4, 3, 2]\n[2, 1, 3, 4]\n[2, 1, 4, 3]\n[2, 3, 1, 4]\n[2, 3, 4, 1]\n[2, 4, 1, 3]\n[2, 4, 3, 1]\n[3, 1, 2, 4]\n[3, 1, 4, 2]\n[3, 2, 1, 4]\n[3, 2, 4, 1]\n[3, 4, 1, 2]\n[3, 4, 2, 1]\n[4, 1, 2, 3]\n[4, 1, 3, 2]\n[4, 2, 1, 3]\n[4, 2, 3, 1]\n[4, 3, 1, 2]\n[4, 3, 2, 1]\n你写的 shuffle() 需要按照相同的概率(1/24)来返回上述排列中的一种。\nfunction shuffle(arr) {\n  for(let i = arr.length - 1; i &gt; 0; i--){\n    let j = Math.floor(Math.random() * (i + 1));\n    [arr[j], arr[i]] = [arr[i], arr[j]];\n  }\n}\n9. decode message\n在一个字符串的二维数组中，有一个隐藏字符串。\nI B C A L K A\nD R F C A E A\nG H O E L A D \n可以按照如下步骤找出隐藏消息\n\n从左上开始，向右下前进\n无法前进的时候，向右上前进\n无法前进的时候，向右下前进\n2和3的重复\n\n无法前进的时候，经过的字符就就是隐藏信息\n比如上面的二维数组的话，隐藏消息是IROCLED\n注：如果没有的话，返回空字符串\n高赞答案\nfunction decode(message) {\n  let i = 0, j = 0, cols = message[0]?.length\n  let decoded = &#039;&#039;, step = 1\n \n  while(j &lt; cols) {\n    decoded += message[i][j]\n    if(!message[i+step]){\n      step *= -1\n    }\n    i += step\n    j++\n  }\n \n  return decoded\n}\n我的答案\nfunction decode(message) {\n  let word = &quot;&quot;;\n  let goingDown = true;\n  let col = 0, row = 0, wallRow = message.length;\n  if(wallRow === 0) return &quot;&quot;;\n  let wallCol = message[0].length;\n  if(wallCol === 0 ) return &quot;&quot;;\n  while (col &lt; wallCol) {\n    word += message[row][col];\n    if(row === wallRow - 1){\n      goingDown = false;\n    } else if(row === 0) {\n      goingDown = true;\n    }\n    if(goingDown){\n      row++;\n    }else{\n      row--;\n    }\n    col++;\n  }\n  return word;\n}\n10. first bad version\n一个程序有多个版本，不知道什么时候开始有个bug混在其中。请你找到第一个坏掉的版本。\n特定版本是否有bug，可以用isBad(revision)进行判定。\n注意\n\n传入的都是非负整数\n如果没有找到，返回-1\n\nfunction firstBadVersion(isBad) {\n    // 一个二分法查找\n  return (version) =&gt; {\n    let start = 0, end = version;\n    while (start &lt;= end) {\n      const mid = Math.floor((start + end) / 2);\n      if(isBad(mid)){\n        end = mid - 1;\n      } else {\n        start = mid + 1;\n      }\n    }\n    return start &gt; version ? -1 : start; \n  }\n}"},"front-end/interview/big-front-end/js-11-20":{"title":"js-11-20","links":[],"tags":[],"content":"11. what is Composition? create a pipe()\n现在需要你自己写一个pipe() 方法。\n假设有一些简单的四则运算方法：\nconst times = (y) =&gt;  (x) =&gt; x * y\nconst plus = (y) =&gt; (x) =&gt; x + y\nconst subtract = (y) =&gt; (x) =&gt; x - y\nconst divide = (y) =&gt; (x) =&gt; x / y\npipe() 可以用来生成新的计算方式\npipe([\n  times(2),\n  times(3)\n])  \n// x * 2 * 3\n \npipe([\n  times(2),\n  plus(3),\n  times(4)\n]) \n// (x * 2 + 3) * 4\n \npipe([\n  times(2),\n  subtract(3),\n  divide(4)\n]) \n// (x * 2 - 3) / 4\n注意\n\n为了简单，可以假设传给pipe()的方法都只有一个参数\n\nfunction pipe(funcs) {\n\treturn (x) =&gt; {\n\t\tlet result = x\n\t\tif(funcs.length &gt; 0){\n\t\t\tfuncs.forEach(f =&gt; result = f(result))\n\t\t}\n\t\treturn result;\n\t}\n}\n12. arguments\nWhat does the code snippet to the right output by console.log\nfunction log(a,b,c,d) {\n  console.log(a,b,c,d)\n  arguments[0] = &#039;bfe&#039;\n  arguments[3] = &#039;dev&#039;\n  console.log(a,b,c,d)\n}\n \nlog(1,2,3)\narguments 是一个包含了传递给函数的参数的类数组对象，类数组意味着 arguments 有长度属性，并且属性的索引是从零开始的，但是它没有 Array 的内置方法，不过可以调用 Array 原型上的方法，此外如果调用的参数多于正式声明接受的参数，这也是一个很好的示例：\nfunction myConcat(separator) {\n  var args = Array.prototype.slice.call(arguments, 1);\n  return args.join(separator);\n}\n \n \n// returns &quot;red, orange, blue&quot;\nmyConcat(&quot;, &quot;, &quot;red&quot;, &quot;orange&quot;, &quot;blue&quot;);\n// returns &quot;elephant; giraffe; lion; cheetah&quot;\nmyConcat(&quot;; &quot;, &quot;elephant&quot;, &quot;giraffe&quot;, &quot;lion&quot;, &quot;cheetah&quot;);\n arguments 在函数中，可以进行赋值更新，但是通过索引进行赋值时，如果是没有传参的形参位置，是不能更新赋值的，所以上面的输出应该是：\n1,2,3,undefined\n&quot;bfe&quot;,2,3,undefined\n13. Operator precedence\nWhat does the code snippet to the right output by console.log\nconsole.log(0 == 1 == 2) // false == 2 👉🏻 0 == 2 👉🏻 false\nconsole.log(2 == 1 == 0) // false == 0 👉🏻 0 == 0 👉🏻 true\nconsole.log(0 &lt; 1 &lt; 2)   // true &lt; 2 👉🏻 1 &lt; 2 👉🏻 true\nconsole.log(1 &lt; 2 &lt; 3)   // true &lt; 3 👉🏻 1 &lt; 3 👉🏻 true\nconsole.log(2 &gt; 1 &gt; 0)   // true &gt; 0 👉🏻 1 &gt; 0 👉🏻 true\nconsole.log(3 &gt; 2 &gt; 1)   // true &gt; 1 👉🏻 1 &gt; 1 👉🏻 false\n这里的一个重要细节是，如果一个操作数是布尔值，另一个是数字，则会先将布尔值转换为数字类型。 true 被转换为数字 1， false 被转换为数字 0。\n这是通过 ECMAScript 的规范中定义的抽象相等比较算法（Abstract Equality Comparison）实现的，其中主要是对 boolean 做了 ToNumber 操作：\n\nToNumber ( argument )\n4. If argument is either null or false, return +0𝔽.\n5. If argument is true, return 1𝔽.\n\n14. Addition vs Unary Plus\nWhat does the code snippet to the right output by console.log\nThere is a difference between Addition Operator(+) and Unary plus operator(+), even though they use the same ’+‘.\nconsole.log(1 + 2) // 3\nconsole.log(1 + + 2) // 1 + (+2) = 1 + 2 = 3\nconsole.log(1 + + + 2) // 1 + (+(+2)) = 1 + 2 = 3\nconsole.log(1 + &#039;2&#039;) // &quot;1&quot; + &quot;2&quot; = &quot;12&quot; \nconsole.log(1 + + &#039;2&#039;) // 1 + (+2) = 1 + 2 = 3\nconsole.log(&#039;1&#039; + 2) // &quot;1&quot; + &quot;2&quot; = &quot;12&quot;\nconsole.log(&#039;1&#039; + + 2) // &quot;1&quot; + (+2) = &quot;1&quot; + 2 = &quot;1&quot; + &quot;2&quot; = &quot;12&quot;\nconsole.log(1 + true) // 1 + 1 = 2\nconsole.log(1 + + true) // 1 + (+true) = 1 + 1 = 2\nconsole.log(&#039;1&#039; + true) // &quot;1&quot; + &quot;true&quot; = &quot;1true&quot;\nconsole.log(&#039;1&#039; + + true) // &quot;1&quot; + (+true) = &quot;1&quot; + 1 = &quot;1&quot; + &quot;1&quot; = &quot;11&quot;\nconsole.log(1 + null) // 1 + 0 = 1\nconsole.log(1 + + null) // 1 + (+null) = 1 + 0 = 1\nconsole.log(&#039;1&#039; + null) // &quot;1&quot; + &quot;null&quot; = &quot;1null&quot;\nconsole.log(&#039;1&#039; + + null) // &quot;1&quot; + (+null) = &quot;1&quot; + 0 = &quot;1&quot; + &quot;0&quot; = &quot;10&quot;\nconsole.log(1 + undefined) // 1 + NaN = NaN\nconsole.log(1 + + undefined) // 1 + (+undefined) = 1 + NaN = NaN\nconsole.log(&#039;1&#039; + undefined) // &quot;1&quot; + &quot;undefined&quot; = &quot;1undefined&quot;\nconsole.log(&#039;1&#039; + + undefined) // &quot;1&quot; + (+undefined) = &quot;1&quot; + NaN = &quot;1&quot; + &quot;NaN&quot; = &quot;1NaN&quot;\nconsole.log(&#039;1&#039; + + + undefined) // &quot;1&quot; +(+(+undefined)) = &quot;1&quot; + NaN = &quot;1&quot; + &quot;NaN&quot; = &quot;1NaN&quot;\nThe unary plus operator (+) 将其后的操作数转为数字类型：\n+1 // 1\n+&quot;1&quot; // 1\n+true // 1\n+null // 0\n+undefined // NaN\n+NaN // NaN\nAddition operator + 前的操作数如果为数字，则会将其后的操作数转为数字进行相加；否则将执行字符串拼接，也就将其后的操作数转为字符串。\n15. instanceOf\nconsole.log(typeof null);                          \n// &quot;object&quot; - &#039;null&#039; has &quot;object&quot; type in js (backward compatibility)\nconsole.log(null instanceof Object);               \n// false - &#039;null&#039; is primitive and doesn&#039;t have &#039;instanceof&#039; keyword\nconsole.log(typeof 1);                             \n// &quot;number&quot; - one of js types\nconsole.log(1 instanceof Number);                  \n// false - &#039;1&#039; is primitive and doesn&#039;t have &#039;instanceof&#039; keyword\nconsole.log(1 instanceof Object);                  \n// false - same as above\nconsole.log(Number(1) instanceof Object);          \n// false - Number(1) === 1 - same as above\nconsole.log(new Number(1) instanceof Object);      \n// true - &#039;new Number(1)&#039; is object, so it&#039;s correct\nconsole.log(typeof true);                          \n// &quot;boolean&quot; - one of js types\nconsole.log(true instanceof Boolean);              \n// false - &#039;true&#039; is primitive and doesn&#039;t have &#039;instanceof&#039; keyword\nconsole.log(true instanceof Object);               \n// false - same as above\nconsole.log(Boolean(true) instanceof Object);      \n// false - Boolean(true) === true - same as above\nconsole.log(new Boolean(true) instanceof Object);  \n// true - &#039;new Boolean(true)&#039; is object, so it&#039;s correct\nconsole.log([] instanceof Array);                  \n// true - &#039;[]&#039; is instanceof Array and Object\nconsole.log([] instanceof Object);                 \n// true - &#039;[]&#039; is instanceof Array and Object\nconsole.log((() =&gt; {}) instanceof Object);         \n// true - if it&#039;s not a primitive it&#039;s object. So callback is instanceof object\n\nNumber 和 Boolean 函数直接调用只是将参数转化为相应的原始类型，真正的创建包装对象，需要使用 new，这个算是个易错点；\ninstanceOf 主要是检查对象的原型链，先获取待检查对象的原型（prototype），然后沿着原型链逐级向上查找，直到找到 null 或者找到与给定构造函数的 prototype 相等的原型；所以对于 Array 实例，[] instanceof Array 和 [] instanceof Object 都是成立的，都在原型链上，当然Object 在 Array 后；\n\n16. parseInt\nconsole.log([&#039;0&#039;].map(parseInt)); // [0]\nconsole.log([&#039;0&#039;,&#039;1&#039;].map(parseInt)); // [0,NaN]\nconsole.log([&#039;0&#039;,&#039;1&#039;,&#039;1&#039;].map(parseInt)); // [0,NaN,1]\nconsole.log([&#039;0&#039;,&#039;1&#039;,&#039;1&#039;,&#039;1&#039;].map(parseInt)); // [0,NaN,1,1]\n问题的关键就是 map 函数的回调有两个参数，当前元素和索引值。\n其次是 parseInt ，第二个参数 radix，如果是0, NaN 或 Infinity，那么会默认为 10；如果  radix &lt; 2 或 radix &gt; 36，那么将返回 NaN。\n[&#039;0&#039;,&#039;1&#039;,&#039;1&#039;,&#039;1&#039;].map(parseInt)\n \n// This actually simplifies to — (2nd parameter is the index)\nparseInt(&#039;0&#039;, 0); // 0 is treated as base 10\nparseInt(&#039;1&#039;, 1); // NaN as radix &lt; 2\nparseInt(&#039;1&#039;, 2); // 1 in radix 2  \nparseInt(&#039;1&#039;, 3); // 1 in radix 3\n17. reduce\n[1,2,3].reduce((a,b) =&gt; {\n  console.log(a,b)\n});\n// 1, 2\n// undefined, 3\n \n[1,2,3].reduce((a,b) =&gt; {\n  console.log(a,b)\n}, 0)\n// 0,1\n// undefined, 2\n// undefined, 3\n18. Promise executor II\nconst p1 = Promise.resolve(1)\nconst p2 = new Promise((resolve) =&gt; resolve(p1))\nconst p3 = Promise.resolve(p1)\nconst p4 = p2.then(() =&gt; new Promise((resolve) =&gt; resolve(p3)))\nconst p5 = p4.then(() =&gt; p4)\n \nconsole.log(p1 == p2) // false\nconsole.log(p1 == p3) // true\nconsole.log(p3 == p4) // false\nconsole.log(p4 == p5) // false\n尽管 p1~p5 最后都是 Promise {&lt;fulfilled&gt;: 1}，但是判断的过程中是不一样的。\n对于 p1 和 p2，p1 为 Promise {&lt;fulfilled&gt;: 1}，而 p2 为Promise {&lt;pending&gt;}，Promise 构造时传入的函数内部的 resolve，其参数只要是 Promise 或者  thenable 对象，执行都是异步的，也就是会有一个新的微任务入队：\nconst p1 = Promise.resolve(1)\nconsole.log(0)\nconst p2 = new Promise((resolve) =&gt; {\n    console.log(1)\n    resolve((console.log(1.5),p1))\n    console.log(2)\n})\nconsole.log(p1, p2)\nvoid setTimeout(()=&gt;{\n    console.log(p1, p2)\n})\n// 0\n// 1\n// 1.5\n// 2\n// Promise {&lt;fulfilled&gt;: 1} Promise {&lt;pending&gt;}\n// Promise {&lt;fulfilled&gt;: 1} Promise {&lt;fulfilled&gt;: 1}\np1 和 p2 本身就不是同一个 promise 对象，且状态还不一样，不可能==判断相等。\n对于 p1 和 p3，Promise.resolve 若传入的是 Promise 那么将直接返回该 Promise，所以 p3 本质上就是 p1，即 p1 == p3。\n对于 p4，在 p2 上调用了 then，这里会有一个微任务入队，不会因 then 的 Promise 的状态而影响，且返回一个新的 Promise 对象，这也不受内部返回值的影响（p2 != p3）；\nlet p3 = null\nconst p1 = Promise.resolve(1)\nconsole.log(0)\nconst p2 = p1.then(() =&gt; {\n    console.log(1)\n    p3 = new Promise((resolve) =&gt; {\n        console.log(2)\n        resolve(p1)\n    })\n    console.log(3)\n    return p3\n})\nconsole.log(4, p1, p2, p3)\nsetTimeout(()=&gt;{\n    console.log(5, p1, p2, p3)\n    console.log(p2 == p3)\n})\n \n// 0\n// 4 Promise {&lt;fulfilled&gt;: 1}  Promise {&lt;pending&gt;}      null\n// 1\n// 2\n// 3 Promise {&lt;fulfilled&gt;: 1}  Promise {&lt;pending&gt;}      Promise {&lt;pending&gt;}\n// 5 Promise {&lt;fulfilled&gt;: 1}  Promise {&lt;fulfilled&gt;: 1} Promise {&lt;fulfilled&gt;: 1}\n// false\n所以 p3，p4 和 p5 都是不同的 promise 对象。\n19. this\nconst obj = {\n  a: 1,\n  b: function() {\n    console.log(this.a)\n  },\n  c() {\n    console.log(this.a)\n  },\n  d: () =&gt; {\n    console.log(this.a)\n  },\n  e: (function() {\n    return () =&gt; {\n      console.log(this.a);\n    }\n  })(),\n  f: function() {\n    return () =&gt; {\n      console.log(this.a);\n    }\n  }\n}\n \nconsole.log(obj.a) // 1\nobj.b() // 1\n;(obj.b)() // 1\nconst b = obj.b\nb() // undefined\nobj.b.apply({a: 2}) // 2\nobj.c() // 1\nobj.d() // undefined\n;(obj.d)() // undefined\nobj.d.apply({a:2}) // undefined\nobj.e() // undefined\n;(obj.e)() // undefined\nobj.e.call({a:2}) // undefined\nobj.f()() // 1\n;(obj.f())() // 1\nobj.f().call({a:2}) // 1\nExplanation\n\nobj.a simply points to the property a on obj；\nobj.b is a normal function and invoking it will log 1；\n(obj.b)() is the same as obj.b()；\nWhen we store the reference of obj.b in a variable, executing it separately loses the reference to obj and instead will point to window hence logging undefined；\nBecause we are using apply to explicitly bind this to {a: 2} it logs 2；\nobj.c is also a normal function, logs 1；\nobj.d is an arrow function, hence it will basically borrow the scope from outside obj which is window；\nSame as above；\napply will not make any difference for arrow functions and it keeps the original this binding i.e. window；\nobj.e is actually an IIFE so this refers to window and it returns an arrow function hence this will take its value from enclosing context i.e. it’ll be window. Logs undefined；\nSame as above；\nOnce again, call will not make any difference for arrow functions and it keeps the original this binding i.e. window；\nobj.f is similar to e but main difference is that its a normal function so this points to obj inside it. The arrow function inside takes this from enclosing context hence referring to obj；\nSame as above；\ncall will not make any difference for arrow functions and it keeps the original this binding i.e. obj and not {a: 2}. Thus it logs 1；\n\n总结\n\nthis  的值取决于函数如何被调用，而不是被声明定义的位置；\napply 和 call 并不会影响箭头函数；\nIIFE 执行时，不是作为对象的方法被调用，而是一个独立的函数调用，非严格模式下，独立函数（非函数方法，构造函数，事件处理函数，或通过 call 和 apply 处理的函数）内的 this 都是全局对象 window；严格模式下则是 undefined；\n\n20. name for Function expression\nfunction a(){\n}\nconst b = function() {\n  \n}\n \nconst c = function d() {\n  console.log(typeof d) // &quot;function&quot;\n  d = &#039;e&#039;\n  console.log(typeof d) // &quot;function&quot;\n}\n \nconsole.log(typeof a) // &quot;function&quot;\nconsole.log(typeof b) // &quot;function&quot;\nconsole.log(typeof c) // &quot;function&quot;\nconsole.log(typeof d) // &quot;undefined&quot;\nc()\n\na is a Function Declaration and has data type function\nb and c are Function Expression and have data type function\nd is a Named Function Expression This name d is then local only to the function body (scope) hence outside the function body typeof d returns undefined\n\nThe special case is inside the named function d. The function name is un-reassignable inside the function. You can easily see the difference if you run this in &quot;use strict&quot; mode where it gives an error Uncaught TypeError: Assignment to constant variable. Thus, d will still point to the named function d despite being reassigned to &quot;e&quot;"},"front-end/interview/big-front-end/js-120-130":{"title":"js-120-130","links":[],"tags":[],"content":"126. BigDecimal addition\nJavaScript并不能精确表示所有十进制的浮点数，因为采用的二进制。\n在基础的运算中，可以用Number.prototype.toFixed()来搞定，但是更复杂的情况下需要使用其他办法来保证精度。\nJavaScript 的 Proposal of BigDecimal 还在尚早的阶段，在那之前我们可以使用一些库来解决精度问题，比如Big.js。\n在该问题中，请实现任意位数的10进制浮点数的加法运算。\nadd(&#039;-999999999999999999&#039;, &#039;-1&#039;)\n// &#039;-1000000000000000000&#039;\n \nadd(\n  &#039;-999999999999999999.999999999999999999999999999999&#039;, \n  &#039;1.0000000000000000000000000001&#039;)\n// &#039;-999999999999999998.999999999999999999999999999899&#039;\n \nadd(\n  &#039;999999999999999999.9999999999999999999999999999&#039;, \n  &#039;1.0000000000000000000000000001&#039;)\n// &#039;1000000000000000001&#039;\n\n该问题同时cover了76. 实现BigInt的加法(含符号）。\n最终结果的结尾的0需要去掉。\n"},"front-end/interview/big-front-end/js-21-30":{"title":"js-21-30","links":["tags/JS/BigInt"],"tags":["JS/BigInt"],"content":"21. Array I\nconst a = [0]\nconsole.log(a.length) // 1 Since array contains one element\na[3] = 3 // a = [0, empty, empty, 3]\nconsole.log(a.length) // 4 Since array contains four elements now(even though only 2 elements are defined)\n \nfor (let item of a) {\n  console.log(item) // prints all the array items\n}\n// 0\n// undefined\n// undefined\n// 3\n \na.map(item =&gt; {console.log(item)}) // only called for assigned values\n// 0\n// 3\n \na.forEach(item =&gt; {console.log(item)}) // only called for assigned values\n// 0\n// 3\n \nconsole.log(Object.keys(a)) // [&quot;0&quot;,&quot;3&quot;] only defined indexes are retuned\n \ndelete a[3] // deletes/unassigns that index\n// a = [0, empty, empty, empty]\nconsole.log(a.length) // 4 since length remains unaffected\n \na[2] = 2 // a = [0, empty, 2, empty]\n \na.length = 1 // this actually truncates the array so that length is only 1 now\n// a = [0]\n \nconsole.log(a[0],a[1],a[2]) // 0,undefined,undefined\n\n可通过设置 length 属性随时截断数组。需要注意的是，length 属性并不一定表示数组中定义的值的数量；\nArray.map() ，Array.forEach() 以及 Object.keys 都只对已赋值的索引（包括值为 undefined 的索引）进行调用和操作。\n使用 delete 删除数组元素只会取消该索引的值（使其变为空），而不会重新排列数组或改变 length 属性。\n\n22. min max\nconsole.log(Math.min()) // Infinity\nconsole.log(Math.max()) // -Infinity\nconsole.log(Math.min(1)) // 1\nconsole.log(Math.max(1,2)) // 2\nconsole.log(Math.min([1,2,3])) // NaN\n\n如果不传递参数，Math.min() 将返回 Infinity，因为 API 在设计时，会与 Infinity 进行比较；对应的 Math.max() 无参将返回 -Infinity；\n对于其二者，如果参数不能转化为 Number，将返回 NaN；\n\n23. Promise.all()\n(async () =&gt; {\n  await Promise.all([]).then((value) =&gt; {\n    console.log(value) // resolves with empty array []\n  }, (error) =&gt; {\n    console.log(error)\n  })\n  \n  await Promise.all([1,2,Promise.resolve(3), Promise.resolve(4)]).then((value) =&gt; {\n    console.log(value) // all promises resolve so returns [1,2,3,4]\n  }, (error) =&gt; {\n    console.log(error)\n  })\n  \n  await Promise.all([1,2,Promise.resolve(3), Promise.reject(&#039;error&#039;)]).then((value) =&gt; {\n    console.log(value)\n  }, (error) =&gt; {\n    console.log(error) // since 4th promise rejected, Promise.all also rejects with that value\n  })\n})()\n \n// []\n// [1,2,3,4]\n// &quot;error&quot;  \n24. Equality &amp; Sameness\nconsole.log(0 == &#039;0&#039;) // true (after type conversion &#039;0&#039; = 0)\nconsole.log(0 === &#039;0&#039;) // false\nconsole.log(Object.is(0, &#039;0&#039;)) // false\n \nconsole.log(0 == 0) // true\nconsole.log(0 === 0) // true\nconsole.log(Object.is(0, 0)) // true\n \nconsole.log(0 == -0) // true\nconsole.log(0 === -0) // true\nconsole.log(Object.is(0, -0)) // false\n \nconsole.log(NaN == NaN) // false\nconsole.log(NaN === NaN) // false\nconsole.log(Object.is(NaN, NaN)) // true\n \nconsole.log(0 == false) // true (after type conversion false = 0)\nconsole.log(0 === false) // false\nconsole.log(Object.is(0, false)) // false\n\n== 和 === 区别主要是 == 会进行隐式的类型转换；\nNaN 使用操作符比较时，与其它任何值都不相等；\nObject.is() 区分 +0和 -0，但不区分 NaN；\n\n25. zero\nconsole.log(1 / 0) // Infinity\nconsole.log(-1 / 0) // -Infinity\nconsole.log(0 / 0) // NaN\nconsole.log(0 === -0) // true\nconsole.log(Object.is(0, -0)) // false\nconsole.log(Object.is(0, Math.round(-0.5))) // Object.is(0, -0) = false\nconsole.log(Object.is(0, Math.round(0.5))) // Object.is(0, 1) = false\nconsole.log(0 * Infinity) // NaN\nconsole.log(Infinity / Infinity) // NaN\nconsole.log(Object.is(0, Math.sign(0))) // Object.is(0, 0) = true\nconsole.log(Object.is(0, Math.sign(-0))) // Object.is(0, -0) = false\nconsole.log(1 / -0) // -Infinity\nconsole.log(1 / 0) // Infinity\nconsole.log(1n / 0n) // gives RangeError in BigInt\n\nMath.sign()返回一个数字的符号，共有 5 种返回值，分别是 1, -1, 0, -0, NaN. 代表的各是正数，负数，正零，负零，NaN。\n可以用在一个整数字面量后面加 n 的方式定义一个 BigInt ，如：10n，或者调用函数 BigInt()传入整数值或者字符串；\n\n不能用于 Math 对象中的方法；\n不能和任何 Number 实例混合运算；\n\n\nBigIntBigInt 类型是为处理大整数而设计的，强调精确的整数数学操作，其中不允许除以零；Number 类型遵循浮点数数学规则，允许除以零并返回无穷大。\n"},"front-end/interview/big-front-end/js-50-60":{"title":"js-50-60","links":[],"tags":[],"content":"63. create _.cloneDeep()\nObject.assign() 可以用来浅拷贝，而_.cloneDeep 在深度拷贝中非常有用。\n你能否实现自己的_.cloneDeep()?\nlodash的实现囊括了多种数据类型，简单起见，该题目中你只需要支持：\n\n基础数据类型 及其包装对象（wrapper object）。\n简单Object（仅需处理可枚举属性）\n数组Array\n\n\n现已有 built-in 的 structuredClone()，不过为了练习用，请不要使用。\n\nfunction cloneDeep(obj, referencesMap = new Map()) {\n    if (obj === null || typeof obj !== &#039;object&#039;) {\n        return obj;\n    }\n \n    if (referencesMap.has(obj)) {\n        return referencesMap.get(obj);\n    }\n \n    const output = Array.isArray(obj) ? [] : {};\n    referencesMap.set(obj, output);\n    const keys = [...Object.getOwnPropertySymbols(obj), ...Object.keys(obj)];\n \n    for (const key of keys) {\n        const val = obj[key];\n        output[key] = cloneDeep(val, referencesMap);\n    }\n \n    return output;\n}\n\nreferencesMap 跟踪已经拷贝过的对象，以避免无限递归地拷贝循环引用的对象；\ngetOwnPropertySymbols() 方法返回一个包含给定对象所有自有 Symbol 属性的数组；\n"},"front-end/interview/big-front-end/react":{"title":"react","links":[],"tags":[],"content":"useTimeout()\nCreate a hook to easily use setTimeout(callback, delay).\n\nreset the timer if delay changes\nDO NOT reset the timer if only callback changes\n\nimport { useEffect, useRef } from &#039;react&#039;\n \nexport function useTimeout(callback: () =&gt; void, delay: number) {\n \n  const callbackRef = useRef(callback)\n  callbackRef.current = callback\n \n  useEffect(() =&gt; {\n \n    const timeoutId = setTimeout(() =&gt; callbackRef.current(), delay)\n \n    return () =&gt; clearTimeout(timeoutId)\n  }, [delay])\n \n}\n难点在第二个要求，主要是隐形的需求，新的 callback 不会创建新的 setTimeout 实例（重置 delay），但是，也就是说 callback 不能加入 useEffect 的依赖数组中，但是这样的话，useEffect 内引用的 callback 就是旧的，不满足要求，所以需要使用 useRef 来每次保存新的 callback。\nuseIsFirstRender()\nimport { useRef } from &#039;react&#039;;\n \nexport function useIsFirstRender(): boolean {\n  const isFirstRender = useRef(true);\n \n  if (isFirstRender.current) {\n    isFirstRender.current = false;\n    return true\n  }\n    \n \n  return false;\n}\nimport React from &#039;react&#039;;\n \nexport function useIsFirstRender(): boolean {\n  const isFirst = React.useRef(true);\n \n  React.useEffect(() =&gt; {\n    isFirst.current = false\n  }, []);\n \n  return isFirst.current;\n} \nuseSWR() I\nLet’s try to implement the basic usage by ourselves.\nimport React from &#039;react&#039;\n \nfunction App() {\n  const { data, error } = useSWR(&#039;/api&#039;, fetcher)\n  if (error) return &lt;div&gt;failed&lt;/div&gt;\n  if (!data) return &lt;div&gt;loading&lt;/div&gt;\n \n  return &lt;div&gt;succeeded&lt;/div&gt;\n}\n\nthis is not to replicate the true implementation of useSWR()\nThe first argument key is for deduplication, we can safely ignore it for now\n\nimport { useEffect, useMemo, useState } from &quot;react&quot;;\n \nexport function useSWR&lt;T = any, E = any&gt;(\n  _key: string,\n  fetcher: () =&gt; T | Promise&lt;T&gt;\n): {\n  data?: T\n  error?: E\n} {\n  // your code here\n  const [data, setData] = useState&lt;T&gt;();\n  const [error, setError] = useState&lt;E&gt;();\n  const result = useMemo(fetcher, [_key]);\n \n  useEffect(() =&gt; {\n    if (result instanceof Promise) {\n      result.then(setData, setError);\n    }\n  }, [])\n \n  return {data: result instanceof Promise ? data : result, error}\n}\n主要是使用 useMemo 缓存 fetcher 的结果，然后一个比较容易犯错的地方的就是异步的结果才需要使用 setState 进行获取更新返回，而同步的结果，直接返回即可，所以需要判断一次是否是 Promise，如果所有结果都使用 setState 保存，那么会造成额外的渲染。\n另一个就是 useEffect 注意只需要初次渲染时，对 promise 进行 获取结果，不然 promise 可以 一直 then，会造成无限循环。\nusePrevious()\nCreate a hook usePrevious() to return the previous value, with initial value of undefined.\nimport { useEffect, useRef } from &quot;react&quot;;\n \nexport function usePrevious&lt;T&gt;(value: T): T | undefined {\n  const last = useRef&lt;T&gt;()\n  useEffect(() =&gt; {\n    last.current = value\n  }, [value])\n \n  return last.current\n}\nuseHover()\nIt is common to see conditional rendering based on hover state of some element.\nWe can achieve it by CSS pseudo class :hover, but for more complex cases it might be better to have state controlled by script.\nNow you are asked to create a useHover() hook.\nfunction App() {\n  const [ref, isHovered] = useHover()\n  return &lt;div ref={ref}&gt;{isHovered ? &#039;hovered&#039; : &#039;not hovered&#039;}&lt;/div&gt;\n}\nimport { Ref, useRef, useState, useEffect } from &#039;react&#039;\n \nexport function useHover&lt;T extends HTMLElement&gt;(): [Ref&lt;T | undefined&gt;, boolean] {\n  const ref = useRef&lt;T&gt;()\n  const [isHovering, setHovering] = useState(false)\n  useEffect(() =&gt; {\n    // false by default if ref.current changes\n    setHovering(false)\n \n    const element = ref.current\n    if (!element)\n      return\n \n    const setYes = () =&gt; setHovering(true)\n    const setNo = () =&gt; setHovering(false)\n  \n    element.addEventListener(&#039;mouseenter&#039;, setYes)\n    element.addEventListener(&#039;mouseleave&#039;, setNo)\n \n    return () =&gt; {\n      element.removeEventListener(&#039;mouseenter&#039;, setYes)\n      element.removeEventListener(&#039;mouseleave&#039;, setNo)\n    }\n  }, [ref.current]) // now we could pass a dependency array for better performances.\n  return [ref, isHovering]\n}\nimport { Ref, useRef, useState, useCallback } from &#039;react&#039;\n \nexport function useHover&lt;T extends HTMLElement&gt;(): [Ref&lt;T&gt;, boolean] {\n  const [isHovered, setIsHovered] = useState&lt;boolean&gt;(false);\n  const controllerRef = useRef(new AbortController());\n \n  const ref = useRef&lt;T&gt;();\n \n  const callbackRef = useCallback(node =&gt; {\n    if (ref.current) {\n      controllerRef.current.abort();\n      controllerRef.current = new AbortController();\n    }\n \n    const { signal } = controllerRef.current\n \n        ref.current = node;\n \n      if (ref.current) {\n        ref.current.addEventListener(&#039;mouseenter&#039;, () =&gt; setIsHovered(true), { signal });\n        ref.current.addEventListener(&#039;mouseleave&#039;, () =&gt; setIsHovered(false), { signal });\n      }\n    }, []);\n    return [callbackRef, isHovered];\n}"},"front-end/interview/bytedance/1":{"title":"字节前端面试题 Ⅰ","links":[],"tags":[],"content":"字节前端面试题 Ⅰ\n数组存储怎么压缩？(提示：稀疏矩阵，三元组有关知识)\n数组存储的压缩通常涉及到稀疏矩阵的处理，其中大部分元素为零。一种有效的方法是使用三元组表示法。在这种表示法中，只存储非零元素的值以及它们的行和列的位置。\n\n在矩阵中，若数值为 0 的元素数目远远多于非 0 元素的数目，并且非 0 元素分布没有规律时，则称该矩阵为稀疏矩阵；与之相反，若非 0 元素数目占大多数时，则称该矩阵为稠密矩阵。\n\n这样，对于一个稀疏矩阵，我们只需要存储非零元素的信息，而对于零元素，可默认它们的值都为零，无需额外存储。\n最常用的稀疏矩阵存储格式主要有：**COO（Coordinate Format）**和 CSR（Compressed Sparse Row）。\nCOO 即使用 3 个数组（三元组）：\n\n值数组（values）： 存储非零元素的值。\n行索引数组（row indices）： 存储每个非零元素所在的行。\n列索引数组（column indices）： 存储每个非零元素所在的列。\n\n举个例子，如果有一个矩阵：\n\\begin{array}{*{20}{c}}\n1&amp;7&amp;0&amp;0\\\\\n0&amp;2&amp;8&amp;0\\\\\n5&amp;0&amp;3&amp;9\\\\\n0&amp;6&amp;0&amp;4\n\\end{array}\n用三元组表示法就是：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntypevalueValues[1,7,2,8,5,3,9,6,4]Row Indices[0,0,1,1,2,2,2,3,3]Column Indices[0,1,1,2,0,2,3,1,3]\n这种方式简单，但是记录单信息多（行列），每个三元组自己可以定位，因此空间不是最优。\nCSR 稍复杂， 也需要三类数据来表达：数值，列号，以及行偏移。\n\n行偏移（row offsets）：表示某一行的第一个元素在 values 里面的起始偏移位置；\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntypevalueValues[1,7,2,8,5,3,9,6,4]Row offsets (item count)[0,2,4,7,9]Column Indices[0,1,1,2,0,2,3,1,3]\nCSR 是比较标准的一种，其不是三元组，而是整体的编码方式。\njs 数据类型有哪些，如何判断？\nJavaScript 中有以下基本数据类型：\n\n基本数据类型（原始数据类型）：\n\nundefined：表示未定义或未赋值。\nnull：表示空值或不存在的对象。\nboolean：表示逻辑值，即 true 或 false。\nnumber：表示数字，可以是整数或浮点数。\nstring：表示字符串。\n\n\n引用数据类型：\n\nobject：表示对象，用于存储复杂数据和功能。\n\n\n\n要判断变量的数据类型，可以使用 typeof 操作符。例如：\njavascriptCopy codelet x = 10;\nconsole.log(typeof x);  // 输出 &quot;number&quot;\n \nlet y = &#039;Hello&#039;;\nconsole.log(typeof y);  // 输出 &quot;string&quot;\n \nlet z = true;\nconsole.log(typeof z);  // 输出 &quot;boolean&quot;\n然而，需要注意的是 typeof null 返回 “object”，这是 JavaScript 中的一个历史遗留问题。\n\n历史遗留问题，即就是一个 bug，js 最初设计时，使用了 32 位的数值来存储数据，其中包含数据类型标签及其真实数据：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n数据类型机器码标识 (低位)Object000int001double010string100boolean110undefined，JSVAL_VOID-2^30 (即全为 1)null，JSVAL_NULL全为 0， NULL 指针\n在判断数据类型时，是根据机器码低位标识来，引擎在判断类型为对象后，接着根据逻辑判断是否为函数，否则即为对象，在这里 null 即被误判了，产生了 bug。\n\nThe history of “typeof null” (2ality.com)\n\n\n另外，如果需要更准确地判断对象的类型，可以使用 instanceof 操作符，且使用该操作符对 null 进行判断时，会输出 false，例如：\nlet obj = {};\nconsole.log(obj instanceof Object); // 输出 true\nconsole.log(null instanceof Object); // 输出 false\n总体来说，typeof 用于基本数据类型的判断，而 instanceof 用于对象类型的判断。\n简述 let、const 与栈、堆之间的关系，栈、堆哪个访问速度更快，为什么？\nlet 和 const\n\nlet 和 const 用于声明变量，它们的作用域是块级作用域，这意味着它们在定义它们的块（通常是由花括号 {} 包围的代码块）内有效。\n这些变量的存储方式与栈和堆的关系不直接相关。它们的内存管理和生命周期与执行上下文有关，而执行上下文包括变量的作用域和闭包等信息。\n\n栈和堆\n\n在 JavaScript 中，栈和堆通常是指存储变量和数据的内存分配方式。\n栈用于存储基本数据类型的变量和引用类型的引用，以及函数调用的上下文信息。栈上的数据是按照后进先出（LIFO）的原则进行管理。\n堆用于存储复杂对象（如对象和数组）和通过 new 关键字创建的对象。堆上的数据不受作用域限制，它的分配和释放相对复杂，需要手动管理。\n\n变量和内存关系:\n\n当使用 let 或 const 声明变量时，变量的具体存储位置（栈还是堆）取决于该变量所引用的值的类型。\n对于基本数据类型，它们通常被存储在栈上，而复杂对象（引用类型）则通常在堆上分配内存。变量本身的值直接存储在栈上，但对于引用类型，变量存储的是对象在堆内存中的引用地址。\n\n关于访问速度，栈的访问速度通常比堆更快。这是因为栈是一种有限的数据结构，它的存取操作非常简单和快速。栈上的变量是按照函数调用的顺序入栈和出栈的，使得对变量的访问非常高效。\n相比之下，堆是一个动态分配的内存区域，对于动态分配的数据，需要在堆上进行内存分配和释放，这可能涉及到更多的操作（垃圾回收，内存碎片整理），相对而言速度较慢一些。\nsetTimeout 和 setInterval 哪个更准确，为什么？延时设为 0ms 会怎样？\nsetTimeout 更为准确，因为 JS 是单线程的，当主线程被阻塞时，定时器的执行会受到影响（延迟执行）。这可能会导致定时器的执行间隔不准确，甚至出现累积性的延迟。\n为了解决延迟不准确的问题，可以使用以下方法\n\n使用 setTimeout 代替 setInterval，并在每次回调执行完成后重新设置下一个定时器，以避免累积性的延迟。\n使用 requestAnimationFrame 来执行定时任务，这样可以确保任务在浏览器准备好渲染下一帧时执行，避免了定时器频繁触发导致的问题。\n使用 Date 对象来计算时间，而不是依赖定时器的间隔，这样可以避免受到主线程阻塞的影响。\n\n\n在浏览器中，setTimeout 大致符合 HTML5 标准，如果嵌套的层级超过了 5 层，并且 timeout 小于 4ms，则设置 timeout 为 4ms。这样操作的目的是为了防止嵌套的定时器在短时间内反复触发，从而导致性能问题。\n\n如果同时设为 0ms， 在目前的 Chrome 中 setInterval 的最小延迟时间不是 0，而是 1，即便你写了 0，也会修改成 1，而 setTimeout 没有这个限制。所以会出现虽然都是 0ms，但是 setTimeout 后定时但是先执行。Firefox 则不会出现这个情况。\nconst sid = setInterval(() =&gt; {\n  console.log(1);\n}, 1);\nsetTimeout(() =&gt; {\n  console.log(2);\n  clearInterval(sid);\n}, 0);\n// chromium: 2\n//  firefox: 1 2\n\ntcp、udp 的区别\nTCP（传输控制协议）和 UDP（用户数据报协议）是互联网的基础协议，它们在数据传输方面有很多不同之处。下面是它们之间的一些关键区别：\n\n\n连接状态：\n\nTCP 是面向连接的协议，需要在传输数据之前建立连接，而且在传输完成后需要关闭连接。\nUDP 是无连接的协议，不需要建立、维护或终止连接，数据可以连续地发送到接收方，而不需要确认接收。\n\n\n\n数据排序：\n\nTCP 能够对数据进行排序（将数据分割成多个数据包，并为每个数据包分配一个序列号），保证数据按发送顺序到达目的地。\nUDP 不能对数据进行排序，数据包是独立发送的，到达接收方后需要按顺序重新组装。\n\n\n\n传输方式：\n\nTCP 将数据视为字节流进行传输，消息按照段边界传输。\nUDP 将数据分割成数据包进行传输，每个数据包都有定义的边界。\n\n\n\n可靠性：\n\nTCP 能够保证数据到达目的路由器，使用多种机制进行错误检查和数据完整性，确认保证数据的可靠性、顺序性和不重复性，通过重传机制和确认机制来确保数据的正确传输。\n\n超时重传：当发送方发送数据后，会启动一个定时器，等待接收方的确认。如果在规定的时间内未收到确认，发送方会认为数据丢失，然后会重新发送数据。这样可以确保即使出现数据包丢失的情况，也能够及时地进行重传，从而保证数据的可靠传输。\n校验机制：TCP 在数据包的头部添加了校验和字段，用于检测数据在传输过程中是否发生了损坏。接收方在接收到数据后会对校验和进行验证，如果发现数据包损坏，会要求发送方重新发送数据。这样可以确保数据在传输过程中的完整性，避免损坏的数据对接收方造成影响。\n\n\nUDP 不能保证数据到达目的路由器，它发送数据包后不会对其进行确认，也不会进行重传操作，只使用基本的校验和机制进行错误检查，因此在传输过程中可能丢失数据、乱序或重复。\n\n\n\n传输效率：\n\n由于 TCP 的可靠性和连接管理机制，它在传输效率上通常比 UDP 低一些。TCP 的连接建立、数据包确认和重传等额外开销会影响传输性能。\nUDP 没有连接管理和重传机制，因此通常比 TCP 具有更高的传输效率。\n\n\n\n广播支持：\n\nUDP 广播是一种在网络中向多个目标发送数据的机制。\nUDP 广播允许数据包从一个源发送到同一子网中的所有设备。发送方将数据包发送到特定的广播地址，接收方可以监听该广播地址以接收数据。这种机制通常用于在局域网中发送一些公告或者发现其他设备。\n\n\nTCP 不支持广播。\nUDP 支持广播。\n\n\n\n应用场景：\n\nTCP 适用于需要可靠数据传输的应用，如网页浏览、文件传输、电子邮件等，以及对数据顺序要求较高的应用。\nUDP 适用于对实时性要求较高，且可以容忍少量数据丢失的应用，如语音通话、视频流、在线游戏等。\n\n\n\nTCP 建立连接为什么需要三次握手，两次行不行？\nTCP 使用三次握手来建立连接的主要原因是确保通信双方的状态同步和可靠性。两次握手的方式可能会导致一些问题，让我们来看看为什么需要三次握手：\n\n确认双方都能收发数据： 在TCP连接建立之前，双方无法确认彼此是否能够接收和发送数据。第一次握手允许客户端向服务器发送连接请求，第二次握手允许服务器向客户端发送连接确认，这样双方就可以确认彼此的能力和状态。\n防止已失效的连接请求报文段引起的错误： 如果使用两次握手，客户端发送的连接请求到达服务器，但是由于网络延迟或者其他原因，服务器没有收到连接请求，或者服务器发送的连接确认到达客户端，但是客户端却没有收到连接确认，此时客户端和服务器都认为连接已经建立，但实际上并没有建立。当客户端开始发送数据时，服务器却无法识别这些数据，导致连接失败。三次握手可以避免这种情况，因为客户端和服务器都要确认对方的连接请求和连接确认。\n防止客户端重复连接请求导致的错误： 如果使用两次握手，客户端发送的连接请求到达服务器，但是因为某种原因客户端没有收到服务器的连接确认，客户端会认为连接建立失败，然后重新发送连接请求。这时候，如果原来的连接请求已经到达服务器，但是服务器却没有收到客户端的连接确认，服务器会再次响应客户端的连接请求，导致重复连接。三次握手可以避免这种情况，因为服务器在收到重复的连接请求时会拒绝，因为已经处于已连接状态。\n\n综上所述，三次握手确保了连接的可靠性和一致性，而且也是TCP协议设计的最小化的安全要求，因此两次握手是行不通的。\nhttp 如何建立连接，有哪些过程？\nHTTP（超文本传输协议）是一种无状态的应用层协议，它使用 TCP 作为传输层协议来传输数据。HTTP 建立连接的过程通常是通过 TCP 的三次握手来完成的。以下是 HTTP 建立连接的过程：\n\n\n客户端发起请求：\n\n客户端（通常是浏览器）向服务器发起 HTTP 请求。这个过程包括构建 HTTP 请求报文，其中包括请求的方法（如 GET、POST）、请求的资源路径、请求头（如 Host、User-Agent 等）以及请求体（如果是 POST 请求）。\n\n\n\nDNS 解析：\n\n\n如果请求的地址是一个域名而不是 IP 地址，客户端首先需要进行 DNS 解析，将域名解析为服务器的 IP 地址。这样客户端才能知道请求应该发送到哪个服务器上。\n\n\n\n\n客户端首先会查询本地 DNS 缓存，查看之前解析过的域名是否存在缓存中；\n缓存不存在，客户端则会向本地 DNS 服务器发起 DNS 查询请求。通常，本地 DNS 服务器由网络服务提供商（ISP）或局域网管理员提供，客户端的网络设置会自动配置本地 DNS 服务器的地址。\n本地 DNS 服务器收到客户端的查询请求后，它会根据查询的域名进行递归查询或迭代查询；\n查询后找到域名对应的 IP 地址，本地 DNS 服务器将 IP 地址返回给客户端，并在本地缓存中保存这个查询结果；\n客户端收到本地 DNS 服务器返回的 IP 地址后，即将其用于发起网络请求。\n\n\n\n\n建立 TCP 连接：\n\n客户端使用请求中的目标服务器 IP 地址和端口号，通过 TCP 连接向服务器发起连接请求。这个过程是 TCP 的三次握手过程：\n\n第一次握手： 客户端向服务器发送一个带有 SYN 标志的数据包，请求建立连接。\n第二次握手： 服务器收到客户端的连接请求后，回复一个带有 SYN 和 ACK 标志的数据包，表示收到了请求，并同意建立连接。\n第三次握手： 客户端收到服务器的确认后，再次向服务器发送一个带有 ACK 标志的数据包，表示连接建立成功。\n\n\n\n\n\n发送 HTTP 请求：\n\n一旦建立了 TCP 连接，客户端就可以向服务器发送 HTTP 请求。请求报文会通过 TCP 连接发送到服务器。\n\n\n\n服务器处理请求：\n\n服务器收到客户端的 HTTP 请求后，会根据请求的内容和目标资源，进行相应的处理。这个过程包括解析请求、处理请求、生成响应等。\n\n\n\n服务器返回响应：\n\n服务器处理完请求后，会生成一个 HTTP 响应报文，其中包括状态码、响应头和响应体等信息。响应报文通过之前建立的 TCP 连接发送到客户端。\n\n\n\n关闭 TCP 连接：\n\n客户端收到服务器的响应后，可以选择关闭 TCP 连接，释放资源。这个过程是 TCP 的四次挥手过程，包括客户端和服务器各发送两个数据包来确认关闭连接。\n\n\n\nhttps 是如何防窃听和篡改？\nHTTPS（超文本传输安全协议）是 HTTP 的加密版本，通过使用 SSL/TLS 协议对通信进行加密来确保数据的安全性和完整性。HTTPS 采取了以下几种方式来防止窃听和篡改：\n\n加密通信：\n\nHTTPS 使用 SSL/TLS 协议对通信数据进行加密，包括请求和响应的内容、头部信息等。这意味着即使通信被窃听，也无法直接获取其中的明文信息，因为加密后的数据只有在合适的密钥下才能被解密。\n\n\n身份验证：\n\nHTTPS 使用数字证书来验证服务器的身份，确保客户端与服务器之间的通信确实是与预期的服务器建立的安全连接。数字证书由可信任的证书颁发机构（CA）颁发，包含了服务器的公钥和其他身份信息。客户端可以使用证书来验证服务器的身份，并确保与合法的服务器进行通信。\n\n\n数据完整性保护：\n\nHTTPS 使用消息摘要算法（如 SHA-256）对传输的数据进行摘要计算，并将摘要添加到消息中。接收方可以使用相同的算法对接收到的数据进行摘要计算，并与原始摘要进行比较，以验证数据的完整性。如果数据在传输过程中被篡改，摘要计算的结果将不匹配，从而可以发现数据的篡改。\n\n\n密钥交换：\n\nHTTPS 使用 SSL/TLS 协议来安全地交换加密通信所需的密钥。这通常涉及到一系列复杂的协商和密钥交换步骤，最终双方通过协商生成一个共享的对称密钥，用于加密和解密通信数据。\n\n\n\n\n虽然 HTTPS 提供了加密保护，但并不意味着它是绝对安全的。攻击者仍然有可能通过某些手段来抓包和劫持修改 HTTPS 通信。这可能涉及到中间人攻击、证书伪造、协议漏洞等问题。\n\n\n中间人攻击是一种常见的方式，攻击者可以在用户与服务器之间插入自己的服务器，使得通信经过攻击者的服务器，从而实现对通信内容的窃取和篡改。\n\n\n证书伪造则是攻击者伪造了一个合法的 SSL 证书，使得用户误以为连接的是合法的服务器，实际上是攻击者控制的服务器。此外，协议漏洞也可能导致 HTTPS 通信被劫持。\n\n\n\n\n当客户端打开到安全 Web 服务器的 SSL / TLS 连接时，它通过检查两个条件来验证服务器的身份：首先，它检查其证书是否已被客户端已知的 CA 签名。其次，它确保服务器的通用名称（CN，即主机名）与其连接的名称相匹配。如果两个条件均为真，客户端假定连接是安全的。\n为了能够窥探连接，抓包工具充当证书颁发机构，但不是一个非常值得信赖的机构：抓包工具不会向实际的人员或组织颁发证书，而是动态地生成证书到连接所需的任何主机名。\n如果客户想要连接到 www.facebook.com，则抓包工具会为 www.facebook.com 生成证书，并使用自己的 CA 进行签名。如果客户端信任此 CA，则上述两个条件均为真（可信 CA，同一 CN）\n这意味着客户端相信抓包工具中转服务器实际上是 www.facebook.com，这种机制称为透明 HTTPS 代理。\n\n在 vue 项目中如何防范 xss 攻击？\n\n使用 Vue 的模板语法：\n\nVue 的模板语法会自动对插值和指令中的变量进行 HTML 转义，防止恶意脚本的注入。在 Vue 组件中，使用双大括号 {{}} 进行数据绑定时，Vue 会自动进行 HTML 转义，将特殊字符转换为对应的 HTML 实体，从而防止 XSS 攻击。\n\n\n使用 v-html 指令时谨慎：\n\nVue 中的 v-html 指令允许将数据作为 HTML 插入到 DOM 中，但要谨慎使用，特别是当插入的数据来自用户输入或不可信任的来源时。在使用 v-html 指令时，确保数据已经经过安全过滤和验证，避免插入恶意脚本。\n\n\n过滤用户输入：\n\n在接收用户输入时，应该对用户输入的数据进行过滤和验证，确保只接受合法的数据。可以使用 Vue提供的过滤器库或者第三方库如 xss 来过滤和清理用户输入，移除其中的恶意脚本和标签。\n\n\n设置 Content Security Policy（CSP）：\n\n在 HTTP 头中设置 Content Security Policy（CSP），限制页面中可以加载的资源和执行的脚本，从而减少 XSS 攻击的风险。CSP 可以配置白名单、限制 eval()、inline 脚本和样式等，提高页面的安全性。\n\n\n避免使用危险的 Vue 特性：\n\nVue 中一些特性如 v-on 和 v-bind 允许动态地绑定事件和属性，如果不谨慎使用，可能会导致 XSS 攻击。避免将不受信任的数据直接绑定到 v-on 和 v-bind 上，尤其是在动态生成标签名、属性名和事件名时。\n\n\n定期更新依赖项：\n\n定期更新 Vue 及其相关依赖项，以获取最新的安全补丁和功能更新，从而提高项目的安全性。\n\n\n\n手写题：遍历DOM树打印每个元素的 tagName\n递归\nfunction printTagName(element){\n    console.log(element.tagName)\n    const { children } = element\n    for (lei i = 0; i &lt; children.length; i++){\n        // 递归调用，打印子节点的 tagName\n        printTagName(children[i])\n    }\n}\n// 从根节点开始遍历整个 DOM 树\nprintTagName(document.documentElement);\n迭代\nfunction printTagNameDFS(root) {\n  let stack = []; // 创建一个栈用于存放待访问的节点\n  stack.push(root); // 将根节点入栈\n  \n  while (stack.length) {\n    let node = stack.pop(); // 弹出栈顶节点\n    console.log(node.tagName); // 打印节点的 tagName\n    let { children } = node; // 获取当前节点的子节点\n    // 将子节点按逆序入栈，保证先访问左子树\n    for (let i = children.length - 1; i &gt;= 0; i--) {\n      stack.push(children[i]);\n    }\n  }\n}\n \n// 从根节点开始遍历整个 DOM 树\nprintTagNameDFS(document.documentElement);\n \n \n \nfunction printTagNameBFS(root) {\n  let queue = []; // 创建一个队列用于存放待访问的节点\n  queue.push(root); // 将根节点入队\n  \n  while (queue.length) {\n    let node = queue.shift(); // 出队首节点\n    console.log(node.tagName); // 打印节点的 tagName\n    let { children } = node; // 获取当前节点的子节点\n    // 将子节点依次入队\n    for (let i = 0; i &lt; children.length; i++) {\n      queue.push(children[i]);\n    }\n  }\n}\n \n// 从根节点开始遍历整个 DOM 树\nprintTagNameBFS(document.documentElement);\n手写题：打印数组全排列，[1,2,3] 即打印[[1,2,3],[1,3,2],[2,1,3],[2,3,1],[3,1,2],[3,2,1]]（leecode-46）\nfunction permute(nums) {\n  let result = [];\n \n  function backtrack(curr, remaining) {\n    // 当剩余数组为空时，将当前排列加入结果数组\n    if (remaining.length === 0) {\n      result.push(curr);\n      return;\n    }\n \n    // 遍历剩余数组的每个元素，依次生成排列\n    for (let i = 0; i &lt; remaining.length; i++) {\n      // 将当前元素加入到排列中\n      let next = curr.concat(remaining[i]); \n      // 生成新的剩余数组\n      let newRemaining = remaining.slice(0, i).concat(remaining.slice(i + 1));\n      // 递归生成剩余元素的排列\n      backtrack(next, newRemaining); \n    }\n  }\n \n  backtrack([], nums); // 初始排列为空，剩余数组为原始数组\n  return result;\n}\n \n// 测试\nconsole.log(permute([1, 2, 3]));\nvar permute = function(nums) {\n    let res = [];\n \n    per(nums,0,nums.length-1,res); // 下标从 0 到 length-1\n \n    return res;\n};\n \nfunction per(arr,p,q,res) {\n    // p===q时，数组操作完成\n    if (p === q) {\n        res.push([...arr])\n    } else {\n        for (let i=p;i&lt;=q;++i) {\n            swap(arr,i,p); // 后边的每一位(i)分别与首位(p)交换\n            per(arr,p+1,q,res); // 除去第一位，后续部分也分别做全排列\n            swap(arr,i,p); // 一轮结束后，将arr还原，再进行下一轮操作\n        }\n    }\n}\n \n// 数值交换\nfunction swap(arr,p,q) {\n    [arr[p],arr[q]] = [arr[q],arr[p]];\n}\n \npermute([1,2,3]); // [[1, 2, 3],[1, 3, 2],[2, 1, 3],[2, 3, 1],[3, 2, 1],[3, 1, 2]]"},"front-end/interview/bytedance/2":{"title":"字节前端面试题 Ⅱ","links":[],"tags":[],"content":"字节前端面试题 Ⅱ\ncanvas、svg 的区别\n\n绘图方式：\n\nCanvas 使用基于像素的绘图方式，它是一种位图绘图技术，通过 JavaScript 脚本绘制图形。在 Canvas 中，你可以直接操作像素来绘制图形。\nSVG 使用基于矢量的绘图方式，它是一种矢量图形技术，使用 XML 格式描述图形，通过标记语言定义图形元素，比如 &lt;circle&gt;、&lt;rect&gt;、&lt;path&gt; 等。SVG 图形是由数学公式定义的，可以无损放大或缩小。\n\n\n绘图性能：\n\nCanvas 适合绘制大量动态图形或实时渲染，因为它直接操作像素，绘图速度较快。但是，Canvas 中的图形是静态的，一旦绘制完成，就无法对其进行修改。\nSVG 适合绘制静态或少量交互的图形，因为它的渲染速度相对较慢，尤其是在处理大型复杂图形时。但是，SVG 图形是可以修改和交互的，可以通过 JavaScript 动态地改变 SVG 元素的属性，实现一些交互效果。\n\n\n图形质量：\n\nCanvas 绘制的图形在放大时会出现锯齿或失真，因为它是基于像素的。这意味着在 Canvas 中绘制的图形不太适合放大或缩小。\nSVG 绘制的图形是矢量图形，可以无损放大或缩小，并且不会出现锯齿或失真。因此，SVG 图形在需要高质量缩放的情况下更适合使用。\n\n\n文档结构：\n\nCanvas 不会在 DOM 中保留绘制的图形，它只是在画布上绘制像素，因此无法通过 CSS 或 JavaScript 直接操作 Canvas 中的图形元素。\nSVG 是 XML 格式的文档，图形元素被表示为 DOM 元素，可以通过 JavaScript 或 CSS 直接操作和修改 SVG 元素。\n\n\n\n总的来说，Canvas 适合绘制动态、复杂的图形，而 SVG 适合绘制静态、交互性较少的图形，并且对图形的质量要求较高的情况。\n简述⼀下 src 与 href 的区别\nsrc 和 href 是 HTML 中常用的两个属性，它们用于指定资源的引用，但在用法和作用上有一些区别：\n\nsrc (source):\n\nsrc 属性通常用于标签（如 &lt;script&gt;、&lt;img&gt;、&lt;iframe&gt;、&lt;audio&gt;、&lt;video&gt; 等），用于指定要加载的外部资源的 URL。该属性指定的资源是必须的，即浏览器会根据 src 属性的值加载并显示相应的内容。\n对于一些嵌入式的内容，如 &lt;script&gt; 和 &lt;iframe&gt;，浏览器会停止解析后续的 HTML，并开始加载并执行指定的资源。\n如果 src 属性引用的资源不存在或加载失败，则相应的标签可能会显示默认内容或无内容，具体表现取决于标签的类型和浏览器的实现。\n\n\nhref (hypertext reference):\n\nhref 属性通常用于超链接标签 &lt;a&gt;、&lt;link&gt;、&lt;area&gt; 等，用于指定链接到的目标资源的 URL。\nhref 属性指定的资源是可选的，即点击链接时浏览器会加载并显示相应的内容，但用户也可以选择不点击，不加载该资源。\n对于 &lt;link&gt; 标签，href 属性通常用于指定外部样式表的 URL；对于 &lt;a&gt; 标签，href 属性用于指定要链接到的网页的 URL。\n\n\n\n总的来说，src 属性用于指定必须加载的资源（如图像、脚本、嵌入式内容等），而 href 属性用于指定可选的链接目标（如超链接、样式表链接等）。\nCSS3 动画有哪些？\ncss3实现动画的方式，有如下几种：\ntransition 渐变动画\ntransition的属性如下：\n\nproperty：填写需要变化的 CSS 属性\nduration：完成过渡效果需要的时间单位(s或者ms)\ntiming-function：完成效果的速度曲线\ndelay：动画效果的延迟触发时间\n\n\n注意：并不是所有的属性都能使用过渡的，如display:none &lt;-&gt; display:block\n\ntransform 转变动画\n包含四个常用的功能：\n\ntranslate：位移\nscale：缩放\nrotate：旋转\nskew：倾斜\n\n一般配合transition过度使用，注意的是，transform不支持inline元素，使用前把它变成block。\nanimation 自定义动画\nanimation是由 8 个属性的简写，分别如下：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n属性描述属性值animation-duration指定动画完成一个周期所需要时间，单位秒（s）或毫秒（ms），默认是 0animation-timing-function指定动画计时函数，即动画的速度曲线，默认是 “ease”linear、ease、ease-in、ease-out、ease-in-outanimation-delay指定动画延迟时间，即动画何时开始，默认是 0animation-iteration-count指定动画播放的次数，默认是 1animation-direction 指定动画播放的方向默认是 normalnormal、reverse、alternate、alternate-reverseanimation-fill-mode指定动画填充模式。默认是 noneforwards、backwards、bothanimation-play-state指定动画播放状态，正在运行或暂停。默认是 runningrunning、pauseranimation-name指定 @keyframes 动画的名称\nanimation 动画只需要定义一些关键的帧，而其余的帧，浏览器会根据计时函数插值计算出来。\n通过 @keyframes 来定义关键帧，例如，如果我们想要让元素旋转一圈，只需要定义开始和结束两帧即可：\n@keyframes rotate{\n    from{\n        transform: rotate(0deg);\n    }\n    to{\n        transform: rotate(360deg);\n    }\n}\nfrom 表示最开始的那一帧，to 表示结束时的那一帧\n也可以使用百分比刻画生命周期：\n@keyframes rotate{\n    0%{\n        transform: rotate(0deg);\n    }\n    50%{\n        transform: rotate(180deg);\n    }\n    100%{\n        transform: rotate(360deg);\n    }\n}\n定义好了关键帧后，下来就可以直接用它了：\nanimation: rotate 2s;\nvue 中 keep-alive 的作用和实现原理\n&lt;keep-alive&gt; 是 Vue.js 提供的一个抽象组件，用于缓存动态组件（或组件的实例），避免在组件切换时销毁和重新创建组件实例，以提高性能和减少资源消耗。其主要作用和实现原理如下：\n作用：\n\n缓存组件状态： &lt;keep-alive&gt; 可以缓存动态组件的状态，当组件被切换隐藏时，不会销毁组件实例，而是将其缓存起来，保留其状态。\n优化性能： 缓存组件状态可以减少组件的销毁和重新创建，从而提高页面切换的性能。特别是对于一些频繁切换或复杂的组件，使用 &lt;keep-alive&gt; 可以有效地减少不必要的性能消耗。\n\n实现原理：\n\n组件缓存： &lt;keep-alive&gt; 内部维护了一个缓存对象，用于存储被包裹的动态组件或组件的实例。当组件被切换隐藏时，不会销毁组件实例，而是将其缓存到这个对象中。\n钩子函数： &lt;keep-alive&gt; 提供了两个钩子函数：activated 和 deactivated。activated 在组件被激活时调用，deactivated 在组件被停用时调用。这些钩子函数可以用于在组件被缓存和激活时执行一些额外的逻辑，比如数据初始化、动画效果等。\n动态组件的 key 属性： &lt;keep-alive&gt; 通过动态组件的 key 属性来区分不同的组件实例。当动态组件的 key 属性发生变化时，&lt;keep-alive&gt; 会销毁之前的缓存实例，并根据新的 key 属性重新创建组件实例。\nLRU 算法： &lt;keep-alive&gt; 使用了 LRU（最近最少使用）算法来管理缓存对象，当缓存对象达到一定大小限制时，会根据 LRU 算法删除最近最少使用的缓存实例，以释放内存。\n\n总的来说，&lt;keep-alive&gt; 通过缓存组件实例，钩子函数和动态组件的 key 属性来实现对动态组件的状态缓存和管理，从而提高性能和优化用户体验。\n首屏渲染优化方式有哪些？\n在现代前端开发中，优化首屏渲染是提高页面性能和用户体验的重要方面。以下是一些常见的首屏渲染优化方式：\n\n代码拆分（Code Splitting）： 将页面的代码拆分成多个块（chunks），根据页面的不同部分或路由进行按需加载。这样可以减少首屏加载时需要下载的资源量，提高页面加载速度。\n懒加载（Lazy Loading）： 将页面中非必要的内容延迟加载，直到用户需要访问时才加载。例如，图片、视频、广告等可以使用懒加载来延迟加载，减少首屏加载时间。\n预加载（Preloading）： 提前加载页面中可能需要的资源，以加速后续页面的加载。可以使用 &lt;link rel=&quot;preload&quot;&gt; 标签或者在 JavaScript 中动态加载资源来实现预加载。\n缓存优化： 合理利用浏览器缓存机制，将静态资源（如图片、样式表、脚本等）缓存到本地，减少重复请求和下载。可以使用缓存控制头（如 Cache-Control、Expires）或者 Service Worker 来实现缓存优化。\n图片优化： 对图片进行优化，包括压缩、转换成 WebP 格式、使用图片矢量化技术（如 SVG）、懒加载等，以减小图片大小和提高加载速度。\n服务器端渲染（SSR）： 使用服务器端渲染技术将页面的初始 HTML 内容直接生成并返回给客户端，加快首屏渲染速度。SSR 可以减少客户端渲染的时间，并提供更好的 SEO 和用户体验。\n代码优化： 对 JavaScript 和 CSS 进行优化，包括减少文件大小、减少不必要的代码、合并、压缩等，以提高资源加载和执行效率。\nDNS 预解析（DNS Prefetching）： 使用 &lt;link rel=&quot;dns-prefetch&quot;&gt; 标签或者通过 HTTP 头部信息来指定需要预解析的域名，加速 DNS 解析过程，减少资源请求的等待时间。\n使用 CDN 加速： 将静态资源部署到 CDN（内容分发网络）上，加速资源的传输和加载速度，提高页面的响应速度和性能。\n**响应式设计（Responsive Design）：**使用响应式设计来优化页面布局，使页面能够适配不同的设备和屏幕大小，提供更好的用户体验。\n\n综上所述，通过代码拆分、懒加载、预加载、缓存优化、图片优化、服务器端渲染、代码优化、DNS 预解析、使用 CDN 加速和响应式设计等方式，可以有效优化首屏渲染，提高页面性能和用户体验。\n前端在进行 WebSocket 通信时，有哪些性能优化措施？\n\n使用消息压缩：对于传输的消息可以使用压缩算法（如 Gzip）来减小数据包的大小，以减少数据传输量，提高通信效率。\n使用二进制数据传输：在需要传输大量数据时，可以使用二进制数据传输（如 ArrayBuffer、Blob 等类型）来传输二进制消息而不是文本数据，以减少数据传输量和提高传输速度。\n减少数据传输量：尽量减少不必要的数据传输，只传输必要的数据，可以通过数据筛选和压缩来实现。\n使用连接池：在客户端和服务器端都可以使用连接池来管理 WebSocket 连接，避免频繁地创建和销毁连接。连接池可以复用已建立的连接，减少连接建立和释放的开销，提高连接的复用率和性能。\n优化服务器端代码：对 WebSocket 服务器端代码进行优化，提高处理消息的效率和并发能力。\n优化心跳和断线重连机制：在 WebSocket 连接中，可以使用心跳机制来保持连接的活跃性，并使用断线重连机制来处理意外断开连接的情况。优化心跳频率和断线重连策略可以提高连接稳定性和性能。\n合理设置缓冲区大小： 在客户端和服务器端，可以通过设置合适的缓冲区大小来优化数据传输性能。合理设置缓冲区大小可以减少数据包的拆分和组装，降低网络传输延迟。\n\n循环引用是什么，产生原因，怎么检查，怎么处理？\n循环引用是指两个或多个对象相互引用，形成一个无限循环的情况。在 JavaScript 中，循环引用可能导致内存泄漏和一些意外行为，并且很难识别和解决。\n\n对象之间相互引用：如在数据结构如链表、树和图中，当一个节点或元素引用另一个节点，而后者最终又指回原始节点时，这样相互引用就会形成循环引用。\n事件处理器或回调函数： 如果一个对象注册了另一个对象的事件处理器或回调函数，而后者又引用了前者，就可能形成循环引用。\n**闭包：**在 JavaScript 中，闭包可能导致循环引用。如果一个函数内部引用了外部作用域的变量，并且外部作用域的变量又引用了该函数，就会形成循环引用。\n\n要检查 JavaScript 对象中是否存在循环引用，可以使用一些方法。例如，在 Chrome 开发者工具中的 Memory 面板中，可以检查堆快照（Heap Snapshot）并查看对象的引用关系。如果存在循环引用，可以在对象引用图中观察到闭环结构。\n或者编写一个函数来检测循环引用。下面是一个检测循环引用的函数示例：\nfunction isCyclic(obj) {\n  var seenObjects = [];\n \n  function detect(obj) {\n    if (obj &amp;&amp; typeof obj === &#039;object&#039;) {\n      if (seenObjects.indexOf(obj) !== -1) {\n        return true;\n      }\n      seenObjects.push(obj);\n      for (var key in obj) {\n        if (obj.hasOwnProperty(key) &amp;&amp; detect(obj[key])) {\n          console.log(obj, &#039;cycle at &#039; + key);\n          return true;\n        }\n      }\n    }\n    return false;\n  }\n  return detect(obj);\n}\n处理循环引用的方法包括手动清理引用、使用序列化来移除循环引用的属性等。下面是一个使用序列化处理循环引用的示例：\nconst getCircularReplacer = () =&gt; {\n  const seen = new WeakSet();\n  return (key, value) =&gt; {\n    if (typeof value === &quot;object&quot; &amp;&amp; value !== null) {\n      if (seen.has(value)) {\n        return;\n      }\n      seen.add(value);\n    }\n    return value;\n  };\n};\n \nconst circularReference = { otherData: 123 };\ncircularReference.myself = circularReference;\n \nJSON.stringify(circularReference, getCircularReplacer());\n// {&quot;otherData&quot;:123}\n手写题：如何画一条 0.5px 的线\nmeta viewport\n&lt;meta\n  name=&quot;viewport&quot;\n  content=&quot;width=device-width, initial-scale=0.5, minimum-scale=0.5, maximum-scale=0.5&quot;\n/&gt;\n1px 的线通过 meta viewport 中，scale 的设置，可以缩放变成 0.5 倍，则得到 0.5px 的线。\ntransform: scale()\n为 1px 的线添加上 CSS 样式，transform:scaleY(0.5)；\n#line {\n  border-bottom: 1px solid black;\n  transform: scaleY(0.5);\n}\nbox-shadow\n&lt;style&gt;\n  .boxshadow {\n    height: 1px;\n    background: none;\n    box-shadow: 0 0.5px 0 #000;\n  }\n&lt;/style&gt;\n&lt;p&gt;box-shadow: 0 0.5px 0 #000&lt;/p&gt;\n \n&lt;div class=&quot;boxshadow&quot;&gt;&lt;/div&gt;\n设置 box-shadow 的第二个参数为 0.5px，表示阴影垂直方向的偏移为 0.5px。\n手写题：实现 new 方法\nnew 做了什么\n\n创建一个空对象{} ( prototype 源于 Object.prototype )\n将该对象的__proto__指向构造函数的的prototype\n构造函数中的 this 指向这个空对象，执行构造函数内部代码（带参数）\n如果该函数没有返回对象，则返回 this\n\nfunction _new(Fn, ...args) {\n  const obj = {};\n  // obj.__proto__ = Fn.prototype  /* deprecated */\n  Object.setPrototypeOf(obj, Fn.prototype);\n    \n  // or: const obj = Object.create(Fn.prototype);\n  const res = Fn.call(obj, ...args)\n  return Object(res) === res ? res : obj\n}\n手写题：实现 Object.create 方法\nObject.create 功能是以一个现有对象作为原型，创建一个新对象，并且可以描述一些新对象的属性：\nfunction create(proto, propertiesObject) {\n  if (typeof proto !== &#039;object&#039; &amp;&amp; typeof proto !== &#039;function&#039;) {\n    throw new TypeError(&#039;Object prototype may only be an Object or null&#039;);\n  }\n    \n  function Fn() {}\n  Fn.prototype = proto;\n  const obj = new Fn();\n    \n  if (propertiesObject !== undefined) {\n    Object.defineProperties(obj, propertiesObject);\n  }\n  return obj;\n}\n场景题：后端返回的 64 位大数，前端怎么处理精度丢失的问题？\n处理后端返回的 64 位大数时，前端可能会遇到精度丢失的问题，因为 JavaScript 中的 Number 类型是基于双精度浮点数表示的，无法精确表示所有的整数。为了避免精度丢失，可以采取以下几种方法：\n\n使用字符串表示： 将后端返回的大数作为字符串处理，而不是直接转换为 JavaScript 中的 Number 类型。这样可以确保数字不会丢失精度，但需要在需要进行数值计算时手动将字符串转换为合适的数值类型。或使用第三方的大数处理库，如 BigNumber.js 等。这些库提供了丰富的功能和方法，用于精确表示和计算大数，并且通常提供了更多的控制选项和功能扩展。\n使用 BigInt 类型（ES2020+）： 如果浏览器支持 BigInt 类型（通常在 ES2020+ 中可用），可以使用 BigInt 类型来表示大整数。BigInt 类型可以精确表示任意大小的整数，但需要注意的是，BigInt 类型的计算与普通的 Number 类型有些许差异，例如不支持位运算符和隐式类型转换。\n"},"front-end/interview/bytedance/3":{"title":"字节前端面试题 Ⅲ","links":[],"tags":[],"content":"字节前端面试题 Ⅲ\njQuery 是什么设计模式？\njQuery 并没有严格遵循某一种特定的设计模式，而是结合了多种设计模式和最佳实践，以实现其提供的功能和特性。然而，可以说 jQuery 在其设计中主要采用了以下一些设计原则和模式：\n\n模块化设计： jQuery 的核心代码被划分为多个模块，每个模块负责不同的功能，如 DOM 操作、事件处理、动画效果等。这种模块化设计使得代码结构清晰，易于维护和扩展。\n链式调用（Chaining）： jQuery 提供了链式调用的方式来操作 DOM 元素和执行方法，可以在一个选择器上连续调用多个方法，从而简化了代码的书写和阅读。\n工厂模式（Factory Pattern）： 在 jQuery 中，使用 $() 或 jQuery() 函数来创建 jQuery 对象，这实际上是一种工厂模式的应用，通过工厂函数来创建对象并封装相关的功能和属性。\n观察者模式（Observer Pattern）： jQuery 中的事件机制采用了观察者模式，通过订阅和发布事件的方式来实现事件的处理和传递。例如，通过 .on() 方法注册事件监听器，实现了观察者模式中的订阅者。\n适配器模式（Adapter Pattern）： jQuery 提供了对浏览器 API 的封装，使得开发者可以更简单地使用统一的 API 来处理跨浏览器兼容性问题，这是一种适配器模式的应用。\n策略模式（Strategy Pattern）： jQuery 中的一些方法，如动画效果的实现，可以根据传入的参数采用不同的策略来执行相应的操作，这是一种策略模式的应用。\n单例模式（Singleton Pattern）： jQuery 的核心库是一个全局单例对象，通过将 jQuery 对象挂载到全局变量 $ 上来提供统一的接口，这是一种单例模式的应用。\n\n综上所述，jQuery 并没有严格遵循某一种设计模式，而是结合了多种设计原则和模式，以实现其提供的功能和特性，并且将这些设计原则和模式融合在一起，使得 jQuery 成为一个强大而灵活的 JavaScript 库。\n301 和 302 状态码\n301和302状态码是HTTP协议中的重定向状态码。\n重定向是指当用户请求一个URL时，服务器返回一个不同的URL，将用户重定向到新的地址。这两种状态码有不同的含义和用途。\n301状态码表示永久重定向，意味着请求的URL已经永久移动到了一个新的地址。这种重定向会传递原始URL的所有排名权重到新的URL，通常用于网页永久性移动或删除的情况。\n302状态码表示临时重定向，意味着请求的URL只是暂时移动到了一个新的地址。这种重定向适用于临时性的情况，比如网页的A/B测试、临时推广页面等。\n在实际应用中，根据需要正确选择301或302状态码，以确保用户和搜索引擎能够正确理解网页的重定向意图，从而避免对网站的SEO和搜索排名产生负面影响。\n讲讲 typescript 中的类型断言，类型守卫及联合类型\n类型断言（Type Assertion）：\n类型断言用于告诉编译器某个值的具体类型，并强制将其视为该类型，但并不会对值进行实质性的转换。在 TypeScript 中，有两种方式可以进行类型断言：\na. 尖括号语法：\ntypescriptCopy codelet value: any = &quot;Hello, TypeScript!&quot;;\nlet length: number = (&lt;string&gt;value).length;\nb. as 语法：\ntypescriptCopy codelet value: any = &quot;Hello, TypeScript!&quot;;\nlet length: number = (value as string).length;\n建议使用 as 语法，因为它在 JSX/TSX 中尖括号语法可能产生歧义。\n类型守卫（Type Guard）\n类型守卫是一种条件语句，通过这些条件语句可以在代码块中缩小某个变量的类型范围。常见的类型守卫包括 typeof、instanceof 和自定义的类型判断函数。\na. typeof 类型守卫：\nfunction printLength(value: string | number): void {\n    if (typeof value === &quot;string&quot;) {\n        console.log(value.length);\n    } else {\n        console.log(&quot;Not a string.&quot;);\n    }\n}\nb. instanceof 类型守卫：\nclass Animal {\n    move() {\n        console.log(&quot;Moving...&quot;);\n    }\n}\n \nclass Bird extends Animal {\n    fly() {\n        console.log(&quot;Flying...&quot;);\n    }\n}\n \nfunction moveAnimal(animal: Animal): void {\n    if (animal instanceof Bird) {\n        animal.fly();\n    } else {\n        animal.move();\n    }\n}\nc. 自定义类型判断函数：\ninterface Car {\n    brand: string;\n    start(): void;\n}\n \ninterface Bicycle {\n    type: string;\n    ride(): void;\n}\n \nfunction isCar(vehicle: Car | Bicycle): vehicle is Car {\n    return &quot;start&quot; in vehicle;\n}\n \nfunction startVehicle(vehicle: Car | Bicycle): void {\n    if (isCar(vehicle)) {\n        vehicle.start();\n    } else {\n        console.log(&quot;Not a car.&quot;);\n    }\n}\n联合类型（Union Types）\n联合类型允许一个变量具有多种类型中的一种。用 | 符号来连接多个类型，表示变量可以是这些类型之一。\nlet result: number | string;\n \nresult = 42;     // 合法\nresult = &quot;Hello&quot;; // 合法\n// result = true;  // 不合法，布尔类型不在联合类型中\n通过联合类型，可以更灵活地处理多种类型的值，但在使用时需要注意类型的相关检查，以避免潜在的运行时错误。\nJWT 是如何进行鉴权的？\nJWT（JSON Web Token）是一种用于在网络应用间传递声明的开放标准（RFC 7519），通常用于对用户进行身份验证和授权。\nJWT 鉴权的过程通常分为以下几个步骤：\n\n用户登录： 用户使用用户名和密码进行登录，服务器验证用户身份，并生成 JWT。\nJWT 生成： 服务器根据用户身份信息生成一个 JWT，并将其发送给客户端。\n客户端存储 JWT： 客户端通常将 JWT 存储在本地，比如将其存储在浏览器的 Local Storage 或者 Session Storage 中。\n客户端请求： 客户端在每次向服务器发送请求时，都会将 JWT 发送给服务器，通常放在请求的头部的 Authorization 字段中。\n服务器验证 JWT： 服务器收到请求后，会从请求头中获取 JWT，并验证其有效性和合法性。验证包括以下几个方面：\n\n验证 JWT 的签名是否有效，以确保 JWT 没有被篡改。\n验证 JWT 的有效期是否过期。\n验证 JWT 的声明（Claims），比如用户的身份信息、权限等。\n\n\n鉴权通过： 如果 JWT 验证通过，服务器会根据 JWT 中包含的用户信息来进行相应的授权处理，比如允许用户访问某些资源或者执行某些操作。\n鉴权失败： 如果 JWT 验证失败，服务器会返回相应的错误信息，并拒绝用户的访问请求。\n\n总的来说，JWT 鉴权通过在客户端和服务器之间传递包含用户身份信息的 Token 来实现用户的身份验证和授权，具有减轻服务器压力、无状态、跨域支持等优点。但需要注意的是，在使用 JWT 时，需要注意 Token 的安全性和有效期，以及对 Token 的正确验证和处理，以避免安全漏洞和信息泄露。\n\n众所周知，在 OAuth2 体系中认证通过后返回的令牌信息分为两大类：不透明令牌（opaque tokens） 和 透明令牌（not opaque tokens）。\n不透明令牌 是一种无可读性的令牌，一般来说就是一段普通的 UUID 字符串。使用不透明令牌时资源服务不知道这个令牌是什么，代表谁，需要调用认证服务器校验、获取用户信息。使用不透明令牌采用的是 中心化 的架构。\n透明令牌 一般指的是我们常说的JWT Token，用户信息保存在 JWT 字符串中，资源服务器自己可以解析令牌不再需要去认证服务器校验令牌。使用JWT是属于 无状态、去中心化 的架构。\n\nJWT 实现主动过期 \\ 权限更新\n使用JWT，就需要明确一点：在不借助外力的情况下，让JWT失效的唯一途径就是等token自己过期，无法做到主动让JWT失效；\n非要让JWT有主动失效的功能只能借助外力，即在服务端存储JWT的状态，在请求时添加判断逻辑，这个与JWT的无状态化、去中心化特性是矛盾的。但是，既然选择了JWT这条路，那就只能接受这个现实。\n\n使用 JWT 的版本号：在用户表中增加一个jwt_version字段，当用户想要注销或者让现有token过期时，他们可以简单地增加jwt_version字段的值。在生成新的JWT token时，将jwt_version编码到JWT负载中，如果新的JWT token应该替换所有其他token，则可以选择在之前增加值。在验证JWT token时，jwt_version字段将与用户ID一起比较，只有当它匹配时才授权。\n白名单机制：认证通过时，把JWT存到Redis中。注销时，从缓存移除JWT。请求资源添加判断JWT在缓存中是否存在，不存在拒绝访问。这种方式和cookie/session机制中的会话失效删除session基本一致。\n黑名单机制：注销登录时，缓存JWT至Redis，且缓存有效时间设置为JWT的有效期，请求资源时判断是否存在缓存的黑名单中，存在则拒绝访问。\n\n说一说 HTTP 请求的 options 预检\nOPTIONS 请求是 HTTP 协议中的一种请求方法，通常用于获取目标资源支持的通信选项（比如哪些 HTTP 方法和头部字段可用），或者测试服务器是否支持某些功能（比如 CORS 跨域请求）。\n而预检请求（Preflight Request）则是在跨域请求中使用的一种 OPTIONS 请求，用于在实际请求之前发送，以检查实际请求是否安全。\n预检请求的主要目的是确保跨域请求的安全性，包括：\n\n是否允许发送跨域请求： 首先，浏览器会发送一个 OPTIONS 请求到目标服务器，询问是否允许发送跨域请求。\n是否支持实际请求的方法和头部字段： 预检请求还可以携带请求头部字段 Access-Control-Request-Method 和 Access-Control-Request-Headers，用于询问服务器是否支持实际请求所使用的方法和头部字段。\n是否允许发送带身份凭证的跨域请求： 预检请求还可以携带请求头部字段 Access-Control-Allow-Credentials，用于询问服务器是否允许发送带身份凭证的跨域请求。\n\n预检请求的具体流程如下：\n\n客户端发起跨域请求，比如使用 XMLHttpRequest 或 Fetch API。\n浏览器自动发送一个 OPTIONS 请求到目标服务器，携带跨域请求的相关信息。\n服务器接收到 OPTIONS 请求后，根据请求头部字段中的信息进行判断和处理，比如验证请求来源、支持的方法和头部字段等。\n服务器返回响应，包括允许的方法和头部字段，以及是否允许发送跨域请求。\n浏览器收到响应后，根据服务器返回的信息判断是否允许发送实际请求。如果允许，浏览器会发送实际请求，否则会抛出相应的错误。\n\n预检请求通常在以下情况下使用：\n\n当实际请求使用了一些浏览器认为对安全性有影响的方法（如 DELETE、PUT 等）时，浏览器会先发送预检请求。\n当实际请求包含了一些自定义的头部时（包括任何不属于简单请求的头部，例如 X-Custom-Header），也会触发预检请求。\n如果实际请求是跨域请求（即请求的来源与目标不在同一个域下），浏览器也会发送预检请求。\n\n总之，预检请求是在浏览器认为需要对跨域请求进行安全检查时使用的。\n总的来说，预检请求通过询问服务器的支持情况，确保跨域请求的安全性和合法性，从而有效防止跨站请求伪造（CSRF）等安全问题。在实际应用中，开发者需要根据服务器的配置和需求，正确处理预检请求，以确保跨域请求能够顺利进行。\n以下是一个预检请求的示例：\nOPTIONS /resource/foo\nAccess-Control-Request-Method: DELETE\nAccess-Control-Request-Headers: Origin, X-Requested-With\nOrigin: foo.bar.org\n\n如果服务器允许该请求，将会响应预检请求，并在响应头中包含类似以下的信息：\nHTTP/1.1 204 No Content\nAccess-Control-Allow-Origin: foo.bar.org\nAccess-Control-Allow-Methods: POST, GET, OPTIONS, DELETE\nAccess-Control-Allow-Headers: Origin, X-Requested-With\nAccess-Control-Max-Age: 86400\n\n预检响应可以选择性地使用 Access-Control-Max-Age 头部进行缓存，以便在同一 URL 下创建的请求中重复使用。浏览器会使用一个特定的缓存来缓存预检响应，而不是通常的 HTTP 缓存。\n讲一讲浏览器的事件循环\n浏览器的事件循环是指浏览器处理事件和执行代码的机制。它允许浏览器在执行 JavaScript 代码的同时，能够响应用户的交互和处理其他异步任务，如网络请求、定时器等。浏览器的事件循环主要由以下几个组件组成：\n\n事件队列（Event Queue）： 事件队列是存储事件的地方，包括用户输入事件（如点击、键盘输入）、定时器事件、网络请求完成事件等。当某个事件发生时，会被加入到事件队列中。\n主线程（Main Thread）： 主线程负责执行 JavaScript 代码和处理事件。当主线程空闲时，会从事件队列中取出事件，并执行相应的回调函数。\n宏任务（Macro Task）： 宏任务是指由浏览器发起的任务，如 DOM 渲染、用户交互事件、定时器事件、网络请求等。每次执行宏任务时，会从事件队列中取出一个事件，然后执行相应的回调函数，直到所有宏任务执行完毕。\n微任务（Micro Task）： 微任务是指由 JavaScript 引擎发起的任务，如 Promise 的回调函数、MutationObserver 的回调函数等。每次执行完一个宏任务后，会先执行所有微任务，然后再执行下一个宏任务。\n\n事件循环的具体执行过程可以概括为以下几个步骤：\n\n执行当前宏任务（Macrotask）： 从事件队列中取出一个宏任务，执行它的回调函数。\n执行微任务（Microtask）： 执行所有微任务队列中的任务，直到微任务队列为空。\n更新渲染（Update Rendering）： 如果需要更新页面渲染，浏览器会执行渲染操作，比如重绘和重排。\n等待下一个宏任务（Waiting for the next Macrotask）： 等待下一个宏任务到达事件队列，然后重复以上步骤。\n\n需要注意的是，在执行微任务时，如果产生了新的微任务，会立即将它们添加到微任务队列中，并在当前微任务执行完毕后继续执行新的微任务，直到微任务队列为空。这意味着微任务具有优先级高于宏任务的特性，可以在宏任务之间执行，从而实现更及时的状态更新和处理。"},"front-end/interview/css":{"title":"css","links":[],"tags":[],"content":"说说你对盒子模型的理解?\n当对一个文档进行布局（layout）的时候，浏览器的渲染引擎会根据标准之一的 CSS 基础框盒模型（CSS basic box model），将所有元素表示为一个个矩形的盒子（box）。\n一个盒子由四个部分组成：content、padding、border、margin：\n\n\n\ncontent，即实际内容，显示文本和图像\n\n\nboreder，即边框，围绕元素内容的内边距的一条或多条线，由粗细、样式、颜色三部分组成\n\n\npadding，即内边距，清除内容周围的区域，内边距是透明的，取值不能为负，受盒子的background属性影响\n\n\nmargin，即外边距，在元素外创建额外的空白，空白通常指不能放其他元素的区域\n\n\n上述是一个从二维的角度观察盒子，下面再看看看三维图：\n\n下面来段代码：\n&lt;style&gt;\n  .box {\n    width: 200px;\n    height: 100px;\n    padding: 20px;\n  }\n&lt;/style&gt;\n&lt;div class=&quot;box&quot;&gt;\n  盒子模型\n&lt;/div&gt;\n当我们在浏览器查看元素时，却发现元素的大小变成了240px。这是因为，在CSS中，盒子模型可以分成：\n\nW3C 标准盒子模型\nIE 怪异盒子模型\n\n默认情况下，盒子模型为W3C 标准盒子模型\n标准盒子模型\n标准盒子模型，是浏览器默认的盒子模型\n从上图可以看到：\n\n盒子总宽度 = width + padding + border + margin;\n盒子总高度 = height + padding + border + margin\n\n也就是，width/height 只是内容高度，不包含 padding 和 border值\n所以上面问题中，设置width为200px，但由于存在padding，但实际上盒子的宽度有240px。\nIE 怪异盒子模型\n同样看看IE 怪异盒子模型的模型图：\n\n从上图可以看到：\n\n盒子总宽度 = width + margin；\n盒子总高度 = height + margin；\n\n也就是，width/height 包含了 padding和 border值；\nBox-sizing\nCSS 中的 box-sizing 属性定义了引擎应该如何计算一个元素的总宽度和总高度\n语法：\nbox-sizing: content-box|border-box|inherit:\n\ncontent-box 默认值，元素的 width/height 不包含padding，border，与标准盒子模型表现一致；\nborder-box 元素的 width/height 包含 padding，border，与怪异盒子模型表现一致；\ninherit 指定 box-sizing 属性的值，应该从父元素继承；\n\n回到上面的例子里，设置盒子为 border-box 模型\n&lt;style&gt;\n  .box {\n    width: 200px;\n    height: 100px;\n    padding: 20px;\n    box-sizing: border-box;\n  }\n&lt;/style&gt;\n&lt;div class=&quot;box&quot;&gt;\n  盒子模型\n&lt;/div&gt;\n这时候，就可以发现盒子的所占据的宽度为200px。\nCSS 选择器有哪些？优先级？哪些属性可以继承？\n选择器\nCSS选择器是CSS规则的第一部分，它是元素和其他部分组合起来告诉浏览器哪个HTML元素应当是被选为应用规则中的CSS属性值的方式。选择器所选择的元素，叫做“选择器的对象”。\n关于css属性选择器常用的有：\n\nid选择器（#box），选择id为box的元素\n类选择器（.one），选择类名为one的所有元素\n标签选择器（div），选择标签为div的所有元素\n后代选择器（#box div），选择id为box元素内部所有的div元素\n子选择器（.one&gt;one_1），选择父元素为.one的所有.one_1的元素\n相邻同胞选择器（.one+.two），选择紧接在.one之后的所有.two元素\n群组选择器（div,p），选择div、p的所有元素\n\n还有一些使用频率相对没那么多的选择器：\n伪类选择器\n:link         选择未被访问的链接\n:visited      选取已被访问的链接\n:active       选择活动链接\n:hover        鼠标指针浮动在上面的元素\n:focus        选择具有焦点的\n:first-child  父元素的首个子元素\n伪元素选择器\n:first-letter  用于选取指定选择器的首字母\n:first-line    选取指定选择器的首行\n:before        选择器在被选元素的内容前面插入内容\n:after         选择器在被选元素的内容后面插入内容\n属性选择器\n[attribute]        选择带有attribute属性的元素\n[attribute=value]  选择所有使用attribute=value的元素\n[attribute~=value] 选择attribute属性包含value的元素\n[attribute|=value] 选择attribute属性以value开头的元素\n在CSS3中新增的选择器有如下：\n\n\n层次选择器（p~ul），选择前面有p元素的每个ul元素\n\n\n伪类选择器\n:first-of-type 表示一组同级元素中其类型的第一个元素\n:last-of-type 表示一组同级元素中其类型的最后一个元素\n:only-of-type 表示没有同类型兄弟元素的元素\n:only-child 表示没有任何兄弟的元素\n:nth-child(n) 根据元素在一组同级中的位置匹配元素\n:nth-last-of-type(n) 匹配给定类型的元素，基于它们在一组兄弟元素中的位置，从末尾开始计数\n:last-child 表示一组兄弟元素中的最后一个元素\n:root 设置HTML文档\n:empty 指定空的元素\n:enabled 选择可用元素\n:disabled 选择被禁用元素\n:checked 选择选中的元素\n:not(selector) 选择与 &lt;selector&gt; 不匹配的所有元素\n\n\n属性选择器\n[attribute*=value]：选择attribute属性值包含value的所有元素\n[attribute^=value]：选择attribute属性开头为value的所有元素\n[attribute$=value]：选择attribute属性结尾为value的所有元素\n\n\n优先级\n相信大家对CSS选择器的优先级都不陌生：\n\n内联 &gt; ID选择器 &gt; 类选择器 &gt; 标签选择器\n\n到具体的计算层⾯，优先级是由 A 、B、C、D 的值来决定的，其中它们的值计算规则如下：\n\n如果存在内联样式，那么 A = 1, 否则 A = 0\nB的值等于 ID选择器出现的次数\nC的值等于 类选择器 和 属性选择器 和 伪类 出现的总次数\nD 的值等于 标签选择器 和 伪元素 出现的总次数\n\n这里举个例子：\n#nav-global &gt; ul &gt; li &gt; a.nav-link\n套用上面的算法，依次求出 A B C D 的值：\n\n因为没有内联样式 ，所以 A = 0\nID选择器总共出现了1次， B = 1\n类选择器出现了1次， 属性选择器出现了0次，伪类选择器出现0次，所以 C = (1 + 0 + 0) = 1\n标签选择器出现了3次， 伪元素出现了0次，所以 D = (3 + 0) = 3\n\n上面算出的A 、 B、C、D 可以简记作：(0, 1, 1, 3)\n知道了优先级是如何计算之后，就来看看比较规则：\n\n从左往右依次进行比较 ，较大者优先级更高\n如果相等，则继续往右移动一位进行比较\n如果4位全部相等，则后面的会覆盖前面的\n\n经过上面的优先级计算规则，我们知道内联样式的优先级最高，如果外部样式需要覆盖内联样式，就需要使用!important。\n继承属性\n在css中，继承是指的是给父元素设置一些属性，后代元素会自动拥有这些属性\n关于继承属性，可以分成：\n\n字体系列属性\n\nfont:组合字体\nfont-family:规定元素的字体系列\nfont-weight:设置字体的粗细\nfont-size:设置字体的尺寸\nfont-style:定义字体的风格\nfont-variant:偏大或偏小的字体\n\n文本系列属性\n\ntext-indent：文本缩进\ntext-align：文本水平对刘\nline-height：行高\nword-spacing：增加或减少单词间的空白\nletter-spacing：增加或减少字符间的空白\ntext-transform：控制文本大小写\ndirection：规定文本的书写方向\ncolor：文本颜色\n\n元素可见性\n\nvisibility\n\n表格布局属性\n\ncaption-side：定位表格标题位置\nborder-collapse：合并表格边框\nborder-spacing：设置相邻单元格的边框间的距离\nempty-cells：单元格的边框的出现与消失\ntable-layout：表格的宽度由什么决定\n\n列表属性\n\nlist-style-type：文字前面的小点点样式\nlist-style-position：小点点位置\nlist-style：以上的属性可通过这属性集合\n\n引用\n\nquotes：设置嵌套引用的引号类型\n\n光标属性\n\ncursor：箭头可以变成需要的形状\n继承中比较特殊的几点：\n\na 标签的字体颜色不能被继承；\nh1-h6标签字体的大小也是不能被继承的；\n\n无继承的属性\n\ndisplay\n文本属性：vertical-align、text-decoration\n盒子模型的属性：宽度、高度、内外边距、边框等\n背景属性：背景图片、颜色、位置等\n定位属性：浮动、清除浮动、定位position等\n生成内容属性：content、counter-reset、counter-increment\n轮廓样式属性：outline-style、outline-width、outline-color、outline\n页面样式属性：size、page-break-before、page-break-after\n\n怎么理解回流跟重绘？什么场景下会触发？\n是什么\n在HTML中，每个元素都可以理解成一个盒子，在浏览器解析过程中，会涉及到回流与重绘：\n\n回流：布局引擎会根据各种样式计算每个盒子在页面上的大小与位置\n重绘：当计算好盒模型的位置、大小及其他属性后，浏览器根据每个盒子特性进行绘制\n\n具体的浏览器解析渲染机制如下所示：\n\n\n解析HTML，生成DOM树，解析CSS，生成CSSOM树\n将DOM树和CSSOM树结合，生成渲染树(Render Tree)\nLayout(回流)：根据生成的渲染树，进行回流(Layout)，得到节点的几何信息（位置，大小）\nPainting(重绘)：根据渲染树以及回流得到的几何信息，得到节点的绝对像素\nDisplay：将像素发送给GPU，展示在页面上\n\n在页面初始渲染阶段，回流不可避免的触发，可以理解成页面一开始是空白的元素，后面添加了新的元素使页面布局发生改变。\n当我们对 DOM 的修改引发了 DOM几何尺寸的变化（比如修改元素的宽、高或隐藏元素等）时，浏览器需要重新计算元素的几何属性，然后再将计算的结果绘制出来。\n当我们对 DOM的修改导致了样式的变化（color或background-color），却并未影响其几何属性时，浏览器不需重新计算元素的几何属性、直接为该元素绘制新的样式，这里就仅仅触发了重绘。\n如何触发\n要想减少回流和重绘的次数，首先要了解回流和重绘是如何触发的\n回流触发时机\n回流这一阶段主要是计算节点的位置和几何信息，那么当页面布局和几何信息发生变化的时候，就需要回流，如下面情况：\n\n添加或删除可见的DOM元素\n元素的位置发生变化\n元素的尺寸发生变化（包括外边距、内边框、边框大小、高度和宽度等）\n内容发生变化，比如文本变化或图片被另一个不同尺寸的图片所替代\n页面一开始渲染的时候（这避免不了）\n浏览器的窗口尺寸变化（因为回流是根据视口的大小来计算元素的位置和大小的）\n\n还有一些容易被忽略的操作：获取一些特定属性的值\n\noffsetTop、offsetLeft、 offsetWidth、offsetHeight、scrollTop、scrollLeft、scrollWidth、scrollHeight、clientTop、clientLeft、clientWidth、clientHeight\n\n这些属性有一个共性，就是需要通过即时计算得到。因此浏览器为了获取这些值，也会进行回流\n除此还包括getComputedStyle方法，原理是一样的。\n重绘触发时机\n触发回流一定会触发重绘。可以把页面理解为一个黑板，黑板上有一朵画好的小花。现在我们要把这朵从左边移到了右边，那我们要先确定好右边的具体位置，画好形状（回流），再画上它原有的颜色（重绘）\n除此之外还有一些其他引起重绘行为：\n\n颜色的修改\n文本方向的修改\n阴影的修改\n\n浏览器优化机制\n由于每次重排都会造成额外的计算消耗，因此大多数浏览器都会通过队列化修改并批量执行来优化重排过程。浏览器会将修改操作放入到队列里，直到过了一段时间或者操作达到了一个阈值，才清空队列。\n当你获取布局信息的操作的时候，会强制队列刷新，包括前面讲到的offsetTop等方法都会返回最新的数据。\n因此浏览器不得不清空队列，触发回流重绘来返回正确的值。\n如何减少\n我们了解了如何触发回流和重绘的场景，下面给出避免回流的经验：\n\n如果想设定元素的样式，通过改变元素的 class 类名 (尽可能在 DOM 树的最里层)\n避免设置多项内联样式\n应用元素的动画，使用 position 属性的 fixed 值或 absolute 值(如前文示例所提)\n避免使用 table 布局，table 中每个元素的大小以及内容的改动，都会导致整个 table 的重新计算\n对于那些复杂的动画，对其设置 position: fixed/absolute，尽可能地使元素脱离文档流，从而减少对其他元素的影响\n使用 css3 硬件加速，可以让transform、opacity、filters这些动画不会引起回流重绘\n避免使用 CSS 的 JavaScript 表达式\n\n在使用 JavaScript 动态插入多个节点时, 可以使用DocumentFragment， 创建后一次插入，就能避免多次的渲染性能。\n但有时候，我们会无可避免地进行回流或者重绘，我们可以更好使用它们。例如，多次修改一个把元素布局的时候，我们很可能会如下操作：\nconst el = document.getElementById(&#039;el&#039;)\nfor(let i = 0; i &lt; 10 ;i++) {\n    el.style.top  = el.offsetTop  + 10 + &quot;px&quot;;\n    el.style.left = el.offsetLeft + 10 + &quot;px&quot;;\n}\n每次循环都需要获取多次offset属性，比较糟糕，可以使用变量的形式缓存起来，待计算完毕再提交给浏览器发出重计算请求\n// 缓存offsetLeft与offsetTop的值\nconst el = document.getElementById(&#039;el&#039;)\nlet offLeft = el.offsetLeft, offTop = el.offsetTop\n \n// 在JS层面进行计算\nfor(let i=0;i&lt;10;i++) {\n  offLeft += 10\n  offTop  += 10\n}\n \n// 一次性将计算结果应用到DOM上\nel.style.left = offLeft + &quot;px&quot;\nel.style.top = offTop  + &quot;px&quot;\n我们还可避免改变样式，使用类名去合并样式\nconst container = document.getElementById(&#039;container&#039;)\ncontainer.style.width = &#039;100px&#039;\ncontainer.style.height = &#039;200px&#039;\ncontainer.style.border = &#039;10px solid red&#039;\ncontainer.style.color = &#039;red&#039;\n使用类名去合并样式\n&lt;style&gt;\n    .basic_style {\n        width: 100px;\n        height: 200px;\n        border: 10px solid red;\n        color: red;\n    }\n&lt;/style&gt;\n&lt;script&gt;\n    const container = document.getElementById(&#039;container&#039;)\n    container.classList.add(&#039;basic_style&#039;)\n&lt;/script&gt;\n前者每次单独操作，都去触发一次渲染树更改（新浏览器不会），\n都去触发一次渲染树更改，从而导致相应的回流与重绘过程\n合并之后，等于我们将所有的更改一次性发出\n我们还可以通过通过设置元素属性display: none，将其从页面上去掉，然后再进行后续操作，这些后续操作也不会触发回流与重绘，这个过程称为离线操作\nconst container = document.getElementById(&#039;container&#039;)\ncontainer.style.width = &#039;100px&#039;\ncontainer.style.height = &#039;200px&#039;\ncontainer.style.border = &#039;10px solid red&#039;\ncontainer.style.color = &#039;red&#039;\n离线操作后\nlet container = document.getElementById(&#039;container&#039;)\ncontainer.style.display = &#039;none&#039;\ncontainer.style.width = &#039;100px&#039;\ncontainer.style.height = &#039;200px&#039;\ncontainer.style.border = &#039;10px solid red&#039;\ncontainer.style.color = &#039;red&#039;\n...（省略了许多类似的后续操作）\ncontainer.style.display = &#039;block&#039;\n伪类和伪元素有什么区别？\n伪类（Pseudo-classes）和伪元素（Pseudo-elements）是 CSS 中的两个不同概念，它们用于向选择器添加特殊的样式规则，以实现一些特定的效果，但它们之间有一些区别：\n伪类（Pseudo-classes）\n\n伪类用于向选择器添加特殊的样式规则，以根据元素的状态或位置来选择元素。\n伪类通常以冒号（:）开头，如 :hover、:active、:focus 等。\n伪类表示元素的特定状态，例如鼠标悬停、元素处于激活状态、元素获得焦点等。\n伪类可以用于任何 CSS 选择器中，包括类选择器、ID 选择器、标签选择器等。\n\n伪元素（Pseudo-elements）\n\n伪元素用于向选择器添加额外的元素，以在选定的元素上创建虚拟的元素。\n伪元素通常以双冒号（::）开头，如 ::before、::after、::first-line 等。\n伪元素用于在选定的元素的特定位置插入内容，例如在元素的前面、后面、第一行等位置。\n伪元素不能用于任何 CSS 选择器中，只能用于部分选择器，如类选择器、ID 选择器、标签选择器等。\n\n你知道哪些实现元素居中的方案？\n文本或内联元素水平居中\n使用text-align: center;属性可以实现文本或内联元素（如链接）的水平居中。\ncss.container {\n  text-align: center;\n}\n适用场景：适用于文本、链接或其他内联元素的水平居中。\n块级元素水平居中\n使用margin: 0 auto;可以实现块级元素（如&lt;div&gt;）的水平居中。\ncss.child {\n  width: 50%; /* 必须指定宽度 */\n  margin: 0 auto;\n}\n适用场景：适用于需要水平居中的块级元素，元素宽度需预先定义。\nFlexbox居中\n水平居中\n在父元素上使用display: flex;和justify-content: center;实现子元素的水平居中。\ncss.container {\n  display: flex;\n  justify-content: center;\n}\n垂直居中\n在父元素上使用display: flex;和align-items: center;实现子元素的垂直居中。\ncss.container {\n  display: flex;\n  align-items: center;\n}\n适用场景：适用于需要在容器内部水平或垂直居中一个或多个元素的情况。Flexbox还支持响应式布局。\nGrid居中\n使用CSS Grid布局，可以通过display: grid;和place-items: center;在两个方向上同时居中元素。\ncss.container {\n  display: grid;\n  place-items: center;\n}\n适用场景：适用于需要在容器内部水平和垂直同时居中一个或多个元素的情况。Grid 布局提供了更为强大和灵活的布局控制。\n绝对定位与负边距/Transform居中\n通过设置父元素position: relative;，子元素position: absolute;和top: 50%; left: 50%;配合transform: translate(-50%, -50%);可以实现元素的完全居中。\n.container {\n  position: relative;\n}\n.child {\n  position: absolute;\n  top: 50%;\n  left: 50%;\n  transform: translate(-50%, -50%);\n}\n适用场景：适用于需要完全居中一个元素，且元素大小未知或动态变化的情况。\n总结，CSS提供了多种方法实现元素的居中，选择哪种方法取决于具体的需求和场景。Flexbox和Grid布局因其灵活性和强大的布局能力，成为现代Web开发中推荐的居中方案。\n为什么要做样式初始化？\n因为浏览器有默认样式，而且不同浏览器默认样式不一样，为了让样式显示一致，要去掉这些默认样式。\n常见的方案有：\n\nreset.css：将所有元素的样式都设置为相同的初始值，以消除不同浏览器之间的差异。这种方式需要注意的是，一些元素的样式可能与开发者所期望的有所不同，因此需要进行特殊处理。\nNormalize.css：只重置一部分元素的样式，而不是重置所有元素。这种方式可以避免一些样式上的问题，同时还可以保留一些元素的默认样式，提高代码的可维护性和可读性。\n\n什么是BFC，有什么作用？\nCSS中的BFC（Block Formatting Context，块级格式化上下文）是Web页面的可视CSS渲染的一部分，它决定了元素如何对其内容进行布局，以及与其他元素的关系和相互作用。\n一个元素形成了BFC之后，那么它内部元素产生的布局不会影响到外部元素，外部元素的布局也不会影响到BFC中的内部元素。一个BFC就像是一个隔离区域，和其他区域互不影响。\nBFC的作用主要包括以下几点：\n\n包含浮动元素（清除浮动）：传统的布局问题之一是浮动元素不会影响其容器的高度，因为浮动元素脱离了文档流。通过创建BFC，可以使得容器包含其内部的浮动元素，从而解决高度塌陷问题。\n阻止外边距折叠：在BFC中，块级元素的垂直外边距不会与其BFC内的兄弟元素发生折叠。这是因为BFC为这些元素提供了一个隔离的环境，使得它们的布局不会相互影响。\n防止文本环绕：在BFC中，浮动元素不会影响到BFC内部的元素布局。这意味着，如果不希望文本环绕在浮动元素周围，可以通过创建BFC来避免这种情况。\n创建独立的布局环境：BFC提供了一个独立的布局环境，其中的元素布局不会影响到外部元素。这对于实现某些布局效果非常有用，比如网页的侧边栏和内容区域的布局。\n\n创建 BFC 的方法有多种，包括：\n\n应用overflow属性（不是visible值）到一个块级元素上。\n将元素设置为浮动（使用float属性，不是none）。\n将元素设置为绝对定位（使用position属性为absolute或fixed）。\n以及其他一些方法，如使用display属性的inline-block、table-cell、table-caption、flex、grid等值。\n\n怎么做移动端适配？\n常用的移动端适配方案有以下几种：\n\nrem方案：淘宝的移动端适配方案，使用相对单位rem结合JS动态计算rem值来实现移动端适配，将页面在不同尺寸的屏幕小按照宽度等比例缩放。\nvw方案：和rem方案原理类似，只是单位换成了vw。\npx方案：rem和vw方案都是等比例缩放，但是对于一些对UI要求特别高的大厂项目，缩放的显示效果并不是最佳，这时候也可以和UI配合采取px绝对像素。\n媒体查询：对于一些具体的场景，可以根据不同设备的像素区间来针对性地编写样式，这时候就使用媒体查询。\n百分比布局：将元素的宽度和高度设置为百分比，使得页面可以根据不同的屏幕尺寸进行等比例缩放，这种方案和rem、vw原理类似，但是计算比较困难，而且百分比相对的元素不固定，容易使问题变得复杂。\n响应式布局：对于一些定制化程度要求不高，但是需要PC和移动两端共用一套代码的场景，可以使用一些响应式布局的样式库，比如Bootstrap和Tailwind。\n\n我在项目里一般使用vw方案，结合自动化工具，如postcss-px-to-viewport和flexible.js进行自动的转换适配。然后对于一些特殊的场景，采用媒体查询作为辅助来实现。\n移动端 1px 边框问题怎么解决？\n由于不同的设备屏幕像素密度的不同，一些边框、线条等细节元素的显示可能会出现“1px问题”，即在某些设备上，本应该显示为1像素的边框或者线条，实际上却被放大成了2像素或者更多像素，导致显示效果不佳。\n常见的解决方案：\n\n\n使用 border-image：使用border-image可以将图片作为边框来显示，避免了使用CSS边框样式时的1px问题。\n\n\n使用box-shadow：使用box-shadow代替边框，然后将边框设为透明，可以避免1px问题。\n.border {\n    box-shadow: 0 0 0 1px #ccc;\n}\n\n\nborder + transform：使用transform将边框缩小一半。\n.border {\n    border: 1px solid #ccc;\n    transform: scaleY(0.5);\n}\n\n\n伪元素 + transform：与3类似，不同的是用伪元素来实现，在父元素上添加一个伪元素，然后给伪元素设置一个边框，并将其缩小为0.5倍。这样就可以实现1px的边框效果了。\n.border:before{\n    content: &quot;&quot;;\n    display: block;\n    position: absolute;\n    left: 0;\n    top: 0;\n    bottom: 0;\n    right: 0;\n    border: 1px solid #ccc;\n    transform-origin: 0 0;\n    transform: scaleY(0.5);\n}\n\n\n使用viewport单位：使用viewport相关的单位（如vw、vh、vmin和vmax）来设置边框或者线条的大小，可以让元素的大小自适应不同的设备像素密度。\n\n\n怎么实现换肤？\n使用CSS变量\n可以定义一个theme-color变量来存储主题色：\n:root {\n  --theme-color: #007bff; /* 定义主题色 */\n}\n然后在需要使用主题色的地方使用var()函数来引用这个变量：\n.button {\n  background-color: var(--theme-color); /* 使用主题色 */\n}\n再通过JS动态更改这个CSS变量的值，从而实现换肤的效果：\n// 获取根元素（即:root）\nconst root = document.documentElement;\n \n// 修改主题色变量的值\nroot.style.setProperty(&#039;--theme-color&#039;, &#039;#ff0000&#039;);\n使用 class 切换\n通过添加或移除不同的class来改变元素的样式，从而实现换肤。比如，可以定义多个class来表示不同的主题样式：\n.theme-blue {\n  /* 定义蓝色主题样式 */\n  background-color: #007bff;\n  color: #fff;\n}\n \n.theme-red {\n  /* 定义红色主题样式 */\n  background-color: #dc3545;\n  color: #fff;\n}\n然后在需要换肤的元素上添加对应的 class：\n&lt;button class=&quot;theme-blue&quot;&gt;蓝色主题&lt;/button&gt;\n&lt;button class=&quot;theme-red&quot;&gt;红色主题&lt;/button&gt;\n最后再通过JS动态添加或移除这些class来改变元素的样式，来实现换肤的效果。\n有没有了解过CSS命名规范？\n常见的CSS命名规范有：BEM规范、SMACSS规范、OOCSS规范。\nBEM规范\nBEM （Block, Element, Modifier）将CSS类名分为块、元素和修饰符三个部分，举个例子：\n&lt;div class=&quot;block&quot;&gt;\n  &lt;h2 class=&quot;block__title&quot;&gt;标题&lt;/h2&gt;\n  &lt;ul class=&quot;block__list&quot;&gt;\n    &lt;li class=&quot;block__list-item&quot;&gt;列表项1&lt;/li&gt;\n    &lt;li class=&quot;block__list-item block__list-item--highlighted&quot;&gt;列表项2&lt;/li&gt;\n  &lt;/ul&gt;\n&lt;/div&gt;\n其中block代表一个组件或UI部件，block__title和block__list代表块的子元素，block__list-item代表列表项。block__list-item--highlighted是一个修饰符，表示该列表项被突出显示。\nSMACSS规范\nSMACSS (Scalable and Modular Architecture for CSS) 不仅仅是命名规范，还包括CSS文件结构的组织规范。SMACSS主要是将样式分成五大类，分别是Base、Layout、Module、State、Theme。其中：\n\nBase类主要是基本样式规则，例如重置浏览器默认样式、设置全局的基本样式等。这些样式通常以选择器（标签选择器、通用选择器）为基础，并且适用于整个项目；\nLayout类用于创建页面布局和网格系统，它定义了页面的整体结构、栏目布局、容器和网格样式等；\nModule类用于定义可重复使用的模块样式；\nState类用于定义组件的状态样式，如.btn和.btn-primary的样式；\nTheme 类主要是主题相关的样式，如.site-title和.module-title的样式；\n\nOOCSS规范\nOOCSS (Object-oriented CSS) 规范主要遵循结构（Structure）与外观（Skin）分离的原则：\n&lt;div class=&quot;box box-red&quot;&gt;你好&lt;/div&gt;\n&lt;div class=&quot;box box-blue&quot;&gt;OOCSS规范&lt;/div&gt;\n其中结构部分（可复用样式）用.box，外观部分（不同样式）用.box-red来命名。\nACSS 规范\nACSS（Atomic CSS），原子化 CSS，它将样式属性分解成小的、可重用的单元（原子），每个原子只包含一个样式属性和它的值，以实现更高程度的样式复用和代码压缩。\nACSS 的核心理念是将样式属性分解成最小的可重用单元，然后根据需要组合这些单元来构建页面样式。\n.m-0 {\n  margin: 0;\n}\n.text-red {\n  color: red;\n}\n通常会使用成熟的CSS 框架，如 Tailwind CSS ， UnoCSS 等。\n什么是CSS工程化？\nCSS 工程化是指在开发和维护大型 Web 项目时，采用一系列规范化、模块化、自动化的工具和方法来提高 CSS 开发效率、代码可维护性和项目的整体质量。CSS 工程化的目标是通过规范化的工具链和工作流，解决 CSS 开发中的一些常见问题，例如命名冲突、样式复用、代码兼容性、性能优化等，从而提升项目的开发效率和质量。\nCSS 工程化通常包括以下几个方面的内容：\n\n规范化： 包括制定 CSS 编码规范、命名规范、组织规范等，统一团队的代码风格，降低团队成员之间的沟通成本。\n模块化： 将 CSS 代码分割成多个模块，每个模块负责管理特定功能或样式，使用模块化的方式可以提高代码的可维护性和复用性。\n预处理器和后处理器： 使用 CSS 预处理器（如 Sass、Less、Stylus 等）来编写更加灵活和可维护的 CSS 代码，通过变量、混合、嵌套、函数等功能来提高 CSS 开发效率。同时，还可以使用后处理器（如 PostCSS）来对生成的 CSS 进行优化、压缩、自动添加浏览器前缀等操作。\n模块打包和构建工具： 使用模块打包工具（如 webpack、Parcel 等）来处理 CSS 文件之间的依赖关系、打包、压缩、代码分割等操作，提高项目的性能和加载速度。\n组件化： 将页面拆分成多个组件，每个组件都有自己的 CSS 样式文件，通过组件化的方式来管理 CSS，降低样式的耦合性，提高代码的可维护性。\n代码检查和测试： 使用 CSS 静态分析工具（如 Stylelint）对 CSS 代码进行规范检查，确保代码符合规范，同时可以编写单元测试和集成测试来验证 CSS 样式的正确性。\n\n通过实施 CSS 工程化，可以有效地提高团队的协作效率、降低项目维护成本，同时提高项目的可扩展性和可维护性，是现代 Web 开发中不可或缺的一部分。"},"front-end/interview/daily/1/css":{"title":"css","links":[],"tags":[],"content":"圣杯布局和双飞翼布局的理解和区别，并用代码实现\n作用：圣杯布局和双飞翼布局解决的问题是一样的，就是两边顶宽，中间自适应的三栏布局，中间栏要在放在文档流前面以优先渲染。\n区别：三栏都使用左浮动，左栏使用 margin-left: -100% 偏移到左侧，右栏使用 margin-right: 2x0px 偏移到右侧；\n区别在于圣杯布局使用父容器的 padding 做防遮挡，而双飞翼在中间容器内创建子容器，使用 margin 做防遮挡：\n\n\n圣杯布局，为了中间 div 内容不被遮挡，将中间 div 设置了左右 padding-left 和 padding-right 后，将左右两个 div 用相对布局 position: relative 并分别配合 right 和 left 属性，以便左右两栏 div 移动后不遮挡中间 div。\n\n\n双飞翼布局，为了中间 div 内容不被遮挡，直接在中间 div 内部创建子 div 用于放置内容，在该子 div 里用 margin-left 和margin-right 为左右两栏 div 留出位置。\n\n"},"front-end/interview/daily/1/html":{"title":"html","links":[],"tags":[],"content":"页面导入样式时，使用link和@import有什么区别？\n\n1.link 是 HTML(XHTML) 标签，@import 是 css 提供的。\nlink 引入的样式页面加载时同时加载，@import 引入的样式需等页面加载完成后再加载。\nlink 没有兼容性问题，@import 是在 CSS2.1 提出的, 不兼容 ie5 以下。\nlink 可以通过 js 操作 DOM 动态引入样式表改变样式，而 @import 不可以。\n\nlink 标签除了引入样式，还可以被用来创建站点图标：\n&lt;link rel=&quot;icon&quot; href=&quot;favicon.ico&quot;&gt;\n "},"front-end/interview/daily/1/js":{"title":"js","links":[],"tags":[],"content":"用递归算法实现，生成数组长度为5且元素是随机数在2-32间不重复的值\n这是一道大题目，把考点拆成了4个小项；需要侯选人用递归算法实现（限制15行代码以内实现；限制时间10分钟内完成）：\n\n生成一个长度为5的空数组 arr。\n生成一个（2－32）之间的随机整数 rand。\n把随机数 rand 插入到数组 arr 内，如果数组arr内已存在与rand相同的数字，则重新生成随机数 rand 并插入到 arr 内[需要使用递归实现，不能使用for/while等循环]\n最终输出一个长度为 5，且内容不重复的数组 arr。\n\nfunction buildArray(arr, length, min, max) {\n    var num = Math.floor(Math.random() * (max - min + 1)) + min;\n    if (!arr.includes(num)) { arr.push(num); }\n    return arr.length === length ? arr : buildArray(arr, length, min, max);\n}\nvar result = buildArray([], 5, 2, 32);\nconsole.table(result);"},"front-end/interview/daily/2/css":{"title":"css","links":[],"tags":[],"content":"CSS3有哪些新增的特性？\n边框圆角\n\nborder-radius\n\n盒子阴影\n\nbox-shadow\n\n文字阴影\n\n\nword-break\n\n\nword-wrap\n\n\ntext-overflow\n\n\ntext-shadow\n\n\ntext-wrap\n\n\ntext-outline\n\n\ntext-justify\n\n\ntext-shadow\n\n\n2d、3d变换\n\n\ntransform\n\n\ntranslate\n\n\ntranslate3d\n\n\nscale3d\n\n\nrotate3d\n\n\n过度动画\n\ntransition\n\n自定义动画\n\nanimation\n\n弹性盒子(flexbox)\nbox-sizing 盒模型\n多媒体查询(@media)\nfilter滤镜"},"front-end/interview/daily/2/html":{"title":"html","links":[],"tags":[],"content":"html的元素有哪些（包含H5）？区分出行内元素、块级元素、空元素并在后面简要标注下作用。如：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n行内元素br - 换行span - 通用行内容器，无特殊语义a - 超链接strong - 文本十分重要，加粗b - 提醒注意（Bring Attention To）元素input - 输入框textarea - 多行文本框em - 文本强调（emphasis），通常为斜体img - 图片标签label - 标签，界面元素说明i - 术语（idiomatic）文本元素，斜体sub - 下标 subscriptbutton - 按钮sup - 上标 superscriptcite - 引用select - 选项菜单\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n块级元素div - 内容划分元素，无特殊语义hr - 主题分割 horizontal rule 水平线p - 文本块head - 文档元数据（头部）元素address - 表示提供了某个人或某个组织的联系信息table - 表单meta - 标注元数据信息fieldset - 用于对表单中的控制元素进行分组h1-h6 区域标题section - 独立章节header  - 用于展示介绍性内容form - 表格article - 文档页面main - 呈现了文档的 body 或应用的主体部分menu - 菜单ol - 有序列表 ordered listfooter - 最近一个章节内容或者根节点元素的页脚li -  列表项 list itemaside - 表示与页面内容几乎无关的部分，如侧边栏ul - 无序列表 unordered listnav - 表示导航链接导航部分，如菜单，目录和索引option - 选项菜单项\nH5 标签\nheader footer section article aside\nvideo audio canvas\nfieldset address\ndialog 对话框\nprogress 进度指示\nmeter 范围值\n&lt;address&gt;\n  &lt;a href=&quot;mailto:jim@example.com&quot;&gt;jim@example.com&lt;/a&gt;&lt;br /&gt;\n  &lt;a href=&quot;tel:+14155550132&quot;&gt;+1 (415) 555‑0132&lt;/a&gt;\n&lt;/address&gt;\n \n \n&lt;nav class=&quot;crumbs&quot;&gt;\n  &lt;ol&gt;\n    &lt;li class=&quot;crumb&quot;&gt;&lt;a href=&quot;#&quot;&gt;Bikes&lt;/a&gt;&lt;/li&gt;\n    &lt;li class=&quot;crumb&quot;&gt;&lt;a href=&quot;#&quot;&gt;BMX&lt;/a&gt;&lt;/li&gt;\n    &lt;li class=&quot;crumb&quot;&gt;Jump Bike 3000&lt;/li&gt;\n  &lt;/ol&gt;\n&lt;/nav&gt;\n \n&lt;form&gt;\n  &lt;fieldset&gt;\n    &lt;legend&gt;Choose your favorite monster&lt;/legend&gt;\n \n    &lt;input type=&quot;radio&quot; id=&quot;kraken&quot; name=&quot;monster&quot; value=&quot;K&quot; /&gt;\n    &lt;label for=&quot;kraken&quot;&gt;Kraken&lt;/label&gt;&lt;br /&gt;\n \n    &lt;input type=&quot;radio&quot; id=&quot;sasquatch&quot; name=&quot;monster&quot; value=&quot;S&quot; /&gt;\n    &lt;label for=&quot;sasquatch&quot;&gt;Sasquatch&lt;/label&gt;&lt;br /&gt;\n \n    &lt;input type=&quot;radio&quot; id=&quot;mothman&quot; name=&quot;monster&quot; value=&quot;M&quot; /&gt;\n    &lt;label for=&quot;mothman&quot;&gt;Mothman&lt;/label&gt;\n  &lt;/fieldset&gt;\n&lt;/form&gt;"},"front-end/interview/daily/2/js":{"title":"js","links":[],"tags":[],"content":"写一个方法去掉字符串中的空格\n我自己写的\nfunction trim(str){\n\treturn str.split(&#039; &#039;).join(&#039;&#039;)    \n}\nfunction trim2(str){\n    return str.replace(&#039;/\\s+/g&#039;, &#039;&#039;)\n}\n参考的：\nstr.replace(/\\s*/g,&quot;&quot;); \t\t//去除字符串内所有的空格\nstr.replace(/^\\s*|\\s*$/g,&quot;&quot;); \t//去除字符串内两头的空格\nstr.replace(/^\\s*/,&quot;&quot;); \t\t//去除字符串内左侧的空格\nstr.replace(/(\\s*$)/g,&quot;&quot;); \t\t//去除字符串内右侧的空格\nconst POSITION = Object.freeze({\n  left: Symbol(),\n  right: Symbol(),\n  both: Symbol(),\n  center: Symbol(),\n  all: Symbol(),\n})\n \nfunction trim(str, position = POSITION.both) {\n  if (!!POSITION[position]) throw new Error(&#039;unexpected position value&#039;)\n  \n  switch(position) {\n      case(POSITION.left):\n        str = str.replace(/^\\s+/, &#039;&#039;)\n        break;\n      case(POSITION.right):\n        str = str.replace(/\\s+$/, &#039;&#039;)\n        break;\n      case(POSITION.both):\n        str = str.replace(/^\\s+/, &#039;&#039;).replace(/\\s+$/, &#039;&#039;)\n        break;\n      case(POSITION.center):\n        while (str.match(/\\w\\s+\\w/)) {\n          str = str.replace(/(\\w)(\\s+)(\\w)/, `$1$3`)\n        }\n        break;\n      case(POSITION.all):\n        str = str.replace(/\\s/g, &#039;&#039;)\n        break;\n      default: \n  }\n  \n  return str\n}"},"front-end/interview/daily/3/css":{"title":"css","links":[],"tags":[],"content":"第3天 在页面上隐藏元素的方法有哪些？\n我的答案\n\ndisplay: none;\n\n\n社区答案\n占位\n\nvisibility: hidden;\nmargin-left: -100%;\nopacity: 0;\ntransform: scale(0);\n\n不占位\n\ndisplay: none;\nwidth: 0; height: 0; overflow: hidden;\n\n位置\n\nz-index:-99999999999\nposition: absolute; top:-9999px; left:-9999px;\n"},"front-end/interview/daily/3/html":{"title":"html","links":[],"tags":[],"content":"第3天 HTML全局属性(global attribute)有哪些（包含H5）？\n全局属性：用于任何HTML5元素的属性\n\naccesskey：设置快捷键\nclass：为元素设置类标识\ncontenteditable：指定元素内容是否可编辑\ncontextmenu：自定义鼠标右键弹出上下文菜单内容（仅firefox支持）\ndata-*：为元素增加自定义属性\ndir：设置元素文本方向（默认ltr；rtl）\ndraggable：设置元素是否可拖拽\ndropzone：设置元素拖放类型（copy|move|link,H5新属性，主流均不支持）\nhidden：规定元素仍未或不在相关\nid：元素id，文档内唯一\nlang：元素内容的语言\nspellcheck：是否启动拼写和语法检查\nstyle：行内css样式\ntabindex：设置元素可以获得焦点，通过tab导航\ntitle：规定元素有关的额外信息\ntranslate：元素和子孙节点内容是否需要本地化（均不支持）\n\naccesskey\n提供了为当前元素生成快捷键的方式。属性值必须包含一个可打印字符。\n激活 accesskey 的操作取决于浏览器及其平台，例如 Firefox 在 Windows 和 Linux平台中为 Alt + Shift + key，在 Mac 中为 Control + Option + key。"},"front-end/interview/daily/3/js":{"title":"js","links":[],"tags":[],"content":"第3天 去除字符串中最后一个指定的字符\n我的答案\nfunction trimLastChar(str, char){\n    let index = str.lastIndexOf(char);\n    str.substring(0, index) + str.substring(index + 1, str.length);\n}\n社区答案\nfunction delLast(str,target) {\n  let reg = new RegExp(`${target}(?=([^${target}]*)$)`)\n  return str.replace(reg,&#039;&#039;)\n}\nfunction delLast(str, target) {\n  return str.split(&#039;&#039;).reverse().join(&#039;&#039;).replace(target, &#039;&#039;).split(&#039;&#039;).reverse().join(&#039;&#039;);\n}\n// 如果 pattern 是字符串，则只会替换第一个匹配项。所以先反转替换后还原。\nconst str = delLast(&#039;asdfghhj&#039;, &#039;h&#039;)"},"front-end/interview/misc":{"title":"misc","links":[],"tags":[],"content":"如何选择图片格式，例如 png, webp ？\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n图片格式压缩方式透明度动画浏览器兼容适应场景JPEG有损压缩不支持不支持所有复杂颜色及形状、尤其是照片GIF无损压缩支持支持所有简单颜色，动画PNG无损压缩支持不支持所有需要透明时APNG无损压缩支持支持Firefox，Safari，iOS Safari需要半透明效果的动画WebP有损压缩支持支持Chrome，Opera，Android Chrome，Android Browser复杂颜色及形状，浏览器平台可预知SVG无损压缩支持支持所有（IE8以上）简单图形，需要良好的放缩体验需要动态控制图片特效\n小程序和 H5 有什么区别？\n\n\n渲染方式与 H5 不同，小程序一般是通过 Native 原生渲染的，但是小程序同时也支持 web 渲染，如果使用 web 渲染的方式，我们需要初始化一个WebView 组件，然后在 WebView 中加载 H5 页面；\n所以当我们开发一个小程序时，通常会使用 hybrid 的方式，即会根据具体情况选择部分功能用小程序原生的代码来开发，部分功能通过 WebView 加载 H5 页面来实现。Native 与 Web 渲染混合使用，以实现项目的最优解；\n这里值得注意的是，小程序下，native 方式通常情况下性能要优于 web 方式。\n\n\n小程序特有的双线程设计。 H5 下我们所有资源通常都会打到一个 bundle.js 文件里（不考虑分包加载），而小程序编译后的结果会有两个bundle，index.js 封装的是小程序项目的 view 层，以及 index.worker.js 封装的是项目的业务逻辑，在运行时，会有两条线程来分别处理这两个bundle，一个是主渲染线程，它负责加载并渲染 index.js 里的内容，另外一个是 Service Worker 线程，它负责执行 index.worker.js 里封装的业务逻辑，这里面会有很多对底层 api 调用。\n\n\n如何判断 0.1 + 0.2 与 0.3 相等？\n数字类型\nECMAScript 中的 Number 类型使用 IEEE754 标准来表示整数和浮点数值。所谓 IEEE754 标准，全称 IEEE 二进制浮点数算术标准，这个标准定义了表示浮点数的格式等内容。\n在 IEEE754 中，规定了四种表示浮点数值的方式：单精确度（32位）、双精确度（64位）、延伸单精确度、与延伸双精确度。像 ECMAScript 采用的就是双精确度，也就是说，会用 64 位来储存一个浮点数。\n浮点数转二进制\n我们来看下 1020 用十进制的表示：\n\n1020 = 1 * 10^3 + 0 * 10^2 + 2 * 10^1 + 0 * 10\n\n所以 1020 用十进制表示就是 1020……(哈哈)\n如果 1020 用二进制来表示呢？\n\n1020 = 1 * 2^9 + 1 * 2^8 + 1 * 2^7 + 1 * 2^6 + 1 * 2^5 + 1 * 2^4 + 1 * 2^3 + 1 * 2^2 + 0 * 2^1 + 0 * 2\n\n所以 1020 的二进制为 1111111100\n那如果是 0.75 用二进制表示呢？同理应该是：\n\n0.75 = a * 2^-1 + b * 2^-2 + c * 2^-3 + d * 2^-4 + …\n\n因为使用的是二进制，这里的 abcd……的值的要么是 0 要么是 1。\n那怎么算出 abcd…… 的值呢，我们可以两边不停的乘以 2 算出来，解法如下：\n\n0.75 = a * 2^-1 + b * 2^-2 + c * 2^-3 + d * 2^-4…\n\n两边同时乘以 2\n\n1 + 0.5 = a * 2^0 + b * 2^-1 + c * 2^-2 + d * 2^-3… (所以 a = 1)\n\n剩下的：\n\n0.5 = b * 2^-1 + c * 2^-2 + d * 2^-3…\n\n再同时乘以 2\n\n1 + 0 = b * 2^0 + c * 2^-2 + d * 2^-3… (所以 b = 1)\n\n所以 0.75 用二进制表示就是 0.ab，也就是 0.11\n然而不是所有的数都像 0.75 这么好算，我们来算下 0.1：\n0.1 = a * 2^-1 + b * 2^-2 + c * 2^-3 + d * 2^-4 + ...\n\n0 + 0.2 = a * 2^0 + b * 2^-1 + c * 2^-2 + ...   (a = 0)\n0 + 0.4 = b * 2^0 + c * 2^-1 + d * 2^-2 + ...   (b = 0)\n0 + 0.8 = c * 2^0 + d * 2^-1 + e * 2^-2 + ...   (c = 0)\n1 + 0.6 = d * 2^0 + e * 2^-1 + f * 2^-2 + ...   (d = 1)\n1 + 0.2 = e * 2^0 + f * 2^-1 + g * 2^-2 + ...   (e = 1)\n0 + 0.4 = f * 2^0 + g * 2^-1 + h * 2^-2 + ...   (f = 0)\n0 + 0.8 = g * 2^0 + h * 2^-1 + i * 2^-2 + ...   (g = 0)\n1 + 0.6 = h * 2^0 + i * 2^-1 + j * 2^-2 + ...   (h = 1)\n....\n\n然后你就会发现，这个计算在不停的循环，所以 0.1 用二进制表示就是 0.00011001100110011……\n浮点数的存储\n虽然 0.1 转成二进制时是一个无限循环的数，但计算机总要储存吧，我们知道 ECMAScript 使用 64 位来储存一个浮点数，那具体是怎么储存的呢？这就要说回 IEEE754 这个标准了，毕竟是这个标准规定了存储的方式。\n这个标准认为，一个浮点数 (Value) 可以这样表示：\n\nValue = sign * exponent * fraction\n\n看起来很抽象的样子，简单理解就是科学计数法……\n比如 -1020，用科学计数法表示就是:\n\n-1 * 10^3 * 1.02\n\nsign 就是 -1，就是 10^3，fraction 就是 1.02\n对于二进制也是一样，以 0.1 的二进制 0.00011001100110011…… 这个数来说：\n可以表示为：\n\n1 * 2^-4 * 1.1001100110011……\n\n其中 sign 就是 1，exponent 就是 2^-4，fraction 就是 1.1001100110011……\n而当只做二进制科学计数法的表示时，这个 Value 的表示可以再具体一点变成：\n\nV = (-1)^S * (1 + Fraction) * 2\n\n(如果所有的浮点数都可以这样表示，那么我们存储的时候就把这其中会变化的一些值存储起来就好了)\n我们来一点点看：\n(-1)^S 表示符号位，当 S = 0，V 为正数；当 S = 1，V 为负数。\n再看 (1 + Fraction)，这是因为所有的浮点数都可以表示为 1.xxxx * 2^xxx 的形式，前面的一定是 1.xxx，那干脆我们就不存储这个 1 了，直接存后面的 xxxxx 好了，这也就是 Fraction 的部分。\n最后再看 2^E\n如果是 1020.75，对应二进制数就是 1111111100.11，对应二进制科学计数法就是 1 * 1.11111110011 * 2^9，E 的值就是 9，而如果是 0.1 ，对应二进制是 1 * 1.1001100110011…… * 2^-4， E 的值就是 -4，也就是说，E 既可能是负数，又可能是正数，那问题就来了，那我们该怎么储存这个 E 呢？\n我们这样解决，假如我们用 8 位来存储 E 这个数，如果只有正数的话，储存的值的范围是 0 ~ 254，而如果要储存正负数的话，值的范围就是 -127~127，我们在存储的时候，把要存储的数字加上 127，这样当我们存 -127 的时候，我们存 0，当存 127 的时候，存 254，这样就解决了存负数的问题。对应的，当取值的时候，我们再减去 127。\n所以呢，真到实际存储的时候，我们并不会直接存储 E，而是会存储 E + bias，当用 8 位的时候，这个 bias 就是 127。\n所以，如果要存储一个浮点数，我们存 S 和 Fraction 和 E + bias 这三个值就好了，那具体要分配多少个位来存储这些数呢？\nIEEE754 给出了标准：\n\n\n1 位存储 S，0 表示正数，1 表示负数。\n\n\n11 位存储 E + bias，对于 11 位来说，bias 的值是 2^(11-1) - 1，也就是 1023。\n\n\n用 52 位存储 Fraction。\n\n\n举个例子，就拿 0.1 来看，对应二进制是 1 * 1.1001100110011…… * 2^-4， Sign 是 0，E + bias 是 -4 + 1023 = 1019，1019 用二进制表示是 1111111011，Fraction 是 1001100110011 ……\n对应 64 位的完整表示就是：\n\n0 01111111011 1001100110011001100110011001100110011001100110011010\n\n同理, 0.2 表示的完整表示是：\n\n0 01111111100 1001100110011001100110011001100110011001100110011010\n\n所以当 0.1 存下来的时候，就已经发生了精度丢失，当我们用浮点数进行运算的时候，使用的其实是精度丢失后的数。\n浮点数的运算\n关于浮点数的运算，一般由以下五个步骤完成：对阶、尾数运算、规格化、舍入处理、溢出判断。我们来简单看一下 0.1 和 0.2 的计算。\n首先是对阶，所谓对阶，就是把阶码调整为相同，比如 0.1 是 1.1001100110011…… * 2^-4，阶码是 -4，而 0.2 就是 1.10011001100110...* 2^-3，阶码是 -3，两个阶码不同，所以先调整为相同的阶码再进行计算，调整原则是小阶对大阶，也就是 0.1 的 -4 调整为 -3，对应变成 0.11001100110011…… * 2^-3\n接下来是尾数计算:\n  0.1100110011001100110011001100110011001100110011001101\n+ 1.1001100110011001100110011001100110011001100110011010\n————————————————————————————————————————————————————————\n 10.0110011001100110011001100110011001100110011001100111\n\n我们得到结果为 10.0110011001100110011001100110011001100110011001100111 * 2^-3\n将这个结果处理一下，即结果规格化，变成 1.0011001100110011001100110011001100110011001100110011(1) * 2^-2\n括号里的 1 意思是说计算后这个 1 超出了范围，所以要被舍弃了。\n再然后是舍入，四舍五入对应到二进制中，就是 0 舍 1 入，因为我们要把括号里的 1 丢了，所以这里会进一，结果变成\n1.0011001100110011001100110011001100110011001100110100 * 2^-2\n\n本来还有一个溢出判断，因为这里不涉及，就不讲了。\n所以最终的结果存成 64 位就是\n\n0 01111111101 0011001100110011001100110011001100110011001100110100\n\n将它转换为10进制数就得到 0.30000000000000004440892098500626\n因为两次存储时的精度丢失加上一次运算时的精度丢失，最终导致了 0.1 + 0.2 !== 0.3\n// 十进制转二进制\nparseFloat(0.1).toString(2);\n=&gt; &quot;0.0001100110011001100110011001100110011001100110011001101&quot;\n \n// 二进制转十进制\nparseInt(1100100,2)\n=&gt; 100\n \n// 以指定的精度返回该数值对象的字符串表示\n(0.1 + 0.2).toPrecision(21)\n=&gt; &quot;0.300000000000000044409&quot;\n(0.3).toPrecision(21)\n=&gt; &quot;0.299999999999999988898&quot;"},"front-end/interview/react":{"title":"react","links":[],"tags":[],"content":"setState 是同步还是异步？\nv18之前\n\n\nReact是希望setState表现为异步的，因为批量更新可以优化性能。因此在React能够管控到的地方，比如生命周期钩子和合成事件回调函数内，表现为异步。\n\n\n在定时器和原生事件里，因为React管控不到，所以表现为同步。\n\n\n在某些情况下，我们需要立即获取更新后的状态，这时可以使用第二个可选参数callback，在状态更新后立即执行回调函数来获取更新后的状态。例如：\nthis.setState({ counter: this.state.counter + 1 }, () =&gt; {\n  console.log(this.state.counter); // 输出更新后的值\n});\n\n\nv18之后\n\nReact18之后，默认所有的操作都放到批处理中，因此setState不管在那儿调用都是异步的了。\n如果希望同步更新，可以使用 flushSync 这个API。\n\nReact组件通信方式有哪些？\n\nProps: 父组件可以通过 props 将数据传递给子组件。子组件可以通过 this.props 访问这些数据。\nCallback: 父组件可以通过回调函数将函数传递给子组件。子组件可以在适当的时候调用这些回调函数，以便与父组件通信。\nContext: 上下文是一种在组件树中共享数据的方法。通过 context，可以在组件树中传递数据，而不需要在每个级别显式地将 props 传递给所有组件。\nRedux: 复杂应用全局状态管理可以使用Redux、Mobx等状态管理库，项目里一般使用React Redux或者RTK工具包。\nPub/Sub: 发布/订阅模式是一种通过事件来进行任意组件间通信的方法，和Vue里的事件总线原理一样。\nHooks里也可以通过useReducer和useContext来实现全局组件通信。\n\nuseMemo 和 useCallback 有什么作用？\n\n\nuseMemo 类似于 Vue 的计算属性\nimport React, { useMemo } from &#039;react&#039;;\n \nfunction ExpensiveComponent({ data }) {\n  const expensiveResult = useMemo(() =&gt; {\n    // 计算昂贵的结果\n    return data.filter(item =&gt; item &gt; 10);\n  }, [data]);\n \n  return &lt;div&gt;{expensiveResult}&lt;/div&gt;;\n}\n\n\nuseCallback：大多数人认为 useCallback 的作用是缓存函数的生成，但在实际应用中这种优化是微不足道的，useCallback 真正的作用是在函数需要作为prop传递给子组件时，使用 useCallback 包裹可以避免子组件无谓的更新。\n\n\n什么是受控组件和非受控组件？\n受控组件和非受控组件是针对表单的。\n1. 受控组件：(类似于Vue的双向绑定)\n\n\nReact默认不是双向绑定的，也就是说当我们在输入框输入的时候，输入框绑定的值并不会自动变化。\n\n\n通过给input绑定onChange事件，让React实现类似于Vue的双向绑定，这就叫受控组件。\n\n\n2. 非受控组件\n\n非受控组件是让用户手动操作Dom来控制表单值。\n非受控组件的好处是更自由，可以更方便地自行选择三方库来处理表单 。\n\nJSX和模板引擎有什么区别？\n\nJSX：更加灵活，既可以写标签，也可以使用原生 js 语法和表达式，在做复杂渲染时更得心应手。\n模板引擎：更简单易上手，开发效率高，结合指令的可读性也比较好。\nJSX 太灵活就导致没法给编译器提供太多的优化线索，不好做静态优化，模板引擎可以在编译时做静态标记，性能更好。\nJSX只是个编译工具，Vue经过一定的配置也可以使用。\n"},"front-end/interview/tencent/1":{"title":"1","links":[],"tags":[],"content":"js 如何控制一次只加载一张图片，加载完成后再加载下一张\nconst imgArrs = [...]; // 图片地址\nconst content = document.getElementById(&#039;content&#039;);\n \nfunction loadImg(){\n  if(imgArrs.length === 0) return;\n \n  const img = new Image(); // 新建一个Image对象\n  img.src = imgArrs[0];\n  img.onload = () =&gt; {\n    imgArrs.shift();\n    setTimeout(()=&gt;{\n      content.appendChild(img)\n      loadImg()\n    }, 1000);\n  }\n  img.onerror = () =&gt; {}\n}\nconst imgArrs = [...]; // 图片地址\nconst content = document.getElementById(&#039;content&#039;);\n \n(()=&gt;{\n  const tasks = imgArrs.map(url =&gt; {\n    return () =&gt; new Promise((resolve, reject) =&gt; {\n      const img = new Image(); // 新建一个Image对象\n      img.src = url;\n      img.onload = () =&gt; {\n        content.appendChild(img);\n        resolve();\n      };\n      img.onerror = (e) =&gt; reject(e);\n    })\n  });\n  tasks.reduce((previousPromise, currentTask) =&gt; {\n    return previousPromise.then(() =&gt; currentTask());\n  }, Promise.resolve())\n  .then(() =&gt; {\n    onsole.log(&#039;All images loaded successfully&#039;);\n  })\n  .catch(error =&gt; {\n    console.error(&#039;Error loading images:&#039;, error);\n  });\n})()"},"front-end/interview/vue":{"title":"vue","links":[],"tags":[],"content":"Vue 面试题\nVue3.0 里为什么要用 Proxy API 替代 defineProperty API ？\nObject.defineProperty\n在一个对象上通过属性描述对象，定义一个新属性，或者修改一个对象的现有属性，并返回此对象。\n如何实现响应式？\n通过defineProperty 两个属性get 及 set，一个示例：\nfunction update() {\n  app.innerText = obj.foo;\n}\n \nfunction defineReactive(obj, key, val) {\n  Object.defineProperty(obj, key, {\n    get() {\n      console.log(`get ${key}:${val}`);\n      return val;\n    },\n    set(newVal) {\n      if (newVal !== val) {\n        val = newVal;\n        update();\n      }\n    },\n  });\n}\n基于此原理，对一个对象进行删除与添加属性操作，是无法无法劫持到的。\n此外，也不能劫持数组的数据读写，因为数组的数据读写是通过索引来进行的，而不是通过属性名。\n还有一个问题则是，如果存在深层的嵌套对象关系，需要深层的进行监听，造成了性能的极大问题。\nproxy\nProxy 的监听是针对一个对象的，那么对这个对象的所有操作会进入监听操作，这就完全可以代理所有属性了。\nfunction reactive(obj) {\n  if (typeof obj !== &quot;object&quot; &amp;&amp; obj != null) {\n    return obj;\n  }\n  // Proxy 相当于在对象外层加拦截\n  const observed = new Proxy(obj, {\n    get(target, key, receiver) {\n      const res = Reflect.get(target, key, receiver);\n      console.log(`获取${key}:${res}`);\n      return res;\n    },\n    set(target, key, value, receiver) {\n      const res = Reflect.set(target, key, value, receiver);\n      console.log(`设置${key}:${value}`);\n      return res;\n    },\n    deleteProperty(target, key) {\n      const res = Reflect.deleteProperty(target, key);\n      console.log(`删除${key}:${res}`);\n      return res;\n    },\n  });\n  return observed;\n}\nProxy可以直接监听数组的变化（push、shift、splice），且有多达 13 种拦截方法，不限于apply、ownKeys、deleteProperty、has等等，这是Object.defineProperty不具备的。\nProxy 不兼容 IE，也没有 polyfill, defineProperty 能支持到 IE9。\nVue3.0 所采用的 Composition Api 与 Vue2.x 使用的 Options Api 有什么不同？\n\n组织代码的方式：\n\nOptions API：Options API 是基于选项的方式来组织组件的代码。一个组件通常包含一个选项对象，其中包含了诸如 data、methods、computed、watch 等属性，这些属性用于定义组件的状态和行为。\nComposition API：Composition API 是基于函数的方式来组织组件的代码。一个组件可以由多个功能相关的逻辑块（composition functions）组成，每个逻辑块都可以包含自己的状态、计算属性、方法等，并且可以根据需要进行复用。\n\n\n逻辑复用性：\n\nOptions API：在 Options API 中，逻辑的复用通常依赖于 mixins 和高阶组件等方式，这可能会导致代码结构的不清晰和难以维护。\nComposition API：Composition API 提供了更灵活和精确的逻辑复用方式。通过将功能相关的代码组织成独立的逻辑块，并在组件中根据需要组合使用这些逻辑块，可以实现更好的代码复用和组织。\n\n\n逻辑关联性：\n\nOptions API：在 Options API 中，组件的状态和行为通常是通过选项对象中的属性来关联的，这可能导致相关逻辑的分散和耦合度较高。\nComposition API：Composition API 允许将相关的状态和行为组织在一起，从而提高了代码的可读性和可维护性。通过将相关逻辑放置在同一个逻辑块中，可以更容易地理解和修改代码。\n\n\nTypeScript 支持：\n\nOptions API：在 Vue 2.x 中，对于 TypeScript 的支持相对有限，需要使用额外的注解来声明组件的类型。\nComposition API：Composition API 明确支持 TypeScript，并且提供了更好的类型推断和类型安全性。通过使用 TypeScript，可以更轻松地编写和维护类型安全的 Vue 组件。\n\n\n\n总的来说，Composition API 提供了一种更灵活、更可复用、更易于维护的方式来组织和编写 Vue 组件的代码，尤其适用于大型项目或需要复杂逻辑的场景。与 Options API 相比，Composition API 在代码组织、逻辑复用、逻辑关联性和 TypeScript 支持等方面具有明显的优势。\nvue2 代码打包时为什么很难处理 Tree shaking ？\n在大多数 Vue 项目中，通常会创建一个根 Vue 实例，并在整个应用中共享该实例。这意味着该根实例及其所依赖的组件和模块在整个项目中都会被引用和使用。Tree shaking 时即使某些组件或模块在项目中并未直接使用，但它们可能仍然会被 Vue 实例间接引用，因此无法被完全移除。\nVue 2 的代码在打包时难以进行 Tree shaking 的另一原因是因为 Vue 2 使用了对象字面量作为组件配置，而不是 ES6 的类。这导致了一些挑战，因为对象字面量在编译时不容易静态分析。这使得 Webpack 在进行 Tree shaking 时难以确定哪些代码是可以安全移除的。\n\n对象字面量是在运行时动态创建的，因为它们的属性和方法可以在任何时候添加、修改或删除。\n相比之下，ES6 的类在定义时就具有了明确定义的结构，并且不容易在运行时动态修改。类的结构在编译时就已经确定，因此静态分析工具可以更容易地识别和优化类的使用。\n\n另一个问题是 Vue 2 中模板的编译方式。Vue 2 模板编译成了一个包含多个嵌套的函数调用的 render 函数，这些函数在编译时难以静态确定。这使得在打包时很难确定哪些代码可以安全地移除。\nVue 中的 $nextTick 有什么作用？\nNextTick 是什么\n官方对其的定义：\n\n在下次 DOM 更新循环结束之后执行延迟回调。在修改数据之后立即使用这个方法，获取更新后的 DOM\n\n什么意思呢？\n我们可以理解成，Vue 在更新 DOM 时是异步执行的。当数据发生变化，Vue 将开启一个异步更新队列，视图需要等队列中所有数据变化完成之后，再统一进行更新。\nHtml结构\n&lt;div id=&quot;app&quot;&gt;{{ message }}&lt;/div&gt;\n构建一个vue实例\nconst vm = new Vue({\n  el: &quot;#app&quot;,\n  data: {\n    message: &quot;原始值&quot;,\n  },\n});\n修改message\nthis.message = &quot;修改后的值1&quot;;\nthis.message = &quot;修改后的值2&quot;;\nthis.message = &quot;修改后的值3&quot;;\n这时候想获取页面最新的DOM节点，却发现获取到的是旧值\nconsole.log(vm.$el.textContent); // 原始值\n这是因为message数据在发现变化的时候，vue并不会立刻去更新Dom，而是将修改数据的操作放在了一个异步操作队列中。如果我们一直修改相同数据，异步操作队列还会进行去重。\n等待同一事件循环中的所有数据变化完成之后，会将队列中的事件拿来进行处理，进行DOM的更新。\n使用场景\n如果想要在修改数据后立刻得到更新后的DOM结构，可以使用Vue.nextTick()\n\n\n第一个参数为：回调函数（可以获取最近的DOM结构）\n\n\n第二个参数为：执行函数上下文\n\n\n// 修改数据\nvm.message = &quot;修改后的值&quot;;\n// DOM 还没有更新\nconsole.log(vm.$el.textContent); // 原始的值\nVue.nextTick(function () {\n  // DOM 更新了\n  console.log(vm.$el.textContent); // 修改后的值\n});\n组件内使用 vm.$nextTick() 实例方法只需要通过this.$nextTick()，并且回调函数中的 this 将自动绑定到当前的 Vue 实例上。\n$nextTick() 会返回一个 Promise 对象，可以是用async/await完成相同作用的事情\nthis.message = &quot;修改后的值&quot;;\nconsole.log(this.$el.textContent); // =&gt; &#039;原始的值&#039;\nawait this.$nextTick();\nconsole.log(this.$el.textContent); // =&gt; &#039;修改后的值&#039;\n实现原理\nallbacks也就是异步操作队列\ncallbacks新增回调函数后又执行了timerFunc函数，pending是用来标识同一个时间只能执行一次\nexport function nextTick(cb?: Function, ctx?: Object) {\n  let _resolve;\n \n  // cb 回调函数会经统一处理压入 callbacks 数组\n  callbacks.push(() =&gt; {\n    if (cb) {\n      // 给 cb 回调函数执行加上了 try-catch 错误处理\n      try {\n        cb.call(ctx);\n      } catch (e) {\n        handleError(e, ctx, &quot;nextTick&quot;);\n      }\n    } else if (_resolve) {\n      _resolve(ctx);\n    }\n  });\n \n  // 执行异步延迟函数 timerFunc\n  if (!pending) {\n    pending = true;\n    timerFunc();\n  }\n \n  // 当 nextTick 没有传入函数参数的时候，返回一个 Promise 化的调用\n  if (!cb &amp;&amp; typeof Promise !== &quot;undefined&quot;) {\n    return new Promise((resolve) =&gt; {\n      _resolve = resolve;\n    });\n  }\n}\ntimerFunc函数定义，这里是根据当前环境支持什么方法则确定调用哪个，分别有：Promise.then、MutationObserver、setImmediate、setTimeout\n通过上面任意一种方法，进行降级操作\nexport let isUsingMicroTask = false;\nif (typeof Promise !== &quot;undefined&quot; &amp;&amp; isNative(Promise)) {\n  //判断1：是否原生支持Promise\n  const p = Promise.resolve();\n  timerFunc = () =&gt; {\n    p.then(flushCallbacks);\n    if (isIOS) setTimeout(noop);\n  };\n  isUsingMicroTask = true;\n} else if (\n  !isIE &amp;&amp;\n  typeof MutationObserver !== &quot;undefined&quot; &amp;&amp;\n  (isNative(MutationObserver) ||\n    MutationObserver.toString() === &quot;[object MutationObserverConstructor]&quot;)\n) {\n  //判断2：是否原生支持 MutationObserver\n  let counter = 1;\n  const observer = new MutationObserver(flushCallbacks);\n  const textNode = document.createTextNode(String(counter));\n  observer.observe(textNode, {\n    characterData: true,\n  });\n  timerFunc = () =&gt; {\n    counter = (counter + 1) % 2;\n    textNode.data = String(counter);\n  };\n  isUsingMicroTask = true;\n} else if (typeof setImmediate !== &quot;undefined&quot; &amp;&amp; isNative(setImmediate)) {\n  //判断3：是否原生支持setImmediate\n  timerFunc = () =&gt; {\n    setImmediate(flushCallbacks);\n  };\n} else {\n  //判断4：上面都不行，直接用setTimeout\n  timerFunc = () =&gt; {\n    setTimeout(flushCallbacks, 0);\n  };\n}\n无论是微任务还是宏任务，都会放到flushCallbacks使用\n这里将callbacks里面的函数复制一份，同时callbacks置空\n依次执行callbacks里面的函数\nfunction flushCallbacks() {\n  pending = false;\n  const copies = callbacks.slice(0);\n  callbacks.length = 0;\n  for (let i = 0; i &lt; copies.length; i++) {\n    copies[i]();\n  }\n}\n小结：\n\n把回调函数放入 callbacks 等待执行\n将执行函数放到微任务或者宏任务中\n事件循环到了微任务或者宏任务，执行函数依次执行 callbacks 中的回调\n\nVue的 data 为什么必须是函数？\n组件是用来复用的，且 Vue 组件和Vue实例之间是通过原型链来继承的。如果data是一个对象，那么在组件复用时，多个组件将共享一个data对象，这样一个组件的状态改变会影响到其他组件。\n这显然不是我们想要的结果，因为通常情况下，每个组件实例都应该维护自己的独立状态。将data选项定义为函数，因为函数每次调用返回的都是一个全新的对象，从而避免状态影响。\n此外，这种设计还有助于节省内存。在一些框架中，比如Angular 2或者在某些情况下的React，每个组件实例都是一个独立的对象，这意味着每个组件需要初始化它所需的一切。而Vue通过让data属性为一个函数，避免了这个问题，因为方法、计算属性定义和生命周期钩子只会被创建和存储一次，然后在每个组件实例中运行。\ncomputed 和 watch 使用场景有什么不同，实现原理呢？\ncomputed：\n\ncomputed是值，依赖于其它的状态。比如购物车的总价格，可以根据其它几个价格算得。\ncomputed有缓存特性，只要依赖的状态没有改变，computed的值就会被缓存起来。当依赖发生变化时，才会重新计算。\n\nwatch：\n\nwatch用于监听状态的变化，比方说监听路由，一旦监听的状态发生变化，就执行某个函数。\nwatch有两个参数也是面试常考点，\n\nimmediate：当我们希望在组件初始化时执行一次watch函数，就可以开启immediate选项\ndeep：深度监听，开启此选项当监听的对象的某个属性值发生变化，也会触发watch监听函数\n\n\n\n实现原理：\n\ncomputed和watch都是基于Vue响应式原理，首先通过initWatcher和initComputed来解析watch和computed选项，然后遍历，给每个watch和computed添加Watcher对象。\n不同的是给computed添加的Watcher对象是lazy Watcher，默认不执行，取值的时候才执行。\ncomputed的缓存特性是通过Watcher对象的dirty属性来实现的。\n\n谈一谈对MVVM的理解？Vue实现双向数据绑定原理是什么？\nMVVM（Model-View-ViewModel）是一种软件架构模式，它将应用程序分为三个主要部分：模型（Model）、视图（View）和视图模型（ViewModel）。MVVM 主要用于构建交互式的用户界面，并且在前端开发中得到广泛应用。\n\n模型（Model）： 模型代表应用程序的数据和业务逻辑。它负责管理数据的获取、存储和操作，与服务器进行通信，并处理应用程序的业务逻辑。\n视图（View）： 视图是用户界面的可视部分，负责将数据呈现给用户，并接收用户的输入。视图通常是通过 HTML、CSS 和 JavaScript 来构建的。\n视图模型（ViewModel）： 视图模型是视图的抽象表示，它负责将模型的数据转换为视图可以使用的格式，并处理视图的用户交互。视图模型通过双向数据绑定将视图和模型连接起来，使得视图的状态可以自动更新，从而实现了视图和模型之间的解耦。\n\nVue是双向绑定的，数据更改时，视图自动更改。在表单应用中，当用户输入引起页面变更的时候，v-model的数据也会自动发生更新。在 Vue 中，双向绑定的实现分为两层：数据 → 视图、视图 → 数据：\n\n从数据到视图的绑定，就是Vue实现响应式那一套，利用数据劫持和观察者模式对数据进行监听，当数据变更时，通知视图更新。\n从视图到数据的绑定实现原理比较简单，是通过监听输入框地input事件，将输入框的值赋给绑定的数据对象属性。\n\n双向数据绑定是通过以下几个步骤实现的：\n\n数据劫持（Data Observation）： Vue 会对 data 对象进行递归遍历，将每个属性转换为 getter/setter，并且在适当的时候触发更新。\n模板编译（Template Compilation）： Vue 将模板解析为抽象语法树（AST），然后将 AST 转换为渲染函数。在编译过程中，遇到绑定的数据，会生成对应的 watcher 对象。\nWatcher 机制（Watcher）： 每个组件实例都会创建一个 watcher 实例对象，它会在组件渲染过程中建立依赖关系，并在数据变化时触发更新。\n响应式更新（Reactivity）： 当数据发生变化时，会触发相应属性的 setter，setter 会通知所有依赖该属性的 watcher 对象进行更新，从而更新视图。\n\n什么是虚拟DOM，有什么作用？有了解过diff算法吗？\n所谓虚拟DOM，简单点说就是个JS对象，它是比DOM更轻量级的对UI的描述。在Vue中，就是由VNode节点构成的树形对象。\n虚拟DOM的作用：\n\n跨平台：因为是纯JS对象，所以可以在任意能运行JS的地方运行，比如SSR和混合开发。\n相对还不错的渲染性能：虚拟DOM可以将DOM操作转换为JS对象操作，通过对比新旧虚拟DOM树的差异（也就是diff算法），只更新发生变化的部分，从而减少不必要的DOM操作，提高渲染性能。但是这种性能提升只是相对的，因为Svelte已经证明了不用虚拟Dom性能也可以很好。\n\nVue diff算法相关知识点：\n\n基于 Snabbdom：Vue的diff算法是基于三方库Snabbdom的diff算法基础上优化得来的。\n采用双端比较：Vue的diff算法采用了双端比较的方式，即同时对新旧两个vnode进行比较。这种方式可以最大限度地复用已有的DOM元素，减少不必要的DOM操作，从而提高更新性能。\n使用 key 进行原地复用：当 diff 算法比较两个vnode时，会先按照 key 值进行比较，如果 key 值相同，则认为这两个vnode是同一个节点，可以进行复用。否则，Vue会将旧节点从DOM中删除，重新创建新节点并插入到DOM中。\n静态节点优化：Vue的diff算法对静态节点进行了优化，即对不需要更新的节点进行缓存，减少不必要的比较和更新操作。\n当比较两个节点时，会首先比较它们的节点类型，如果不同，则直接替换。如果类型相同，则会继续比较节点的key、数据和子节点等属性，找出它们之间的差异，从而更新DOM。\n\nVue模板编译原理了解吗？\n模板编译流程：\n模板编译的目标是要把 template 模板转换成渲染函数，主要分成3个步骤，parse → optimize → generate ：\n\nparse(解析模板)：首先会用正则等方式将模板解析为 AST（抽象语法树），这个过程包括词法分析和语法分析两个过程。在这个过程中，模板会被分解成一些列的节点，包括普通元素节点、文本节点、注释节点等，同时也会解析出这些节点的标签名、属性、指令等信息。\noptimize(静态分析)：静态分析是指分析模板中的所有节点，找出其中的静态节点和静态属性，并将其标记出来。所谓静态节点是指节点的内容不会发生变化的节点，例如纯文本节点、含有静态属性的节点等，而静态属性则是指节点上的属性值不会改变的属性，例如 class 和 style 属性。标记静态节点和静态属性可以帮助 Vue 在后续的更新中跳过这些节点的比对和更新过程，从而提高应用的性能。\ngenerate(代码生成)：将 AST 转换为可执行的渲染函数。\n\n什么是自定义指令，怎么实现？\nVue自定义指令可以用来复用代码，封装常用的DOM操作或行为。常见的自定义指令有监听滚动事件、图片懒加载、设置 loading、权限管理等。\n自定义指令可以全局注册或局部注册，注册后可以在模板中使用 v-前缀调用，如 v-mydirective。\n自定义指令的实现需要定义一个对象，其中包含指令名称、生命周期钩子函数和更新函数等属性，具体如下：\n\nbind钩子函数：指令第一次绑定到元素时触发，可以用于初始化一些数据或添加事件监听器等操作。\ninserted钩子函数：指令所在元素插入到父节点后触发，常用于添加一些 UI 元素或获取焦点等操作。\nupdate钩子函数：指令所在元素更新时触发，可以获取新旧值并进行比较后更新UI。\ncomponentUpdated钩子函数：指令所在元素及其子节点全部更新后触发，常用于需要操作DOM的指令，如监听滚动事件。\nunbind钩子函数：指令与元素解绑时触发，可以清除绑定的事件监听器等操作。\n\n举个例子：\nVue.directive(&#039;focus&#039;, {\n  inserted: function (el) {\n    el.focus()\n  }\n})\n该指令实现元素自动获取焦点功能，在模板中使用该指令：\n&lt;input v-focus&gt;"},"front-end/interview/webpack":{"title":"webpack","links":[],"tags":[],"content":"Webpack 常见面试题\n1. 什么是 loader？有哪些常见的 loader？怎么配置 loader？\nWebpack 作为一个 js 打包工具，默认只认识 js，对于非 JS 的文件，比方说样式，图片，文件，json 等等，就需要一些工具来帮忙翻译。而 loader，就是作为翻译官的角色，可以解析非原生 JS 的代码或文件。\n常见的 Webpack loader 有：\n\nbabel-loader：处理 ES 语法的 loader。\ncss-loader：处理 CSS 的 loader。\nstyle-loader：将 CSS 插入到 HTML 页面中的&lt;style&gt;标签的 loader。\nless-loader：处理 less 的 loader。\nfile-loader：处理文件的 loader。\nurl-loader：处理文件的 loader，类似于 file-loader，但可以将小文件转换为 Data URL。\nimage-webpack-loader：处理图片的 loader。\neslint-loader：运行 ESLint 检查的 loader。\n\nloader 配置步骤：\n\nnpm 下载对应的 loader。\n在 module 选项里配置 rules，每个 rule 是个对象，用来表示对一个文件的处理规则，test 表示要处理的文件，使用通配符匹配文件，use 里可以通过配置多个 loader 来以流水线方式进行处理。要注意 loader 的执行顺序为：从下到上，从右到左。\n\n3. 什么是 plugin？有哪些常见的 plugin？怎么配置 plugin？\nPlugin，即插件。Webpack 插件是对 Webpack 功能的扩展和增强，可以帮助我们在打包过程中自动执行一些额外的操作，例如生成 HTML 文件、压缩代码、提取 CSS 等。\n常见的 plugin 有：\n\nHtmlWebpackPlugin：根据模板生成 HTML 文件，可以自动引入打包后的资源。\nUglifyJsPlugin：压缩 JavaScript 代码。\nCleanWebpackPlugin：在每次构建前清理输出目录。\nMiniCssExtractPlugin：将 CSS 代码提取到单独的文件中。\nDefinePlugin：定义全局常量，可以在代码中直接使用。\nCopyWebpackPlugin：将文件复制到输出目录。\nProvidePlugin：自动加载模块，使其在所有模块中可用。\n\nPlugin 配置步骤：\n\nnpm 下载要用的 plugin。\n在 plugins 选项里配置 plugin，每个 plugin 是一个类，new 这个类，然后可以根据文档和需求配置 option 即可。\n\n3. 什么是文件指纹？\nWebpack 的文件指纹是指在打包过程中为每个文件生成唯一的标识符，以便于版本管理和缓存控制。比方说 Vue 项目打包后生成的 css 文件和 js 文件，一般都会有奇奇怪怪的文件名，那就是文件指纹。\n文件指纹的实现原理是根据文件内容生成哈希值，一般是利用 Webpack 内置的 HashedModuleIdsPlugin 和 MiniCssExtractPlugin 来实现。\n4. 什么是 Source Map？怎么配置？\nSource Map 概念：\n在开发过程中，我们经常需要对编译后的代码进行调试，但是编译后的代码往往很难阅读和理解。Source Map（源映射）是一种文件格式，它可以将编译后的代码映射回源代码。通过使用 Source Map，我们可以在浏览器中直接调试源代码，而不需要在编译后的代码中进行调试，从而更容易地排查问题。\n比如 Vue 项目，跑在浏览器里的代码其实并不是你写的.Vue 文件，而是经过编译后的。可是平时调试的时候，我们写的代码位置却能和浏览器控制台对应上。\n而帮我们做这个事情的，就是 Source Map。\nSource Map 原理：Source Map 包含了源代码和编译后的代码之间的映射关系，通常是一个 JSON 文件，它包含了每行代码的映射信息，例如源文件路径、行号、列号等。当浏览器执行编译后的代码时，它会通过 Source Map 将执行位置映射回源代码的位置，从而使得开发者可以直接在源代码中进行调试。\n怎么配置 Source Map：在 Webpack 中，可以使用 devtool 配置选项来生成 Source Map。常用的选项有：\n\neval：生成每个模块的 eval 代码，并且模块执行完后，eval 代码被执行。这种方式速度很快，但是不适合生产环境。\nsource-map：生成独立的 source-map 文件，适合生产环境，但是会增加构建时间和文件大小。\ncheap-source-map：生成 source-map，但是不包含列信息，适合大型项目。\ncheap-module-source-map：生成 source-map，同时会将 loader 的 sourcemap 也加入进来。\n\n5. 了解过 Tree-shaking 吗？\n\n概念：Tree-shaking 又叫摇树优化，是通过静态分析消除 JS 模块中未使用的代码，减小项目体积。\n原理：Tree-shaking 依赖于 ES6 的模块机制，因为 ES6 模块是静态的，编译时就能确定模块的依赖关系。对于非 ES6 模块的代码或者动态引入的代码，无法被消除掉。\n配置：Tree-Shaking 需要配置 optimization 选项中的 usedExports 为 true，同时在 babel 配置中使用 babel-preset-env，开启 modules 选项为 false，这样可以保证 ES6 模块在编译时不会被转换为 CommonJS 模块。\n\n6. 什么是 HMR，原理是什么？\nHMR：即热更新，简单说就是在我们写代码保存后不需要手动刷新浏览器，就能直接看到更新后的结果，而且只改变我们更改的那部分内容。\nHMR 的原理：将需要更新的模块通过 websocket 与 Webpack Dev Server 建立连接，当模块发生变化时，Webpack Dev Server 会将新的模块代码推送给浏览器端，浏览器端通过将新代码插入到运行时环境中，来实现实时更新。\n怎么配置 HMR：\n\n在配置文件中添加 webpack.HotModuleReplacementPlugin 插件。\n在 webpack-dev-server 的配置中添加 hot: true，启用热替换。\n在 entry 中添加 hot module replacement runtime。\n在模块代码中使用 module.hot.accept 方法，以接受新模块的更新。\n\nHMR 只适用于开发环境，不能用于生产环境，因为 HMR 需要额外的代码和性能消耗。在生产环境中，应该禁用 HMR，使用正常的文件更新机制。\n7. 有没有写过自定义的 loader？\nloader 本质是一个函数，接受源代码作为参数，返回处理后的结果，举个最简单的例子：\nmodule.exports = function (source) {\n  return source.toLowerCase(); // 将源代码所有字母转成小写\n};\n在开发自定义 loader 时可以借助 loader-utils 这个工具库，可以通过调用 loader-utils 中提供的 API 来获取 loader 选项、文件路径、查询字符串等信息。\nloader-utils 提供的常用 API 包括：\n\ngetOptions(loaderContext)：获取 Loader 的选项，返回一个包含选项信息的对象。\nparseQuery(queryString)：解析查询字符串，返回一个包含解析结果的对象。\nstringifyRequest(loaderContext, request)：将请求转换为字符串，返回一个包含转换结果的字符串。\ngetRemainingRequest(loaderContext)：获取请求中的剩余部分，返回一个包含剩余部分的字符串。\ngetCurrentRequest(loaderContext)：获取当前请求的完整部分，返回一个包含当前请求的字符串。\n\n8. 有没有写过自定义的 plugin？\n自定义 plugin 本质是一个类，这个类实现了 apply 方法，在 apply 方法中，通过 compiler 对象注册一个或多个 Webpack 生命周期事件的监听器，然后在监听器函数中，实现自定义的逻辑。\n举个简单的例子：\nclass MyPlugin {\n  apply(compiler) {\n    compiler.hooks.done.tap(&quot;MyPlugin&quot;, (stats) =&gt; {\n      console.log(&quot;Bundle is now finished!\\n&quot;);\n      console.log(stats.toString());\n    });\n  }\n}\n \nmodule.exports = MyPlugin;\n使用这个 plugin：\nconst MyPlugin = require(&quot;./my-plugin&quot;);\n \nmodule.exports = {\n  // ...\n  plugins: [new MyPlugin()],\n};\n当然，一般自定义的 plugin 不会这么简单，还需要使用一些进阶技巧，比如：\n\n合理使用 Webpack 的生命周期事件：Webpack 提供了许多生命周期事件，可以通过这些事件来监听 Webpack 构建过程中的各个阶段。在编写自定义插件时，需要选择合适的生命周期事件来监听，并在其中执行自定义逻辑。例如，如果需要在 Webpack 构建完成后输出一份打包报告，可以使用 done 事件来实现。\n使用 Webpack 提供的钩子函数：Webpack 提供了一些钩子函数，可以方便地实现一些常见的功能，如资源解析、模块加载等。在编写自定义插件时，可以通过调用这些钩子函数来实现自定义逻辑。例如，如果需要在 Webpack 解析模块时，修改模块的路径或内容，可以使用 normalModuleFactory 钩子函数来实现。\n使用 Webpack 提供的工具函数和 API：Webpack 提供了许多工具函数和 API，可以帮助开发者更加方便地操作 Webpack 构建过程中的各种资源。在编写自定义插件时，可以使用这些工具函数和 API 来实现自定义逻辑。例如，如果需要将某些资源复制到输出目录下，可以使用 copy-webpack-plugin 插件提供的 copyWebpackPlugin 函数来实现。\n使用 Webpack 提供的配置项：Webpack 提供了许多配置项，可以用来控制 Webpack 的构建行为。在编写自定义插件时，可以通过配置这些选项来实现一些特定的构建需求。例如，如果需要在 Webpack 打包时生成 SourceMap 文件，可以使用 devtool 配置项来实现。\n\n9. Webpack 打包流程是怎么样的？\n\n解析配置文件：Webpack 会读取项目根目录下的 Webpack 配置文件(webpack.config.js)，解析其中的配置项，并根据配置项构建打包流程(environment 钩子函数)。\n解析模块依赖：Webpack 会从 entry 配置中指定的入口文件开始(entryOption钩子)，递归解析模块之间的依赖关系，并构建模块依赖图谱 (compilation 钩子函数) 。\n加载模块：Webpack 会根据模块依赖图谱，加载所有需要打包的模块，通过配置的 loader 将文件转换成 Webpack 可识别的模块 (buildModule 钩子函数)。\n执行插件：Webpack 会在打包流程中执行一系列插件，插件可以用于完成各种任务，例如生成 HTML 文件、压缩代码等等。\n输出打包结果：Webpack 会将打包后的代码和资源输出到指定的输出目录，可以使用配置项进行相关设置。\n监听变化：在开发模式下，Webpack 会在代码修改后重新构建打包流程，并将修改后的代码热更新到浏览器中。\n\n10. Webpack 事件机制了解吗？\n\nWebpack 常见的事件有：\n\nbefore-run: 在 Webpack 开始执行构建之前触发，可以用于清理上一次构建的临时文件或状态。\nrun: 在 Webpack 开始执行构建时触发。\nbefore-compile: 在 Webpack 开始编译代码之前触发，可以用于添加一些额外的编译配置或预处理代码。\ncompile: 在 Webpack 开始编译代码时触发，可以用于监听编译过程或处理编译错误。\nthis-compilation: 在创建新的 Compilation 对象时触发，Compilation 对象代表当前编译过程中的所有状态和信息。\ncompilation: 在 Webpack 编译代码期间触发，可以用于监听编译过程或处理编译错误。\nemit: 在 Webpack 生成输出文件之前触发，可以用于修改输出文件或生成一些附加文件。\nafter-emit: 在 Webpack 生成输出文件后触发，可以用于清理中间文件或执行一些其他操作。\ndone: 在 Webpack 完成构建时触发，可以用于生成构建报告或通知开发者构建结果。\n\n\nWebpack 的事件机制是基于 Tapable 实现的，Tapable 是 Webpack 事件机制的核心类，它封装了事件的订阅和发布机制。在 Webpack 中，Compiler 对象和 Compilation 对象都是 Tapable 类的实例对象。\n\n11. 有了解过 Webpack5 吗，相比于 Webpack4 有哪些提升?\nWebpack5 相对于 Webpack4 有以下提升：\n\n更快的构建速度：Webpack5 在构建速度方面进行了大量优化，尤其是在开发模式下，构建速度有了明显提升。\nTree Shaking 优化：Webpack5 进一步改进了 Tree Shaking 算法，可以更准确地判断哪些代码是无用的，从而更好地优化构建输出的文件大小。\n内置的持久化缓存：Webpack5 在持久化缓存方面进行了优化，可以缓存每个模块的编译结果，从而加速后续的构建。\n支持 WebAssembly：Webpack5 增加了对 WebAssembly 的原生支持。\n模块联邦（Module Federation）：Webpack5 引入了模块联邦的概念，可以实现多个独立的 Webpack 构建之间的模块共享和远程加载，为微前端架构提供了更好的支持。\n"},"front-end/javascript/advanced/promise/memoization":{"title":"memoization","links":[],"tags":[],"content":"高级 Promise 模式 - Promise 缓存\n在本文中，我们将介绍常见的缓存实现在并发条件下存在的问题。然后我们将介绍如何修复它，并且在此过程中简化代码。\n我们将通过介绍基于 Singleton Promise 模式的 Promise Memoization 模式来做到这一点。\n一个例子：缓存异步请求结果\n下面是一个简单的 API 客户端：\nconst getUserById = async (userId: string): Promise&lt;User&gt; =&gt; {\n  const user = await request.get(`https://users-service/${userId}`);\n  return user;\n};\n非常简单。\n但是，如果要关注性能，该怎么办？users-service 解析用户详细信息可能很慢，也许我们经常使用相同的用户 ID 集来调用此方法。\n我们可能要添加缓存，该怎么做？\n简单的解决方案\nconst usersCache = new Map&lt;string, User&gt;();\n \nconst getUserById = async (userId: string): Promise&lt;User&gt; =&gt; {\n  if (!usersCache.has(userId)) {\n    const user = await request.get(`https://users-service/${userId}`);\n    usersCache.set(userId, user);\n  }\n \n  return usersCache.get(userId);\n};\n这非常简单：在从 users-service 中解析了用户详细信息之后将结果填充到内存中的缓存中。\n并发场景\n上面的代码，它将在以下情况下进行重复的网络调用：\nawait Promise.all([\n  getUserById(&#039;user1&#039;),\n  getUserById(&#039;user1&#039;)\n]);\n问题在于直到第一个调用解决后，我们才分配缓存。但是，等等，如何在获得结果之前填充缓存？\n单例 Promise\n如果我们缓存结果的 Promise 而不是结果本身，会怎样？代码如下：\nconst userPromisesCache = new Map&lt;string, Promise&lt;User&gt;&gt;();\n \nconst getUserById = (userId: string): Promise&lt;User&gt; =&gt; {\n  if (!userPromisesCache.has(userId)) {\n    const userPromise = request.get(`https://users-service/v1/${userId}`);\n    userPromisesCache.set(userId, userPromise);\n  }\n \n  return userPromisesCache.get(userId)!;\n};\n非常相似，但是我们没有 await 发出网络请求，而是将其 Promise 放入缓存中，然后将其返回给调用方。\n注意，我们不需要使用 async 声明我们的方法  ，因为它不再调用 await 。我们的方法签名虽然没有改变仍然返回一个 promise的结果 ，但是我们是同步进行的。\n这样可以解决并发条件，无论时间如何，当我们对进行多次调用时，只会触发一个网络请求 getUserById(&#039;user1&#039;)。这是因为所有后续调用者都收到与第一个相同的 Promise 单例。\nPromise 缓存\n从另一个角度看，我们的最终的缓存实现实际上只是在记忆 getUserById！给定我们已经看到的输入后，我们只返回存储的结果（恰好是一个Promise）。\n因此，memoizing  异步方法可以使我们在没有竞争条件的情况下进行缓存。\n借助 lodash，我们可以将最后一个解决方案简化为：\nimport _ from &#039;lodash&#039;;\n \nconst getUserById = _.memoize(async (userId: string): Promise&lt;User&gt; =&gt; {\n  const user = await request.get(`https://users-service/${userId}`);\n  return user;\n});\n我们采用了原始的无缓存实现，并放入了 _.memoize 包装器，十分简洁与非侵入性。\n错误处理\n对于 API 客户端，你应考虑操作可能失败的可能性。如果我们的内存实现已缓存了 rejected 的 Promise ，则所有将来的调用都将以同样的失败 Promise 被拒绝！\n幸运的是，memoizee(www.npmjs.com/package/memoizee) 库支持此功能。我们的最后一个示例变为：\nimport memoize from &#039;memoizee&#039;;\n \nconst getUserById = memoize(async (userId: string): Promise&lt;User&gt; =&gt; {\n  const user = await request.get(`https://users-service/${userId}`);\n  return user;\n}, { promise: true});"},"front-end/javascript/advanced/promise/singleton":{"title":"singleton","links":[],"tags":[],"content":"高级异步模式 - Promise 单例\n\nwww.jonmellman.com/posts/singleton-promises\n\n单例 Promise\n在本文中，我们将研究如何使用我所说的 Singleton Promise 模式来改进并发的 JavaScript 代码。\n首先我们会看一个常见的延迟初始化用例。然后我们将展示一个简单的解决方案，如何包含竞争条件错误。最后，我们将使用单例 Promise 来解决竞争条件并正确解决问题。\n一个例子：一次性懒惰初始化\n“一次性懒惰初始化” 是一个很麻烦的操作，但实际上使用场景很普遍。例如，它通常适用于数据库客户端（Sequelize，Mongoose，TypeORM 等），或基于这些客户端的封装。\n用简单的说法解释：懒惰的一次性初始化意味着数据库客户端在执行任何查询之前会根据需要初始化自身，并且只会执行一次。\n初始化\n在这种情况下，初始化意味着使用数据库服务器进行身份验证，从连接池中获取连接或执行查询之前必须完成的所有操作。\n懒惰\n请注意，支持延懒惰始化是符合人体工程学的。这意味着客户端将在执行第一个查询的时候自动连接。调用者不需要显式连接数据库客户端，因为客户端封装了连接状态。\n一次性\n一次性意味着初始化仅发生一次。这很重要，因为例如过多的初始化可能会增加延迟或耗尽连接池。\n简单的解决方案\n我们了解了需求以后，先实现一个简单的数据库客户端。\n首先公开一个 getRecord() 方法，该方法在内部调用 .connect() 执行初始化的私有方法：\nclass DbClient {\n  private isConnected: boolean;\n \n  constructor() {\n    this.isConnected = false;\n  }\n \n  private async connect() {\n    if (this.isConnected) {\n      return;\n    }\n \n    await connectToDatabase(); // stub\n    this.isConnected = true;\n  }\n \n  public async getRecord(recordId: string) {\n    await this.connect();\n    return getRecordFromDatabase(recordId); // stub\n  }\n}\n\n实际实现 connectToDatabase() 和 getRecordFromDatabase() 在这里并不重要。\n\n乍一看，这看起来还不错。如果客户端还没连接，它将自动连接。这意味着使用者可以简单地执行查询而无需关心连接状态：\nconst db = new DbClient()\nconst record = await db.getRecord(&#039;record1&#039;);\n所以，我们实现了一次懒惰的初始化，对吗？\n没那么快。再看一下这个 .getRecord() 方法，看看是否可以发现并发竞争条件。\n条件竞争\n如果我们有一个并发查询的场景：\nconst db = new DbClient();\nconst [record1, record2] = await Promise.all([\n  db.getRecord(&#039;record1&#039;),\n  db.getRecord(&#039;record2&#039;),\n]);\n这可能会导致我们的数据库客户端连接两次！我们违反了“一次性”要求！\n问题是这样的：因为我们的数据库客户端的 .connect() 方法是异步的，所以在 .getRecord() 执行第二个调用时不太可能已经完成。this.isConnected 依然是 false。\n\ndb.getRecord(&#039;record1&#039;)和db.getRecord(&#039;record2&#039;)，实际上是同步执行的，而修改状态 isConnected是在 connectToDatabase 方法后，所以 connectToDatabase 被调用两次是必然的 。\n\n这似乎看起来没什么大不了的。但是，这个问题曾经真实发生在我负责的一个系统上，它造成了资源泄漏，最终导致服务器瘫痪～\n单例 Promise\n就像上面说的，问题很细节，但是很重要！\n我们可以引入一个额外的 isConnectionInProgress 布尔值，用于记录第一个 .connect() 调用的 Promise 的引用。然后，我们可以保证在执行任何将来的查询之前，该 Promise 已得到解决：\nclass DbClient {\n  private connectionPromise: Promise&lt;void&gt; | null;\n \n  constructor() {\n    this.connectionPromise = null;\n  }\n \n  private async connect() {\n    if (!this.connectionPromise) {\n      this.connectionPromise = connectToDatabase(); // stub\n    }\n \n    return this.connectionPromise;\n  }\n \n  public async getRecord(recordId: string) {\n    await this.connect();\n    return getRecordFromDatabase(recordId); // stub\n  }\n}\n由于变量 this.connectionPromise 是同步分配的，因此 .getRecord() 可以确保重复调用始终重用相同的 Promise 。这意味着第二个 .getRecord() 调用将等到第一个调用 .connect()解决后再继续。\n我们已经修复了该错误！\n我们可以称 connectionPromise 为一个单例 Promise，因为它的实例永远不会超过一个。通过这样的限制，我们可以防止并发初始化。\n一个实验\n如果您不熟悉 Promise ，我们的最终 DbClient 实现可能对你而言并不直观。我们如何在 connectionPromise 不执行 await 的情况下使用它，以及如何在它已经被 resolved 的情况下，调用 await this.connectionPromise ？\n之所以可行，是因为resolved的 Promise仍可以被 await 。（这实际上是 await Promise.resolve() 工作方式，因为 Promise.resolve() 返回了resolved的 Promise。）\n你可以在浏览器的JS控制台中运行该实验：\nconst sleep = (ms) =&gt; new Promise((resolve) =&gt; setTimeout(resolve, ms));\nconst myPromise = sleep(5000); // Note we don&#039;t `await` yet.\n \nconsole.time(&#039;first await&#039;);\nawait myPromise;\nconsole.timeEnd(&#039;first await&#039;);\n \nconsole.time(&#039;second await&#039;);\nawait myPromise;\nconsole.timeEnd(&#039;second await&#039;);\n它输出：\nfirst await: 5002ms - timer ended\nsecond await: 0ms - timer ended\n\n该实验表明：\n\n我们可以多次等待同样的 Promise 。\n我们可以等待已经解决的 Promise ，并且将立即解决。\n"},"front-end/javascript/reading/structuredClone":{"title":"structuredClone","links":[],"tags":[],"content":"用现代方式深度拷贝 JavaScript 中的对象\nJavaScript 中现在有一种原生方法可以对对象进行深度复制。\n没错，这个 structuredClone 函数就是内置于 JavaScript 运行时中的：\nconst calendarEvent = {\n   title: &quot;Builder.io Conf&quot;,\n   date: new Date(123),\n   attendees: [&quot;Steve&quot;]\n }\n \n // 😍\n const copied = structuredClone(calendarEvent)\n你是否注意到，在上面的示例中，我们不仅复制了对象，还复制了嵌套数组，甚至复制了Date对象？\n所有操作都完全符合预期：\n copied.attendees // [&quot;Steve&quot;]\n copied.date // Date: Wed Dec 31 1969 16:00:00\n cocalendarEvent.attendees === copied.attendees // false\n没错，structuredClone 不仅能实现上述功能，还能实现其他功能：\n\n克隆无限嵌套的对象和数组\n克隆循环引用\n克隆多种 JavaScript 类型，如 Date、Set、Map、Error、RegExp、ArrayBuffer、Blob、File、ImageData 等。\n传输任何可传输对象\n\n因此，举例来说，这种疯狂的做法甚至可以达到预期的效果：,\n const kitchenSink = {\n   set: new Set([1, 3, 3]),\n   map: new Map([[1, 2]]),\n   regex: /foo/,\n   deep: { array: [ new File(someBlobData, &#039;file.txt&#039;) ] },\n   error: new Error(&#039;Hello!&#039;)\n }\n kitchenSink.circular = kitchenSink\n \n // ✅ All good, fully and deeply copied!\n const clonedSink = structuredClone(kitchenSink)\n为什么不只是对象传播？\n需要注意的是，我们说的是深度复制。如果你只需要进行浅拷贝，也就是不拷贝嵌套对象或数组的拷贝，那么我们可以只进行对象扩散：\nconst simpleEvent = {\n   title: &quot;Builder.io Conf&quot;,\n }\n // ✅ no problem, there are no nested objects or arrays\n const shallowCopy = {...calendarEvent}\n如果你愿意，也可以选择这些：\n const shallowCopy = Object.assign({}, simpleEvent)\n const shallowCopy = Object.create(simpleEvent)\n但是，一旦出现嵌套项，我们就会遇到麻烦：\n const calendarEvent = {\n   title: &quot;Builder.io Conf&quot;,\n   date: new Date(123),\n   attendees: [&quot;Steve&quot;]\n }\n\n const shallowCopy = {...calendarEvent}\n\n // 🚩 oops - we just added &quot;Bob&quot; to both the copy *and* the original event\n shallowCopy.attendees.push(&quot;Bob&quot;)\n\n // 🚩 oops - we just updated the date for the copy *and* original event\n shallowCopy.date.setTime(456)\n\n正如你所看到的，我们并没有完整复制这个对象。\n嵌套的日期和数组仍然是两个对象之间的共享引用，如果我们要编辑这些引用，以为我们只是在更新复制的日历事件对象，这可能会给我们带来很大的麻烦。\n为什么不使用 JSON.parse (JSON.stringify (x)) 呢？\n对了，就是这一招。这其实是一个很好的方法，而且性能出奇的好，但也有一些不足之处，structuredClone 可以解决这些问题。\n举个例子：\n const calendarEvent = {\n   title: &quot;Builder.io Conf&quot;,\n   date: new Date(123),\n   attendees: [&quot;Steve&quot;]\n }\n \n // 🚩 JSON.stringify converted the `date` to a string\n const problematicCopy = JSON.parse(JSON.stringify(calendarEvent))\n如果我们打印 problematicCopy，就会得到：\n{\n   title: &quot;Builder.io Conf&quot;,\n   date: &quot;1970-01-01T00:00:00.123Z&quot;\n   attendees: [&quot;Steve&quot;]\n }\n这不是我们想要的！date 应该是一个日期对象，而不是字符串。\n出现这种情况是因为 JSON.stringify 只能处理基本对象、数组和基础类型。其他类型的处理方式很难预测。例如，日期会被转换为字符串。但集合会被简单地转换为 {}。\nJSON.stringify 甚至会完全忽略某些东西，比如 undefined 或 Function。\n例如，如果我们用这个方法复制 kitchenSink 的示例：\nconst kitchenSink = {\n   set: new Set([1, 3, 3]),\n   map: new Map([[1, 2]]),\n   regex: /foo/,\n   deep: { array: [ new File(someBlobData, &#039;file.txt&#039;) ] },\n   error: new Error(&#039;Hello!&#039;)\n }\n \n const veryProblematicCopy = JSON.parse(JSON.stringify(kitchenSink))\n我们会得到:\n {\n   &quot;set&quot;: {},\n   &quot;map&quot;: {},\n   &quot;regex&quot;: {},\n   &quot;deep&quot;: {\n     &quot;array&quot;: [\n       {}\n     ]\n   },\n   &quot;error&quot;: {},\n }\nEw！\n哦，对了，我们还删除原来为此设置的循环引用，因为 JSON.stringify 遇到循环引用时会直接抛出错误。\n因此，如果我们的要求符合该方法的功能，那么该方法就会非常棒，但是我们可以使用 structuredClone（也就是上面我们没有做到的所有功能）来实现很多该方法无法实现的功能。\n为什么不使用 _.cloneDeep？\n迄今为止，Lodash 的 cloneDeep 函数一直是解决这一问题的常用方法。\n而事实上，它也确实能达到预期的效果：\n import cloneDeep from &#039;lodash/cloneDeep&#039;\n \n const calendarEvent = {\n   title: &quot;Builder.io Conf&quot;,\n   date: new Date(123),\n   attendees: [&quot;Steve&quot;]\n }\n \n const clonedEvent = cloneDeep(calendarEvent)\n但有一点需要注意。我的集成开发环境中的 “Import Cost” 扩展可以打印我导入任何东西的 kb 成本，根据该扩展，这个函数的最小化成本为 17.4kb（压缩后为 5.3kb）。\n这还只是假设你只导入了这个函数。如果你采用了更常见的导入方式，而没有意识到 “tree shaking” 并不总能如你所愿，那么你可能会因为这一个函数而意外导入多达 25kb 的数据 😱 。\n虽然这对任何人来说都不会是世界末日，但在我们的情况下根本没有必要，因为浏览器已经内置了 structuredClone。\nstructuredClone 不能克隆什么\n函数不能克隆\n它们会引发 DataCloneError 异常：\n // 🚩 Error!\n structuredClone({ fn: () =&gt; { } })\nDOM 节点\n也会引发 DataCloneError 异常：\n // 🚩 Error!\n structuredClone({ el: document.body })\ndescriptor、setter &amp; getter\n以及类似元数据的功能不会被克隆。\n例如，对于 getter，结果值会被克隆，但 getter 函数本身（或任何其他属性元数据）不会被克隆：\n structuredClone({ get foo() { return &#039;bar&#039; } })\n // Becomes: { foo: &#039;bar&#039; }\n对象原型\n原型链不会被移动或复制。因此，如果克隆 MyClass 的实例，克隆的对象将不再是该类的实例（但该类的所有有效属性都将被克隆）\n class MyClass {\n   foo = &#039;bar&#039;\n   myMethod() { /* ... */ }\n }\n const myClass = new MyClass()\n \n const cloned = structuredClone(myClass)\n // Becomes: { foo: &#039;bar&#039; }\n \n cloned instanceof myClass // false\n受支持类型的完整列表\n更简单地说，不在下面列表中的任何内容都不能克隆：\nJS 内置类型\n数组、ArrayBuffer、布尔、DataView、日期、错误类型（下面特别列出的类型）、Map、对象（但仅限普通对象，例如来自对象字面的对象）、原始类型（符号除外）（又称数字、字符串、null、未定义、布尔、BigInt）、RegExp、Set、TypedArray\n错误类型\nError, EvalError, RangeError, ReferenceError , SyntaxError, TypeError, URIError\n网络 / API 类型\nAudioData, Blob, CryptoKey, DOMException, DOMMatrix, DOMMatrixReadOnly, DOMPoint, DomQuad, DomRect, File, FileList, FileSystemDirectoryHandle, FileSystemFileHandle, FileSystemHandle, ImageBitmap, ImageData, RTCCertificate, VideoFrame\n浏览器和运行时支持\n最棒的是，structuredClone 支持所有主流浏览器，甚至 Node.js 和 Deno。"},"front-end/javascript/red-book/animation-and-canvas":{"title":"animation&canvas","links":[],"tags":[],"content":"requestAnimationFrame\nFirefox 4 率先在浏览器中为 JavaScript 动画增加了一个名为 mozRequestAnimationFrame()方法的 API。\n\n\n定时动画的问题在于无法准确知晓循环之间的延时。\n\n\n如果同时运行多个动画，可能需要加以限流；\n\n\n无论 setInterval()还是 setTimeout()都是不能保证时间精度的，因为他们的第二个参数只能保证何时会把代码添加到浏览器的任务队列，不能保证添加到队列就会立即运行  。\n\n\nMozilla 的 Robert O’Callahan 一直在思考这个问题，并提出了一个独特的方案。他指出，浏览器知道 CSS 过渡和动画应该什么时候开始，并据此计算出正确的时间间隔，到时间就去刷新用户界面。\n他给出的方案是创造一个名为 mozRequestAnimationFrame() 的新方法，用以通知浏览器某些 JavaScript 代码要执行动画了；\nrequestAnimationFrame()方法接收一个参数，此参数是一个要在重绘屏幕前调用的函数。这个函数就是修改 DOM 样式以反映下一次重绘有什么变化的地方。\n与 setTimeout()类似， requestAnimationFrame()也返回一个请求 ID，可以用于通过另一个方法 cancelAnimationFrame()来取消重绘任务。\nrequestAnimationFrame 节流\n支持这个方法的浏览器实际上会暴露出作为钩子的回调队列。所谓钩子（ hook），就是浏览器在执行下一次重绘之前的一个点。\n通过 requestAnimationFrame()递归地向队列中加入回调函数，可以保证每次重绘最多只调用一次回调函数。这是一个非常好的节流工具。\n配合计时器，可以限制实际的操作执行间隔，而 requestAnimationFrame 控制在浏览器的哪个渲染周期中执行。\n画布 Canvas\n要在画布上绘制图形，首先要取得绘图上下文。\n2D 上下文的坐标原点(0, 0)在 &lt;canvas&gt; 元素的左上角；2D 上下文有两个基本绘制操作：填充和描边。"},"front-end/javascript/red-book/async-await":{"title":"async-await","links":[],"tags":[],"content":"reject 的 Promise 的错误不会被异步函数捕获：\nasync function foo() {\n    console.log(1);\n    Promise.reject(3);\n}\n// 给返回的期约添加一个拒绝处理程序\nfoo().catch(console.log);\nconsole.log(2);\n// 1\n// 2\n// Uncaught (in promise): 3\n而对 reject 的 Promise 使用 await 则会释放（ unwrap）错误值（将 Promise 返回）：\nasync function foo() {\n    console.log(1);\n    await Promise.reject(3);\n    console.log(4); // 这行代码不会执行\n}\n// 给返回的期约添加一个拒绝处理程序\nfoo().catch(console.log);\nconsole.log(2);\n// 1\n// 2\n// 3\nawait 的限制\nawait 关键字必须在异步函数中使用，不能在顶级上下文如 &lt;script&gt; 标签或模块中使用；不过可以使用立即调用异步函数：\n// 立即调用的异步函数表达式\n(async function() {\n    console.log(await Promise.resolve(3));\n})();\n// 3\n停止和恢复\nJavaScript 运行时在碰到 await 关键字时，会记录在哪里暂停执行。等到 await 右边的值可用了， 运行时会向消息队列中推送一个任务，这个任务会恢复异步函数的执行；\nasync function foo() {\n    console.log(await Promise.resolve(&#039;foo&#039;));\n}\nasync function bar() {\n    console.log(await &#039;bar&#039;);\n}\nasync function baz() {\n    console.log(&#039;baz&#039;);\n}\nfoo();\nbar();\nbaz();\n// baz\n// foo\n// bar\n每次执行到 await 会将其后的 Promise 或立即可用值的包装 Promise resolve 然后向队列中添加一个任务，并在主线程执行完毕后，从队列（先进先出）中取出任务进行处理；\n实现 sleep()\nasync function sleep(delay) {\n    return new Promise((resolve) =&gt; setTimeout(resolve, delay));\n}\nasync function foo() {\n    const t0 = Date.now();\n    await sleep(1500); // 暂停约 1500 毫秒\n    console.log(Date.now() - t0);\n}\nfoo();\n// 1502\n平行执行\nasync function randomDelay(id) {\n  // 延迟 0~1000 毫秒\n  const delay = Math.random() * 1000;\n  console.log(`${id} ready`)\n  return new Promise((resolve) =&gt; {setTimeout(() =&gt; {\n    console.log(`${id} finished`);\n    resolve();\n  }, delay);\n  console.log(`${id} runing`)\n});\n}\nasync function foo() {\n  const t0 = Date.now();\n  await randomDelay(0);\n  console.log(&quot;0 over&quot;)\n  await randomDelay(1);\n  console.log(&quot;1 over&quot;)\n  await randomDelay(2);\n  console.log(&quot;2 over&quot;)\n  await randomDelay(3);\n  console.log(&quot;3 over&quot;)\n  await randomDelay(4);\n  console.log(&quot;4 over&quot;)\n  console.log(`${Date.now() - t0}ms elapsed`);\n}\nfoo();\nconsole.log(&quot;foo over&quot;)\n这些 Promise 间没有依赖，异步函数也会依次暂停，等待每个超时完成。这样可以保证执行顺序，但总执行时间会变长；\n可以先一次性初始化所有期约，然后再分别等待它们的结果：\nasync function foo() {\n  const t0 = Date.now();\n  const p0 = randomDelay(0);\n  const p1 = randomDelay(1);\n  const p2 = randomDelay(2);\n  const p3 = randomDelay(3);\n  const p4 = randomDelay(4);\n  console.log(&quot;---- init over ----&quot;)\n  await p0;\n  console.log(&quot;0 over&quot;)\n  await p1;\n  console.log(&quot;1 over&quot;)\n  await p2;\n  console.log(&quot;2 over&quot;)\n  await p3;\n  console.log(&quot;3 over&quot;)\n  await p4;\n  console.log(&quot;4 over&quot;)\n  setTimeout(console.log, 0, `---- ${Date.now() - t0}ms elapsed ----`);\n}\n串行执行\nasync function addTwo(x) {return x + 2;}\nasync function addThree(x) {return x + 3;}\nasync function addFive(x) {return x + 5;}\n \nasync function addTen(x) {\n    for (const fn of [addTwo, addThree, addFive]) {\n        x = await fn(x);\n    }\n    return x;\n}\naddTen(9).then(console.log); // 19\n栈追踪与内存管理\nJavaScript 引擎会在创建 Promise 时尽可能保留完整的调用栈，在抛出错误时，调用栈可以由运行时的错误处理逻辑获取，因而就会出现在栈追踪信息中；\n使用异步函数，会将已经返回的函数排除在错误信息中，从而可减少一些计算和存储成本；\nJavaScript 运行时可以简单地在嵌套函数中存储指向包含函数的指针，就跟对待同步函数调用栈一样。这个指针实际上存储在内存中，可用于在出错时生成栈追踪信息。"},"front-end/javascript/red-book/bom":{"title":"bom","links":[],"tags":[],"content":"window 对象\n\nECMAScript 中的 Global 对象\n浏览器窗口的 JavaScript 接口\n\n通过 var 声明的所有全局变量和函数都会变成 window 对象的属性和方法；\n窗口关系\n\ntop 对象始终指向最上层（最外层）窗口，即浏览器窗口本身；\nparent 对象则始终指向当前窗口的父窗口；\nself 对象，它是终极 window 属性，始终会指向 window；\n\n窗口位置与像素比\n\nscreenLeft 和 screenTop 属性，表示窗口相对于屏幕左侧和顶部的位置；\nmoveTo(absolute position) 和 moveBy(relative position) 方法移动窗口；\n\n窗口大小\n\nouterWidth 和 outerHeight 返回浏览器窗口自身的大小；\ninnerWidth 和 innerHeight 返回浏览器窗口中页面视口的大小；\nresizeTo() 和 resizeBy() 方法调整窗口大小；\n\n浏览器窗口自身的精确尺寸不好确定，但可以确定页面视口的大小，如下：\nlet pageWidth = window.innerWidth, pageHeight = window.innerHeight;\nif (typeof pageWidth != &quot;number&quot;) {\n    if (document.compatMode == &quot;CSS1Compat&quot;){\n        pageWidth = document.documentElement.clientWidth;\n        pageHeight = document.documentElement.clientHeight;\n    } else {\n        pageWidth = document.body.clientWidth;\n        pageHeight = document.body.clientHeight;\n    }\n}\n视口位置\n\n度量文档相对于视口滚动距离的属性有两对，返回相等的值： window.pageXoffset/window.scrollX 和 window.pageYoffset/window.scrollY；\nscroll()、 scrollTo() 和 scrollBy() 方法滚动页面；它们都接收一个 ScrollToOptions 字典，除了提供偏移值，还可以通过 behavior 属性告诉浏览器是否平滑滚动；\n\n导航与打开新窗口\n\nwindow.open() 方法可以用于导航到指定 URL，也可以用于打开新浏览器窗口；接收 4个参数：要加载的 URL、目标窗口、特性字符串和表示新窗口在浏览器历史记录中是否替代当前加载页面的布尔值；\n\n在某些浏览器中，每个标签页会运行在独立的进程中。如果一个标签页打开了另一个，而 window\n对象需要跟另一个标签页通信，那么标签便不能运行在独立的进程中。在这些浏览器中，可以将新打开\n的标签页的 opener 属性设置为 null，表示新打开的标签页可以运行在独立的进程中。\n系统对话框\nalert()、 confirm() 和 prompt() 方法，可以让浏览器调用系统对话框向用户显示消息；\n这些对话框都是同步的模态对话框，即它们显示的时候，代码会停止执行，它们消失以后，代码才会恢复执行；\n\n警告框（ alert）通常用于向用户显示一些他们无法控制的消息；\n确认框，调用 confirm()来显示。确认框跟警告框类似，都会向用户显示消息，确认框有两个按钮；\n提示框，通过调用 prompt()方法来显示。提示框的用途是提示用户输入消息。\n\n另外两种对话框： find()和 print()。这两种对话框都是异步显示的，即控制权会立即返回给脚本。分别是浏览器菜单上选择“查找”（ find）和“打印”（ print） ；\n很多浏览器针对这些系统对话框添加了特殊功能：\n\n网页中的脚本生成了两个或更多系统对话框，则除第一个之外，所有后续的对话框上都会显示一个复选框，如果用户选中则会禁用后续的弹框，直到页面刷新；\n如果用户选中了复选框并关闭了对话框，在页面刷新之前，所有系统对话框（警告框、确认框、提\n示框）都会被屏蔽  ；\n\nlocation 对象\n\n提供了当前窗口中加载文档的信息，以及通常的导航功能；\n既 是 window 的 属 性 ， 也 是 document 的 属 性；\n还保存了把 URL 解析为离散片段后能够通过属性访问的信息\n\n\nURLSearchParams  ：可以检查和修改查询字符串，实例上暴露了 get()、set() 和 delete()等方法；大多数支持 URLSearchParams 的浏览器也支持将 URLSearchParams 的实例用作可迭代对象；\n通过修改 location 对象修改浏览器的地址，会立即启动导航到新 URL 的操作，同时在浏览器历史记录中增加一条记录：\nlocation.assign(&quot;www.xxx.com&quot;);\n如果给 location.href 或 window.location 设置一个 URL，也会以同一个 URL 值调用 assign() 方法：\nwindow.location = &quot;www.xxx.com&quot;;\nlocation.href = &quot;www.xxx.com&quot;;\n除了 hash 之外，只要修改 location 的一个属性，就会导致页面重新加载新 URL ；\n修改 hash 的值会在浏览器历史中增加一条新记录，单击“后退”按钮时，就会导航到前一个页面。如果不希望增加历史记录，可以使用 replace() 方法；\nreload() 方法能重新加载当前显示的页面，传入可选参数 true，表示强制从服务器加载；\n脚本中位于 reload()调用之后的代码可能执行也可能不执行，这取决于网络延迟和系统资源等因素；\nnavigator 对象\nnavigator 对 象 实 现 了 NavigatorID 、 NavigatorLanguage 、 NavigatorOnLine 、NavigatorContentUtils 、NavigatorStorage 、 NavigatorStorageUtils 、 NavigatorConcurrentHardware、 NavigatorPlugins 和NavigatorUserMedia 接口定义的属性和方法；\n检测插件\n。。。\n注册处理程序\n现代浏览器支持 navigator 上的（在 HTML5 中定义的） registerProtocolHandler()方法。这个方法可以把一个网站注册为处理某种特定类型信息应用程序；\n必须传入 3 个参数：要处理的协议（如”mailto”或”ftp”）、处理该协议的 URL，以及应用名称；\nscreen 对象\nwindow 的另一个属性 screen 对象，是为数不多的几个在编程中很少用的 JavaScript 对象；\n用于保存客户端能力信息，也就是浏览器窗口外面的客户端显示器的信息，比如像素宽度和像\n素高度  ；\nhistory 对象\nhistory 对象表示当前窗口首次使用以来用户的导航历史记录；\n出于安全考虑，这个对象不会暴露用户访问过的 URL，但可以通过它在不知道实际 URL 的情况下前进和后退\n导航\n\ngo() 方法可以在用户历史记录中沿任何方向导航，可以前进也可以后退，参数为整数，表示步数；\ngo()有两个简写方法： back()和 forward() ；\nhistory 对象还有一个 length 属性，表示历史记录中有多个条目；\n\n历史状态管理\nhashchange 会在页面 URL 的散列变化时被触发，开发者可以在此时执行某些操作。而状态管理 API 则可以让开发者改变浏览器 URL 而不会加载新页面；\nhistory.pushState() 接收 3 个参数：一个 state 对象、一个新状态的标题和一个（可选的）相对 URL：\nlet stateObject = {foo:&quot;bar&quot;};\nhistory.pushState(stateObject, &quot;My title&quot;, &quot;baz.html&quot;);\n因为 pushState() 会创建新的历史记录，所以也会相应地启用“后退”按钮；\n页面初次加载时没有状态。因此点击“后退”按钮直到返回最初页面时， event.state 会为 null；\nstate 对象应该只包含可以被序列化的信息。因此，DOM 元素之类并不适合放到状态对象里保存；"},"front-end/javascript/red-book/client-detection":{"title":"client-detection","links":[],"tags":[],"content":"能力检测\n能力检测的关键是理解两个重要概念：\n\n首先，应该先检测最常用的方式；\n其次是必须检测切实需要的特性；\n\n能力检测最有效的场景是检测能力是否存在的同时，验证其是否能够展现出预期的行为。\n如尝试检测某个对象是否可以排序：\n// 不要这样做！错误的能力检测，只能检测到能力是否存在\nfunction isSortable(object) {\nreturn !!object.sort;\n}\n简单地测试到一个属性存在并不代表这个对象就可以排序。更好的方式是检测 sort 是不是函数：\n// 好一些，检测 sort 是不是函数\nfunction isSortable(object) {\nreturn typeof object.sort == &quot;function&quot;;\n}\n进行能力检测时应该尽量使用 typeof 操作符；\n浏览器分析\n1. 可以按照能力将浏览器归类；\n如果你的应用程序需要使用特定的浏览器能力，那么最好集中检测所有能力，而不是等到用的时候再重复检测；\n2. 对浏览器特性进行检测与已知特性对比，确认用户使用浏览器类型；\n这样可以获得比用户代码嗅探更准确的结果。但未来的浏览器版本可能不适用于这套方案；\n// 测试 chrome 对象及其 webstore 属性\n// Opera 的某些版本有 window.chrome，但没有 window.chrome.webstore\n// 所有版本的 Chrome 都支持\nthis.isChrome_Gte1 = !!window.chrome &amp;&amp; !!window.chrome.webstore;\n \nisChrome() { return this.isChrome_Gte1; }\n随着浏览器的变迁及发展，可以不断调整底层检测逻辑，但主要的 API 可以保持不变；\n用户代理检测\n用户代理检测通过浏览器的用户代理字符串确定使用的是什么浏览器。\n用户代理字符串包含在每个HTTP 请求的头部，在 JavaScript 中可以通过 navigator.userAgent 访问；\n浏览器分析\n想要知道自己代码运行在什么浏览器上，大部分开发者会分析 window.navigator.userAgent 返回的字符串值；\n1. 伪造用户代理\n实现 window.navigator 对象的浏览器（即所有现代浏览器）都会提供 userAgent 这个只读属性；\n2. 分析浏览器\n通过解析浏览器返回的用户代理字符串，可以极其准确地推断出下列相关的环境信息：\n\n浏览器\n浏览器版本\n浏览器渲染引擎\n设备类型（桌面/移动）\n设备生产商\n设备型号\n操作系统\n操作系统版本\n\n软件与硬件检测\n识别浏览器与操作系统\n1. navigator.oscpu：字符串属性，通常对应用户代理字符串中操作系统/系统架构相关信息；\n2. navigator.vendor：字符串属性，通常包含浏览器开发商信息；\n3. navigator.platform：字符串属性，通常表示浏览器所在的操作系统；\n4. screen.colorDepth 和 screen.pixelDepth：返回一样的值，即显示器每像素颜色的位深。\n根据 CSS 对象模型（ CSSOM）规范：\nscreen.colorDepth 和 screen.pixelDepth 属性应该返回输出设备中每像素用于显示颜色的位数，不包含 alpha 通道。\nChrome 中这两个属性的值如下所示：\nconsole.log(screen.colorDepth); // 24\nconsole.log(screen.pixelDepth); // 24\n5. screen.orientation：返回一个 ScreenOrientation 对象，其中包含 Screen Orientation API 定义的屏幕信息；\n其中有两个属性 angle 和 type，前者返回相对于默认状态下屏幕的角度，\n后者返回以下 4 种枚举值之一：\n\nportrait-primary\nportrait-secondary\nlandscape-primary\nlandscape-secondary\n\n根据规范，这些值的初始化取决于浏览器和设备状态；根据规范，这些值的初始化取决于浏览器和设备状态；\n浏览器元数据\n1. Geolocation API：一个对象，可以让浏览器脚本感知当前设备的地理位置。只在安全执行环境（通过 HTTPS 获取的脚本）中可用；\n\n根据 Geolocation API 规范：\n地理位置信息的主要来源是 GPS 和 IP 地址、射频识别（ RFID）、 Wi-Fi 及蓝牙 Mac 地址、GSM/CDMA 蜂窝 ID 以及用户输入等信息。\n\n要 获 取 浏 览 器 当 前 的 位 置 ， 可 以 使 用 getCurrentPosition()方 法；方法也接收失败回调函数作为第二个参数，这个函数会收到一个 PositionError 对象，包含 code 和 message 两个属性；\n第三个参数提供 PositionOptions 对象作为配置，\n\nenableHighAccuracy：布尔值， true 表示返回的值应该尽量精确；\ntimeout：毫秒，表示在以 TIMEOUT 状态调用错误回调函数之前等待的最长时间；\nmaximumAge：毫秒，表示返回坐标的最长有效期，默认值为 0；\n\n2. Connection State 和 NetworkInformation API：浏览器会跟踪网络连接状态并以两种方式暴露这些信息：连接事件和 navigator.onLine 属性；\n\n在设备连接到网络时，浏览器会记录这个事实并在 window 对象上触发 online 事件；\n断开网络连接后，浏览器会在 window 对象上触发 offline 事件；\n\n任何时候，都可以通过 navigator.onLine 属性来确定浏览器的联网状态；\n到底怎么才算联网取决于浏览器与系统实现；\nnavigator 对象还暴露了 NetworkInformation API，可以通过 navigator.connection 属性使用。\n这个 API 提供了一些只读属性，并为连接属性变化事件处理程序定义了一个事件对象\n3. Battery Status API：浏览器可以访问设备电池及充电状态的信息。 navigator.getBattery() 方法会返回一个包装了 BatteryManager 对象的 Promise 实例。\n对象包含四个只读属性：charging，chargingTime，dischargingTime，level；\n这个 API 还提供了 4 个事件属性：\n\nonchargingchange\nonchargingtimechange\nondischargingtimechange\nonlevelchange\n\n硬件\n浏览器检测硬件的能力相当有限，\n\n处理器核心数 navigator.hardwareConcurrency 属性返回浏览器支持的逻辑处理器核心数量，包含表示核心\n数的一个整数值（如果核心数无法确定，这个值就是 1）。关键在于，这个值表示浏览器可以并行执行的\n最大工作线程数量，不一定是实际的 CPU 核心数。\n设备内存大小\nnavigator.deviceMemory 属性返回设备大致的系统内存大小，包含单位为 GB 的浮点数（舍入\n为最接近的 2 的幂： 512MB 返回 0.5， 4GB 返回 4）。\n最大触点数\nnavigator.maxTouchPoints 属性返回触摸屏支持的最大关联触点数量，包含一个整数值。\n"},"front-end/javascript/red-book/client-storage":{"title":"client-storage","links":[],"tags":[],"content":"Cookie\ncookie 由古老的网景公司发明，由一份名为 Persistent Client State: HTTP Cookies 的规范定义；\n\n这个规范要求服务器在响应 HTTP 请求时，通过发送 Set-Cookie HTTP 头部包含会话信息；\n浏览器会存储这些会话信息，并在之后的每个请求中都会通过 HTTP 头部 cookie 再将它们发回服务器；\ncookie 是与特定域绑定的，如果 cookie 总数超过了单个域的上限，浏览器就会删除之前设置的 cookie；\n大多数浏览器对 cookie 的限制是不超过 4096 字节，否则会静默删除；\n\nSet-Cookie: name=value; expires=Mon, 22-Jan-07 07:10:24 GMT; domain=.wrox.com; path=/; secure\n\ndocument.cookie 返回包含页面中所有有效 cookie 的字符串（根据域、路径、过期时间和安全设置），以分号分隔；\n没有直接删除已有 cookie 的方法。为此，需要再次设置同名 cookie（包括相同路径、域和安全选项），\n但要将其过期时间设置为某个过去的时间。\nHTTP-only 的 cookie。 HTTP-only 可以在浏览器设置，也可以在服务器设置，但只能在服务器上读取，这是因为 JavaScript 无法取得这种 cookie 的值；\n浏览器存储 API\nWeb Storage 最早是网页超文本应用技术工作组（ WHATWG， Web Hypertext Application Technical\nWorking Group）在 Web Applications 1.0 规范中提出的。\nStorage 类型用于保存名/值对数据，直至存储空间上限（由浏览器决定）；\n\n\nlength 属性可以确定 Storage 对象中保存了多少名/值对；\n\n\n无法确定对象中所有数据占用的空间大小；\n\n\nStorage 类型只能存储字符串；\n\n\nsessionStorage 对象只存储会话数据，这意味着数据只会存储到浏览器关闭；\n\n与服务器会话紧密相关，所以在运行本地文件时不能使用；\n所有现代浏览器在实现存储写入时都使用了同步阻塞方式，因此数据会被立即提交到存储；\n\n要访问同一个 localStorage 对象，页面必须来自同一个域（子域不可以）、在相同的端口上使用相同的协议。\n\n存储在 localStorage 中的数据会保留到通过 JavaScript 删除或者用户清除浏览器缓存。\nlocalStorage 数据不受页面刷新影响，也不会因关闭窗口、标签页或重新启动浏览器而丢失。\n\n\n每当 Storage 对象发生变化时，都会在文档上触发 storage 事件；\n\n\ndomain：存储变化对应的域\n\n\nkey：被设置或删除的键\n\n\nnewValue：键被设置的新值，若键被删除则为 null\n\n\noldValue：键变化之前的值\n\n\n一般来说，客户端数据的大小限制是按照每个源（协议、域和端口）来设置的，因此每个源有固定大小的数据存储空间。\nIndexeDB\nIndexed Database API 简称 IndexedDB，是浏览器中存储结构化数据的一个方案。 IndexedDB 用于代替目前已废弃的 Web SQL Database API。\n\nIndexedDB 的设计几乎完全是异步的。绝大多数 IndexedDB 操作要求添加 onerror 和 onsuccess 事件处理程序来确定输出；\n与传统数据库最大的区别在于，IndexedDB 使用对象存储而不是表格保存数据；\n\n使用 IndexedDB 数据库的第一步是调用 indexedDB.open()方法 ：\n\n在创建对象存储前，有必要想一想要存储什么类型的数据；\n创建了对象存储之后，剩下的所有操作都是通过事务完成的；\n有了事务的引用， 就可以使用 objectStore()方法并传入对象存储的名称以访问特定的对象存储；\n可以使用 add() 和 put() 方法添加和更新对象，使用 get() 取得对象，使用 delete() 删除对象，使用 clear()删除所有对象；\n事务对象本身也有事件处理程序： onerror 和 oncomplete。这两个事件可以用来获取事务级的状态信息；\n\n使用事务可以通过一个已知键取得一条记录。如果想取得多条数据，则需要在事务中创建一个游标。游标是一个指向结果集的指针。\n\n需要在对象存储上调用 openCursor()方法创建游标；\nupdate()方法使用指定的对象更新当前游标对应的值；\n默认情况下，每个游标只会创建一个请求。要创建另一个请求，必须调用下列中的一个方法。\n\ncontinue(key)：移动到结果集中的下一条记录。参数 key 是可选的。如果没有指定 key，游\n标就移动到下一条记录；如果指定了，则游标移动到指定的键。\nadvance(count)：游标向前移动指定的 count 条记录。\n\n\n键范围对应 IDBKeyRange 的实例。有四种方式指定键范围；\n\nopenCursor()的第一个参数是 null，表示默认的键范围是所有值；\n\n第一次打开数据库时，添加 onversionchange 事件处理程序非常重要。 另一个同源标签页将数据库打开到新版本时，将执行此回调。对这个事件最好的回应是立即关闭数据库；\nIndexedDB 数据库是与页面源（协议、域和端口）绑定的，因此信息不能跨域共享；\n每个源都有可以存储的空间限制，Firefox 还有一个限制——本地文本不能访问 IndexedDB 数据库；"},"front-end/javascript/red-book/closure":{"title":"closure","links":[],"tags":[],"content":"闭包\nwindow.identity = &#039;The Window&#039;;\nlet object = {\n    identity: &#039;My Object&#039;,\n    getIdentity () {\n        return this.identity;\n    }\n};\n因为赋值表达式的值是函数本身， this 值不再与任何对象绑定，所以：\n(object.getIdentity = object.getIdentity)(); // &#039;The Window&#039;\nIIFE\nlet divs = document.querySelectorAll(&#039;div&#039;);\n// 达不到目的！\nfor (var i = 0; i &lt; divs.length; ++i) {\n    divs[i].addEventListener(&#039;click&#039;, function() {\n        console.log(i);\n    });\n}\n虽然循环体结束了，但是addEventListener内部的匿名函数执行时 i 的值都是最后的索引，而且循环体外部也能获取到该值；\n以往的操作是，借助IIFE执行函数表达式，即将匿名函数改成一个带参函数，类似一个闭包将索引保存到匿名函数外部作用域：\nfor (var i = 0; i &lt; divs.length; ++i) {\n    divs[i].addEventListener(&#039;click&#039;, (function(frozenCounter) {\n        return function() {\n            console.log(frozenCounter);\n        };\n    })(i));\n}\n块级作用域变量 ，则直接使用let声明：\nfor (let i = 0; i &lt; divs.length; ++i) {}\n但是将let i;声明在循环块级作用域外部，也就等价于使用var了；\n\n立即调用的函数表达式如果不在包含作用域中将返回值赋给一个变量，则其包含的所有变量都\n会被销毁；\n\n私有变量\n\n把所有私有变量和私有函数都定义在构造函数中；\n创建一个能够访问这些私有成员的特权方法；\n\n原理是定义在构造函数中的特权方法是一个闭包，具有访问构造函数中定义的所有变量和函数的能力；\n静态私有变量\n创建了一个包含构造函数及其方法的 IIFE 私有作用域，内部包含私有变量和函数，还有构造函数和以及在其原型上的公有方法：\n(function() {\n    // 私有变量和私有函数\n    let privateVariable = 10;\n    function privateFunction() {\n        return false;\n    }\n    // 构造函数\n    MyObject = function() {};\n    // 公有和特权方法\n    MyObject.prototype.publicMethod = function() {\n        privateVariable++;\n        return privateFunction();\n    };\n})();\n不使用关键字声明的变量会创建在全局作用域中，即 MyObject 为全局变量，可在这个私有作用域外部被访问。\n在严格模式下给未声明的变量赋值会导致错误；\n模块模式\n模块模式是在单例对象基础上加以扩展，使其通过作用域链来关联私有变量和特权方法。\n匿名函数返回一个对象，在匿名函数内部，定义私有变量和私有函数；之后，创建一个要通过匿名函数返回的对象字面量，对象字面量中只包含可以公开访问的属性和方法：\nlet singleton = function() {\n    // 私有变量和私有函数\n    let privateVariable = 10;\n    function privateFunction() {\n        return false;\n    }\n    // 特权/公有方法和属性\n    return {\n        publicProperty: true,\n        publicMethod() {\n            privateVariable++;\n            return privateFunction();\n        }\n    };\n}();\n模块增强模式\n即将模块模式返回的对象增强，使实例满足某种特定类型，则不能直接返回对象字面量，而是使用 new：\nlet singleton = function() {\n    // 私有变量和私有函数...\n    \n    // 创建对象\n    let object = new CustomType();\n    \n    // 添加特权/公有属性和方法...\n    // 返回对象\n    return object;\n}();"},"front-end/javascript/red-book/dom-extend":{"title":"dom-extend","links":[],"tags":[],"content":"Selectors API\nSelectors API 是 W3C 推荐标准，规定了浏览器原生支持的 CSS 查询 API；\nSelectors API Level 1 核心是两个方法：\n\nquerySelector()\nquerySelectorAll()\n\nSelectors API Level 2 规范在 Element 类型上新增了更多方法，比如 matches()、 find() 和 findAll()；\nquerySelector()\nquerySelector()方法接收 CSS 选择符参数，返回匹配该模式的第一个后代元素，如果没有匹配项则返回 null；\nquerySelectorAll()\n返回的是一个 NodeList 的静态实例，这样的底层实现避免了使用 NodeList 对象可能造成的性能问题；\nmatches()\n接收一个 CSS 选择符参数，如果元素匹配则该选择符返回 true，否则返回 false；\n元素遍历\nElement Traversal API 为 DOM 元素添加了 5 个属性：\n\nchildElementCount，返回子元素数量（不包含文本节点和注释）；\nfirstElementChild，指向第一个 Element 类型的子元素（ Element 版 firstChild）；\nlastElementChild，指向最后一个 Element 类型的子元素（ Element 版 lastChild）；\npreviousElementSibling ， 指 向 前 一 个 Element 类 型 的 同 胞 元 素 （ Element 版\npreviousSibling）；\nnextElementSibling，指向后一个 Element 类型的同胞元素（ Element 版 nextSibling）。\n\nHTML5\nHTML5 代表着与以前的 HTML 截然不同的方向。在所有以前的 HTML 规范中，从未出现过描述\nJavaScript 接口的情形；\nCSS 类扩展\ngetElementsByClassName() 接收一个参数，即包含一个或多个类名的字符串，返回类名中\n包含相应类的元素的 NodeList。如果提供了多个类名，则顺序无关紧要；\n要操作类名，可以通过 className 属性实现添加、删除和替换；\nclassList 是一个新的集合类型 DOMTokenList 的实例。  提供 add(value)，contains(value)，remove(value)，toggle(value)方法进行操作；\n焦点管理\n\ndocument.activeElement，始终包含当前拥有焦点的 DOM 元素；\n默认情况下， document.activeElement 在页面刚加载完之后会设置为 document.body；\ndocument.hasFocus()方法，该方法返回布尔值，表示文档是否拥有焦点；\n\nHTMLDocument 扩展\n\ndocument.readState 返回 loading / complete，以判断文档是否加载完毕；\n标准模式下 document.compatMode 的值是”CSS1Compat”，而在混杂模式下，\ndocument.compatMode 的值是”BackCompat” ；\nHTML5 增加了 document.head 属性，指向文档的&lt;head&gt;元素；\n\n字符集属性\n\ncharacterSet 属性表示文档实际使用的字符集；\n\n自定义数据属性\n\nHTML5 允许给元素指定非标准的属性，但要使用前缀 data-以便告诉浏览器；\n定义了自定义数据属性后，可以通过元素的 dataset 属性来访问。\ndataset 属性是一个 DOMStringMap 的实例，其中通过 data-后面的字符串作为键来访问；\n\n插入标记\n\n在读取 innerHTML 属性时，会返回元素所有后代的 HTML 字符串，包括元素、注释和文本节点；\n在写入 innerHTML 时，则会根据提供的字符串值以新的 DOM 子树替代元素中原来包含的所有节点；\n实际返回的文本内容会因浏览器而不同，若不包含任何 HTML 标签，则直接生成一个文本节点；\n在所有现代浏览器中，通过 innerHTML 插入的&lt;script&gt;标签是不会执行的；\n\n\n\n读取 outerHTML 属性时，会返回调用它的元素（及所有后代元素）的 HTML 字符串；\n在写入outerHTML 属性时，调用它的元素会被传入的 HTML 字符串经解释之后生成的 DOM 子树取代；\n\n\n\ninsertAdjacentHTML()和 insertAdjacentText()；\n这两个方法最早源自 IE，它们都接收两个参数：要插入标记的位置和要插入的 HTML 或文本；\ninsertAdjacentHTML()和 insertAdjacentText()。这两\n个方法最早源自 IE，它们都接收两个参数：要插入标记的位置和要插入的 HTML 或文本；\n\n“beforebegin”，插入当前元素前面，作为前一个同胞节点；\n“afterbegin”，插入当前元素内部，作为新的子节点或放在第一个子节点前面；\n“beforeend”，插入当前元素内部，作为新的子节点或放在最后一个子节点后面；\n“afterend”，插入当前元素后面，作为下一个同胞节点；\n\n\n\nscrollIntoView()\nscrollIntoView()方法存在于所有 HTML 元素上，可以滚动浏览器窗口或容器元素以便包含元\n素进入视口。这个方法的参数如下：\n\n\nalignToTop 是一个布尔值：\n\ntrue：窗口滚动后元素的顶部与视口顶部对齐。\nfalse：窗口滚动后元素的底部与视口底部对齐。\n\n\n\nscrollIntoViewOptions 是一个选项对象：\n\nbehavior：定义过渡动画，可取的值为”smooth”和”auto”，默认为”auto”。\nblock：定义垂直方向的对齐，可取的值为”start”、 “center”、 “end”和”nearest”，默\n认为 “start”。\ninline：定义水平方向的对齐，可取的值为”start”、 “center”、 “end”和”nearest”，默\n认为 “nearest”。\n\n\n\n不传参数等同于 alignToTop 为 true；\n\n\n专有扩展\nchildren 属性\n\n\nchildren 属性是一个 HTMLCollection，只包含元素的 Element 类型的子节点；\n\n\n如果元素的子节点类型全部是元素类型，那 children 和 childNodes 中包含的节点应该是一样的；\n\n\ncontains()方法\n\n如果目标节点是被搜索节点的后代， contains()返回 true，否则返回 false  ；\n使用 DOM Level 3 的 compareDocumentPosition()方法也可以确定节点间的关系；\n\n插入标记\n\ninnerText 属性对应元素中包含的所有文本内容，无论文本在子树中哪个层级；\n设置 innerText 会移除元素之前所有的后代节点，完全改变 DOM 子树；\n因为设置 innerText 只能在容器元素中生成一个文本节点，所以为了保证一定是文本节点，就必\n须进行 HTML 编码；\n\nouterText 属性\n\n要读取文本值时，outerText 与 innerText 实际上会返回同样的内容；\n在写入文本值时，outerText 不止会移除所有后代节点，而是会替换整个元素；\n本质上，这相当于用新的文本节点替代 outerText 所在的元素；\n此时，原来的元素会与文档脱离关系，因此也无法访问。\n\n滚动\n\n\nscrollIntoViewIfNeeded(alingCenter) 会在元素不可见的情况下，将其滚动到窗口或包含窗口中，使其可见；\n\n\n如果已经在视口中可见，则这个方法什么也不做。\n\n\n如果将可选的参数 alingCenter 设置为 true，则浏览器会尝试将其放在视口中央。\n\n"},"front-end/javascript/red-book/dom":{"title":"dom","links":[],"tags":[],"content":"节点层级\nDOM 中总共有 12 种节点类型，这些类型都继承一种基本类型；\nNode 类型\n所有 DOM 节点类型都实现了 Node 接口，即所有类型都共享其中的基本属性和方法；\n每个节点都有 nodeType 属性，表示该节点的类型。节点类型由定义在 Node 类型上的 12 个数值\n常量表示；\n浏览器并不支持所有节点类型。开发者最常用到的是元素节点和文本节点；\n每个节点都有一个 childNodes 属性，其中包含一个 NodeList 的实例。  NodeList 并不是 Array 的实例，但类似于 Array；NodeList 是实时的活动对象，而不是第一次访问时所获得内容的快照；\n操纵节点\n\nappendChild()，用于在 childNodes 列表末尾添加节点；\n使用 insertBefore()方法，把节点放到 childNodes 中的特定位置而不是末尾；\nreplaceChild()方法接收两个参数：要插入的节点和要替换的节点，用于替换节点；\n要移除节点而不是替换节点，可以使用 removeChild() 方法；\n\n并非所有节点类型都有子节点，如果在不支持子节点的节点上调用这些方法，则会导致抛出错误；\n\ncloneNode()，会返回与调用它的节点一模一样的节点。 该方法接收一个布尔值参数，表示是否深复制。在传入 true 参数时，会进行深复制，复制节点及其整个子 DOM 树。如果传入 false，则只会复制调用该方法的节点。复制返回的节点属于文档所有，但尚未指定父节点，所以可称为孤儿节点（ orphan）。\nnormalize()，这个方法唯一的任务就是处理文档子树中的文本节点；\n\nDocument 类型\n在浏览器中，文档对象 document 是 HTMLDocument 的实例（ HTMLDocument 继承 Document），表示整个 HTML 页面。 document 是 window 对象的属性，因此是一个全局对象。\nDocument 类型的节点中，**子节点可以是 DocumentType（最多一个）、 Element（最多一个）**等；\ndocument 作为 HTMLDocument 的实例，还有一些标准 Document 对象上所没有的属性：\n\ntitle，包含 &lt;title&gt; 元素中的文本，通常显示在浏览器窗口或标签页的标题栏；修改 title 属性并不会改变&lt;title&gt;元素；\nURL 包含当前页面的完整 URL（地址栏中的 URL）， domain 包含页面的域名，而 referrer 包含链接到当前页面的那个页面的 URL。\n\n只有 domain 属性是可以设置的，且只能设置同域的域名；\n\n\ngetElementById() 和 getElementsByTagName() 就是 Document 类型提供的获取某个或某组元素的引用的方法；\n对 HTMLCollection 对象而言，中括号既可以接收数值索引，也可以接收字符串索引。而在后台，\n数值索引会调用 item()，字符串索引会调用 namedItem()；\nHTMLDocument 上还定义 getElementsByName()方法，该方法会返回具有给定 name 属性的所有元素；\n\n\n\n\n在页面渲染期间通过 document.write() 可向文档中输出内容；在页面加载完之后再调用 document.write()，则输出的内容会重写整个页面；\nopen()和 close() 方法分别用于打开和关闭网页输出流。在调用 write()和 writeln()时，这两\n个方法都不是必需的；\n\nElement 类型\nElement 表示 XML 或 HTML 元素，对外暴露出访问元素标签名、子节点和属性的能力；\ndiv.tagName 实际上返回的是”DIV”而不是”div”。在 HTML 中，元素标签名始终以全大写表示； 先把标签名转换为全部小写后再比较，这是推荐的做法；\n所有 HTML 元素都通过 HTMLElement 类型表示，包括其直接实例和间接实例。另外， HTMLElement\n直接继承 Element 并增加了一些属性；\n与属性相关的 DOM 方法主要有 3 个： getAttribute()、 setAttribute()和 removeAttribute()。\n注意，属性名不区分大小写，通过 DOM 对象访问的属性中有两个返回的值跟使用 getAttribute()取得的值不一样：\n\nstyle：DOM 对象的属性访问返回 CSSStyleDeclaration；\n事件处理程序：是一个 JavaScript 函数（未指定该属性则返回 null）；\n\nElement 类型是唯一使用 attributes 属性的 DOM 节点类型。 attributes 属性包含一个 NamedNodeMap 实例，是一个类似 NodeList 的“实时”集合。\nattributes 属性最有用的场景是需要迭代元素上所有属性的时候；不同浏览器返回的 attributes 中的属性顺序也可能不一样。\nText 类型\nText 节点由 Text 类型表示，包含按字面解释的纯文本，也可能包含转义后的 HTML 字符，但不含 HTML 代码；\n修改文本节点还有一点要注意，就是 HTML 或 XML 代码（取决于文档类型）会被转换成实体编码，即小于号、大于号或引号会被转义；\n一般来说一个元素只包含一个文本子节点。不过，也可以让元素包含多个文本子节点；\n有一个方法可以合并相邻的文本节点，即 normalize()，是在 Node 类型中定义的（因此所有类型的节点上都有这个方法）。\nText 类型定义了一个与 normalize()相反的方法——splitText()。这个方法可以在指定的偏移位置拆分 nodeValue，将一个文本节点拆分成两个文本节点。\nComment 类型\nDOM 中的注释通过 Comment 类型表示，Comment 类型与 Text 类型继承同一个基类（ CharacterData），因此拥有除 splitText() 之外Text 节点所有的字符串操作方法；\n此外，浏览器不承认结束的&lt;/html&gt;标签之后的注释。如果要访问注释节点，则必须确定它们是&lt;html&gt;元素的后代；\nCDATASection 类型\nCDATASection 类型表示 XML 中特有的 CDATA 区块。 CDATASection 类型继承 Text 类型，因此拥有包括 splitText()在内的所有字符串操作方法；\nCDATA 区块只在 XML 文档中有效，因此某些浏览器比较陈旧的版本会错误地将 CDATA 区块解析为 Comment 或 Element ；\nDocumentType 类型\nDocumentType 类型的节点包含文档的文档类型（ doctype）信息，\n\nname 是文档类型的名称；\nentities 是这个文档类型描述的实体的 NamedNodeMap；\nnotations 是这个文档类型描述的表示法的 NamedNodeMap；\n\n浏览器中的文档通常是 HTML 或 XHTML 文档类型，所以 entities 和 notations 列表为空。（这个对象只包含行内声明的文档类型。）无论如何，只有 name 属性是有用的；\nDocumentFragment 类型\n在所有节点类型中，DocumentFragment 类型是唯一一个在标记中没有对应表示的类型。 DOM 将\n文档片段定义为 “轻量级” 文 档， 能够包含和操作节点， 却没有完整文档那样额外的消耗 。\n不能直接把文档片段添加到文档。相反，文档片段的作用是充当其他要被添加到文档的节点的仓库；\n如果文档中的一个节点被添加到一个文档片段，则该节点会从文档树中移除，不会再被浏览器渲染；\nAttr 类型\n元素数据在 DOM 中通过 Attr 类型表示。 Attr 类型构造函数和原型在所有浏览器中都可以直接访问。技术上讲，属性是存在于元素 attributes 属性中的节点；\n属性节点尽管是节点，却不被认为是 DOM 文档树的一部分。 Attr 节点很少直接被引用；\n将属性作为节点来访问多数情况下并无必要。推荐使用 getAttribute()、removeAttribute()和 setAttribute()方法操作属性，而不是直接操作属性节点；\nDOM 编程\n\n通过 innerHTML 属性创建的&lt;script&gt;元素永远不会执行；\n应该把&lt;link&gt;元素添加到&lt;head&gt;元素而不是&lt;body&gt;元素，这样才能保证所有浏览器都能正常运行；\n通过外部文件加载样式是异步的；因此，样式的加载和正执行的 JS 代码并没有先后顺序。一般也没有必要知道样式什么时候加载完成。\n\n理解 NodeList 对象和相关的 NamedNodeMap、 HTMLCollection，是理解 DOM 编程的关键。\n这 3 个集合类型都是“实时的” ，在每次访问时更新集合；\nlet divs = document.getElementsByTagName(&quot;div&quot;);\nfor (let i = 0; i &lt; divs.length; ++i){\n    let div = document.createElement(&quot;div&quot;);\n    document.body.appendChild(div);\n}\n如上的例子，代码永远不会遍历结束，因为 i 和 divs.length 在同时递增；解决方法是再定义一个变量用于保存 divs.length：\nfor (let i = 0, len = divs.length; i &lt; len; ++i) {}\nMutationObserver\n不久前添加到 DOM 规范中的 MutationObserver 接口，可以在 DOM 被修改时异步执行回调，该接口是为了取代废弃的 MutationEvent；\nMutationObserver 的实例要通过调用 MutationObserver 构造函数并传入一个回调函数来创建：\nlet observer = new MutationObserver(() =&gt; console.log(&#039;DOM was mutated!&#039;));  \n使用 observe() 方法把这个 observer 与 DOM 关联起来，方法接收两个必需的参数：\n\n要观察其变化的 DOM 节点；\n一个 MutationObserverInit 对象  ；\n\nMutationObserverInit 对象用于控制观察哪些方面的变化， 是一个键/值对形式配置选项的字典。\n例如，下面的代码会创建一个观察者（observer）并配置它观察&lt;body&gt;元素上的属性变化：\nlet observer = new MutationObserver(() =&gt; console.log(&#039;&lt;body&gt; attributes changed&#039;));\nobserver.observe(document.body, { attributes: true }); \n\n每次执行回调都会传入一个包含按顺序入队的 MutationRecord 实例的数组；\n传给回调函数的第二个参数是观察变化的 MutationObserver 的实例；\n默认情况下，只要被观察的元素不被垃圾回收；要提前终止执行回调，可以调用 disconnect() 方法：observer.disconnect();  \n多次调用 observe() 方法，可以复用一个 MutationObserver 对象观察多个不同的目标节点；\ndisconnect() 方法是一个“一刀切”的方案，调用它会停止观察所有目标；\n调用 disconnect() 并不会结束 MutationObserver 的生命。还可以重新使用这个观察者，再将它关联到新的目标节点；\n\nMutationObserverInit 对象用于控制对目标节点的观察范围。粗略地讲，观察者可以观察的事\n件包括属性变化、文本变化和子节点变化：\n\nsubtree：子树\nattributes：属性\nattributeFilter：哪些属性\nattributeOldValue：记录旧的属性值\ncharacterData：字符数据\ncharacterDataOldValue：字符数据旧值\nchildList：修改子节点\n\n在调用 observe()时， MutationObserverInit 对象中的属性必须至少有一项为 true（无论是直接设置这几个属性，还是通过设置 attributeOldValue 等属性间接导致它们的值转换为 true）。否则会抛出错误，因为没有任何变化事件可能触发回调。\n\n每次 MutationRecord 被添加到 MutationObserver 的记录队列时，仅当之前没有已排期的微任务回调时（队列中微任务长度为 0），才会将观察者注册的回调（在初始化 MutationObserver 时传入）作为微任务调度到任务队列上。这样可以保证记录队列的内容不会被回调处理两次。\n调用 MutationObserver 实例的 takeRecords() 方法可以清空记录队列，取出并返回其中的所\n有 MutationRecord 实例。\n将变化回调委托给微任务来执行可以保证事件同步触发，同时避免随之而来的混乱。为MutationObserver 而实现的记录队列，可以保证即使变化事件被爆发式地触发，也不会显著地拖慢浏览器；\n\n\nMutationObserver 实例与目标节点之间的引用关系是非对称的。\nMutationObserver 拥有对要观察的目标节点的弱引用。因为是弱引用，所以不会妨碍垃圾回收程序回收目标节点；目标节点却拥有对 MutationObserver 的强引用。如果目标节点从 DOM 中被移除，随后被垃圾回收，则关联的 MutationObserver 也会被垃圾回收\n\n\n记录队列中的每个 MutationRecord 实例至少包含对已有 DOM 节点的一个引用\n如果变化是 childList 类型，则会包含多个节点的引用；\n\n"},"front-end/javascript/red-book/dom2-and-dom3":{"title":"dom2&dom3","links":[],"tags":[],"content":"DOM 的演进\nDOM2 和 DOM3 Core 模块的目标是扩展 DOM API，满足 XML 的所有需求并提供更好的错误处理和特性检测；\n\nDOM2 Core 仅在 DOM1 Core 基础上增加了一些方法和属性；\nDOM3 Core 则除了增强原有类型，也新增了一些新类型；\n\nXML 命名空间\nXML 命名空间可以实现在一个格式规范的文档中混用不同的 XML 语言，而不必担心元素命名冲突；\n严格来讲， XML 命名空间在 XHTML 中才支持， HTML 并不支持；\n\n可以使用 xmlns 给命名空间创建一个前缀，格式为“xmlns: 前缀”；\n如果文档中只使用一种 XML 语言，那么命名空间前缀其实是多余的；\n\n\n在 DOM2 中， Node 类型包含以下特定于命名空间的属性：\n\nlocalName，不包含命名空间前缀的节点名；\nnamespaceURI，节点的命名空间 URL，如果未指定则为 null；\nprefix，命名空间前缀，如果未指定则为 null。\n\nDOM3 进一步增加了如下与命名空间相关的方法：\n\nisDefaultNamespace(namespaceURI)，返回布尔值，表示 namespaceURI 是否为节点的默认命名空间；\nlookupNamespaceURI(prefix)，返回给定 prefix 的命名空间 URI；\nlookupPrefix(namespaceURI)，返回给定 namespaceURI 的前缀；\n\n主要用于通过元素查询前面和命名空间 URI，以确定元素与文档的关系\n\nDOM2 在 Document 类型上新增了如下命名空间特定的方法：\n\ncreateElementNS(namespaceURI, tagName)，以给定的标签名 tagName 创建指定命名空\n间 namespaceURI 的一个新元素；\ncreateAttributeNS(namespaceURI, attributeName)，以给定的属性名 attributeName\n创建指定命名空间 namespaceURI 的一个新属性；\ngetElementsByTagNameNS(namespaceURI, tagName)，返回指定命名空间 namespaceURI\n中所有标签名为 tagName 的元素的 NodeList。\n\n这些命名空间特定的方法只在文档中包含两个或两个以上命名空间时才有用。\n\nDOM2 Core 对 Element 类型的更新主要集中在对属性的操作上。下面是新增的方法：\n\ngetAttributeNS(namespaceURI, localName)，取得指定命名空间 namespaceURI 中名为\nlocalName 的属性；\ngetAttributeNodeNS(namespaceURI, localName)，取得指定命名空间 namespaceURI 中\n名为 localName 的属性节点；\ngetElementsByTagNameNS(namespaceURI, tagName)，取得指定命名空间 namespaceURI\n中标签名为 tagName 的元素的 NodeList；\nhasAttributeNS(namespaceURI, localName)，返回布尔值，表示元素中是否有命名空间\nnamespaceURI 下名为 localName 的属性（注意， DOM2 Core 也添加不带命名空间的\nhasAttribute()方法）；\nremoveAttributeNS(namespaceURI, localName)，删除指定命名空间 namespaceURI 中\n名为 localName 的属性；\nsetAttributeNS(namespaceURI, qualifiedName, value)， 设置指定命名空间 namespaceURI\n中名为 qualifiedName 的属性为 value；\nsetAttributeNodeNS(attNode)，为元素设置（添加）包含命名空间信息的属性节点 attNode。\n这些方法与 DOM1 中对应的方法行为相同，除 setAttributeNodeNS()之外都只是多了一个命名空间参数\n\n\nNamedNodeMap 也增加了以下处理命名空间的方法。因为 NamedNodeMap 主要表示属性：\n\ngetNamedItemNS(namespaceURI, localName)，取得指定命名空间 namespaceURI 中名为\nlocalName 的项；\nremoveNamedItemNS(namespaceURI, localName)，删除指定命名空间 namespaceURI 中\n名为 localName 的项；\nsetNamedItemNS(node)，为元素设置（添加）包含命名空间信息的节点。\n\n这些方法很少使用，因为通常都是使用元素来访问属性；\n其他变化\nDocumentType 新增了 3 个属性： publicId、 systemId 和 internalSubset。\n\npublicId、systemId 表示文档类型声明中有效但无法使用 DOM1 API 访问的数据；\ninternalSubset 用于访问文档类型声明中可能包含的额外定义；\n\n通常在网页中很少需要访问这些信息，XML 文档中稍微常用一些；\n\nDocument 类型的更新中唯一跟命名空间无关的方法是 importNode()。这个方法的目的是从其他文档获取一个节点并导入到新文档，以便将其插入新文档。\nimportNode()方法跟 cloneNode()方法类似，同样接收两个参数：要复制的节点和表示是否同时\n复制子树的布尔值，返回结果是适合在当前文档中使用的新节点\nDOM2 View 给 Document 类型增加了新属性 defaultView，是一个指向拥有当前文档的窗口（或窗格&lt;frame&gt;） 的指针。\nDOM2 Core 还针对 document.implementation 对象增加了两个新方法： createDocumentType()和 createDocument()。前者用于创建 DocumentType 类型的新节点，  后者用于创建新文档；\nDOM2 HTML 模块也为 document.implamentation 对象添加了 createHTMLDocument()方法。\n使用这个方法可以创建一个完整的 HTML 文档，包含&lt;html&gt;、 &lt;head&gt;、 &lt;title&gt;和&lt;body&gt;元素；\n\nDOM3 新增了两个用于比较节点的方法： isSameNode()和 isEqualNode()；\n\n\n节点相同，意味着引用同一个对象；\n\n\n节点相等，意味着节点类型相同，拥有相等的属性（nodeName、 nodeValue 等）；\n\n\nDOM3 也增加了给 DOM 节点附加额外数据的方法，用于给节点追加数据；setUserData()方法接收 3 个参数：键、值、处理函数；\n处理函数接收 5 个参数：表示操作类型的数值（ 1 代表复制，2 代表导入， 3 代表删除， 4 代表重命名）、数据的键、数据的值、源节点和目标节点。\nsetUserData()的处理函数会在包含数据的节点被复制、删除、重命名或导入其他文档的时候执行，可以在这时候决定如何处理用户数据；\n\nDOM2 HTML 给 HTMLIFrameElement（即&lt;iframe&gt;，内嵌窗格）类型新增了一个属性，叫 contentDocument。这个属性包含代表子内嵌窗格中内容的 document 对象的指针；\n\ncontentDocument 属性是 Document 的实例，拥有所有文档属性和方法；\n\n样式\nHTML 中的样式有 3 种定义方式：外部样式表（通过&lt;link&gt;元素）、文档样式表（使用&lt;style&gt;元\n素）和元素特定样式（使用 style 属性）。 DOM2 Style 为这 3 种应用样式的机制都提供了 API ；\n\n任何支持 style 属性的 HTML 元素在 JavaScript 中都会有一个对应的 style 属性；\nHTML style 属性中的 CSS 属性在 JavaScript style 对象中都有对应的属性；\nfloat 是 JavaScript 的保留字，所以不能用作属性名； DOM2 Style 规定它在 style 对象中对应的属性应该是 cssFloat；\n在标准模式下，所有尺寸都必须包含单位，否则会被忽略；\n\nDOM2 Style 规范也在 style 对象上定义了一些属性和方法，提供了元素 style 属性的信息并支持修改；\nDOM2 Style在 document.defaultView 上增加了 getComputedStyle() 方法，用于取得元素和伪元素（如”:after”）的计算样式；\n\nCSSStyleSheet 类型表示 CSS 样式表，包括使用&lt;link&gt;元素和通过&lt;style&gt;元素定义的样式表。\n注意，这两个元素本身分别是 HTMLLinkElement 和 HTMLStyleElement。\nCSSStyleSheet类型继承StyleSheet，后者可用作非 CSS样式表的基类；\ndocument.styleSheets 表示文档中可用的样式表集合；\nCSSRule 类型表示样式表中的一条规则。这个类型也是一个通用基类，很多类型都继承它，但其中最常用的是表示样式信息的 CSSStyleRule；\n\nDOM 规定，可以使用 insertRule()方法向样式表中添加新规则；\n从样式表中删除规则的 DOM 方法是 deleteRule()；\n\n\n偏移尺寸（ offset dimensions），包含元素在屏幕上占用的所有视觉空间。元素在页\n面上的视觉空间由其高度和宽度决定，包括所有内边距、滚动条和边框（但不包含外边距）。\n4 个属性用于取得元素的偏移尺寸，offsetHeight，offsetLeft，offsetTop，offsetWidth；\noffsetLeft 和 offsetTop 是相对于包含元素的，包含元素保存在 offsetParent 属性中；offsetParent 不一定是 parentNode。\n要确定一个元素在页面中的偏移量，可以把它的 offsetLeft 和 offsetTop 属性分别与 offsetParent\n的相同属性相加，一直加到根元素。\n一般来说，包含在&lt;div&gt;元素中所有元素都以&lt;body&gt;为其 offsetParent；\n\n元素的客户端尺寸（ client dimensions）包含元素内容及其内边距所占用的空间。\n\n\nclientWidth：内容区宽度加左、右内边距宽度；\n\n\nclientHeight：内容区高度加上、下内边距高度；\n\n\n客户端尺寸实际上就是元素内部的空间，因此不包含滚动条占用的空间；\n这两个属性最常用于确定浏览器视口尺寸，即检测 document.documentElement 的 clientWidth 和 clientHeight；\n\n滚动尺寸（ scroll dimensions），提供了元素内容滚动距离的信息。&lt;html&gt;无须任何代码就可以自动滚动，而其他元素则需要使用 CSS 的 overflow 属性令其滚动。滚动尺寸相关的属性有如下 4 个。scrollHeight，scrollLeft，scrollTop，scrollWidth；\n浏览器在每个元素上都暴露了 getBoundingClientRect()方法，返回一个 DOMRect 对象，包含6 个属性： left、 top、 right、 bottom、 height 和 width；\n遍历\nDOM2 Traversal and Range 模块定义了两个类型 NodeIterator 和 TreeWalker  用于辅助顺序遍历 DOM 结构， 从某个起点开始执行对 DOM 结构的深度优先遍历；\n可以通过 document.createNodeIterator() 方法创建其实例：\n\n\nwhatToShow 参数是一个位掩码，通过应用一个或多个过滤器来指定访问哪些节点；\n\n\nfilter 参数可以用来指定自定义 NodeFilter 对象，或者一个作为节点过滤器的函数；\n\nNodeFilter 对象只有一个方法 acceptNode()，如果给定节点应该访问就返回 NodeFilter.FILTER_ACCEPT，否则返回 NodeFilter.FILTER_SKIP；\n\n\n\n要创建一个简单的遍历所有节点的 NodeIterator，可以使用以下代码：\nlet iterator = document.createNodeIterator(document, NodeFilter.SHOW_ALL, null, false);\nNodeIterator 的两个主要方法是 nextNode() 和 previousNode()；\n以下面的 HTML 片段为例：\n&lt;div id=&quot;div&quot;&gt;\n    &lt;p&gt;&lt;b&gt;Hello&lt;/b&gt; world!&lt;/p&gt;\n    &lt;ul&gt;\n        &lt;li&gt;List item 1&lt;/li&gt;\n        &lt;li&gt;List item 2&lt;/li&gt;\n        &lt;li&gt;List item 3&lt;/li&gt;\n    &lt;/ul&gt;\n&lt;/div&gt;\n假设想要遍历&lt;div&gt;元素内部的所有元素，那么可以使用如下代码：\nlet div = document.getElementById(&quot;div&quot;);\nlet iterator = document.createNodeIterator(div, NodeFilter.SHOW_ELEMENT,null, false);\nlet node = iterator.nextNode();\nwhile (node !== null) {\n    console.log(node.tagName); // 输出标签名\n    node = iterator.nextNode();\n} \n如果只想遍历&lt;li&gt;元素，可以传入一个过滤器，比如：\nlet div = document.getElementById(&quot;div1&quot;);\nlet filter = function(node) {\n    return node.tagName.toLowerCase() == &quot;li&quot; ?\n        NodeFilter.FILTER_ACCEPT :\n    NodeFilter.FILTER_SKIP;\n};\nlet iterator = document.createNodeIterator(div, NodeFilter.SHOW_ELEMENT,\n                                           filter, false);  \n\nTreeWalker 是 NodeIterator 的高级版。除了包含同样的 nextNode()、 previousNode()方法，TreeWalker 还添加了如下在 DOM 结构中向不同方向遍历的方法。\n\nparentNode()，遍历到当前节点的父节点。\nfirstChild()，遍历到当前节点的第一个子节点。\nlastChild()，遍历到当前节点的最后一个子节点。\nnextSibling()，遍历到当前节点的下一个同胞节点。\npreviousSibling()，遍历到当前节点的上一个同胞节点。\n\nTreeWalker 对 象 要 调用 document.createTreeWalker() 方法来创建 ，\n\n节点过滤器（ filter）除了可以返回 NodeFilter.FILTER_ACCEPT 和 NodeFilter.FILTER_SKIP，还可以返回 NodeFilter.FILTER_REJECT。\nNodeFilter.FILTER_REJECT 则表示跳过该节点以及该节点的整个子树；\nfirstChild()，nextSibling()，currentNode\n\n范围\nDOM2 在 Document 类型上定义了一个 createRange() 方法，暴露在 document 对象上。使用这个方法可以创建一个 DOM 范围对象；\n通过范围选择文档中某个部分最简单的方式，就是使用\n\nselectNode()：选择整个节点，包括其后代节点；\nselectNodeContents()：只选择节点的后代；\n\n要创建复杂的范围，需要使用 setStart() 和 setEnd() 方法；\n\nsetStart()，参照节点会成为 startContainer，而偏移量会赋值给 startOffset；\nsetEnd()，参照节点会成为 endContainer，而偏移量会赋值给 endOffset；\n"},"front-end/javascript/red-book/events":{"title":"events","links":[],"tags":[],"content":"事件流\nIE 事件流被称为事件冒泡，这是因为事件被定义为从最具体的元素（文档树中最深的节点）开始触发，然后向上传播至没有那么具体的元素（文档）。\nNetscape Communicator 团队提出了另一种名为事件捕获的事件流。事件捕获的意思是最不具体的节点应该最先收到事件，而最具体的节点应该最后收到事件。\nDOM2 Events 规范规定事件流分为 3 个阶段：事件捕获、到达目标和事件冒泡。\n\n\n事件捕获最先发生，为提前拦截事件提供了可能。\n\n\n然后，实际的目标元素接收到事件。\n\n\n最后一个阶段是冒泡，最迟要在这个阶段响应事件。\n\n\n事件处理程序\n\n作为事件处理程序执行的代码可以访问全局作用域中的一切；\n在 HTML 中定义的事件处理程序，会创建一个函数来封装属性的值。函数有一个局部变量 event 对象实例；\n该函数的作用域通过with被扩展了，document 和元素自身的成员都可以被当成局部变量来访问；\n\n在 HTML 中指定事件处理程序有一些问题：\n\n时机问题：事件处理程序的代码可能在HTML元素定义的后面；\n对事件处理程序作用域链的扩展在不同浏览器中可能导致不同的结果，访问无限定的对象成员可能导致错误；\nHTML 与 JavaScript 强耦合。如需要修改事件处理程序，则必须在 HTML 和 JavaScript 两处都修改代码；\n\n\n在 JavaScript 中指定事件处理程序的传统方式是把一个函数赋值给（ DOM 元素的）一个事件处理程\n序属性（DOM0 方式）。\n\n以这种方式添加事件处理程序是注册在事件流的冒泡阶段的；\n\nDOM2 Events 为事件处理程序的赋值和移除定义了两个方法： addEventListener()和removeEventListener()，这两个方法暴露在所有 DOM 节点上；\n\n与 DOM0 方式类似，这个事件处理程序同样在被附加到的元素的作用域中运行；\n使用 DOM2方式的主要优势是可以为同一个事件添加多个事件处理程序；\n只能使用 removeEventListener()并传入与添加时同样的参数来移除（匿名函数无法移除）；\n\n\nIE 实现了与 DOM 类似的方法，即 attachEvent()和 detachEvent()；\n注意， attachEvent()的第一个参数是”onclick”，而不是 DOM 的 addEventListener()方法的”click”\n事件处理程序的作用域：\n\nDOM0方式时，事件处理程序中的 this 值等于目标元素。\nattachEvent()时，事件处理程序是在全局作用域中运行的，因此 this 等于 window。\n\n事件对象\n所有事件对象都会包含下列的这些公共属性和方法：\n\nbubbles：布尔值，只读，表示事件是否冒泡；\ncancelable：布尔值，只读，表示是否可以取消事件的默认行为；\ncurrentTarget：元素，只读，当前事件处理程序所在的元素；\ndefaultPrevented：布尔值，只读，true 表示已经调用 preventDefault()方法（ DOM3 Events 中新增）；\ndetail：整数，只读，事件相关的其他信息；\neventPhase：整数，只读，表示调用事件处理程序的阶段： 1 代表捕获阶段， 2 代表到达目标， 3 代表冒泡阶段；\npreventDefault()：函数，只读，用于取消事件的默认行为。只有事件对象的 cancelable 属性为 true 才可以调用这个方法；\nstopImmediatePropagation()：函数 只读 用于取消所有后续事件捕获或事件冒泡，并阻止调用任何后续事件处理程序（ DOM3 Events 中新增）；\nstopPropagation()：函数 只读 用于取消所有后续事件捕获或事件冒泡。只有 bubbles 为 true 才可以调用这个方法；\ntarget：元素，只读，事件目标，即真正触发了事件的元素；\ntrusted：布尔值 只读 true 表示事件是由浏览器生成的。 false 表示事件是开发者通过 JavaScript 创建的（ DOM3 Events 中新增）；\ntype：字符串，只读，被触发的事件类型；\nView：AbstractView，只读，与事件相关的抽象视图。等于事件所发生的 window 对象\n\n在事件处理程序内部， this 对象始终等于 currentTarget 的值，而 target 只包含事件的实际目标；\nevent 对象只在事件处理程序执行期间存在，一旦执行完毕，就会被销毁。\n\n与 DOM 事件对象不同， IE 事件对象可以基于事件处理程序被指定的方式以不同方式来访问；\n\n\n使用 DOM0 方式指定的，则 event 对象只是 window 对象的一个属性；\n\n\n如果事件处理程序是使用 attachEvent()指定的，则 event 对象会作为唯一的参数传给处理函数；\n\n\n使用 attachEvent() 时， event 对象仍然是 window 对象的属性（像 DOM0 方式那样），只是出\n于方便也将其作为参数传入\n\n\n基于触发的事件类型不同， event 对象中包含的属性和方法也不一样：\n\ncancelBubble：布尔值，读/写，默认为 false，设置为 true 可以取消冒泡（与 DOM 的 stopPropagation()方法相同）；\nreturnValue：布尔值，读/写，默认为 true，设置为 false 可以取消事件默认行为（与 DOM 的 preventDefault()方法相同）；\nsrcElement：元素，只读，事件目标（与 DOM 的 target 属性相同）；\ntype：字符串，只读，触发的事件类型；\n\n由于事件处理程序的作用域取决于指定它的方式，因此 this 值并不总是等于事件目标。为此，更好的方式是使用事件对象的 srcElement 属性代替 this。\n事件类型\nDOM3 Events 定义了如下事件类型：\n\n用户界面事件（ UIEvent）：涉及与 BOM 交互的通用浏览器事件。\n焦点事件（ FocusEvent）：在元素获得和失去焦点时触发。\n鼠标事件（ MouseEvent）：使用鼠标在页面上执行某些操作时触发。\n滚轮事件（ WheelEvent）：使用鼠标滚轮（或类似设备）时触发。\n输入事件（ InputEvent）：向文档中输入文本时触发。\n键盘事件（ KeyboardEvent）：使用键盘在页面上执行某些操作时触发。\n合成事件（ CompositionEvent）：在使用某种 IME（ Input Method Editor，输入法编辑器）输入\n字符时触发。\n\n用户界面事件\n\n在 window 对象上， load 事件会在整个页面（包括所有外部资源如图片、 JavaScript 文件和 CSS 文件）加载完成后触发；\n根据 DOM2 Events， load 事件应该在 document 而非 window 上触发。可是为了向后兼容，所有浏览器都在 window 上实现了 load 事件；\nunload 事件会在文档卸载完成后触发。 unload 事件一般是在从一个页面导航到另一个页面时触发，最常用于清理引用，以避免内存泄漏；\n\n焦点事件\n\n焦点事件中的两个主要事件是 focus 和 blur，focusin 和 focusout  则是相应的冒泡版事件；\n当焦点从页面中的一个元素移到另一个元素上时，会依次发生如下事件。\n\nfocuscout 在失去焦点的元素上触发。\nfocusin 在获得焦点的元素上触发。\nblur 在失去焦点的元素上触发。\nDOMFocusOut 在失去焦点的元素上触发。\nfocus 在获得焦点的元素上触发。\nDOMFocusIn 在获得焦点的元素上触发。\n\n\n\n鼠标和滚轮事件\n\n\n页面中的所有元素都支持鼠标事件。除了 mouseenter 和 mouseleave，所有鼠标事件都会冒泡；\n\n\n4 个鼠标事件永远会按照如下顺序触发：\n\nmousedown\nmouseup\nclick\nmousedown\nmouseup\nclick\ndblclick\n\n\n\n滚轮事件只有一个事件 mousewheel，反映的是鼠标滚轮或带滚轮的类似设备上滚轮的交互；\n\n\nmousewheel 事件的 event 对象包含鼠标事件的所有标准信息，此外还有一个名为 wheelDelta 的新属性，当鼠标滚轮向前滚动时，wheelDelta 每次都是+120，反之则是-120 ；\n\n\n客户端坐标是事件发生时鼠标光标在客户端视口中的坐标，而页面坐标是事件发生时鼠标光标在页面上的坐标；在页面没有滚动时， pageX 和 pageY 与 clientX 和 clientY 的值相同；\n\n\n可以通过 event 对象的 screenX 和 screenY 属性获取鼠标光标在屏幕上的坐标；\n\n\nshiftKey、 ctrlKey、 altKey 和 metaKey 会在各自对应的修饰键被按下时包含布尔值 true ；\n\n\n对鼠标事件来说， detail 包含一个数值，表示在给定位置上发生了多少次单击；\n\n\n键盘和输入事件\n当用户按下键盘上的某个字符键时，首先会触发 keydown 事件，然后触发 keypress 事件，最后\n触发 keyup 事件。\n\n\nDOM3 Events 废弃了 keypress 事件，而推荐 textInput 事件；\n\n\nkeydown 和 keypress 事件会在文本框出现变化之前触发，而 keyup 事件会在文本框出现变化之后触发；\n\n\nDOM3 Events 也支持一个名为 location 的属性，该属性是一个数值，表示是在哪里按的键；\n\n\nevent 对象的 getModifierState()方法可检测 Shift、 Control、 Alt、 AltGraph 或 Meta 修饰键是否被锁住；\n\n\nDOM3 Events 规范增加了一个名为 textInput 的事件，其在字符被输入到可编辑区域时触发，用于替代 可以keypress 事件：\n\nkeypress 会在任何可以获得焦点的元素上触发，而 textInput 只在可编辑区域上触发；\ntextInput 只在新字符被插入时才会触发，而 keypress 对任何可能影响文本的键都会触发（包括退格键）；\n\n\n\nevent 对象上还有一个名为 inputMethod 的属性，用于判断向控件中输入文本的手段；\n\n\n合成事件\n合成事件是 DOM3 Events 中新增的，用于处理通常使用 IME 输入时的复杂输入序列；\n\ncompositionstart，在 IME 的文本合成系统打开时触发，表示输入即将开始；\ncompositionupdate，在新字符插入输入字段时触发；\ncompositionend，在 IME 的文本合成系统关闭时触发，表示恢复正常键盘输入；\n\n变化事件\n变化事件已经被 Mutation Observers 所取代\nHTML5 事件\n如何避免默认的上下文菜单起作用。结果就出现了 contextmenu 事件，以专门用于表示何时该显示上下文菜单，从而允许开发者取消默认的上下文菜单并提供自定义菜单；\nbeforeunload 事件会在 window 上触发，用意是给开发者提供阻止页面被卸载的机会；\nwindow 的 load 事件会在页面完全加载后触发，而 DOMContentLoaded 事件会在 DOM 树构建完成后立即触发；\nFirefox 和 Opera 开发了一个名为往返缓存（ bfcache， back-forward cache）的功能，此旨在使用浏览器“前进”和“后退”按钮时加快页面之间的切换。\n这个缓存不仅存储页面数据，也存储 DOM 和JavaScript 状态，实际上是把整个页面都保存在内存里。如果页面在缓存中，那么导航到这个页面时就不会触发 load 事件。\nHTML5 增加了 hashchange 事件，用于在 URL 散列值（ URL 最后#后面的部分）发生变化时通知开发者。onhashchange 事件处理程序必须添加给window；\n设备事件\n\n苹果公司在移动 Safari 浏览器上创造了 orientationchange 事件，以方便开发者判断用户的设备是处于垂直模式还是水平模式。\nDeviceOrientationEvent 规范定义的事件。如果可以获取设备的加速计信息，而且数据发生了变化，这个事件就会在 window 上触发；\ndevicemotion 事件。这个事件用于提示设备实际上在移动，而不仅仅是改变了朝向。\n\n触摸及手势事件\nWebKit 也为 Android 定制了很多专有事件，成为了事实标准，并被纳入 W3C 的 Touch Events 规范；\n\n\ntouchstart：手指放到屏幕上时触发（即使有一个手指已经放在了屏幕上）。\n\n\ntouchmove：手指在屏幕上滑动时连续触发。在这个事件中调用 preventDefault() 可以阻止滚动；\n\n\n只有在两个手指同时接触事件接收者时，这些事件才会触发。在一个元素上设置事件处理程序，意味着两个手指必须都在元素边界以内才能触发手势事件：\n\ngesturestart：一个手指已经放在屏幕上，再把另一个手指放到屏幕上时触发。\ngesturechange：任何一个手指在屏幕上的位置发生变化时触发。\ngestureend：其中一个手指离开屏幕时触发。\n\n内存与性能\n“过多事件处理程序”的解决方案是使用事件委托。事件委托利用事件冒泡，可以只使用一个事件处理程序来管理一种类型的事件。\n使用事件委托，只要给所有元素共同的祖先节点添加一个事件处理程序；\n\ndocument 对象随时可用，任何时候都可以给它添加事件处理程序 ；\n节省 DOM 引用，也可以节省时间；\n减少页面的内存，提升性能；\n\n除了通过事件委托来限制这种连接之外，还应该及时删除不用的事件处理程序；\n被 innerHTML 删除的元素上如果有事件处理程序，就不会被垃圾收集程序正常清\n理；\n在事件处理程序中删除按钮会阻止事件冒泡；只有事件目标仍然存在于文档中时，事\n件才会冒泡。\n最好在 onunload 事件处理程序中趁页面尚未卸载先删除所有事件处理程序。\n模拟事件\n任何时候，都可以使用 document.createEvent()方法创建一个 event 对象，创建 event 对象之后，需要使用事件相关的信息来初始化；\n事件模拟的最后一步是触发事件。为此要使用 dispatchEvent()方法，\nDOM3 增加了自定义事件的类型。自定义事件不会触发原生 DOM 事件，但可以让开发者定义自己的 事 件 。 要 创 建 自 定 义 事 件 ， 需 要 调 用 createEvent(“CustomEvent”) 。 返 回 的 对 象 包 含 initCustomEvent()方法"},"front-end/javascript/red-book/form":{"title":"form","links":[],"tags":[],"content":"\n\n有几种方式可以取得对 &lt;form&gt; 元素的引用。最常用的是将表单当作普通元素为它指定一个 id 属性，从而可以使用 getElementById()来获取表单；\n\n\nfocus()方法把浏览器焦点设置到表单字段，这意味着该字段会变成活动字段并可以响应键盘事件。\n\n\nfocus()的反向操作是 blur()，其用于从元素上移除焦点。\n\n\n对于&lt;input&gt;和&lt;textarea&gt;元素， change 事件会在字段失去焦点，同时 value 自控件获得焦点后发生变化时触发。对于&lt;select&gt;元素， change 事件会在用户改变了选中项时触发，不需要控件失去焦点。\n\n\n&lt;input&gt;元素size 属性指定文本框的宽度，这个宽度是以字符数来计量的；\n\n\n&lt;textarea&gt;的初始值必须包含在&lt;textarea&gt;和&lt;/textarea&gt;之间；\n\n\n应该使用 value 属性，而不是标准 DOM 方法读写文本框的值；\n\n\n剪贴板上的数据可以通过 window 对象（ IE）或 event 对象（ Firefox、 Safari 和 Chrome）上的 clipboardData 对象来获取。\n\n\n在 Firefox、 Safari 和 Chrome 中，为防止未经授权访问剪贴板，只能在剪\n贴板事件期间访问 clipboardData 对象；\n\n\nHTML5 为文本字段新增了 pattern 属性。这个属性用于指定一个正则表达式；\n\n\n使用 checkValidity()方法可以检测表单中任意给定字段是否有效；\n\n\nvalidity 属性会告诉我们字段为什么有效或无效。这个属性是一个对象，包含一系列返回布尔值的属性；\n\n\n通过指定 novalidate 属性可以禁止对表单进行任何验证；\n\n\n\n\n富文本编辑的基本技术就是在空白 HTML 文件中嵌入一个iframe。通过 designMode 属性，可以将这个空白文档变成可以编辑的，实际编辑的则是&lt;body&gt;元素的 HTML；\n可以给页面中的任何元素指定 contenteditable 属性，然后该元素会立即被用户编辑；\n通过表单提交富文本，通常的解决方案是在表单中添加一个隐藏字段，使用内嵌窗格或\ncontenteditable 元素的 HTML 更新它的值；\n"},"front-end/javascript/red-book/javascript-api":{"title":"javascript-api","links":[],"tags":[],"content":"Atomics与SharedArrayBuffer\n多个上下文访问SharedArrayBuffer时，如果同时对缓冲区执行操作，就可能出现资源争用问题；\nAtomicsAPI通过强制同一时刻只能对缓冲区执行一个操作，可以让多个上下文安全地读写一个SharedArrayBuffer；\n\n原子操作的本质会排斥操作系统或计算机硬件通常会自动执行的优化；\n原子操作也让并发访问内存变得不可能；\n\n\nSharedArrayBuffer与ArrayBuffer具有同样的API：\n\nArrayBuffer必须在不同执行上下文间切换；\nSharedArrayBuffer则可以被任意多个执行上下文同时使用；\n\n传统JavaScript操作对于并发内存访问导致的资源争用没有提供保护，\n在底层，这些方法都会从SharedArrayBuffer中某个位置读取值，Atomics对象上暴露了用于执行线程安全操作的一套静态方法；\n在底层，这些方法都会从SharedArrayBuffer中某个位置读取值，然后执行算术或位操作，最后再把计算结果写回相同的位置。\n这些操作的原子本质意味着上述读取、修改、写回操作会按照顺序执行，不会被其他线程中断。\n浏览器的JavaScript编译器和CPU架构本身都有权限重排指令以提升程序执行效率。\n正常情况下，JavaScript的单线程环境是可以随时进行这种优化的。但多线程下的指令重排可能导致资源争用，而且极难排错。\n\nAtomicsAPI通过两种主要方式解决了这个问题。\n\n所有原子指令相互之间的顺序永远不会重排；\n使用原子读或原子写保证所有指令（包括原子和非原子指令）都不会相对原子读/写重新排序；\n\n这意味着位于原子读/写之前的所有指令会在原子读/写发生前完成，而位于原子读/写之后的所有指令会在原子读/写完成后才会开始；\n除了读写缓冲区的值，Atomics.load() 和 Atomics.store() 还可以构建“代码围栏”。JavaScript引擎保证非原子指令可以相对于 load() 或 store() 本地重排，但这个重排不会侵犯原子读/写的边界；\n\n为了保证连续、不间断的先读后写，AtomicsAPI 提供了两种方法\n\nAtomics.exchange() 执行简单的交换，以保证其他线程不会中断值的交换；\ncompareExchange()方法只在目标索引处的值与预期值匹配时才会执行写操作；\n\n如果没有某种锁机制，多线程程序就无法支持复杂需求，Atomics API 提供了模仿 Linux Futex（ 快速用户空间互斥量， fast user-space mutex）的方法：Atomics.wait()和 Atomics.notify() ；\nAtomics API 还提供了 Atomics.isLockFree()方法，在高性能算法中可以用来确定是否有必要获取锁；\n跨上下文消息\n跨文档消息，有时候也简称为 XDM（ cross-document messaging），是一种在不同执行上下文（如不同工作线程或不同源的页面）间传递信息的能力；\nXDM 的核心是 postMessage() 方法；\nlet iframeWindow = document.getElementById(&quot;myframe&quot;).contentWindow;\niframeWindow.postMessage(&quot;A secret&quot;, &quot;www.wrox.com&quot;);\n如果源匹配，那么消息将会交付到内嵌窗格；否则， postMessage()什么也不做。\n接收到 XDM 消息后， window 对象上会触发 message 事件。  事件对象包括：\n\ndata：作为第一个参数传递给 postMessage()的字符串数据。\norigin：发送消息的文档源，例如”www.wrox.com”。\nsource：发送消息的文档中 window 对象的代理。\n\nEncodingAPI\nEncoding API 主要用于实现字符串与定型数组之间的转换。规范新增了 4 个用于执行转换的全局类：TextEncoder、 TextEncoderStream、 TextDecoder 和 TextDecoderStream。\nEncoding API 提供了两种将字符串转换为定型数组二进制格式的方法：批量编码和流编码 ；\n\n批量指的是 JavaScript 引擎会同步编码整个字符串，通过 TextEncoder 的实例完成的；\nTextEncoderStream 其实就是 TransformStream 形式的 TextEncoder。将解码后的文本流通过管道输入流编码器会得到编码后文本块的流。\n\nFileAPI与BlobAPI\nFileReader 类型表示一种异步文件读取机制，progress 事件每 50 毫秒就会触发一次；\nblob 表示二进制大对象（ binary larget object），是 JavaScript 对不可修改二进制数据的封装类型。\nBlob 对象有一个 size 属性和一个 type 属性，还有一个 slice()方法用于进一步切分数据。\n要创建对象 URL，可以使用 window.URL.createObjectURL()方法并传入 File 或 Blob 对象。\n拖放文件会触发 drop 事件。被放置的文件可以通过事件的 event.dataTransfer.files 属性读到 ；\n媒体元素\nHTML5 新增了两个与媒体相关的元素，即&lt;audio&gt;和&lt;video&gt;，从而为浏览器提\n供了嵌入音频和视频的统一解决方案；\n使用&lt;audio&gt;和&lt;video&gt;的 play() 和 pause()方法，可以手动控制媒体文件的播放；\n这两个媒体元素都有一个名为 canPlayType()的方法，该方法接收一个格式/编解码器字符串，返回一个字符串值： “probably”、 “maybe”或&quot;&quot;（空字符串）；\n&lt;audio&gt;元素还有一个名为 Audio 的原生 JavaScript 构造函数，创建 Audio 的新实例就会开始下载指定的文件。下载完毕后，可以调用 play() 来播放音频。\n原生拖放\nHTML5 在 IE 的拖放实现基础上标准化了拖放功能。所有主流浏览器都根据 HTML5 规范实现了原生的拖放。\n在某个元素被拖动时，会（按顺序）触发以下事件：dragstart，drag，dragend；\n拖动开始后，大多数浏览器此时会创建元素的一个半透明副本，始终跟随在光标下方。\n在把某个元素拖动到无效放置目标上时，会看到一个特殊光标（圆环中间一条斜杠）表示不能放下。\n通过覆盖 dragenter 和 dragover 事件的默认行为，可以把任何元素转换为有效的放置目标；\n在 Firefox 中，放置事件的默认行为是导航到放在放置目标上的 URL。\nevent 的属性中的 dataTransfer 对象，用于从被拖动元素向放置目标传递字符串数据：\n\ndataTransfer 对象有两个主要方法： getData()和 setData()；\nHTML5 已经将其扩展为允许任何 MIME 类型；\n\n在从文本框拖动文本时，浏览器会调用 setData()并将拖动的文本以”text”格式存储起来。  在拖动链接或图片时，浏览器会调用 setData()并把 URL 存储起来；\ndataTransfer 对象不仅可以用于实现简单的数据传输，还可以用于确定能够对被拖动元素和放置目标执行什么操作。\n可以使用两个属性： dropEffect 与 effectAllowed：\n\ndropEffect 属性可以告诉浏览器允许哪种放置行为，除非同时设置 effectAllowed，否则 dropEffect 属性也没有用  ；\neffectAllowed 属性表示对被拖动元素是否允许 dropEffect，必须在 ondragstart 事件处理程序中设置这个属性；\n\n默认情况下，图片、链接和文本是可拖动的，这意味着无须额外代码用户便可以拖动它们；\nHTML5 在所有 HTML 元素上规定了一个 draggable 属性，表示元素是否可以拖动；\nNotificationAPI\nNotifications API 用于向用户显示通知。\nNotifications API 在 Service Worker 中非常有用。渐进 Web 应用（ PWA， Progressive Web Application）通过触发通知可以在页面不活跃时向用户显示消息，看起来就像原生应用。\n默认会开启两项安全措施：\n\n通知只能在运行在安全上下文的代码中被触发；\n通知必须按照每个源的原则明确得到用户允许。\n\n一旦拒绝，就无法通过编程方式挽回，因为不可能再触发授权提示；\nNotifications API 提供了 4 个用于添加回调的生命周期方法：\n\nonshow 在通知显示时触发；\nonclick 在通知被点击时触发；\nonclose 在通知消失或通过 close()关闭时触发；\nonerror 在发生错误阻止通知显示时触发。\n\nPageVisibilityAPI\nWeb 开发中一个常见的问题是开发者不知道用户什么时候真正在使用页面。  Page Visibility API 旨在为开发者提供页面对用户是否可见的信息。\ndocument.visibilityState 值，表示下面 4 种状态之一。\n\n页面在后台标签页或浏览器中最小化了；\n页面在前台标签页中；\n实际页面隐藏了，但对页面的预览是可见的（例如在 Windows 7 上，用户鼠标移到任务栏图标上会显示网页预览）；\n页面在屏外预渲染；\n\nvisibilitychange 事件，该事件会在文档从隐藏变可见（或反之）时触发；\ndocument.hidden 布尔值，表示页面是否隐藏\nStreamAPI\nWeb 应用如何消费有序的小信息块而不是大块信息？\n\n大块数据可能不会一次性都可用；\n大块数据可能需要分小部分处理；\n\nStream API 直接解决的问题是处理网络请求和读写磁盘。\n\n可读流：数据在内部从底层源进入流，然后由**消费者（ consumer）**进行处理；\n可写流： 生产者（ producer）将数据写入流，数据在内部传入底层数据槽（sink）。\n转换流：由两种流组成，可写流用于接收数据（可写端），可读流用于输出数据（可读端）。这\n两个流之间是转换程序（ transformer），可以根据需要检查和修改流内容；\n\n所有流都会为已进入流但尚未离开流的块提供一个内部队列；\n\n流不能允许其内部队列无限增大，因此会使用**反压（ backpressure）**通知流入口停止发送数据；\n这个策略定义了内部队列可以占用的最大内存，即高水位线（ high water mark）；\n\n一个 ReadableStreamDefaultReader 的实例，可以通过流的 getReader()方法获取。调用这个方法会获得\n流的锁，保证只有这个读取器可以从流中读取值：\n数据写入流，可以通过流的 getWriter()方法获取 WritableStreamDefaultWriter 的实例。\n\n在向流中写入数据前，生产者必须确保写入器可以接收值；\n\n转换流用于组合可读流和可写流 ，数据块在两个流之间的转换是通过 TransformStream 的实例的 transform() 方法完成的；\n流可以通过管道连接成一串。最常见的用例是使用 pipeThrough()方法把 ReadableStream 接入 TransformStream。\n计时API\n\nwindow.performance.now() 这个方法返回一个微秒精度的浮点值，采用相对度量，即在执行上下文创建时从 0 开始计时；\n\n不同上下文之间如果没有共享参照点则不可能直接比较；\nperformance.timeOrigin 属性返回计时器初始化时全局系统时钟的值；\n\n\n在一个执行上下文中被记录的所有性能条目可以通过 performance.getEntries() 获取\n\n返回的集合代表浏览器的性能时间线（ performance timeline）\n\n\nUser Timing API 用于记录和分析自定义性能条目；\n\n即使用 performance.mark() 方法，  在计算开始前和结束后各创建一个自定义性能条目可以计算时间差。\n最新的标记（ mark）会被推到 getEntriesByType()返回数组；\n由 performance.measure() 方法生成   PerformanceMeasure（性能度量）条目，对应由名字作为标识的两个标记之间的持续时间；\n\n\nNavigation Timing API 提供了高精度时间戳，用于度量当前页面加载速度：\n\n浏览器会在导航事件发生时自动记录 PerformanceNavigationTiming 条目；\nconst [performanceNavigationTimingEntry] = performance.getEntriesByType(&#039;navigation&#039;);  \n\n\nResource Timing API 提供了高精度时间戳，用于度量当前页面加载时请求资源的速度：\n\n浏览器会在加载资源时自动记录 PerformanceResourceTiming；\n这个对象会捕获大量时间戳，用于描述资源加载的速度；\n\n\n\nWeb组件\nWeb 组件指的是一套用于增强 DOM 行为的工具，包括影子 DOM、自定义\n元素和 HTML 模板。\n一直缺少基于 HTML 解析构建 DOM 子树，然后在需要时再把这个子树渲染出\n来的机制：\n\n使用 innerHTML 把标记字符串转换为 DOM 元素；\n使用 document.createElement()构建每个元素；\n\n使用 DocumentFragment 可以一次性添加所有子节点，最多只会有一次布局重排；\nconst fragment = new DocumentFragment();\nfragment.appendChild(document.createElement(&#039;p&#039;));\n脚本执行可以推迟到将 DocumentFragment 的内容实际添加到 DOM 树；\n\n影子 DOM（ shadow DOM） Web 组件可以将一个完整的 DOM 树作为\n节点添加到父 DOM 树；\n影子 DOM 与 HTML 模板很相似，因为它们都是类似 document 的结构，影子 DOM 的内容会实际渲染到页面上，而 HTML 模板的内容不会；\n\n把 CSS 限制在使用它们的 DOM 上：这正是影子 DOM 最初的使用场景；\n\n影子 DOM 是通过 attachShadow()方法创建并添加给有效 HTML 元素的。\n\n\n容纳影子 DOM 的元素被称为影子宿主（ shadow host）；\n\n\n影子 DOM 的根节点被称为影子根（ shadow root）；\n\n\nWebCryptographyAPI\nWeb Cryptography API 描述了一套密码学工具，规范了 JavaScript 如何以安全和符合惯例的方式实现加密；\n\ncrypto.getRandomValues() 在全局 Crypto 对象上访问，把随机值写入作为参数传给它的定型数组 ；\n通过 window.crypto.subtle 访问 SubtleCrypto 对象，用于执行常见的密码学功能，如加密、散列、签名和生成密钥；\n使用 SubtleCrypto.generateKey()方法可以生成随机 CryptoKey；\n如果密钥是可提取的，那么就可以在 CryptoKey 对象内部暴露密钥原始的二进制内容；\n使用 SubtleCrypto 对象可以通过可配置的属性从已有密钥获得新密钥；\n通过 SubtleCrypto 对象可以使用公钥算法用私钥生成签名，或者用公钥验证签名；\nSubtleCrypto 对象支持使用公钥和对称算法加密和解密消息；\n"},"front-end/javascript/red-book/promise":{"title":"promise","links":[],"tags":[],"content":"Promise 基础\n以往的异步编程模式，常使用用回调函数，但是串联多个异步操作时，会出现“回调地狱”；\n2010 年， CommonJS 项目实现的 Promises/A 规范日益流行起来； Q 和 Bluebird 等第三方 JavaScript 期约库也在社区中广泛使用；\nECMAScript 6 增加了对 Promises/A+ 规范的完善支持，即 Promise 类型；\n\n\nPromise 三种状态，哪种状态都是不可逆的；\nPromise 的状态是私有的，不能直接通过 JavaScript 检测或修改；\nPromise.resolve() 将任何值包装为一个resolved 的 Promise ，传入 Promise 对象，则是一个幂等操作；\nPromise.reject() 类似于 resolve() ，只不过传入 Promise 会会成为其 rejected 的理由；\n\nPromise.prototype.then() 返回一个新的 Promise 实例：\n\n如果没有提供这个处理程序，则 Promise.resolve() 就会包装上一个 Promise resolve 之后的值；\n如果没有显式的返回语句，则 Promise.resolve() 会包装默认的返回值 undefined ；\n抛出异常会返回 rejected 的 Promise ，返回错误对象则会被包装在一个 resolved 的 Promise 中；\nonRejected 处理程序返回的值也会被 Promise.resolve() 包装，在捕获错误后不抛出异常是符合 Promise 的行为，应该返回一个 resolved 的 Promise；\n\nPromise.prototype.catch()   用于给 Promise 添加 reject 处理程序：\n\n一个语法糖，调用它就相当于调用 Promise.prototype.then(null, onRejected)；\n\nPromise.prototype.finally() 用于给 Promise 添加 onFinally 处理程序：\n\n这个处理程序在 Promise 转换为 resolved 或 rejected 状态时都会执行；\nonFinally 处理程序没有办法知道 Promise 具体状态，所以这个方法主要用于添加清理代码；\n如果返回的是一个待定的期约，或者 onFinally 处理程序抛出了错误（显式抛出或返回了一个拒\n绝期约），则会返回相应的期约（待定或拒绝）；\n返回 pending 的 Promise 的情形并不常见，这是因为只要内部的 Promise resolve 了，仍然会原样后传初始的Promise；\n\n非重入方法\n当 Promise 状态改变时，与该状态相关的处理程序会被排期，而非立即执行；\n这个特性由 JavaScript 运行时保证，被称为“非重入”（ non-reentrancy）特性；\nlet synchronousResolve;\n \nlet p = new Promise((resolve) =&gt; {\n    synchronousResolve = function() {\n        console.log(&#039;1: invoking resolve()&#039;);\n        resolve();\n        console.log(&#039;2: resolve() returns&#039;);\n    };\n});\np.then(() =&gt; console.log(&#039;4: then() handler executes&#039;));\nsynchronousResolve();\nconsole.log(&#039;3: synchronousResolve() returns&#039;);\n \n// 实际的输出：\n// 1: invoking resolve()\n// 2: resolve() returns\n// 3: synchronousResolve() returns\n// 4: then() handler executes\n处理程序的执行顺序\n如果给 Promise 添加了多个处理程序，当其状态变化时，相关处理程序会按照添加它们的顺序依次执行；\n无论是 then()、 catch() 还是 finally() 添加的处理程序都是如此 ；\nlet p1 = Promise.resolve();\nlet p2 = Promise.reject();\np1.then(() =&gt; setTimeout(console.log, 0, 1));\np1.then(() =&gt; setTimeout(console.log, 0, 2));\n// 1\n// 2\n错误处理\nPromise 可以以任何理由拒绝，包括 undefined，但最好统一使用错误对象。这样做主要是因为创建错误对象可以让浏览器捕获错误对象中的栈追踪信息；\n在 Promise 中抛出错误时，错误实际上是从消息队列中异步抛出的，所以并不会阻止运行时继续执行同步指令  ；\n异步错误只能通过异步的 onRejected 处理程序捕获；这不包括捕获执行函数中的错误，在 resolve 或 reject Promise 之前，仍然可以使用 try/catch 在执行函数中捕获错误；\nthen() 和 catch() 的 onRejected 处理程序在语义上相当于 try/catch， onRejected 处理程序的任务应该是在捕获异步错误之后返回一个 resolved 的 Promise；\n扩展取消和通知\n&lt;button id=&quot;start&quot;&gt;Start&lt;/button&gt;\n&lt;button id=&quot;cancel&quot;&gt;Cancel&lt;/button&gt;\n \n&lt;script&gt;\n    class CancelToken {\n        constructor(cancelFn) {\n            this.promise = new Promise((resolve, reject) =&gt; {\n                cancelFn(() =&gt; {\n                    setTimeout(console.log, 0, &quot;delay cancelled&quot;);\n                    resolve();\n                });\n            });\n        }\n    }\n    const startButton = document.querySelector(&#039;#start&#039;);\n    const cancelButton = document.querySelector(&#039;#cancel&#039;);\n    \n    function cancellableDelayedResolve(delay) {\n        setTimeout(console.log, 0, &quot;set delay&quot;);\n        return new Promise((resolve, reject) =&gt; {\n            const id = setTimeout((() =&gt; {\n                setTimeout(console.log, 0, &quot;delayed resolve&quot;);\n                resolve();\n            }), delay);\n            \n            const cancelToken = new CancelToken((cancelCallback) =&gt;\n                                                cancelButton.addEventListener(&quot;click&quot;, cancelCallback));\n            cancelToken.promise.then(() =&gt; clearTimeout(id));\n        });\n    }\n    startButton.addEventListener(&quot;click&quot;, () =&gt; cancellableDelayedResolve(1000));\n&lt;/script&gt;\n \n每次单击“Start”按钮都会开始计时，并实例化一个新的 CancelToken 的实例。\n此时，“Cancel” 按钮一旦被点击，就会触发令牌实例中的 Promise resolve。\n而解决之后，单击“Start”按钮设置的超时也会被取消；\n\nclass TrackablePromise extends Promise {\n    constructor(executor) {\n        const notifyHandlers = [];\n        super((resolve, reject) =&gt; {\n            return executor(resolve, reject, (status) =&gt; {\n                notifyHandlers.map((handler) =&gt; handler(status));\n            });\n        });\n        this.notifyHandlers = notifyHandlers;\n    }\n    notify(notifyHandler) {\n        this.notifyHandlers.push(notifyHandler);\n        return this;\n    }\n}\n \nlet p = new TrackablePromise((resolve, reject, notify) =&gt; {\n    function countdown(x) {\n        if (x &gt; 0) {\n            notify(`${20 * x}% remaining`);\n            setTimeout(() =&gt; countdown(x - 1), 1000);\n        } else {\n            resolve();\n        }\n    }\n    countdown(5);\n});\n \np.notify((x) =&gt; setTimeout(console.log, 0, &#039;progress:&#039;, x));\np.then(() =&gt; setTimeout(console.log, 0, &#039;completed&#039;));\n \n// （约 1 秒后） 80% remaining\n// （约 2 秒后） 60% remaining\n// （约 3 秒后） 40% remaining\n// （约 4 秒后） 20% remaining\n// （约 5 秒后） completed\nES6 不支持取消 Promise 和进度通知，一个主要原因就是过度复杂化了；\n连锁的 Promise 和 Promise.all() 中的某一个取消了或者发出了通知，那么接下来应该发生什么完全说不清楚；"},"front-end/javascript/red-book/recursion":{"title":"recursion","links":[],"tags":[],"content":"\narguments.callee 就是一个指向正在执行的函数的指针，因此可以在函数内部递归调用；\n尾调用优化：即外部函数的返回值是一个内部函数的返回值，引擎会在函数调用过程中，将没必要的栈帧弹出；优化有如下几个要求：\n\n代码在严格模式下执行；\n外部函数的返回值是对尾调用函数的调用；\n尾调用函数返回后不需要执行额外的逻辑；\n尾调用函数不是引用外部函数作用域中自由变量的闭包；\n\n\n\n尾调用优化的斐波那契函数代码：\n&quot;use strict&quot;;\n// 基础框架\nfunction fib(n) {\nreturn fibImpl(0, 1, n);\n}\n// 执行递归\nfunction fibImpl(a, b, n) {\nif (n === 0) {\nreturn a;\n}\nreturn fibImpl(b, a + b, n - 1);\n}"},"front-end/javascript/red-book/request-and-remote-source":{"title":"request&remote-source","links":[],"tags":[],"content":"2005 年， Jesse James Garrett 撰写的文章中描绘了一个被他称作 Ajax（ Asynchronous JavaScript+XML，即异步 JavaScript 加 XML）的技术，涉及发送服务器请求额外数据而不刷新页面；\n\n把 Ajax 推到历史舞台上的关键技术是 XMLHttpRequest（ XHR）对象；\n这个技术主要是可以实现在不刷新页面的情况下从服务器获取数据，格式并不一定是 XML ；\nXHR 对象的 API 被普遍认为比较难用，而 Fetch API （支持期约（ promise）和服务线程（ service worker）自从诞生以后就迅速成为了 XHR 更现代的替代标准。\n\nXMLHttpRequest 对象\n通过 XMLHttpRequest 构造函数原生支持 XHR 对象：\n\n调用 open()不会实际发送请求，只是为发送请求做好准备；\nsend()方法接收一个参数，是作为请求体发送的数据；\n多数情况下最好使用异步请求，这样可以不阻塞 JavaScript 代码继续执行；\n每次 readyState 从一个值变成另一个值，都会触发 readystatechange 事件；\n在收到响应之前如果想取消异步请求，可以调用 abort() 方法；\n\n\n默认情况下， XHR 请求会发送以下头部字段：\n\n\nAccept：浏览器可以处理的内容类型。\n\n\nAccept-Charset：浏览器可以显示的字符集。\n\n\nAccept-Encoding：浏览器可以处理的压缩编码类型。\n\n\nAccept-Language：浏览器使用的语言。\n\n\nConnection：浏览器与服务器的连接类型。\n\n\nCookie：页面中设置的 Cookie。\n\n\nHost：发送请求的页面所在的域。\n\n\nReferer：发送请求的页面的 URI。注意，这个字段在 HTTP 规范中就拼错了，所以考虑到兼容\n性也必须将错就错。（正确的拼写应该是 Referrer）\n\n\nUser-Agent：浏览器的用户代理字符串\n\n\n如果需要发送额外的请求头部，可以使用 setRequestHeader() 方法；\n\n\n必须在 open()之后、 send()之前调用 setRequestHeader() ；\n\n\n有些浏览器允许重写默认头部，有些浏览器则不允许；\n\n\n最常用的请求方法是 GET 请求，用于向服务器查询某些信息：\n\n查询字符串中的每个名和值都必须使用 encodeURIComponent() 编码；\n\nPOST 请求，用于向服务器发送应该保存的数据：\n\n使用 XHR 模拟表单提交。为此，第一步需要把 ContentType 头部设置为&quot;application/x-www-formurlencoded&quot; ；\n\nXMLHttpRequest Level 1 只是把已经存在的 XHR 对象的实现细节明确了一下。 XMLHttpRequest Level 2\n又进一步发展了 XHR 对象；\n\nXMLHttpRequest Level 2 新增了 FormData 类型；\nFormData 实例可直接传给 XHR 对象的 send()方法，不再需要给 XHR 对象显式设置任何请求头部了；\n在给 timeout 属性设置了一个时间且在该时间过后没有收到响应时， XHR 对象就会触发 timeout 事件；\nFirefox 首先引入了 overrideMimeType() 方法用于重写 XHR 响应的 MIME 类型，必须在调用 send() 之前调用 overrideMimeType()；\n\n进度事件\n这些事件最初只针对 XHR，现在也推广到了其他类似的 API：\n\nloadstart：在接收到响应的第一个字节时触发。\nprogress：在接收响应期间反复触发。\nerror：在请求出错时触发。\nabort：在调用 abort() 终止连接时触发。\nload：在成功接收完响应时触发。\nloadend：在通信完成时，且在 error、 abort 或 load 之后触发\n\nload 事件在响应接收完成后立即触发，这样就不用检查 readyState 属性：\n\nonload 事件处理程序会收到一个 event 对象，其 target 属性设置为 XHR 实例\n\nMozilla 在 XHR 对象上另一个创新是 progress 事件：\n\n事件的 event 对象，其 target 属性是 XHR 对象，且包含 3 个额外属性： lengthComputable、 position 和 totalSize，分别表示进度信息是否可用、接收到的字节数；、响应的 ContentLength 头部定义的总字节数；\n有了这些信息，就可以给用户提供进度条了；\n\n跨源资源共享\n通过 XHR 进行 Ajax 通信的一个主要限制是跨源安全策略。\n跨源资源共享（ CORS， Cross-Origin Resource Sharing）定义了浏览器与服务器如何实现跨源通信。\n基本思路就是使用自定义的 HTTP 头部允许浏览器和服务器相互了解，以确实请求或响应应该成功还是失败。\n\n发送请求时，没有自定义头部，则会创建一个 Origin 头部，包含发送请求的页面的源（协议、域名和端口）；\n如果服务器决定响应请求，那么应该发送 Access-Control-Allow-Origin 头部，包含相同的源；\n如果资源是公开的，那么就包含”*”  ；\n\n现代浏览器通过 XMLHttpRequest 对象原生支持 CORS ；出于安全考虑，跨域 XHR 对象也施加了一些额外限制：\n\n不能使用 setRequestHeader()设置自定义头部。\n不能发送和接收 cookie。\ngetAllResponseHeaders()方法始终返回空字符串。\n\n\n某些请求不会触发CORS 预检请求，称为简单请求；若请求满足所有下述条件，则该请求可视为简单请求：\n\n使用下列方法之一：GET、HEAD、POST\n除了被用户代理自动设置的头部字段（例如Connection，User-Agent）和在 Fetch 规范中定义为禁用头部名称 的其他头部，允许人为设置的字段为 Fetch 规范定义的对 CORS 安全的头部字段集合。该集合为：\n\nAccept\nAccept-Language\nContent-Language\nContent-Type（需要注意额外的限制）\n\n\nContent-Type 的值仅限于下列三者之一：\n\ntext/plain\nmultipart/form-data\napplication/x-www-form-urlencoded\n\n\n请求中的任意 XMLHttpRequest对象均没有注册任何事件监听器；XMLHttpRequest对象可以使用 XMLHttpRequest.upload属性访问。\n请求中没有使用 ReadableStream对象。\n\n\n跨源资源共享标准新增了一组 HTTP 头部字段，允许服务器声明哪些源站通过浏览器有权限访问哪些资源。\n另外，规范要求，对那些可能对服务器数据产生副作用的 HTTP 请求方法（特别是 GET 以外的 HTTP 请求，或者搭配某些 MIME 类型 的 POST 请求），浏览器必须首先使用 OPTIONS 方法发起一个预检请求（preflight request），从而获知服务端是否允许该跨源请求；\n服务器确认允许之后，才发起实际的 HTTP 请求。在预检请求的返回中，服务器端也可以通知客户端，是否需要携带身份凭证（包括 Cookies 和 HTTP 认证 相关数据）。\n与前述简单请求不同，“需预检的请求”要求必须首先使用 OPTIONS 方法发起一个预检请求到服务器，以获知服务器是否允许该实际请求。预检请求的使用，可以避免跨域请求对服务器的用户数据产生未预期的影响。\n预检请求可以查询允许使用的自定义头部、除 GET 和 POST 之外的方法，以及可发送的不同请求体内容类型。\n服务器会通过在预检请求响应中发送如下头部信息：\n\nAccess-Control-Allow-Origin：与简单请求相同。\nAccess-Control-Allow-Methods：允许的方法（逗号分隔的列表）。\nAccess-Control-Allow-Headers：服务器允许的头部（逗号分隔的列表）。\nAccess-Control-Max-Age：缓存预检请求的秒数\n\n在Access-Control-Max-Age有效时间内，浏览器无须为同一请求再次发起预检请求。\n请注意，浏览器自身维护了一个 最大有效时间，如果该首部字段的值超过了最大有效时间，将不会生效。\n当响应的是附带身份凭证的请求时，服务端必须明确 Access-Control-Allow-Origin 的值，而不能使用通配符*；\n\n默认情况下，跨源请求不提供凭据（ cookie、 HTTP 认证和客户端 SSL 证书）。可以通过将 withCredentials 属性设置为 true 来表明请求会发送凭据。\n但是，如果服务器端的响应中未携带 Access-Control-Allow-Credentials: true，浏览器将不会把响应内容返回给请求的发送者（ responseText 是空字符串， status 是 0， onerror()被调用） 。\nCORS 预检请求不能包含凭据。预检请求的响应必须指定 Access-Control-Allow-Credentials: true 来表明可以携带凭据进行实际的请求；\n替代性跨源技术\n图片探测（ image pings）是利用 &lt;img&gt; 标签实现跨域通信的最早的一种技术。任何页面都可以跨域加载图片而不必担心限制；可以通过监听 onload 和 onerror 事件知道什么时候能接收到响应；\nimg.src = &quot;www.example.com/test\n图片探测频繁用于跟踪用户在页面上的点击操作或动态显示广告。当然，图片探测的缺点是只能发\n送 GET 请求和无法获取服务器响应的内容；\nJSONP 是“JSON with padding”的简写，JSONP 格式包含两个部分：回调和数据，JSONP 服务通常支持以查询字符串形式指定回调函数的名称；\nJSONP 服务通常支持以查询字符串形式指定回调函数的名称；JSONP 响应在被加载完成之后会立即执行；\nfunction handleResponse(response) {\nconsole.log(`\nYou&#039;re at IP address ${response.ip}, which is in\n${response.city}, ${response.region_name}`);\n}\nlet script = document.createElement(&quot;script&quot;);\nscript.src = &quot;freegeoip.net/json/\ndocument.body.insertBefore(script, document.body.firstChild);\n\nJSONP 是从不同的域拉取可执行代码。如果这个域并不可信，则可能在响应中加入恶意内容；\n不好确定 JSONP 请求是否失败。虽然 HTML5 规定了元素的 onerror 事件处理程序，但还没有被任何浏览器实现；\n\nFetch API\nFetch API 能够执行 XMLHttpRequest 对象的所有任务，但更容易使用，接口也更现代化，能够在\nWeb 工作线程等现代 Web 工具中使用：\n\n\nXMLHttpRequest 可以选择异步，而 Fetch API 则必须是异步；\n\n\nfetch()方法是暴露在全局作用域中的，包括主页面执行线程、模块和工作线程\n\n\nFetch API 支持通过 AbortController/AbortSignal 对中断请求。调用 AbortController.abort()会中断所有网络传输，特别适合希望停止传输大型负载的情况。\nlet abortController = new AbortController();\nfetch(&#039;wikipedia.zip&#039;, { signal: abortController.signal })\n.catch(() =&gt; console.log(&#039;aborted!&#039;);\n// 10 毫秒后中断请求\nsetTimeout(() =&gt; abortController.abort(), 10);\n// 已经中断\n在初始化 Headers 对象时，也可以使用键/值对形式的对象，而 Map 则不可以；\n\nHeaders 对象使用护卫来防止不被允许的修改；\n在通过构造函数初始化 Request 对象， 对 mode 属性赋值；\n\n使用 Request 构造函数和使用 clone() 方法，可以创建 Request 对象的副本：\n\ninit 对象，则 init 对象的值会覆盖源对象中同名的值；\n第一个请求（赋值请求）的请求体 (bodyUsed) 会被标记为“已使用”  ；\n如果源对象与创建的新对象不同源，则 referrer 属性会被清除；\n使用 clone() 方法，这个方法会创建一模一样的副本；\n如果请求对象的 bodyUsed 属性为 true（即请求体已被读取），这无法再使用上述方式克隆；\n\n在调用 fetch() 时，可以传入已经创建好的 Request 实例而不是 URL：\n\nfetch()也不能拿请求体已经用过的 Request 对象来发送请求；\n想基于包含请求体的相同 Request 对象多次调用 fetch()，必须在第一次发送 fetch()请求前\n调用 clone()；\n\nBeacon API\nBeacon API 给 navigator 对象增加了一个 sendBeacon() 方法；\n\n方法接收一个 URL 和一个数据有效载荷参数，并会发送一个 POST 请求；\n有效载荷参数有 ArrayBufferView、 Blob、 DOMString、 FormData 实例；\n\nnavigator.sendBeacon(&#039;example.com/analytics-reporting-url&#039;, &#039;{foo: &quot;bar&quot;}&#039;);\n\nsendBeacon() 并不是只能在页面生命周期末尾使用，而是任何时候都可以使用；\n调用 sendBeacon()后，浏览器会把请求添加到一个内部的请求队列。浏览器会主动地发送队\n列中的请求。\n浏览器保证在原始页面已经关闭的情况下也会发送请求。\n状态码、超时和其他网络原因造成的失败完全是不透明的，不能通过编程方式处理。\n信标（ beacon）请求会携带调用 sendBeacon()时所有相关的 cookie\n\nWeb Socket\nWeb Socket（套接字）的目标是通过一个长时连接实现与服务器全双工、双向的通信；\n一个 HTTP 请求会发送到服务器以初始化连接。服务器响应后，连接使用 HTTP的 Upgrade 头部从 HTTP 协议切换到 Web Socket 协议；\n客户端与服务器之间可以发送非常少的数据，不会对HTTP 造成任何负担；\n\n必须给 WebSocket 构造函数传入一个绝对 URL。同源策略不适用于 Web Socket；\nWebSocket 对象没有 readystatechange 事件；\n要向服务器发送数据，使用 send()方法并传入一个字符串、 ArrayBuffer 或 Blob ；\n服务器向客户端发送消息时， WebSocket 对象上会触发 message 事件 ；\nWebSocket 对象不支持 DOM Level 2 事件监听器，因此需要使用 DOM Level 0 风格的事件处理；\n只有 close 事件的 event 对象上有额外信息。这个对象上有 3 个额外属性：wasClean、 code 和 reason；\n\n安全\n在未授权系统可以访问某个资源时，可以将其视为跨站点请求伪造（ CSRF， cross-site request forgery）\n攻击。  需要验证请求发送者拥有对资源的访问权限。可以通过如下方式实现：\n\n要求通过 SSL 访问能够被 Ajax 访问的资源。\n要求每个请求都发送一个按约定算法计算好的令牌（ token）\n"},"front-end/javascript/review/await/generator":{"title":"generator","links":[],"tags":[],"content":"ES6 系列之 Babel 将 Generator 编译成了什么样子\nGenerator\nfunction* helloWorldGenerator() {\n  yield &#039;hello&#039;;\n  yield &#039;world&#039;;\n  return &#039;ending&#039;;\n}\n我们打印下执行的结果：\nvar hw = helloWorldGenerator();\n \nconsole.log(hw.next()); // {value: &quot;hello&quot;, done: false}\nconsole.log(hw.next()); // {value: &quot;world&quot;, done: false}\nconsole.log(hw.next()); // {value: &quot;ending&quot;, done: true}\nconsole.log(hw.next()); // {value: undefined, done: true}\nBabel\n具体的执行过程就不说了，我们直接在 Babel 官网的 Try it out 粘贴上述代码，然后查看代码被编译成了什么样子：\n\n需要在 ENV PRESET 中开启 FORCE ALL TRANSFORMS 选项；\n\n/**\n * 省略了 regeneratorRuntime 部分代码\n */\nvar _marked = /*#__PURE__*/ regeneratorRuntime.mark(helloWorldGenerator);\n \nfunction helloWorldGenerator() {\n  return regeneratorRuntime.wrap(\n    function helloWorldGenerator$(_context) {\n      while (1) {\n        switch ((_context.prev = _context.next)) {\n          case 0:\n            _context.next = 2;\n            return &quot;hello&quot;;\n \n          case 2:\n            _context.next = 4;\n            return &quot;world&quot;;\n \n          case 4:\n            return _context.abrupt(&quot;return&quot;, &quot;ending&quot;);\n \n          case 5:\n          case &quot;end&quot;:\n            return _context.stop();\n        }\n      }\n    },\n    _marked,\n    this\n  );\n}\n上述代码中省略了运行时部分，源代码是 Facebook 编写的一个工具：regenerator/runtime.js at main · facebook/regenerator。\nmark 函数\n编译后的代码第一段是这样的：\nvar _marked = /*#__PURE__*/ regeneratorRuntime.mark(helloWorldGenerator);\n我们查看源码中中 mark 函数的源码：\nexports.mark = function(genFun) {\n    if (Object.setPrototypeOf) {\n        Object.setPrototypeOf(genFun, GeneratorFunctionPrototype);\n    } else {\n        genFun.__proto__ = GeneratorFunctionPrototype;\n        define(genFun, toStringTagSymbol, &quot;GeneratorFunction&quot;);\n    }\n    genFun.prototype = Object.create(Gp);\n    return genFun;\n};\n \n这其中又涉及了 GeneratorFunctionPrototype ，Gp 等变量及define函数，我们也查看下对应的代码：\nvar toStringTagSymbol = $Symbol.toStringTag || &quot;@@toStringTag&quot;;\n \nfunction Generator() {}\nfunction GeneratorFunction() {}\nfunction GeneratorFunctionPrototype() {}\n \nvar Gp = GeneratorFunctionPrototype.prototype =\n    Generator.prototype = Object.create(IteratorPrototype);\nGeneratorFunction.prototype = GeneratorFunctionPrototype;\n \nfunction define(obj, key, value) {\n    Object.defineProperty(obj, key, {\n        value: value,\n        enumerable: true,\n        configurable: true,\n        writable: true\n    });\n    return obj[key];\n}\n这段代码构建了一堆看起来很复杂的关系链，其实这是参照着 ES6 规范 构建的关系链：\n\n图中 +@@toStringTag:s = &#039;Generator&#039; 的就是 Gp，+@@toStringTag:s = &#039;GeneratorFunction&#039; 的就是 GeneratorFunctionPrototype。\n构建关系链的目的在于判断关系的时候能够跟原生的保持一致，就比如：\nfunction* f() {}\nvar g = f();\nconsole.log(g.__proto__ === f.prototype); // true\nconsole.log(g.__proto__.__proto__ === f.__proto__.prototype); // true\n为了简化起见，我们可以把 Gp 先设置为一个空对象，不过正如你在上图中看到的，next()、 throw()、return() 函数都是挂载在 Gp 对象上，实际上，在完整的编译代码中，确实有为 Gp 添加这三个函数的方法：\n// Helper for defining the .next, .throw, and .return methods of the\n// Iterator interface in terms of a single ._invoke method.\nfunction defineIteratorMethods(prototype) {\n    [&quot;next&quot;, &quot;throw&quot;, &quot;return&quot;].forEach(function(method) {\n        define(prototype, method, function(arg) {\n            return this._invoke(method, arg);\n        });\n    });\n}\n// Define Generator.prototype.{next,throw,return} in terms of the\n// unified ._invoke helper method.\ndefineIteratorMethods(Gp);\n归纳起来，mark 即是改变生成器函数的原型为 Gp，简单起见，我们将整个 mark 函数简化为：\nmark = function(genFun) {\n    var generator = Object.create({\n        next: function(arg) {\n            return this._invoke(&#039;next&#039;, arg)\n        }\n    });\n    genFun.prototype = generator;\n    return genFun;\n};\nwrap 函数\n除了设置关系链之外，mark 函数的返回值 genFun 还作为了 wrap 函数的第二个参数传入：\nfunction helloWorldGenerator() {\n    return regeneratorRuntime.wrap(\n        function helloWorldGenerator$(_context) {\n            //...\n        },\n        _marked,\n        this\n    );\n}\n我们再看下 wrap 函数：\nfunction wrap(innerFn, outerFn, self, tryLocsList) {\n    // If outerFn provided and outerFn.prototype is a Generator, \n    // then outerFn.prototype instanceof Generator.\n    var protoGenerator = outerFn &amp;&amp; outerFn.prototype instanceof Generator ? outerFn : Generator;\n    var generator = Object.create(protoGenerator.prototype);\n    var context = new Context(tryLocsList || []);\n \n    // The ._invoke method unifies the implementations of the .next,\n    // .throw, and .return methods.\n    defineProperty(generator, &quot;_invoke&quot;, { value: makeInvokeMethod(innerFn, self, context) });\n \n    return generator;\n}\nexports.wrap = wrap;\n当执行 var hw = helloWorldGenerator(); 的时候，其实执行的是 wrap 函数，wrap  函数返回了 generator，generator 是一个对象，原型是 outerFn.prototype, outerFn.prototype 其实就是 genFun.prototype， genFun.prototype 是一个空对象，原型上有 next() 方法。\n所以当你执行 hw.next() 的时候，执行的其实是 hw 原型的原型上的 next 函数，next 函数执行的又是 hw 的 _invoke 函数：\ndefineProperty(generator, &quot;_invoke&quot;, { value: makeInvokeMethod(innerFn, self, context) });\ninnerFn 就是 wrap 包裹的那个函数，其实就是 helloWordGenerato$ 函数，呐，就是这个函数：\nhelloWorldGenerator$(_context) {\n    while (1)\n        switch ((_context.prev = _context.next)) {\n            case 0:\n                _context.next = 2;\n                return &quot;hello&quot;;\n            case 2:\n                _context.next = 4;\n                return &quot;world&quot;;\n            case 4:\n                return _context.abrupt(&quot;return&quot;, &quot;ending&quot;);\n            case 5:\n            case &quot;end&quot;:\n                return _context.stop();\n        }\n}\n而 context 你可以直接理解为这样一个全局对象：\nvar ContinueSentinel = {};\n \nvar context = {\n  done: false,\n  method: &quot;next&quot;,\n  next: 0,\n  prev: 0,\n  abrupt: function(type, arg) {\n    var record = {};\n    record.type = type;\n    record.arg = arg;\n \n    return this.complete(record);\n  },\n  complete: function(record, afterLoc) {\n    if (record.type === &quot;return&quot;) {\n      this.rval = this.arg = record.arg;\n      this.method = &quot;return&quot;;\n      this.next = &quot;end&quot;;\n    }\n \n    return ContinueSentinel;\n  },\n  stop: function() {\n    this.done = true;\n    return this.rval;\n  }\n};\n每次 hw.next 的时候，就会修改 next 和 prev 属性的值，当在 generator 函数中 return 的时候会执行 abrupt，abrupt 中又会执行 complete，执行完 complete，因为 this.next = end 的缘故，再执行就会执行 stop 函数。\n我们来看下 makeInvokeMethod 函数：\n  function makeInvokeMethod(innerFn, self, context) {\n    var state = GenStateSuspendedStart;\n \n    return function invoke(method, arg) {\n      if (state === GenStateExecuting) {\n        throw new Error(&quot;Generator is already running&quot;);\n      }\n \n      if (state === GenStateCompleted) {\n        if (method === &quot;throw&quot;) {\n          throw arg;\n        }\n \n        // Be forgiving, per 25.3.3.3.3 of the spec:\n        // people.mozilla.org/~jorendorff/es6-draft.html#sec-generatorresume\n        return doneResult();\n      }\n \n      context.method = method;\n      context.arg = arg;\n \n      while (true) {\n        var delegate = context.delegate;\n        if (delegate) {\n          var delegateResult = maybeInvokeDelegate(delegate, context);\n          if (delegateResult) {\n            if (delegateResult === ContinueSentinel) continue;\n            return delegateResult;\n          }\n        }\n \n        if (context.method === &quot;next&quot;) {\n          // Setting context._sent for legacy support of Babel&#039;s\n          // function.sent implementation.\n          context.sent = context._sent = context.arg;\n \n        } else if (context.method === &quot;throw&quot;) {\n          if (state === GenStateSuspendedStart) {\n            state = GenStateCompleted;\n            throw context.arg;\n          }\n \n          context.dispatchException(context.arg);\n \n        } else if (context.method === &quot;return&quot;) {\n          context.abrupt(&quot;return&quot;, context.arg);\n        }\n \n        state = GenStateExecuting;\n \n        var record = tryCatch(innerFn, self, context);\n        if (record.type === &quot;normal&quot;) {\n          // If an exception is thrown from innerFn, we leave state ===\n          // GenStateExecuting and loop back for another invocation.\n          state = context.done\n            ? GenStateCompleted\n            : GenStateSuspendedYield;\n \n          if (record.arg === ContinueSentinel) {\n            continue;\n          }\n \n          return {\n            value: record.arg,\n            done: context.done\n          };\n \n        } else if (record.type === &quot;throw&quot;) {\n          state = GenStateCompleted;\n          // Dispatch the exception by looping back around to the\n          // context.dispatchException(context.arg) call above.\n          context.method = &quot;throw&quot;;\n          context.arg = record.arg;\n        }\n      }\n    };\n  }\n基本的执行过程就不分析了，我们重点看第三次执行 hw.next() 的时候:\n第三次执行 hw.next() 的时候，其实执行了\nthis._invoke(&quot;next&quot;, undefined);\n我们在 invoke 函数中构建了一个 record 对象：\nvar record = tryCatch(innerFn, self, context);\n \n// Try/catch helper to minimize deoptimizations. Returns a completion\n// record like context.tryEntries[i].completion. This interface could\n// have been (and was previously) designed to take a closure to be\n// invoked without arguments, but in all the cases we care about we\n// already have an existing method we want to call, so there&#039;s no need\n// to create a new function object. We can even get away with assuming\n// the method takes exactly one argument, since that happens to be true\n// in every case, so we don&#039;t have to touch the arguments object. The\n// only additional allocation required is the completion record, which\n// has a stable shape and so hopefully should be cheap to allocate.\nfunction tryCatch(fn, obj, arg) {\n    try {\n        return { type: &quot;normal&quot;, arg: fn.call(obj, arg) };\n    } catch (err) {\n        return { type: &quot;throw&quot;, arg: err };\n    }\n}\n而在 innerFn.call(self, context) 中，因为 _context.next 为 4 的缘故，其实执行了:\n_context.abrupt(&quot;return&quot;, &#039;ending&#039;);\n而在 abrupt 中，我们又构建了一个 record 对象：\nvar record = finallyEntry ? finallyEntry.completion : {};\nrecord.type = type;\nrecord.arg = arg;\n然后执行了 this.complete(record)，在 complete 中，因为 record.type === &quot;return&quot;\nthis.rval = this.arg = record.arg;\nthis.method = &quot;return&quot;;\nthis.next = &quot;end&quot;;\n然后返回了全局对象 ContinueSentinel，其实就是一个全局空对象。\n然后在 invoke 函数中，因为 record.arg === ContinueSentinel 的缘故，没有执行后面的 return 语句，就直接进入下一个循环。\n于是又执行了一遍 innerFn.call(self, context)，此时 _context.next 为 end, 执行了 _context.stop(), 在 stop 函数中：\nstop: function() {\n    this.done = true;\n \n    var rootEntry = this.tryEntries[0];\n    var rootRecord = rootEntry.completion;\n    if (rootRecord.type === &quot;throw&quot;) {\n        throw rootRecord.arg;\n    }\n \n    return this.rval; // this.rval 其实就是 `ending`\n},\n所以最终返回的值为:\n{\n    value: &#039;ending&#039;,\n    done: true\n};\n之后，我们再执行 hw.next() 的时候，因为 state 已经是 ‘completed’ 的缘故，直接就返回 { value: undefined, done: true}\n\ngithub.com/facebook/regenerator/blob/main/packages/transform/src/index.js\n"},"front-end/javascript/review/copy":{"title":"copy","links":[],"tags":[],"content":"浅拷贝、深拷贝\n浅拷贝的几种实现\nObject.assign()会拷贝原始对象中的所有属性到一个新对象上，如果属性为对象，则拷贝的是对象的地址，改变对象中的属性值，新拷贝出来的对象依然会受影响。\n使用ES6的 ...扩展运算符。\n深拷贝几种实现"},"front-end/javascript/review/extend":{"title":"extend","links":[],"tags":[],"content":"继承\n在JavaScriptES6之前，实现继承需要依赖原型、原型链和构造函数等等技术手段组合使用，在ES6之后，可以使用Class类继承(并没有真正的类，只是一个语法糖，实质依然是函数)。\n继承的几种方式：\n\n原型链实现继承\n借用构造函数实现继承\n组合继承\n寄生组合继承\nES6 Class 继承\n\n原型链实现继承\n通过重写子类的原型，并将它指向父类的手段实现。这种方式实现的继承，创建出来的实例既是子类的实例，又是父类的实例。它有如下几种缺陷：\n\n不能向父类构造函数传参\n父类上的引用类型属性会被所有实例共享，其中一个实例改变时，会影响其他实例；\n\nfunction Animal() {\n  this.colors = [&#039;red&#039;,&#039;blue&#039;];\n}\nfunction Dog(name) {\n  this.name = name;\n}\nDog.prototype = new Animal();\n \nvar dog1 = new Dog(&#039;旺财&#039;);\nvar dog2 = new Dog(&#039;钢镚&#039;);\n \ndog2.colors.push(&#039;yellow&#039;);\nconsole.log(dog1.colors); // [&quot;red&quot;, &quot;blue&quot;, &quot;yellow&quot;]\nconsole.log(dog2.colors); // [&quot;red&quot;, &quot;blue&quot;, &quot;yellow&quot;]\n \nconsole.log(dog1 instanceof Dog);   // true\nconsole.log(dog1 instanceof Animal);// true\n借用构造函数实现继承\n借用构造函数实现继承，通过在子类中使用call()方法，实现借用父类构造函数并向父类构造函数传参的目的。但这种方法，无法继承父类原型对象上的属性和方法。\nfunction Animal(name) {\n  this.name = name;\n  this.colors = [&#039;red&#039;,&#039;blue&#039;];\n}\nAnimal.prototype.eat = function() {\n  console.log(this.name + &#039; is eating!&#039;);\n}\nfunction Dog(name) {\n  Animal.call(this,name);\n}\n \nvar dog1 = new Dog(&#039;旺财&#039;);\nvar dog2 = new Dog(&#039;钢镚&#039;);\n \ndog2.colors.push(&#039;yellow&#039;);\n \nconsole.log(dog1.colors); // [&quot;red&quot;, &quot;blue&quot;]\nconsole.log(dog2.colors); // [&quot;red&quot;, &quot;blue&quot;, &quot;yellow&quot;]\n \nconsole.log(dog1 instanceof Dog);   // true\nconsole.log(dog2 instanceof Animal);// false\n \nconsole.log(dog1.eat()); // 报错\n组合继承\n组合继承是组合了原型链继承和借用构造函数继承这两种方法，它保留了两种继承方式的优点，但它并不是百分百完美的：\n\n父类构造函数被调用多次。\n\nfunction Animal(name) {\n  this.name = name;\n  this.colors = [&#039;red&#039;,&#039;blue&#039;];\n}\nAnimal.prototype.eat = function() {\n  console.log(this.name + &#039; is eatting&#039;);\n}\nfunction Dog(name) {\n  Animal.call(this,name);\n}\nDog.prototype = new Animal(); // 第一次调用\nvar dog1 = new Dog(&#039;dog1&#039;);   // 第二次调用\nvar dog2 = new Dog(&#039;dog2&#039;);   // 第三次调用\ndog1.colors.push(&#039;yellow&#039;);\nconsole.log(dog1.name);  // 输出dog1\nconsole.log(dog2.colors);// 输出[&#039;red&#039;,&#039;blue&#039;]\nconsole.log(dog2.eat()); // 输出dog2 is eatting\n寄生组合继承\n寄生组合继承是在组合继承的基础上，采用Object.create()方法来改造实现\nfunction Animal(name) {\n  this.name = name;\n  this.colors = [&#039;red&#039;,&#039;blue&#039;];\n}\nAnimal.prototype.eat = function() {\n  console.log(this.name + &#039; is eatting&#039;);\n}\nfunction Dog(name) {\n  Animal.call(this,name);\n}\nDog.prototype = Object.create(Animal.prototype);\nDog.prototype.constructor = Dog;\nvar dog1 = new Dog(&#039;dog1&#039;);\nvar dog2 = new Dog(&#039;dog2&#039;);\ndog1.colors.push(&#039;yellow&#039;);\nconsole.log(dog1.name);  // 输出dog1\nconsole.log(dog2.colors);// 输出[&#039;red&#039;,&#039;blue&#039;]\nconsole.log(dog2.eat()); // 输出dog2 is eatting\nES6 Class 继承\nclass Animal {\n  constructor(name) {\n    this.name = name;\n    this.colors = [&#039;red&#039;,&#039;blue&#039;];\n  }\n  eat() {\n    console.log(this.name + &#039; is eatting&#039;);\n  }\n}\nclass Dog extends Animal {\n  constructor(name) {\n    super(name);\n  }\n}\nvar dog1 = new Dog(&#039;dog1&#039;);\nvar dog2 = new Dog(&#039;dog2&#039;);\n \ndog1.colors.push(&#039;yellow&#039;);\nconsole.log(dog1.name);  // 输出dog1\nconsole.log(dog2.colors);// 输出[&#039;red&#039;,&#039;blue&#039;]\nconsole.log(dog2.eat()); // 输出dog2 is eatting"},"front-end/javascript/review/symbol":{"title":"symbol","links":[],"tags":[],"content":"是什么\nSymbol 是 ES6 新增的基本数据类型——符号，它具有唯一性、不可变性。因此能确保对象属性的唯一性，不会发生冲突。\nSymbol 和其他基本类型：null、undefined、boolean、number、string的不同是没有对应的包装类和 new 一起使用。\n基本用法\n// 创建\nlet s = Symbol()\nlet name = Symbol(&#039;name&#039;) // 传入字符串作为符号的描述，主要用于调试代码\nlet s1 = Symbol()\nlet s2 = Symbol()\n \n// 比较\ns1 == s2 // false\n \nlet s3 = Symbol(&#039;name&#039;)\nlet s4 = Symbol(&#039;name&#039;)\n \ns3 == s4 // false\n之前对象的属性的键只能是字符串类型，现在可以是 Symbol 的实例：\nlet name = Symbol(&#039;name&#039;)\nlet o = {\n    [name]:&#039;zhangsan&#039;\n}\n那相对于字符串类型的优点就是唯一性，不会覆盖已有的属性：比如想对第三方的一个对象 people 添加属性时，如果使用字符串作为属性很有可能会覆盖原有的属性，而使用 Symbol 就算属性名相同也不会：\nlet id = Symbol(&quot;id&quot;);\n \npeople[id] = &quot;新增值&quot;;\n全局符号注册表\nSymbol 每次创建都是唯一的，那如何复用呢？js 运行时维护了一个 symbol 注册表，Symbol.for 就用于向其中注册，可解决共享和重用的问题：\nlet name = Symbol.for(&#039;name&#039;) // 第一次时全局注册表不存在则创建并添加到注册表中。\n \nlet otherName = Symbol.for(&#039;name&#039;) // 后续使用相同字符串，先检索全局注册表有就返回，反之创建。\n \nname == otherName // true\n为防止冲突，常见的技巧是，加上前缀，定义命名空间：\nlet foo = Symbol.for(&quot;ns.foo&quot;);\nlet bar = Symbol.for(&quot;ns.bar&quot;);\n我们可以通过 Symbol.keyFor 来反查字符串键：\nlet name = Symbol.for(&#039;name&#039;)\nSymbol.keyFor(name) // &#039;name&#039;\n使用普通符号：\nlet name = Symbol(&#039;name&#039;)\nSymbol.keyFor(name) // undefined\n对象属性遍历\nfor...in 会忽略 Symbol：\nlet id = Symbol(&quot;id&quot;);\nlet user = {\n  name: &quot;John&quot;,\n  age: 30,\n  [id]: 123\n};\n \nfor (let key in user) alert(key); // name, age (no symbols)\nObject.keys(usr) // [&#039;name&#039;,&#039;age&#039;]\nObject.getOwnPropertyNames(user) // [&#039;name&#039;,&#039;age&#039;]\nObject.getOwnPropertySymbols(user) // [Symbol(id)]\n \n \nlet clone = Object.assign({}, user);\nclone[id] // 123\n常用使用场景\n\n使用 Symbol 让数据对象的特殊属性私有化；\n使用 Symbol 定义类的私有属性或方法；\n使用 Symbol 代替常量；\n\n内置的 Symbol 值\nSymbol.hasInstance\n指向一个内部方法。当其他对象使用 instanceof 运算符，判断是否为该对象的实例时，会调用这个方法。\nSymbol.isConcatSpreadable\n对象的Symbol.isConcatSpreadable属性等于一个布尔值，表示该对象用于Array.prototype.concat()时，是否可以展开。\nlet arr1 = [&#039;c&#039;, &#039;d&#039;];\n[&#039;a&#039;, &#039;b&#039;].concat(arr1, &#039;e&#039;) // [&#039;a&#039;, &#039;b&#039;, &#039;c&#039;, &#039;d&#039;, &#039;e&#039;]\narr1[Symbol.isConcatSpreadable] // undefined\n \nlet arr2 = [&#039;c&#039;, &#039;d&#039;];\narr2[Symbol.isConcatSpreadable] = false;\n[&#039;a&#039;, &#039;b&#039;].concat(arr2, &#039;e&#039;) // [&#039;a&#039;, &#039;b&#039;, [&#039;c&#039;,&#039;d&#039;], &#039;e&#039;]\nSymbol.species\n对象的Symbol.species属性，指向一个构造函数。创建衍生对象时，会使用该属性。默认的Symbol.species属性等同于下面的写法。\nstatic get [Symbol.species]() {\n  return this;\n}\n定义Symbol.species属性要采用get取值器，创建衍生对象如数组调用map或filter方法返回的数组，可以返回函数，作为构造函数进行实例0化；\nSymbol.match\n对象的Symbol.match属性，指向一个函数。当执行str.match(myObject)时，如果该属性存在，会调用它，返回该方法的返回值。\nSymbol.replace\n对象的Symbol.replace属性，指向一个方法，当该对象被String.prototype.replace方法调用时，会返回该方法的返回值。\nSymbol.search\n对象的Symbol.search属性，指向一个方法，当该对象被String.prototype.search方法调用时，会返回该方法的返回值。\nSymbol.split\n对象的Symbol.split属性，指向一个方法，当该对象被String.prototype.split方法调用时，会返回该方法的返回值。\nSymbol.iterator\n对象的Symbol.iterator属性，指向该对象的默认遍历器方法。\nSymbol.toPrimitive\n对象的Symbol.toPrimitive属性，指向一个方法。该对象被转为原始类型的值时，会调用这个方法，返回该对象对应的原始类型值。\nSymbol.toStringTag\n对象的Symbol.toStringTag属性，指向一个方法。在该对象上面调用Object.prototype.toString方法时，如果这个属性存在，它的返回值会出现在toString方法返回的字符串之中，表示对象的类型。也就是说，这个属性可以用来定制[object Object]或[object Array]中object后面的那个字符串。\nSymbol.unscopables\n对象的Symbol.unscopables属性，指向一个对象。该对象指定了使用with关键字时，哪些属性会被with环境排除。"},"front-end/javascript/review/type":{"title":"type","links":["front-end/interview/bytedance/1"],"tags":[],"content":"类型\n原始类型\nJavaScript 中原始类型有六种，原始类型既只保存原始值，是没有函数可以调用的。\n六种原始类型：string，number，boolean，null，undefined，symbol；\n为什么说原始类型没有函数可以调用，但&#039;1&#039;.toString()却又可以在浏览器中正确执行？\n因为&#039;1&#039;.toString()中的字符串&#039;1&#039;在这个时候会被封装成其对应的字符串对象，以上代码相当于new String(&#039;1&#039;).toString()，因为new String(&#039;1&#039;)创建的是一个对象，而这个对象里是存在toString()方法的。\n原始类型本身不具有方法或属性。但为了提供更方便的操作，JavaScript 会在需要时将原始类型临时转换为其对应的对象类型。这种过程称为自动包装（Autoboxing）。\nJavaScript 引擎创建一个临时的对象，临时对象上调用方法，调用结束后，这个临时对象会被销毁，返回结果仍然是一个原始类型。\n对象类型\n除了原始类型，其他的都是对象类型，对象类型存储的是地址，而原始类型存储的是值。\ntypeof 和 instanceof\ntypeof能准确判断除null以外的原始类型的值，对于对象类型，除了函数会判断成function，其他对象类型一律返回object；\n\n在底层实现中，JavaScript 引擎使用了一种称为 “内部方法” 的机制，这些内部方法可以用于区分不同类型的对象。\n如果一个对象实现了 [[Call]] 内部方法，引擎会将其识别为一个函数，并且 typeof 操作符将返回 &quot;function&quot;。\n\ninstanceof 运算符用于检查对象是否是特定类（构造函数）的实例。其判断依据是检查对象的原型链，具体来说是判断对象的原型链中是否包含指定类的原型（或者该类的任何父类的原型）。\n在底层，instanceof 通过检查对象的原型链，即 [[Prototype]] 链，来确定对象是否是指定类的实例。这可以通过访问对象的 __proto__ 属性来实现，但需要注意的是，__proto__ 是非标准的属性（早期的许多 JS 引擎都实现了 __proto__ 属性，但并没有纳入标准，不同的实现可能存在差异），不建议在生产代码中使用。更推荐使用 Object.getPrototypeOf 方法来获取对象的原型。\nclass Animal {}\n \nclass Dog extends Animal {}\n \nlet myDog = new Dog();\n \nconsole.log(myDog instanceof Dog); // true，因为 myDog 是 Dog 类的实例\nconsole.log(myDog instanceof Animal); // true，因为 Dog 类继承自 Animal 类\nconsole.log(myDog instanceof Object); // true，所有对象都是 Object 类的实例\n \nlet myDog = new Dog();\nconsole.log(myDog.__proto__ === Dog.prototype); // true，不推荐使用 __proto__\nconsole.log(Object.getPrototypeOf(myDog) === Dog.prototype); // 推荐使用 Object.getPrototypeOf\n 和 =\n=== 严格相等\n左右两边不仅值要相等，类型也要相等（也就不会进行隐式类型转换），例如&#039;1&#039;===1的结果是false，因为一边是string，另一边是number。\n== 不严格相等\n对于一般情况，只要值相等，就返回true，但==还涉及一些类型转换，它的转换规则如下：\n\n其中一个操作数是对象，另一个是基本类型，按此顺序使用对象的 @@toPrimitive()（以 &quot;default&quot; 作为提示），valueOf() 和 toString() 方法将对象转换为基本类型。\n两个操作时都是基本类型时：\n\n如果其中一个操作数是 Symbol 而另一个不是，返回 false。\n如果其中一个操作数是布尔型而另一个不是，则将布尔型转换为数字：true 转换为 1，false 转换为 0；然后继续不严格相等判断。\n操作数是String和 Number/BigInt，把String类型转换成Number/BigInt，再进行比较；\n\n\n\n不严格相等是对称的：A == B 对于 A 和 B 的任何值总是具有与 B == A 相同的语义（应用转换的顺序除外）。\n来看一道经典的面试题：\nconsole.log([]==![]); // true\n左侧对象（数组）[]，右侧为布尔值false；根据转换规则，对象先转为原始类型，即空字符串&quot;&quot;，继续按照规则，存在布尔值，即 false ==&gt; 0；接着是 String和Number，则会将空字符串转为 0，最后是0 == 0，即为 true。\n\ntypeof document.all === &#039;undefined&#039; 是检测中的一个特例，document.all 被标准委员会认为是一个不符合标准的特性，并逐渐被现代浏览器所摒弃。\n在处理 typeof document.all 时，浏览器引擎会检测到操作数是 document.all，并直接返回 &#039;undefined&#039;，而不是对其进行通常的类型检测。\n"},"front-end/javascript/sandbox":{"title":"sandbox","links":[],"tags":[],"content":"实现 JavaScript 沙箱的几种方式\n沙箱(sandbox)是一种安全机制， 为运行中的程序提供的隔离环境。通常是作为一些来源不可信、具破坏力或无法判定程序意图的程序提供实验之用。沙盒通常严格控制其中的程序所能访问的资源，比如，沙盒可以提供用后即回收的磁盘及内存空间。\nJS 中沙箱的使用场景\n前端 JS 中也会有应用到沙箱的时候，毕竟有时候你要获取到的是第三方的 JS 文件或数据？而这数据又是不一定可信的时候，创建沙箱，做好保险工作尤为重要\n\njsonp：解析服务器所返回的 jsonp 请求时，如果不信任 jsonp 中的数据，可以通过创建沙箱的方式来解析获取数据；（TSW 中处理 jsonp 请求时，创建沙箱来处理和解析数据）；\n执行第三方 js：当你有必要执行第三方 js 的时候，而这份 js 文件又不一定可信的时候；\n在线代码编辑器：相信大家都有使用过一些在线代码编辑器，而这些代码的执行，基本都会放置在沙箱中，防止对页面本身造成影响；（例如：codesandbox.io/s/new）\nvue 模板中表达式计算：vue 模板中表达式的计算被放在沙盒中，只能访问全局变量的一个白名单，如 Math 和 Date 。你不能够在模板表达式中试图访问用户定义的全局变量\n\n总而言之：当你要解析或执行不可信的 JS 的时候，当你要隔离被执行代码的执行环境的时候，当你要对执行代码中可访问对象进行限制的时候，沙箱就派上用场了。\nJS 沙箱实现\neval\neval 大家都非常熟系，可以将一个 JavaScript 字符作为代码片段来执行:\nconst str = `\n    var a = 0\n    a = 1 + 1;\n    console.log(&#039;total a&#039;, a);\n`;\neval(str)\n\neval 在运行时提供了一个编译器，可快速将字符串转换为代码\n\n但 eval 具有诸多安全隐患，比如代码注入：\nglobal.name = &#039;x1_debug&#039;\n \neval(&#039;console.log(name&#039;) // x1_debug\n除此以外，eval 的编译过程对性能有一定影响。代码复杂时，会极大增加调试的难度。\nvm.runInContext\n在 Node.js 中，我们可以通过 VM 模块来创建一个独立的执行上下文，我们熟知的 common.js 的规范，便采用了这种方式执行 require 的代码片段, 下面是 vm 沙箱的一个简单是示例：\nconst vm = require(&#039;vm&#039;);\n \nconst script = new vm.Script(&#039;a + b&#039;)\nconst sandbox = { a: 1, b: 2 };\ncontext = vm.createContext(sandbox)\n \nconsole.log(script.runInContext(context)) // 3\n通过 Node vm 模块可以快速创建一个与外界隔离的执行环境，但是确可以通过一些方式来完成沙箱的「逃逸」， node 官网对 vm 模块也标记了 「vm 模块不是安全的机制。 不要使用它来运行不受信任的代码。 」：\nconst vm = require(&quot;vm&quot;);\nconst env = vm.runInNewContext(`\n   this.constructor.constructor(&#039;return this.process.env&#039;)()`\n);\nconsole.log(env); // process.env\n\n可以看到，我们通过 runInNewContext 可以访问到外层 node 环境的 process 对象，完成了沙箱的逃逸\n\n为何会这样呢？\n这是因为 JS 基于原型链，js 对象通过 proto 指向 Object.prototype，通过 Object.prototype 向上查找到 Function，最终完成沙盒逃逸并执行代码:\nconst vm = require(&quot;vm&quot;);\nconst env = vm.runInNewContext(`\n  this.constructor.constructor\n`);\nconsole.log(env); // [Function: Function]\n当然，如果在 node.js 环境中有这种安全述求，可以使用 vm2 更安全的 vm 模块：\nconst { VM } = require(&#039;vm2&#039;);\nconst vm = new VM();\n \nvm.run(`process.exit()`); // TypeError: process.exit is not a function\n通过上述原因，可以进一步推测下 VM2 模块中对于「沙箱逃逸」阻隔的实现：\nclass Vm2 {\n constructor() {\n  ...\n  Object.defineProperties(this, {\n   __proto__: null,\n   _runScript: {\n    __proto__: null, \n    value: runScript\n   },\n   ...\n  });\n  ...\n }\n \n run(script) { this._runScript(script) } \n}\niframe\niframe 是一个非常安全的隔离环境，在浏览器中，我们也可以利用 iframe 来实现沙箱的效果：\n&lt;iframe\n  id=&quot;sandbox&quot;\n  sandbox=&quot;”allow-forms&quot;\n  allow-same-origin\n  allow-scripts”\n  src=&quot;./iframe.html&quot;\n&gt;&lt;/iframe&gt;\n \n&lt;script&gt;\nconst iframe = document.getElementById(&#039;sandbox&#039;)\niframe.contentWindow.postMessage(&quot;a + b&quot;, &#039;*&#039;)\n&lt;/script&gt;\niframe.html\n&lt;!--iframe.html--&gt;\n&lt;script&gt;\n  var a = 1;\n  var b = 2;\n  var _this = this\n  window.addEventListener(&#039;message&#039;, function(e) {\n    const result = eval(e.data)\n    _this.postMessage(result, e.origin) // 沙箱执行完毕，通知外部执行结果\n  })\n&lt;/script&gt;\n可以看到通过这种方式，可以有效完成作用域的隔离。并且 iframe 为我们提供了多个安全参数，比如allow-scripts、allow-forms、allow-same-origin 方便我们对沙箱进行安全控制。\n但这种方式过于臃肿，还需要考虑浏览器的兼容性，也不是最好的解决方案\nFunction\nFunction 构造函数创建一个新的 Function 对象。直接调用此构造函数可用动态创建函数，但会遇到和 eval 类似的的安全问题和(相对较小的)性能问题。然而，与 eval 不同的是，Function 创建的函数只能在全局作用域中运行。\nvar x = 10;\n \nfunction createFunction1() {\n    var x = 20;\n    return new Function(&#039;return x;&#039;); // 这里的 x 指向最上面全局作用域内的 x\n}\n \nfunction createFunction2() {\n    var x = 20;\n    function f() {\n        return x; // 这里的 x 指向上方本地作用域内的 x\n    }\n    return f;\n}\n \nvar f1 = createFunction1();\nconsole.log(f1());          // 10\nvar f2 = createFunction2();\nconsole.log(f2());          // 20\n使用 new Function 的方式来创建沙箱：\nglobalThis.name = &#039;hello&#039;\n \nfunction sandbox() {\n const a = 1\n  const ctx = &quot;console.log(&#039;name&#039;, name, &#039;varA&#039;, a);&quot;\n  return new Function(ctx)()\n}\n \nsandbox() //  name hello varA a-a\n可以配合 with 关键字解决上面的问题，我们稍加改造\nglobalThis.name = &#039;hello&#039;\n \nfunction compileCode(expose) {\n    const code = `with(context) { return ${expose} }`\n    return new Function(&#039;context&#039;, code)\n  }\n \ncompileCode(&quot;console.log(&#039;name&#039;, name, &#039;varA&#039;, a)&quot;).call(this, { a: &#039;xx&#039; })\n \n// name hello varA xx\n\n如上代码，expose 执行时，首先会寻找 context 中的变量，如果不存在，会往上追溯 global 对象，虽然有一道防火墙，但是依然不能阻止 fn 访问全局作用域。Vue 在早期也曾使用这种方式来编译运行时的表达式\n\n似乎在 ECMAScript 5 中，无法解决变量访问「逃逸」的问题了，但是 ES6 中未我们提供了解决方案。\nES6 Proxy\nES6 中提供了一个 Proxy 函数，他会给对象架设一层拦截器，代理了对对象的各种操作, 我们可以使用 Proxy 对上面的案列在做下修改：\nclass SandBox&lt;T extends { [key: string]: unknown }&gt; {\n  scope: T\n \n  constructor(context: T) {\n    const proxy = new Proxy&lt;T&gt;(context, {\n      get(target, p: string) {\n        return target[p]\n      },\n      has(target, key: string) {\n  if (!target[key]) return false\n        return true // 通过 has 拦截器，我们可以过滤掉不受信息的 key\n      }\n    })\n \n    this.scope = proxy\n  }\n}\n通过这种方式, 我们可以拦截或过滤外界对于对象的访问，并且可以控制属性查找的方式，但是 es6 当中有些方法是不会被 with scope 所影响，主要是通过Symbol.unscopables 来检测。\nSymbol.unscopables\nSymbol 能够产生的一个唯一的值，具备一些内建的特性，这些属性可以进行一定程度的”元编程“，通过 symbol.unscopables 可以影响 with 的行为：\nvar name = () =&gt; &#039;global name&#039;\nconst Sandbox = {\n  property1: 42,\n  name() { return &#039;Sandbox name&#039;; }\n};\n \nSandbox[Symbol.unscopables] = {\n  property: false,\n  name: true\n};\n \nwith (Sandbox) {\n  console.log(property); // 42\n  console.log(name()); // &#039;global name&#039;\n}\n对象 Symbol.unscopables 指用对象自身和继承的属性，通过返回 boolean 来改变 with 环境下排除的属性。\n微前端的沙箱方式\n微前端架构中，不同的微前端场景里，快照的方式也不同：\n快照沙箱 - Snapshot Sandbox\n单应用（实例）的微前端场景中，我们可以采用 ”快照” 的方式创建沙箱，不同的实例共享一个全局变量：\nclass SnapshotSandbox {\n    constructor() {\n        this.proxy = window;\n        this.dirtyProps = {};\n        this.active();\n    }\n \n    active() {\n        this.snapshot = {};\n        for (const prop in window) {\n            if (hasOwnProperty(window, prop)) {\n                this.snapshot[prop] = window[prop];\n            }\n        }\n        Object.keys(this.dirtyProps).forEach(p =&gt; {\n            window[p] = this.dirtyProps[p];\n        });\n    }\n    a\n    inactive() {\n        for (const prop in window) {\n            if (hasOwnProperty(window, prop)) {\n                // 将快照变量 和 当前 window 属性做对比\n                if (window[prop] !== this.snapshot[prop]) {\n                    this.dirtyProps[prop] = window[prop];\n                    window[prop] = this.snapshot[prop]; // 根据 快照 还原上一次变量\n                }\n            }\n        }\n    }\n}\n \n代理沙箱 - Proxy Sandbox\nclass ProxySandBox&lt;T extends { [key: string]: unknown }&gt; {\n  scope: T\n \n  constructor(context: T) {\n    const proxy = new Proxy&lt;T&gt;(context, {\n      get(target, p: string) {\n        return target[p]\n      },\n      has(target, key: string) {\n\t\tif (!target[key]) return false\n        return true // 通过 has 拦截器，我们可以过滤掉不受信息的 key\n      }\n    })\n \n    this.scope = proxy\n  }\n \n  protected compileCode(expose: string) {\n    const code = `with(context) { return ${expose} }`\n    return new Function(&#039;context&#039;, code)\n  }\n \n  // eslint-disable-next-line\n  public runInContext(exp: string): void {\n      return this.compileCode(exp).call(this.scope, this.scope)\n  }\n}\n \nlet sandbox1 = new ProxySandBox();\nlet sandbox2 = new ProxySandBox();\n沙箱在小程序的作用\n在小程序里，逻辑层（Service）和渲染层（Render）分别用于处理不同的逻辑运算。\n我们知道小程序渲染层负责页面 UI 渲染，而逻辑层负责 JS 脚本的执行与计算。但在一些交互场景下，为了提高小程序的执行效率，我们可以采用 WXS / SJS 等脚本能力来提高性能。这类 xml 脚本通过自建脚本执行环境，限制脚本的能力来让业务的代码可以安全、高效的运行时在小程序的渲染层。\n通过环境注入的 Api，可完成与逻辑层的通讯与 api 调用:\n以下是一个简单的 xml 脚本使用示例：\n// index.xjs \nmodule.exports.getName = function() { return &#039;test-name&#039; }\n \n// index.xml\n&lt;import-xjs from=&quot;./template.xjs&quot; module=&quot;scopeName&quot; /&gt;\n&lt;view&gt;hello, i am scope from {{ scopeName.getName() }}&lt;/view&gt; \n \n// hello, i am scope from test-name\n在渲染层，我们可以使用 沙箱 来完成这类能力：\nclass ProxySandBox&lt;T extends { [key: string]: unknown }&gt; {\n    scope: T\n \n    constructor(context: T) {\n        const proxy = new Proxy&lt;T&gt;(context, {\n            get(target, p: string) {\n                if (p in xjsModuleName) { // 如果访问的 key 在 xjs 文件模块内\n                    const m = Module._Load(xjsModuleName[p]) // 拿到 xjs 模块\n                    return m[p]\n                }\n            },\n            has(target, key: string) {\n                if (!target[key]) return false\n                return true // 通过 has 拦截器，我们可以过滤掉不受信息的 key\n            }\n        })\n \n        this.scope = proxy\n    }"},"front-end/others/esbuild":{"title":"esbuild","links":[],"tags":[],"content":"Esbuild 初体验\n创建一个工程：\n|-- package.json\n|-- public\n|   `-- index.html\n`-- src\n    `-- index.js\n在 public/index.html 中引入 js 文件，当然现在还没有该文件，需要使用 esbuild 进行处理：\n&lt;script type=&quot;module&quot; src=&quot;./main.js&quot;&gt;&lt;/script&gt;\n安装 esbuild ：\n$ npm install esbuild --save-dev \n使用如下命令转译 js 文件，也可以将其写入 package.json 中：\n$ npx esbuild --bundle src/index.js --outfile=www/main.js\n--outfile 参数指定转译后的 js 输入路径，如果不提供将会输出到标准输出流；\n自动热重载\n可使用的方式有两种：\n检测模式\n即使用 esbuild 提供的 --watch 选项：\n$ npx esbuild --bundle src/index.js --outfile=www/main.js --watch\n这样每次代码发生变动，则会立即自动转译了。\n开发服务器\n即使用 esbuild 提供的开发服务器：\n$ esbuild --bundle src/index.js --outfile=www/main.js --servedir=public\n这样，每次重新加载页面都会触发 esbuild 重新转译。\n简单技巧\n当我们把上述的命令都写到 package.json 中时，可能会像这样：\n&quot;build&quot;: &quot;esbuild --bundle src/index.js --outfile=www/main.js&quot;,\n&quot;start&quot;: &quot;esbuild --bundle src/index.js --outfile=www/main.js --servedir=www&quot;,\n&quot;watch&quot;: &quot;esbuild --bundle src/index.js --outfile=www/main.js --watch&quot;\n这样看起来很整齐，实际上太冗余了，完全可以再优化一下：\n&quot;build&quot;: &quot;esbuild --bundle src/index.js --outfile=www/main.js&quot;,\n&quot;start&quot;: &quot;npm run build -- --servedir=www&quot;,\n&quot;watch&quot;: &quot;npm run build -- --watch&quot;\n完全热重载\n需要安装依赖 esbuild-serve：\n$ npm install esbuild-serve -D\n之后根据 esbuild-server 文档，编写 esbuild.config.js 配置文件：\n#!/usr/bin/env node\n \nimport esbuildServe from &quot;esbuild-serve&quot;;\n \nesbuildServe(\n  {\n    logLevel: &quot;info&quot;,\n    entryPoints: [&quot;src/index.js&quot;],\n    bundle: true,\n    outfile: &quot;www/main.js&quot;,\n  },\n  { root: &quot;www&quot; }\n);\n我们有两种方式来运行这个配置文件：\n\nnode esbuild.config.js，仅是转译\nnode esbuild.config.js -w， 开启一个服务\n\n\n如果运行时报错import esbuildServe from &quot;esbuild-serve&quot;;，\n那么需要在 package.json中指明：&quot;type&quot;: &quot;module&quot;；\n\n如此一来，则可以更新 package.json 中的命令了：\n&quot;build&quot;: &quot;node esbuild.config.js&quot;,\n&quot;start&quot;: &quot;node esbuild.config.js -w&quot;\n这样就完成了开发是随改随编译的热更新了。\n处理 CSS\nesbuild 可以直接转译 css 文件，如：\n$ esbuild style.css --outfile=out.css --bundle\n也能处理在 js 引入的 css 文件：\n/* /src/style.css */\nbody {\n  color: #66f;\n}\n然后在 js 文件中引入\n// src/index.js\nimport &quot;./style.css&quot;;\n \nconst header = document.createElement(&quot;h1&quot;);\n \nheader.innerHTML = &quot;Hello world&quot;;\n \ndocument.body.appendChild(header);\n默认情况下，esbuild 会配置对 css 的加载，不过不会打包进入 js 文件；\n当我们运行npm run build 或使用 npm run start运行服务器后，会发现 header 并没有颜色改变；\n这是因为样式被打包到了一个与 js 输出的打包文件同名的 css 文件中了，所以我们需要在 html 中引入：\n &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;./main.css&quot;/&gt;\n处理图片\n处理图片，常用两种方案，一是使用 base64 引入，二是直接使用文件链接导入；\n在 esbuild 中，导入图片可使用 import 语句：\nimport png_url from &#039;./image.png&#039;\nimport jpg_url from &#039;./image.jpg&#039;\n在转译时，可对每一种扩展名进行不同的处理，例如：\n$ esbuild input_image.js --bundle --loader:.png=dataurl --loader:.jpg=file --outfile=out_image.js\n编写构建脚本\n我们能使用一个外部的 js 脚本来处理 esbuild ：\n$ touch build.js\n$ chmod +x build.js\n并在文件顶部标注为使用 node 执行：\n#!/usr/bin/env node\n之后，我们可以将 npm run build 的逻辑简单改写到脚本中：\n#!/usr/bin/env node\n \nrequire(&quot;esbuild&quot;)\n  .build({\n    logLevel: &quot;info&quot;,\n    entryPoints: [&quot;src/index.js&quot;],\n    bundle: true,\n    outfile: &quot;www/main.js&quot;,\n  })\n  .catch(() =&gt; process.exit(1));\n所以在 package.json 中也随之简化：\n&quot;build&quot;: &quot;./build.js&quot;\n但是，显而易见，这样处理之后，--watch这样的参数则不起作用了。\n生成 SourceMap\n只需要在之前的esbuild.config.js文件中，开启配置即可：\nesbuildServe(\n  {\n    ...\n    outfile: &quot;public/main.js&quot;,\n+   sourcemap: true,\n  },\n  { root: &quot;public&quot; }\n);\n重启服务后，在浏览器的开发工具的源代码选项中，则可以看到 src/index.js了\n转译 TypeScript\n使用命令行\n我们新建一个 ts 文件，简单几句代码：\n// hello.ts\nlet message: string = &quot;Hello, esbuild!&quot;;\nfunction sayHello(hi:string){\n  console.log(hi);\n}\n \nsayHello(message)\n然后执行转译命令：\n$ npx esbuild src/hello.ts --outfile=hello.js --bundle --loader:.ts=ts\n--loader 选项用于指定扩展名加载 ts 文件，该选项是可以省略的，esbuild 会基于文件扩展名判断；\n--bundle 用于将所有依赖内联到当前的入口点文件，例如一个 js/ts 文件：\n// index.js\nimport { SayHello } from &quot;./library&quot;;\n \nSayHello();\n然后还有它的依赖：\n// library.js\nexport function SayHello() {\n  console.log(&quot;Hello, esbuild!&quot;);\n}\n如果单纯使用命令打包：esbuild index.js ，转译出来的产物是不带依赖的；\n使用配置文件\n配置文件下，可直接选择 ts 文件作为入口点：\nimport esbuildServe from &quot;esbuild-serve&quot;;\n \nesbuildServe(\n  {\n    logLevel: &quot;info&quot;,\n    entryPoints: [&quot;src/main.ts&quot;],\n    bundle: true,\n    sourcemap: true,\n    outfile: &quot;public/main.js&quot;,\n  },\n  { root: &quot;public&quot; }\n);\n打包 React 项目\n简单测试一下，安装依赖：\n$ npm install react react-dom\n挂载代码：\nimport React from &quot;react&quot;;\nimport ReactDOM from &quot;react-dom&quot;;\n \nfunction App() {\n  return (\n    &lt;div&gt;Hello, esbuild!&lt;/div&gt;\n  );\n}\n \nReactDOM.render(&lt;App /&gt;, document.getElementById(&quot;root&quot;));\n并且在 html 中挂载 root 元素以及引入 打包后的 js ：\n&lt;body&gt;\n  &lt;div id=&quot;root&quot;&gt;&lt;/div&gt;\n  &lt;script src=&quot;AppBundle.js&quot;&gt;&lt;/script&gt;\n&lt;/body&gt;\n命令转译：\n$ npx esbuild src/app.js --minify --bundle \n\t--outfile=public/AppBundle.js \n\t--loader:.js=jsx\n\t--target=chrome58,firefox57,safari11,edge16\n--minify 选项用于压缩代码，--target 选项用于设置浏览器环境，做一些针对性的 polyfills\n使用插件\nesbuild 原生不支持打包 sass 文件，可通过社区插件进行处理；\n我们随便选一个来试试：\n$ npm install esbuild-plugin-sass\n使用 build API 进行转译打包：\nconst sassPlugin = require(&quot;esbuild-plugin-sass&quot;);\n \nrequire(&quot;esbuild&quot;).build({\n  entryPoints: [&quot;style.scss&quot;],\n  outfile: &quot;bundle.css&quot;,\n  bundle: true,\n  plugins: [sassPlugin()]\n})\n.then(() =&gt; console.log(&quot;⚡ Done&quot;))\n.catch(() =&gt; process.exit(1));"},"front-end/others/eslint":{"title":"eslint","links":[],"tags":[],"content":"前言\nlint 工具简史\n\n在计算机科学中，lint是一种工具的名称，它用来标记代码中，某些可疑的、不具结构性（可能造成bug）的语句。它是一种静态程序分析工具，最早适用于C语言，在UNIX平台上开发出来。后来它成为通用术语，可用于描述在任何一种编程语言中，用来标记代码中有疑义语句的工具。— by wikipedia\n\n在 JavaScript 20 多年的发展历程中，也出现过许许多多的 lint 工具，文章介绍主流的三款 lint 工具：JSLint，JSHint，ESLint；\nJSLint 可以说是最早出现的 JavaScript 的 lint 工具，由 Douglas Crockford (《JavaScript 语言精粹》作者) 开发。从《JavaScript 语言精粹》的笔风就能看出，Douglas 是个眼里容不得瑕疵的人，所以 JSLint 也继承了这个特色，JSLint 的所有规则都是由 Douglas 自己定义的，可以说这是一个极具 Douglas 个人风格的 lint 工具，如果你要使用它，就必须接受它所有规则。值得称赞的是，JSLint 依然在更新，而且也提供了 node 版本：node-jslint。\n由于 JSLint 让很多人无法忍受它的规则，感觉受到了压迫，所以 Anton Kovalyov (现在在 Medium 工作) 基于 JSLint 开发了 JSHint。JSHint 在 JSLint 的基础上提供了丰富的配置项，给了开发者极大的自由，JSHint 一开始就保持着开源软件的风格，由社区进行驱动，发展十分迅速。早期 jQuery 也是使用 JSHint 进行代码检查的，不过现在已经转移到 ESLint 了。\nESLint 由 Nicholas C. Zakas (《JavaScript 高级程序设计》作者) 于2013年6月创建，它的出现因为 Zakas 想使用 JSHint 添加一条自定义的规则，但是发现 JSHint 不支持，于是自己开发了一个。\nESLint 号称下一代的 JS Linter 工具，它的灵感来源于 PHP Linter，将源代码解析成 AST，然后检测 AST 来判断代码是否符合规则。ESLint 使用 esprima 将源代码解析成 AST，然后就可以使用任意规则来检测 AST 是否符合预期，这也是 ESLint 高可扩展性的原因。\n但是，那个时候 ESLint 并没有大火，因为需要将源代码转成 AST，运行速度上输给了 JSHint ，并且 JSHint 当时已经有完善的生态（编辑器的支持）。真正让 ESLint 大火是因为 ES6 的出现。\nES6 发布后，因为新增了很多语法，JSHint 短期内无法提供支持，而 ESLint 只需要有合适的解析器就能够进行 lint 检查。这时 babel 为 ESLint 提供了支持，开发了 babel-eslint，让 ESLint 成为最快支持 ES6 语法的 lint 工具。\n在 2016 年，ESLint整合了与它同时诞生的另一个 lint 工具：JSCS，因为它与 ESLint 具有异曲同工之妙，都是通过生成 AST 的方式进行规则检测。\n自此，ESLint 在 JS Linter 领域一统江湖，成为前端界的主流工具。\nlint 工具的意义\nLint 工具对工程师来说到底是代码质量的保证还是一种束缚？\n以下是 ESLint 官网给出的答案：\n\n代码检查是一种静态的分析，常用于寻找有问题的模式或者代码，并且不依赖于具体的编码风格。对大多数编程语言来说都会有代码检查，一般来说编译程序会内置检查工具。\nJavaScript 是一个动态的弱类型语言，在开发中比较容易出错。因为没有编译程序，为了寻找 JavaScript 代码错误通常需要在执行过程中不断调试。像 ESLint 这样的可以让程序员在编码的过程中发现问题而不是在执行的过程中。\n\n再引用一下 ESLint 官网的介绍。\n\n「Find Problems」：ESLint statically analyzes your code to quickly find problems. ESLint is built into most text editors and you can run ESLint as part of your continuous integration pipeline.\n「Fix Automatically」：Many problems ESLint finds can be automatically fixed. ESLint fixes are syntax-aware so you won’t experience errors introduced by traditional find-and-replace algorithms.\n「Customize」：Preprocess code, use custom parsers, and write your own rules that work alongside ESLint’s built-in rules. You can customize ESLint to work exactly the way you need it for your project.\n\n也就是三部分：「找出代码问题」，「自动修复」，「自定义规则」。于此可可以归纳 Lint 工具的优势：\n\n\n避免低级 bug，找出可能发生的语法错误。使用未声明变量、修改 const 变量……\n\n\n提示删除多余的代码。声明而未使用的变量、重复的 case ……\n\n\n确保代码遵循最佳实践。可参考 airbnb style、javascript standard\n\n\n统一团队的代码风格。加不加分号？使用 tab 还是空格？\n\n\nESLint 经过许多年的发展已经非常成熟，加上社区诸多开发者的不断贡献，目前社区也已经积累了许多优秀的代码写法约定，为了项目代码的健康，也为了开发人员的身心健康，尽早地引入合适的 ESLint 规则是非常有必要的。\nESLint 使用\n初始化\n在现有的项目中引入 ESLint ，可运行如下几个命令：\n# 全局安装 ESLint\n$ npm install -g eslint\n# 进入项目\n$ cd ~/eslint-demo\n# 初始化 ESLint 配置\n$ eslint --init  \n# 或者直接使用快捷指令\n$ npm init @eslint/config\n在命令执行后，会出现很多用户配置项，具体可以参考：eslint cli 部分的源码；经过一系列一问一答的环节后，你会发现在你文件夹的根目录生成了一个 .eslintrc.js 文件，即 ESLint 的配置文件；\n配置方式\n0. 在命令行中进行规则配置\n严格来看，这并不算对规则进行了配置，而是一种测试，可以快速测试某个或某一些规则的效果：\n$ eslint src --rule &quot;{eqeqeq: off}&quot;\n1. 使用注释把 lint 规则直接嵌入到源代码中\n这是最简单粗暴的方式，直接在源代码中使用 ESLint 能够识别的注释方式，进行 lint 规则的定义：\n/* eslint eqeqeq: &quot;error&quot; */\nvar num = 1\nnum == &#039;1&#039;\n如上，则是定义了一个规则 eqeqeq，该规则要求使用 = 和 ! ：\n$ eslint src\n \nD:\\Code\\eslint-demo\\src\\index.js\n  5:5  error  Expected &#039;===&#039; and instead saw &#039;==&#039;  eqeqeq     \n \n✖ 1 problem (1 error, 0 warnings)\n当然我们一般使用注释是为了临时禁止某些严格的 lint 规则出现的警告：\nalert(&#039;该注释放在文件顶部，整个文件都不会出现 lint 警告&#039;)\t/* eslint-disable */\nalert(&#039;重新启用 lint 告警&#039;)\t\t/* eslint-enable */\nalert(&#039;只禁止某一个或多个规则&#039;)\t /* eslint-disable eqeqeq */\nalert(&#039;当前行禁止 lint 警告&#039;)      /* eslint-disable-next-line */\nalert(&#039;当前行禁止 lint 警告&#039;) \t    // eslint-disable-line\n2. 使用配置文件进行 lint 规则配置\n即使用我们之前在项目中初始化 ESLint 时生成的配置文件；在初始化时，有一个选项就是选择何种文件类型进行 lint 配置，官方一共提供了三个选项：\n\nJavaScript (.eslintrc.js)\nYAML (eslintrc.yaml)\nJSON (eslintrc.json)\n\n此外，也还可以自己在 package.json 文件中添加 eslintConfig 字段进行配置；并具有不同的优先级：\n.eslintrc.js &gt; .eslintrc.yaml  &gt; .eslintrc.yml &gt; .eslintrc.json &gt; .eslintrc &gt; package.json\n\n也还有可以通过命令行参数-c 指定配置文件路径：\n$ eslint -c ./.eslintrc.js src\n项目级与目录级的配置\n例如，项目中有如下的目录结构：\n|-- package.json\n|-- src\n|   |-- .eslintrc.js\n|   `-- index.js\n`-- .eslintrc.js\n\n此时，有两个配置文件 .eslintrc.js（项目级配置） 和 src/.eslintrc.js（目录级配置），这两个配置文件会进行合并，但是 src/.eslintrc.js 具有更高的优先级。\n不过，我们只要在 src/.eslintrc.js 中配置 “root”: true，那么 ESLint 就会认为 src 目录为根目录，不再向上查找配置：\n{ &quot;root&quot;: true }\n配置参数\n解析器配置\n{\n    // 解析器类型\n    // espima(默认), babel-eslint, @typescript-eslint/parse\n    &quot;parse&quot;: &quot;esprima&quot;,\n    // 解析器配置参数\n    &quot;parseOptions&quot;: {\n        // 代码类型：script(默认), module\n        &quot;sourceType&quot;: &quot;script&quot;,\n        // es 版本号，默认为 5，也可以是用年份，比如 2015 (同 6)\n        &quot;ecamVersion&quot;: 6,\n        // es 特性配置\n        &quot;ecmaFeatures&quot;: {\n            &quot;globalReturn&quot;: true, // 允许在全局作用域下使用 return 语句\n            &quot;impliedStrict&quot;: true, // 启用全局 strict mode\n            &quot;jsx&quot;: true // 启用 JSX\n        },\n    }\n}\n对于 @typescript-eslint/parse 这个解析器，主要是为了替代之前存在的 TSLint，TS 团队因为 ESLint 生态的繁荣，且 ESLint 具有更多的配置项，不得不抛弃 TSLint 转而实现一个 ESLint 的解析器。同时，该解析器拥有不同的配置：\n{\n    &quot;parserOptions&quot;: {\n        &quot;ecmaFeatures&quot;: {\n            &quot;jsx&quot;: true\n        },\n        &quot;useJSXTextNode&quot;: true,\n        &quot;project&quot;: &quot;./tsconfig.json&quot;,\n        &quot;tsconfigRootDir&quot;: &quot;../../&quot;,\n        &quot;extraFileExtensions&quot;: [&quot;.vue&quot;]\n    }\n}\n环境与全局变量\nESLint 会检测未声明的变量，并发出警告，但是有些变量是我们引入的库声明的，这里就需要提前在配置中声明。\n{\n    &quot;globals&quot;: {\n        // 声明 jQuery 对象为全局变量\n        &quot;$&quot;: false // true 表示该变量为 writeable，而 false 表示 readonly\n    }\n}\n在 globals 中一个个的进行声明未免有点繁琐，这个时候就需要使用到 env ，这是对一个环境定义的一组全局变量的预设（类似于 babel 的 presets）。\n{\n    &quot;env&quot;: {\n        &quot;amd&quot;: true,\n        &quot;commonjs&quot;: true,\n        &quot;jquery&quot;: true\n    }\n}\n可选的环境很多，预设值都在这个文件中进行定义，查看源码可以发现，其预设变量都引用自 globals 包。\n规则设置\nESLint 附带有大量的规则，你可以在配置文件的 rules 属性中配置你想要的规则。每一条规则接受一个参数，参数的值如下：\n\n\n“off” 或 0：关闭规则\n\n\n“warn” 或 1：开启规则，warn 级别的错误 (不会导致程序退出)\n\n\n“error” 或 2：开启规则，error级别的错误(当被触发的时候，程序会退出)\n\n\n事情往往没有我们想象中那么简单，ESLint 的规则不仅只有关闭和开启这么简单，每一条规则还有自己的配置项。如果需要对某个规则进行配置，就需要使用数组形式的参数。\n我们以 quotes 规则为例，对照中文官网文档，该规则有两个选项，一个是字符串，一个是对象：\n\n\n字符串选项：\n\n\n“double” (默认) 要求尽可能地使用双引号\n\n\n”single” 要求尽可能地使用单引号\n\n\n”backtick” 要求尽可能地使用反勾号\n\n\n\n\n对象选项：\n\n\n“avoidEscape”: true 允许字符串使用单引号或双引号，只要字符串中包含了一个其它引号，否则需要转义\n\n\n”allowTemplateLiterals”: true 允许字符串使用反勾号\n\n\n\n\n{\n    &quot;rules&quot;: {\n        // 使用数组形式，对规则进行配置\n        // 第一个参数为是否启用规则\n        // 后面的参数才是规则的配置项\n        &quot;quotes&quot;: [\n            &quot;error&quot;,\n            &quot;single&quot;,\n            {\n                &quot;avoidEscape&quot;: true \n            }\n        ]\n    }\n}\n扩展\n扩展就是直接使用别人已经写好的 lint 规则，方便快捷。扩展一般支持三种类型：\n{\n  &quot;extends&quot;: [\n    &quot;eslint:recommended&quot;,\n    &quot;plugin:react/recommended&quot;,\n    &quot;eslint-config-standard&quot;,\n  ]\n}\n\n\neslint： 开头的是 ESLint 官方的扩展，一共有两个：eslint:recommended 、eslint:all。\n\n\nplugin：开头的是扩展是插件类型，也可以直接在 plugins 属性中进行设置，后面一节会详细讲到。\n\n\n最后一种扩展来自 npm 包，官方规定 npm 包的扩展必须以 eslint-config-开头，使用时可以省略这个头，上面案例中 eslint-config-standard 可以直接简写成 standard。\n\n\n如果你觉得自己的配置十分满意，也可以将自己的 lint 配置发布到 npm 包，只要将包名命名为 eslint-config-xxx 即可，同时，需要在 package.json 的 peerDependencies 字段中声明你依赖的 ESLint 的版本号。\n插件\n使用插件\n虽然官方提供了上百种的规则可供选择，但是这还不够，因为官方的规则只能检查标准的 JavaScript 语法，如果你写的是 JSX 或者 Vue 单文件组件，ESLint 的规则就开始束手无策了。\n这个时候就需要安装 ESLint 的插件，来定制一些特定的规则进行检查。ESLint 的插件与扩展一样有固定的命名格式，以 eslint-plugin- 开头，使用的时候也可以省略这个前缀。\n$ npm install --save-dev eslint-plugin-vue eslint-plugin-react\n{\n  &quot;plugins&quot;: [\n    &quot;react&quot;, // eslint-plugin-react\n    &quot;vue&quot;,   // eslint-plugin-vue\n  ]\n}\n或者是在扩展中引入插件，前面有提到 plugin: 开头的是扩展是进行插件的加载。\n{\n  &quot;extends&quot;: [\n    &quot;plugin:react/recommended&quot;,\n  ]\n}\n通过扩展的方式加载插件的规则如下：\nextPlugin = `plugin:${pluginName}/${configName}`\n对照上面的案例，插件名(pluginName) 为 react，也就是之前安装 eslint-plugin-react 包，配置名(configName)为 recommended。那么这个配置名又是从哪里来的呢？\n可以看到 eslint-plugin-react 的源码。\nmodule.exports = {\n  // 自定义的 rule\n  rules: allRules,\n  // 可用的扩展\n  configs: {\n    // plugin:react/recommended\n    recomended: {\n      plugins: [ &#039;react&#039; ]\n      rules: {...}\n    },\n    // plugin:react/all\n    all: {\n      plugins: [ &#039;react&#039; ]\n      rules: {...}\n    }\n  }\n}\n配置名是插件配置的 configs 属性定义的，这里的配置其实就是 ESLint 的扩展，通过这种方式即可以加载插件，又可以加载扩展。\n开发插件\nESLint 官方为了方便开发者，提供了 Yeoman 的模板（generator-eslint）。\n# 安装模块\n$ npm install -g yo generator-eslint\n \n# 创建目录\n$ mkdir eslint-plugin-demo\n$ cd eslint-plugin-demo\n \n# 创建模板\n$ yo eslint:plugin\n创建好项目之后，就可以开始创建一条规则了，幸运的是 generator-eslint 除了能够生成插件的模板代码外，还具有创建规则的模板代码。\n打开之前创建的 eslint-plugin-demo 文件夹，在该目录下添加一条规则，我希望这条规则能检测出我的代码里面是否有 console ，所以，我给该规则命名为 disable-console。\n$ yo eslint:rule\n接下来我们看看如何来指定 ESLinte 的一个规则；打开 lib/rules/disable-console.js ，可以看到默认的模板代码如下：\n/** @type {import(&#039;eslint&#039;).Rule.RuleModule} */\nmodule.exports = {\n  meta: {\n    type: null, // `problem`, `suggestion`, or `layout`\n    docs: {\n      description: &quot;disable console&quot;,\n      recommended: false,\n      url: null, // URL to the documentation page for this rule\n    },\n    fixable: null, // Or `code` or `whitespace`\n    schema: [], // Add a schema if the rule has options\n  },\n \n  create(context) {\n    // variables should be defined here\n    //----------------------------------------------------------------------\n    // Helpers\n    //----------------------------------------------------------------------\n    // any helper functions should go here or else delete this section\n    //----------------------------------------------------------------------\n    // Public\n    //----------------------------------------------------------------------\n    return {\n      // visitor functions for different types of nodes\n    };\n  },\n};\n简单的介绍下其中的参数（更详细的介绍可以查看官方文档）：\n\n\nmeta：规则的一些描述元信息：\n\n\ntype (string) 指示规则的类型，值为 “problem”、“suggestion” 或 “layout”；\n\n\ndocs (object) ：规则核心的描述对象：\n\ndescrition(string)：规则的简短描述\ncategory(string)：规则的类别，具体类别参考文档\nrecommended(boolean)：配置文件中是否加入 eslint:recommended\n\n\n\nschema(array)：规则所接受的配置项\n\n\nfixable：如果规则不是可修复的，就省略 fixable 属性，否则需要实现 fix功能\n\n\n\n\ncreate：返回一个对象，该对象包含 ESLint 在遍历 JavaScript 代码 AST 时，所触发的一系列事件勾子。\n\n\nESLint 使用了一个叫做 Espree 的 JavaScript 解析器来把 JavaScript 代码解析为一个 AST 。然后深度遍历 AST，每条规则都会对匹配的过程进行监听，每当匹配到一个类型，相应的规则就会进行检查。\nastexplorer 是一个工具网站，能十分清晰的查看一段代码解析成 AST 之后的样子；如果你想找到所有 AST 节点的类型，可以查看 espree。\n当我们在左侧的代码输入框中键入console.log(&quot;hello world&quot;)时，可以看到 console.log() 属于 ExpressionStatement(表达式语句) 中的 CallExpression(调用语句)。\n{\n    &quot;type&quot;: &quot;ExpressionStatement&quot;,\n    &quot;expression&quot;: {\n        &quot;type&quot;: &quot;CallExpression&quot;,\n        &quot;callee&quot;: {\n            &quot;type&quot;: &quot;MemberExpression&quot;,\n            &quot;object&quot;: {\n                &quot;type&quot;: &quot;Identifier&quot;,\n                &quot;name&quot;: &quot;console&quot;\n            },\n            &quot;property&quot;: {\n                &quot;type&quot;: &quot;Identifier&quot;,\n                &quot;name&quot;: &quot;log&quot;\n            },\n            &quot;computed&quot;: false\n        },\n        &quot;arguments&quot;: [\n                {\n                  &quot;type&quot;: &quot;Literal&quot;,\n                  &quot;value&quot;: &quot;hello world&quot;,\n                  &quot;raw&quot;: &quot;\\&quot;hello world\\&quot;&quot;\n                }\n              ]\n    }\n}\n所以，我们要判断代码中是否调用了 console，可以在 create 方法返回的对象中，写一个 CallExpression 方法，在 ESLint 遍历 AST 的过程中，对调用语句进行监听，然后检查该调用语句是否为 console 调用。\nmodule.exports = {\n  create: function(context) {\n    return {\n      CallExpression(node) {\n        // 获取调用语句的调用对象\n        const callObj = node.callee.object\n        if (!callObj) {\n          return\n        }\n        if (callObj.name === &#039;console&#039;) {\n          // 如果调用对象为 console，通知 ESLint\n          context.report({\n            node,\n            message: &#039;error: should remove console&#039;\n          })\n        }\n      },\n    }\n  }\n}\n可以看到我们最后通过 context.report 方法，告诉 ESLint 这是一段有问题的代码，具体要怎么处理，就要看 ESLint 配置中，该条规则是 [off, warn, error] 中的哪一个了。\n之前介绍规则的时候，有讲到规则是可以接受配置的，下面看看我们自己制定规则的时候，要如何接受配置项。\n其实很简单，只需要在 meta 对象的 schema 中定义好参数的类型，然后在 create 方法中，通过 context.options 获取即可。\n下面对 disable-console 进行修改，毕竟禁止所有的 console 太过严格，我们可以添加一个参数，该参数是一个数组，表示允许调用的 console 方法。\nmodule.exports = {\n  meta: {\n    docs: {\n      description: &quot;disable console&quot;, // 规则描述\n      category: &quot;Possible Errors&quot;,    // 规则类别\n      recommended: false\n    },\n    schema: [ // 接受一个参数\n      {\n        type: &#039;array&#039;, // 接受参数类型为数组\n        items: {\n          type: &#039;string&#039; // 数组的每一项为一个字符串\n        }\n      }\n    ]\n  },\n \n  create: function(context) {\n    const logs = [ // console 的所以方法\n        &quot;debug&quot;, &quot;error&quot;, &quot;info&quot;, &quot;log&quot;, &quot;warn&quot;, \n        &quot;dir&quot;, &quot;dirxml&quot;, &quot;table&quot;, &quot;trace&quot;, \n        &quot;group&quot;, &quot;groupCollapsed&quot;, &quot;groupEnd&quot;, \n        &quot;clear&quot;, &quot;count&quot;, &quot;countReset&quot;, &quot;assert&quot;, \n        &quot;profile&quot;, &quot;profileEnd&quot;, \n        &quot;time&quot;, &quot;timeLog&quot;, &quot;timeEnd&quot;, &quot;timeStamp&quot;, \n        &quot;context&quot;, &quot;memory&quot;\n    ]\n    return {\n      CallExpression(node) {\n         // 接受的参数\n        const allowLogs = context.options[0]\n        const disableLogs = Array.isArray(allowLogs)\n          // 过滤掉允许调用的方法\n          ? logs.filter(log =&gt; !allowLogs.includes(log))\n          : logs\n        const callObj = node.callee.object\n        const callProp = node.callee.property\n        if (!callObj || !callProp) {\n          return\n        }\n        if (callObj.name !== &#039;console&#039;) {\n          return\n        }\n        // 检测掉不允许调用的 console 方法\n        if (disableLogs.includes(callProp.name)) {\n          context.report({\n            node,\n            message: &#039;error: should remove console&#039;\n          })\n        }\n      },\n    }\n  }\n}\n规则写完之后，打开 tests/rules/disable-console.js ，编写测试用例：\nconst ruleTester = new RuleTester();\nruleTester.run(&quot;disable-console&quot;, rule, {\n  valid: [{\n    code: &quot;console.info(test)&quot;,\n    options: [[&#039;info&#039;]]\n  }],\n \n  invalid: [\n    {\n      code: &quot;console.log()&quot;,\n      errors: [{ message: &quot;error: should remove console&quot; }],\n    },\n  ],\n});\n之后使用命令 npm test，运行测试用例；最后，只需要引入插件，然后开启规则即可：\n// eslintrc.js\nmodule.exports = {\n  plugins: [ &#039;demo&#039; ],\n  rules: {\n    &#039;demo/disable-console&#039;: [\n      &#039;error&#039;, [ &#039;info&#039; ]\n    ],\n  }\n}\n\n这里插一点相关的，当前我们的插件还未发布到 npm 仓库，可以在 eslint-plugin-demo 路径下使用 npm link，接着再到之前的项目 eslint-demo路径下执行 npm link eslint-plugin-demo，即可连接到一起了；\n\n最后是测试一下是否正常使用：\n// console.js\nconsole.log(&#039;&#039;);\nconsole.info(&#039;&#039;);\n$ eslint ./src/console.js\n \nD:\\Code\\eslint-demo\\src\\console.js\n  1:1  error  error: should remove console  demo/disable-console\n \n✖ 1 problem (1 error, 0 warnings)\n最佳配置\n业界有许多 JavaScript 的推荐编码规范，较为出名的就是下面两个：\n\nairbnb style\njavascript standard\n\n同时这里也推荐 AlloyTeam 的 eslint-config-alloy。\n但是代码规范这个东西，最好是团队成员之间一起来制定，确保大家都能够接受，如果实在是有人有异议，就只能少数服从多数了。虽然这节的标题叫最佳配置，但是软件行业并有没有什么方案是最佳方案，即使 javascript standard 也不是 javascript 标准的编码规范，它仅仅只是叫这个名字而已，只有适合的才是最好的。\n最后安利一下，将 ESLint 和 Prettier 结合使用，不仅统一编码规范，也能统一代码风格。\nESLint 工作原理\nESLint 使用 espree 生成 AST 的，对其进行遍历，然后在遍历到「不同的节点」或者「特定的时机」的时候，触发相应的处理函数，然后在函数中，可以抛出错误，给出提示。\n读取配置"},"front-end/others/esmodule":{"title":"esmodule","links":[],"tags":[],"content":"漫画：深入浅出 ES 模块\nES 模块为 JavaScript 提供了官方标准化的模块系统。然而，这中间经历了一些时间 —— 近 10 年的标准化工作。\n但等待已接近尾声。随着 5 月份 Firefox 60 发布（目前为 beta 版），所有主流浏览器都会支持 ES 模块，并且 Node 模块工作组也正努力在 Node.js 中增加 ES 模块支持。同时用于 WebAssembly 的 ES 模块集成 也在进行中。\n许多 JavaScript 开发人员都知道 ES 模块一直存在争议。但很少有人真正了解 ES 模块的运行原理。\n让我们来看看 ES 模块能解决什么问题，以及它们与其他模块系统中的模块有什么不同。\n模块要解决什么问题？\n你可以仔细回想，JavaScript 的编码都是关于管理变量的。所做的事都是为变量赋值，或者在变量上做加法，或者将两个变量组合在一起并放入另一个变量中。\n\n因为你的代码中很多都是关于改变变量的，你如何组织这些变量会对你的编码方式以及代码的可维护性产生很大的影响。\n一次只需要考虑少量的变量就可以让我们的工作变得更简单。JavaScript 有一种方法可以帮助你做到这点，称为作用域。由于 JavaScript 中的作用域机制，一个函数无法访问在其他函数中定义的变量。\n\n这很好。这意味着当你写一个函数时，只需关注这个函数本身。你不必担心其他函数可能会对函数内的变量做些什么。\n尽管如此，它仍然存在缺陷。这使得在函数间共享变量变得有点困难。\n如果你想在作用域外共享变量，会怎么做呢？一种常见方法是将它放在更外层的作用域里……例如，在全局作用域中。\n你可能还记得这个在 jQuery 时代的操作。在加载任何 jQuery 插件之前，你必须确保 jQuery 在全局作用域中。\n\n这是没问题的，但是会产生一些烦人的问题。\n首先，所有的 script 标签都需要按照正确的顺序排列。且你必须谨慎确保那个顺序不被打乱。\n如果你打乱了这个顺序，那么在运行的过程中，你的应用程序就会抛出一个错误。当函数寻找它期望的 jQuery 时 —— 在全局作用域里 —— 却没有找到它，它会抛出一个错误并停止运行。\n\n这使得维护代码非常棘手。这让移除老代码或老 script 标签变成了一场轮盘赌游戏。你不知道会弄坏什么。代码的不同部分之间的依赖关系是隐式的。任何函数都可以获取全局作用域中的任何东西，所以你不知道哪些函数依赖于哪些 script 标签。\n第二个问题是，因为这些变量位于全局范围内，所以全局范围内的代码的每个部分都可以更改该变量。恶意代码可能会故意更改该变量，以使你的代码执行某些你并不想要的操作，或者非恶意代码可能会意外地弄乱你的变量。\n模块是如何提供帮助的？\n模块为你提供了更好的方法来组织这些变量和函数。通过模块，你可以将变量和函数更好地分组在一起。\n这会将这些函数和变量放入模块作用域。模块作用域能被用于在模块中的函数间共享变量。\n但是与函数作用域不同，模块作用域有一种方式使其变量对其他模块可用。它们可以显式地表明了模块中的哪些变量、类或函数是可用的。\n当将某些东西对其他模块可用时，这被称为 export ；一旦你声明了一个 export，其他模块就可以显式地说它们依赖于该变量、类或函数。\n\n因为这是显式的关系，所以当删除了某个模块时，你可以确定哪些模块会出问题。\n一旦你能够在模块之间导出和导入变量，就可以更容易地将代码分解为可独立工作的小块。然后，你可以组合或重组这些代码块（像乐高一样），从同一组模块中创建出各种不同的应用程序。\n由于模块非常有用，历史上有多次向 JavaScript 添加模块功能的尝试。如今有两个模块系统正在大范围地使用。CommonJS（CJS）是 Node.js 历史上使用的。ESM（EcmaScript 模块）是一个更新的系统，已被添加到 JavaScript 规范中。浏览器已经支持了 ES 模块，并且 Node 也正在添加支持。\n让我们来深入了解这个新模块系统的工作原理。\nES 模块如何工作\n使用模块开发时，会建立一个依赖图。不同依赖项之间的连接来自你使用的所有 import 语句。\n浏览器或者 Node 通过 import 语句来确定需要加载什么代码。你给定一个文件来作为依赖图的入口。之后将会随着 import 语句来找到所有剩余的代码。\n\n但这些文件本身并不能被浏览器直接使用。浏览器需要把这些文件解析成一种叫做模块记录（Module Records）的数据结构。这样它就知道了文件中到底是什么情况。\n\n之后，模块记录需要转化为模块实例（module instance）。一个实例包含两个部分：代码和状态。\n代码基本上是一组指令。它像是一个告诉你如何制作某些东西的配方。但仅靠代码本身并不能做任何事情。你需要将原材料和这些指令组合起来使用。\n什么是状态？状态就是给你这些原材料的东西。状态是所有变量在任何时间的实际值的集合。当然，这些变量只是内存中保存值的数据块的别名而已。\n所以模块实例将代码（指令列表）和状态（所有变量的值）组合在一起。\n\n我们需要的是每个模块的模块实例。模块加载就是从此入口文件开始，到生成包含全部模块实例的依赖图的过程。\n对于 ES 模块来说，这主要有三个步骤：\n\n构造 —— 查找、下载并解析所有文件到模块记录中。\n实例化 —— 在内存中寻找一块区域来存储所有导出的变量（但还没有填充值）。然后让 export 和 import 都指向这些内存块。这个过程叫做链接（linking）。\n求值 —— 运行代码，在内存块中填入变量的实际值。\n\n\n人们说 ES 模块是异步的。你可以把它当作时异步的，因为整个过程被分为了三阶段 —— 加载、实例化和求值 —— 这三个阶段可以分开完成。\n这意味着 ES 规范确实引入了一种在 CommonJS 中并不存在的异步性。我稍后会再解释，但是在 CJS 中，一个模块和其下的所有依赖会一次性完成加载、实例化和求值，中间没有任何中断。\n当然，这些步骤本身并不必须是异步的。它们可以以同步的方式完成。这取决于什么在做加载这个过程。这是因为 ES 模块规范并没有控制所有的事情。实际上有两部分工作，这些工作分别由不同的规范控制。\nES模块规范说明了如何将文件解析到模块记录，以及如何实例化和求值该模块。但是，它并没有说明如何首先获取文件。\n是加载器来获取文件。加载器在另一个不同的规范中定义。对于浏览器来说，这个规范是 HTML 规范。但是你可以根据所使用的平台有不同的加载器。\n\n加载器还精确控制模块的加载方式。它调用 ES 模块的方法 —— ParseModule、Module.Instantiate 和 Module.Evaluate。这有点像通过提线来控制 JS 引擎这个木偶。\n\n现在让我们更详细地介绍每一步。\n构造\n在构造阶段，每个模块都会经历三件事情。\n\n找出从哪里下载包含该模块的文件（也称为模块解析）\n获取文件（从 URL 下载或从文件系统加载）\n将文件解析为模块记录\n\n查找文件并获取\n加载器将负责查找文件并下载它。首先它需要找到入口文件。在 HTML 中，你通过使用 script 标记来告诉加载器在哪里找到它。\n\n但它如何找到剩下的一堆模块 —— 那些 main.js 直接依赖的模块？\n这就要用到 import 语句了。import 语句中的一部分称为模块标识符。它告诉加载器哪里可以找到余下的模块。\n\n关于模块标识符有一点需要注意：它们有时需要在浏览器和 Node 之间进行不同的处理。每个宿主都有自己的解析模块标识符字符串的方式。要做到这一点，它使用了一种称为模块解析的算法，它在不同平台之间有所不同。目前，在 Node 中可用的一些模块标识符在浏览器中不起作用，但这个问题正在被修复。\n在修复之前，浏览器只接受 URL 作为模块标识符。它们将从该 URL 加载模块文件。但是，这并不是在整个依赖图上同时发生的。在解析文件前，并不知道这个文件的模块中需要再获取哪些依赖……并且在获取文件之前无法解析那个文件。\n这意味着我们必须逐层遍历依赖树，解析一个文件，然后找出它的依赖关系，然后查找并加载这些依赖\n\n如果主线程要等待这些文件的下载，那么很多其他任务将堆积在队列中。\n这是就是为什么当你使用浏览器时，下载部分需要很长时间。\n\n像这样阻塞主线程会让采用了模块的应用程序速度太慢而无法使用。这是 ES 模块规范将算法分为多个阶段的原因之一。将构造过程单独分离出来，使得浏览器在执行同步的初始化过程前可以自行下载文件并建立自己对于模块图的理解。\n这种方法 —— 将算法分解成不同阶段 —— 是 ES 模块和 CommonJS 模块之间的主要区别之一。\nCommonJS 可以以不同的方式处理的原因是，从文件系统加载文件比在 Internet 上下载需要少得多的时间。这意味着 Node 可以在加载文件时阻塞主线程。而且既然文件已经加载了，直接实例化和求值（在 CommonJS 中并不区分这两个阶段）就理所当然了。这也意味着在返回模块实例之前，你遍历了整棵树，加载、实例化和求值了所有依赖关系。\n\nCommonJS 的方法有一些隐式特性，稍后我会解释。其中一个是，在使用 CommonJS 模块的 Node 中，可以在模块标识符中使用变量。在查找下一个模块之前，你执行了此模块中的所有代码（直至 require 语句）。这意味着当你去做模块解析时，变量会有值。\n但是对于 ES 模块，在进行任何求值之前，你需要事先构建整个模块图。这意味着你的模块标识符中不能有变量，因为这些变量还没有值。\n\n但有时候在模块路径使用变量确实非常有用。例如，你可能需要根据代码的运行情况或运行环境来切换加载某个模块。\n为了让 ES 模块支持这个，有一个名为 动态导入 的提案。有了它，你可以像 import(${path}/foo.js 这样使用 import 语句。\n它的原理是，任何通过 import() 加载的的文件都会被作为一个独立的依赖图的入口。动态导入的模块开启一个新的依赖图，并单独处理。\n\n有一点需要注意，同时存在于这两个依赖图中的模块都将共享同一个模块实例。这是因为加载器会缓存模块实例。对于特定全局作用域中的每个模块，都将只有一个模块实例。\n这意味着引擎的工作量减少了。例如，这意味着即使多个模块依赖某个模块，这个模块的文件也只会被获取一次。（这是缓存模块的一个原因，我们将在求值部分看到另一个。）\n加载器使用一种叫做模块映射的东西来管理这个缓存。每个全局作用域都在一个单独的模块映射中跟踪其模块。\n当加载器开始获取一个 URL 时，它会将该 URL 放入模块映射中，并标记上它正在获取文件。然后它会发出请求并继续开始获取下一个文件。\n\n如果另一个模块依赖于同一个文件会发生什么？加载器将查找模块映射中的每个 URL。如果看到了 fetching，它就会直接开始下一个 URL。\n但是模块映射不只是跟踪哪些文件正在被获取。模块映射也可以作为模块的缓存，接下来我们就会看到。\n解析\n现在我们已经获取了这个文件，我们需要将它解析为模块记录。这有助于浏览器了解模块的不同部分。\n\n一旦模块记录被创建，它会被记录在模块映射中。这意味着在这之后的任意时间如果有对它的请求，加载器就可以从映射中获取它。\n\n解析中有一个细节可能看起来微不足道，但实际上有很大的影响。所有的模块都被当作在顶部使用了 &quot;use strict&quot; 来解析。还有一些其他细微差别。例如，关键字 await 保留在模块的顶层代码中，this 的值是 undefined。\n这种不同的解析方式被称为「解析目标」。如果你使用不同的目标解析相同的文件，你会得到不同的结果。所以在开始解析前你想知道正在解析的文件的类型 —— 它是否是一个模块。\n在浏览器中这很容易。你只需在 script 标记中设置 type=&quot;module&quot;。这告诉浏览器此文件应该被解析为一个模块。另外由于只有模块可以被导入，浏览器也就知道任何导入的都是模块。\n\n但是在 Node 中，不使用 HTML 标签，所以没法选择使用 type 属性。社区试图解决这个问题的一种方法是使用 .mjs 扩展名。使用该扩展名告诉 Node「这个文件是一个模块」。你会看到大家将这个叫做解析目标的标志。讨论仍在进行中，所以目前还不清楚 Node 社区最终会决定使用什么标志。\n无论哪种方式，加载器会决定是否将文件解析为模块。如果是一个模块并且有导入，则加载器将再次启动该过程，直到获取并解析了所有的文件。\n我们完成了！在加载过程结束时，从只有一个入口文件变成了一堆模块记录。\n\n下一步是实例化此模块并将所有实例链接在一起。\n实例化\n就像我之前提到的，实例将代码和状态结合起来。状态存在于内存中，因此实例化步骤就是将内容连接到内存。\n首先，JS 引擎创建一个模块环境记录（module environment record）。它管理模块记录对应的变量。然后它为所有的 export 分配内存空间。模块环境记录会跟踪不同内存区域与不同 export 间的关联关系。\n这些内存区域还没有被赋值。只有在求值之后它们才会获得真正的值。这条规则有一点需要注意：任何 export 的函数声明都在这个阶段初始化。这让求值更加容易。\n为了实例化模块图，引擎将执行所谓的深度优先后序遍历。这意味着它会深入到模块图的底部 —— 直到不依赖于其他任何东西的底部 —— 并处理它们的 export。\n\n引擎将某个模块下的所有导出都连接好 —— 也就是这个模块所依赖的所有导出。之后它回溯到上一层来连接该模块的所有导入。\n请注意，导出和导入都指向内存中的同一个区域。先连接导出保证了所有的导出都可以被连接到对应的导入上。\n\n这与 CommonJS 模块不同。在 CommonJS 中，整个 export 对象在 export 时被复制。这意味着 export 的任何值（如数字）都是副本。\n这意味着如果导出模块稍后更改该值，则导入模块并不会看到该更改。\n\n相比之下，ES 模块使用叫做动态绑定（live bindings）的东西。两个模块都指向内存中的相同位置。这意味着当导出模块更改一个值时，该更改将反映在导入模块中。\n导出值的模块可以随时更改这些值，但导入模块不能更改其导入的值。但是，如果一个模块导入一个对象，它可以改变该对象上的属性值。\n\n之所以使用动态绑定，是因为这样你就可以连接所有模块而不需要运行任何代码。这有助于循环依赖存在时的求值，我会在下面解释。\n因此，在此步骤结束时，我们将所有实例和导出 / 导入变量的内存位置连接了起来。\n现在我们可以开始求值代码并用它们的值填充这些内存位置。\n求值\n最后一步是在内存中填值。JS 引擎通过执行顶层代码 —— 函数之外的代码来实现这一点。\n除了在内存中填值，求值代码也会引发副作用。例如，一个模块可能会请求服务器。\n\n由于潜在的副作用，你只想对模块求值一次。对于实例化中发生的链接过程，多次链接会得到相同的结果，但与此不同的是，求值结果可能会随着求值次数的不同而变化。\n这是需要模块映射的原因之一。模块映射通过规范 URL 来缓存模块，所以每个模块只有一个模块记录。这确保了每个模块只会被执行一次。就像实例化一样，这会通过深度优先后序遍历完成。\n那些我们之前谈过的循环依赖呢？\n如果有循环依赖，那最终会在依赖图中产生一个循环。通常，会有一个很长的循环路径。但为了解释这个问题，我打算用一个短循环的人为的例子。\n\n让我们看看 CommonJS 模块如何处理这个问题。首先，main 模块会执行到 require 语句。然后它会去加载 counter 模块。\n\n然后 counter 模块会尝试从导出对象访问 message。但是，由于这尚未在 main 模块中进行求值，因此将返回 undefined。JS 引擎将为局部变量分配内存空间并将值设置为 undefined。\n\n求值过程继续，直到 counter 模块顶层代码的结尾。我们想看看最终是否会得到正确的 message 值（在 main.js 求值之后），因此我们设置了 timeout。之后在 main.js 上继续求值。\n\nmessage 变量将被初始化并添加到内存中。但是由于两者之间没有连接，它将在 counter 模块中保持 undefined。\n\n如果使用动态绑定处理导出，则 counter 模块最终会看到正确的值。在 timeout 运行时，main.js 的求值已经结束并填充了该值。\n支持这些循环依赖是 ES 模块设计背后的一大缘由。正是这种三段式设计使其成为可能。\nES 模块的现状如何？\n随着 5 月初会发布的 Firefox 60，所有主流浏览器均默认支持 ES 模块。Node 也增加了支持，一个工作组正致力于解决 CommonJS 和 ES 模块之间的兼容性问题。\n这意味着你可以在 script 标记中使用 type=module，并使用 import 和 export。但是，更多模块特性尚未实现。动态导入提议正处于规范过程的第 3 阶段，有助于支持 Node.js 用例的 import.meta 也一样，模块解析提议也将有助于抹平浏览器和 Node.js 之间的差异。所以我们可以期待将来的模块支持会更好。\n\nES modules: A cartoon deep-dive - Mozilla Hacks - the Web developer blog\n"},"front-end/others/git/branch":{"title":"branch","links":[],"tags":[],"content":"\n图解Git分支和命令\nLearn Git Branching\n\n主分支\n在 Git 中新建一个项目后，默认有一个分支，即主分支。主分支一般表示项目的稳定版本，主分支应该包含稳定没有 Bug 的代码，并保持随时可以发布的状态，对于小型项目来说，只有一个主分支就够用了，每次我们提交都会创建一个commit节点。\n$ git commit -m &quot;C0&quot;\n$ git commit -m &quot;C1&quot;\n$ git commit -m &quot;C2&quot;\n上面的命令会创建三个commit节点，此时main分支如下图所示：\n\n主分支上应该只包合并提交，所有的迭代应该都在分支上进行，如果是简单的改动，直接在主分支修改也是可以的；\n如果功能较复杂，且需要多次提交，不建议在主分支直接修改。\n功能分支\n当有新的功能要开发时，应该新建一个功能分支，命令如下：\n$ git checkout -b feature/a\n接下来在分支上创建两个提交，命令如下：\n$ git commit -m &quot;C3&quot;\n$ git commit -m &quot;C4&quot;\n此时提交树如下图所示：\n\n当功能分支开发完成后，需要合并回主分支，合并回主分支有两种选择，快速合并和非快速合并，二者的区别在于是否创建提交节点，命令如下：\n$ git merge feature/a \t\t\t# 快速合并\n$ git merge --no-ff feature/a \t# 非快速合并\n\n合并分支前，需要将HEAD切换到main分支；\n\n快速合并的结果，会直接将 master 指向了 feature/a，如下图所示：\n\n非快速合并的结果，会在 main 分支创建合并提交节点，如下图所示：\n\n此时我们需要撤销上一次快速合并，可以使用命令：git reset --hard C2\n\n\n两种合并方式都可以，如果选择快速合并，需要保证每个提交都是独立且完整的，如果不满足要求，Git 支持修改提交历史，需要修改后再次合并。\n修改历史可以使用 rebase 命令，下面的命令可以修改最近四个提交，将第二个提交的 pick 改为 squash，可以合并第一个和第二个提交，将第三个提交的 pick 改为 edit，可以修改第三个提交的提交信息。\n$ git rebase -i HEAD~3\n \n# Commands:\n# p, pick &lt;commit&gt; = use commit\n# r, reword &lt;commit&gt; = use commit, but edit the commit message\n# e, edit &lt;commit&gt; = use commit, but stop for amending\n# s, squash &lt;commit&gt; = use commit, but meld into previous commit\n# f, fixup &lt;commit&gt; = like &quot;squash&quot;, but discard this commit&#039;s log message\n# x, exec &lt;command&gt; = run command (the rest of the line) using shell\n# b, break = stop here (continue rebase later with &#039;git rebase --continue&#039;)\n# d, drop &lt;commit&gt; = remove commit\n\n在创建当前分支之后，主分支可能又有新的提交，如下图所示：\n\n在合并之前，建议先将主分支新的提交合并到当前分支，有两种策略可以选择，合并和变基，合并操作更简单，变基操作提交树更清晰，建议使用变基的方式。\n先来看下合并操作的过程，命令如下：\n$ git checkout feature/a\t# 先切到 feature/a 分支\n$ git merge main\t\t\t# 左图\n$ git checkout main\n$ git merge feature/a\t\t# 右图\n合并操作过程的提交树如下图所示：\n\n变基会修改feature/a分支的历史，就像 feature/a 是在 master 之后开发的一样，变基命令如下：\n$ git rebase main\t\t# 左图\n$ git checkout main\n$ git merge feature/a\t# 右图\n变基操作后的提交树如下图所示，暗色的提交是feature/a变基之前的状态，在变基后，暗色的提交不再有分支指向，但并不会删除，而是变成 Git 中的游离节点，在 Git 执行 GC（垃圾清理）操作后，节点才会彻底删除。\n\n故障分支\n如果发现存在 Bug，要尽快修复，此时可以基于主分支新建故障分支，命令如下：\n$ git checkout -b bugfix/b\n当验证没问题后，故障分支需要合并回主分支，并在主分支上发布新的补丁版本，命令如下：\n$ git checkout main\n$ git merge --no-ff bugfix/b  # 测试 构建 打标签 发布到npm\n主分支更新后，下游的公共分支要及时同步变更，建议使用变基进行同步，命令如下：\n$ git checkout feature/a\n$ git rebase main\n故障分支模型如下图所示，bugfix/b 分支合并到 main 后，feature/a 分支进行了变基操作。\n\n标签与历史\n每次发布新版本时都要打标签，版本号需要符合语义化版本规范，一般功能分支发布次版本号，故障分支发布修订版本号，使用 Git 添加 tag 的命令如下所示：\n# 假设当前版本是 1.1.0\n$ git tag 1.1.1 # 修改次版本号\n$ git tag 1.2.0 # 修改主版本\nGit 的版本号，还可以添加 v 前缀，两种风格都可以，建议在一个项目里面保持统一，添加 v 前缀的版本示例如下：\n# 假设当前版本是 v1.1.0\n$ git tag v1.1.1 # 修改次版本号\n$ git tag v1.2.0 # 修改主版本号\n出于各种原因，存在需要维护历史版本的需求，对于还有用户使用需求的历史版本，需要提供 bug 修复的支持。\n此时创建的标签就起作用了，可以基于标签新建一个版本分支，并在版本分支上修复 bug，且发布新的版本，历史版本分支，不需要再次合并回主干分支，创建标签分支的示例如下：\n$ git checkout -b v0.0.x v0.0.1"},"front-end/others/graphql-js":{"title":"graphql-js","links":[],"tags":[],"content":"GraphQL.js 入门\n脚本中运行\nimport { graphql, buildSchema } from &#039;graphql&#039;;\n \n// 使用 GraphQL schema language 构建一个 schema\nconst schema = buildSchema(`\n  type Query {\n    hello: String\n  }\n`);\n \n// 根节点为每个 API 入口端点提供一个 resolver 函数\nconst root = {\n  hello: () =&gt; {\n    return &#039;Hello world!&#039;;\n  },\n};\n \n// 运行 GraphQL query &#039;{ hello }&#039; ，输出响应\ngraphql({schema, source: &#039;{ hello }&#039;, rootValue: root}).then((response) =&gt; {\n  console.log(JSON.stringify(response));\n});\n服务端中运行\nimport express from &#039;express&#039;;\nimport { graphqlHTTP } from &#039;express-graphql&#039;;\nimport { buildSchema } from &#039;graphql&#039;;\n \n// 使用 GraphQL Schema Language 创建一个 schema\nvar schema = buildSchema(`\n  type Query {\n    hello: String\n  }\n`);\n \n// root 提供所有 API 入口端点相应的解析器函数\nvar root = {\n  hello: () =&gt; {\n    return &#039;Hello world!&#039;;\n  },\n};\n \nvar app = express();\napp.use(&#039;/graphql&#039;, graphqlHTTP({\n  schema: schema,\n  rootValue: root,\n  graphiql: true,\n}));\napp.listen(4000);\nconsole.log(&#039;Running a GraphQL API server at http://localhost:4000/graphql&#039;);\n服务器启动后，会跳转到一个web页面，向左侧中 GraphQL 中查询 { hello }，返回结果为 { data: { hello: &#039;Hello world!&#039; } }；\n客户端中运行\ncurl -X POST \\\n-H &quot;Content-Type: application/json&quot; \\\n-d &#039;{&quot;query&quot;: &quot;{ hello }&quot;}&#039; \\\nhttp://localhost:4000/graphql\n案例中的查询是硬编码的字符串。一旦你的应用变得复杂，你添加了像传递参数中描述的那种接收参数的 GraphQL 入口端点，就会想在客户端代码中使用参数构建 GraphQL 查询。你可以在查询中包含一个以$开头的关键字，并传递额外的 variables 字段给载荷来完成这个。\n基本类型\n大多数情况下，你所需要做的只是使用 GraphQL schema language 指定你的 API 需要的类型，然后作为参数传给 buildSchema 函数；\nGraphQL schema language 支持的标量类型有 String、Int、Float、Boolean 和 ID，因此你可以在传给 buildSchema 的 schema 中直接使用这些类型。\n默认情况下，每个类型都是可以为空的 —— 意味着所有的标量类型都可以返回 null。使用感叹号可以标记一个类型不可为空，如 String! 表示非空字符串。\n如果是列表类型，使用方括号将对应类型包起来，如 [Int] 就表示一个整数列表。\nimport express from &#039;express&#039;;\nimport { graphqlHTTP } from &#039;express-graphql&#039;;\nimport { buildSchema } from &#039;graphql&#039;;\n \n// 使用 GraphQL schema language 构建一个 schema\nconst schema = buildSchema(`\n  type Query {\n    quoteOfTheDay: String\n    random: Float!\n    rollThreeDice: [Int]\n  }\n`);\n \n// root 将会提供每个 API 入口端点的解析函数\nconst root = {\n  quoteOfTheDay: () =&gt; {\n    return Math.random() &lt; 0.5 ? &#039;Take it easy&#039; : &#039;Salvation lies within&#039;;\n  },\n  random: () =&gt; {\n    return Math.random();\n  },\n  rollThreeDice: () =&gt; {\n    return [1, 2, 3].map(_ =&gt; 1 + Math.floor(Math.random() * 6));\n  },\n};\n \nconst app = express();\napp.use(&#039;/graphql&#039;, graphqlHTTP({\n  schema: schema,\n  rootValue: root,\n  graphiql: true,\n}));\napp.listen(4000);\n \nconsole.log(&#039;Running a GraphQL API server at localhost:4000/graphql&#039;);\n传递参数\n就像 REST API 一样，在 GraphQL API 中，通常向入口端点传入参数，在 schema language 中定义参数，并自动进行类型检查。每一个参数必须有名字和数据类型。\n如我们将上例中的掷骰子改成掷任意个骰子，\ntype Query {\n  rollDice(numDice: Int!, numSides: Int): [Int]\n}\nInt! 中的感叹号表示参数 numDice 不能为 null ；解析器需要接受参数对象：\nvar root = {\n  rollDice: (args) =&gt; {\n    var output = [];\n    for (var i = 0; i &lt; args.numDice; i++) {\n      output.push(1 + Math.floor(Math.random() * (args.numSides || 6)));\n    }\n    return output;\n  }\n};\n在Web端调用时，代码如下：\n{\n  rollDice(numDice: 3, numSides: 6)\n}\n在脚本中发起请求时，可以使用字符串模板：\nconst dice = 3;\nconst sides = 6;\nconst query = `query RollDice($dice: Int!, $sides: Int) {\n  rollDice(numDice: $dice, numSides: $sides)\n}`;\n \nfetch(&#039;/graphql&#039;, {\n  method: &#039;POST&#039;,\n  headers: {\n    &#039;Content-Type&#039;: &#039;application/json&#039;,\n    &#039;Accept&#039;: &#039;application/json&#039;,\n  },\n  body: JSON.stringify({\n    query,\n    variables: { dice, sides },\n  })\n})\n  .then(r =&gt; r.json())\n  .then(data =&gt; console.log(&#039;data returned:&#039;, data));\n对象类型\n在 GraphQL schema language 中，定义一个新的对象类型就和我们在示例中定义的 Query 类型一样。每个对象可以有返回指定类型的字段，以及带有参数的方法。\n例如之前提到的rollDice的例子，如果随着时间的推移，我们想要有越来越多的基于随机骰子的方法，我们可以实现一个 RandomDie 的对象类型来替代：\ntype RandomDie {\n  roll(numRolls: Int!): [Int]\n}\n \ntype Query {\n  getDie(numSides: Int): RandomDie\n}\n对于 RandomDie 类型的根级别解析器来说，我们可以用 ES6 的 class 语法来替代，这样的话这些解析器就是这个类的实例方法了：\nclass RandomDie {\n  constructor(numSides) {\n    this.numSides = numSides;\n  }\n \n  rollOnce() {\n    return 1 + Math.floor(Math.random() * this.numSides);\n  }\n \n  roll({numRolls}) {\n    var output = [];\n    for (var i = 0; i &lt; numRolls; i++) {\n      output.push(this.rollOnce());\n    }\n    return output;\n  }\n}\n对于那些不使用任何参数的字段来说，你可以使用对象属性或实例方法来表示。对于上面的示例方法，不论是 numSides 还是 rollOnce 实际上都可以被用来实现 GraphQL 的字段，所以上面的代码同样可以以 schema 的方式来实现：\ntype RandomDie {\n  numSides: Int!\n  rollOnce: Int!\n  roll(numRolls: Int!): [Int]\n}\n \ntype Query {\n  getDie(numSides: Int): RandomDie\n}\n当你对一个返回对象类型的 API 发出 GraphQL 查询时，你可以通过嵌套 GraphQL 字段名来一次性调用对象上的多个方法。例如，如果你想在调用 rollOnce 方法掷 1 次骰子的同时也调用 roll 方法来掷 3 次骰子的话，你可以这么做：\n{\n  getDie(numSides: 6) {\n    rollOnce\n    roll(numRolls: 3)\n  }\n}\n你可以只用一次请求就能获取到所有信息，而不是一次请求只能获取到一个对象的相关信息，然后还要请求一系列 API 才能获取到其他对象的信息。这样不仅节省了带宽、让你的应用跑得更快，同时也简化了你客户端应用的逻辑。\n变更和输入类型\n用于处理变更数据或插入数据，在 GraphQL 中，你应该将这个入口端点做为 Mutation 而不是 Query；\n假设我们有一个“今日消息”服务器，每个人都可以在上面更新“今日消息”，或者阅读当前的“今日消息”。这个服务器的 GraphQL schema 很简单：\ntype Mutation {\n  setMessage(message: String): String\n}\n \ntype Query {\n  getMessage: String\n}\n将一个变更（mutation）映射到数据库的 create 或者 update 操作会很方便，如 setMessage，其会返回数据库所存的数据。这样一来，你修改了服务端的数据，客户端就能获知这个修改。\n不论是变更还是查询，根级解析器都能够处理，因此实现 schema 的 root 可以如下：\nvar fakeDatabase = {};\nvar root = {\n  setMessage: ({message}) =&gt; {\n    fakeDatabase.message = message;\n    return message;\n  },\n  getMessage: () =&gt; {\n    return fakeDatabase.message;\n  }\n};\n通常情况下，你会发现有多个不同的变更接受相同的输入参数。常见的案例是在数据库中创建对象和更新对象的接口通常会接受一样的参数。你可以使用“输入类型”来简化 schema，使用 input 关键字而不是 type 关键字即可。\n例如，我们每天有多条而不是一条消息，在数据库中以 id 字段为索引，每条消息都有一个 content 和 author 字符串。我们需要一个变更 API，用于创建新消息和更新旧消息。我们可以使用这个 schema：\ninput MessageInput {\n  content: String\n  author: String\n}\n \ntype Message {\n  id: ID!\n  content: String\n  author: String\n}\n \ntype Query {\n  getMessage(id: ID!): Message\n}\n \ntype Mutation {\n  createMessage(input: MessageInput): Message\n  updateMessage(id: ID!, input: MessageInput): Message\n}\n此处的变更返回一个 Message 类型，因此客户端通过变更的请求就能获取到新修改的 Message 的信息。\n输入类型的字段不能是其他对象类型，只能是基础标量类型、列表类型或者其他输入类型。\n一个有用的惯例是在 schema 的末尾使用 Input 命名输入类型，因为对于单一概念对象，通常你想要输入和输出类型之间只有略微不同。\n你必须在你的 GraphQL 查询前面使用关键字 mutation 才能调用变更，并将数据作为 JSON 对象以传入输入类型。如果用上面定义的服务器，你可以使用以下操作创建一条消息并返回这条消息的 id：\nmutation {\n    createMessage(input: {\n        author: &quot;andy&quot;,\n        content: &quot;hope is a good thing&quot;,\n\t}) {\n\t\tid\n\t}\n}\n认证和 Express 中间件\nExpress 中间件可以很方便地结合 express-graphql 使用，这也是一个良好的认证处理模式。\n你可以就像普通 Express 应用使用中间件一样把中间件和 GraphQL 解析器一起使用。然后 request 对象就会作为解析函数的第三参数传入；\n举个例子，假设我们想要服务器记录每个请求的 IP 地址，并编写一个返回调用者 IP 地址的 API。前者我们通过中间件完成，后者在解析器中取 request 对象即可。下面是实现这个功能的服务端代码：\nimport express, { Request, Response, NextFunction } from &#039;express&#039;;\nimport { graphqlHTTP } from &#039;express-graphql&#039;;\nimport { buildSchema } from &#039;graphql&#039;;\n \nconst schema = buildSchema(`\n  type Query {\n    ip: String\n  }\n`);\n \nconst loggingMiddleware = (req: Request, res: Response, next: NextFunction) =&gt; {\n  console.log(&#039;ip:&#039;, req.ip);\n  next();\n}\n \nconst root = {\n  ip: function (args: any, request: Request) {\n    return request.ip;\n  }\n};\n \nconst app = express();\napp.use(loggingMiddleware);\napp.use(&#039;/graphql&#039;, graphqlHTTP({\n  schema: schema,\n  rootValue: root,\n  graphiql: true,\n}));\napp.listen(4000);\nconsole.log(&#039;Running a GraphQL API server at localhost:4000/graphql&#039;);\n在 REST API 中，认证通常是借由 header 处理的，其中包含一个 auth token 用于识别发出请求的用户。\nExpress 中间件会处理这些 header，并将认证数据放进 Express 的 request 对象。像这样处理认证的中间件模块有 Passport、 express-jwt 和 express-session。这些模块每一个都能配合 express-graphql 使用。"},"front-end/others/jenkins":{"title":"jenkins","links":[],"tags":[],"content":""},"front-end/others/lerna":{"title":"lerna","links":[],"tags":[],"content":"什么是 monorepo\nmonorepo这个词是meno和repo两个缩写词的组合，meno是更少的意思，repo是repository的缩写，也就是仓库，合起来就是使用更少的仓库来进行版本管理控制，将所有项目都放在一个代码仓库进行管理。\n为什么要使用 monorepo\n使用monorepo有以下好处：\n\n代码复用更简单，类似的功能或通信协议可以抽象到共享库中，而不需要依赖包管理器；\n原子级别的提交使得不同项目版本管理更加方便，例如babel内部包含@babel/parser，@babel/traverse等许多子项目，这些模块同时修改都在一个仓库代码内，修改完一次提交就行了；\n避免重复安装第三方依赖，在大型项目中肯定会使用大量第三方依赖包，这些包的版本管理和安装需要不断重复进行，而monorepo内部只需要管理和安装一次，其他package都可以共享；\n跨团队协作更加方便，由于代码都在一个仓库内部，所以基本没有权限限制，大家都可以参与和维护；\n\n不过，使用monorepo也有一些不便：\n\npackage划分的粒度不好控制，这一般取决于架构的水平\n随着不同项目的进行，整个monorepo会越来越大\n权限控制没有multirepo那样精细到项目\n团队协作导致的修改可能因为沟通不及时的问题而影响很多面，不过这都是开发者不规范使用的问题；\n\nlerna\n\nlerna 是一个工具，它优化了使用 git 和 npm 管理多包存储库的工作流。\n\n在lerna架构中，每个单独的项目都是放在package目录的子文件夹下进行管理，每个package内部都有管理自身配置项的package.json文件，依赖也都会安装在各个package文件夹内的node_modules内部。\n安装使用命令\nyarn global add lerna\n \nlerna init\n版本控制\nlerna提供两种版本控制的方式：\n\n一种是所有项目固定使用一个版本号，位于monorepo内部的lerna.json内部指定的version，这样就会导致执行lerna publish会更新所有package的版本号；\n另一种是使用lerna init --independent创建的项目，可以独立管理每个package.json内部的版本号，每次执行lerna publish的时候，可以单独选择每个修改过的package内部的版本号。\n\n配置项\n在lerna.json中可以指定以下配置项：\n{\n  &quot;version&quot;: &quot;1.1.3&quot;,\n  &quot;npmClient&quot;: &quot;npm&quot;,\n  &quot;command&quot;: {\n    &quot;publish&quot;: {\n      &quot;ignoreChanges&quot;: [&quot;ignored-file&quot;, &quot;*.md&quot;],\n      &quot;message&quot;: &quot;chore(release): publish&quot;,\n      &quot;registry&quot;: &quot;npm.pkg.github.com&quot;\n    },\n    &quot;bootstrap&quot;: {\n      &quot;ignore&quot;: &quot;component-*&quot;,\n      &quot;npmClientArgs&quot;: [&quot;--no-package-lock&quot;]\n    }\n  },\n  &quot;packages&quot;: [&quot;packages/*&quot;]\n}\n\nversion：版本号，指定为independent表示每个package单独管理\nnpmClient：使用npm还是yarn安装依赖\ncommand.publish.ignoreChanges：忽略以某些文件修改导致的发布更新，使用glob模式\ncommand.publish.message：执行发布的提交信息\ncommand.publish.registry：发布源\ncommand.bootstrap.ignore：取消引导安装依赖的文件\ncommand.bootstrap.npmClientArgs：执行lerna bootstrap时传递给npm install或者yarn install命令的参数\ncommand.bootstrap.scope：限制lerna bootstrap引导的package\npackages：指定lerna package目录，默认就是packages文件夹\nuseWorkspaces：是否使用yarn workspace，如果开启需要在仓库根目录下的package.json指定workspaces\n\n命令行\nlerna init\n创建基于lerna的monorepo仓库，或者更新当前仓库的lerna版本。\nlerna bootstrap\n安装所有package的依赖项。lerna为项目内的每个package执行npm install或者yarn install，然后在这些包之间创建symlink，以相互引用。\n例如babel项目中babel-core依赖@babel/generator，而且它们都在同一个monorepo中，那么在packages/babel-core下安装的@babel/generator会通过symlink链接到同级的@babel/generator目录。\nsymlink是一类特殊的文件，包含一条以绝对路径或者相对路径形式指向其他文件或者目录的引用。目前 Unix，Windows 都支持symlink，一个符号链接文件仅包含有一个文本字符串，其被操作系统解释为一条指向另一个文件或者目录的路径。\nlerna bootstrap --use-workspaces使用yarn workspace的形式管理packages的依赖。\nlerna add\nlerna add &lt;package&gt; --scope=[package] --dev\nlerna add用于安装依赖到指定package内部，如果没有指定scope，那么默认安装到所有package内部。\n注意不同package之间如果相互依赖，也需要通过lerna add安装，这样lerna才能创建symlink关联到依赖的package内部。\nlerna publish\n发布所有更新过内容的package仓库到npm，会提示version的更新。\nlerna exec\n在每一个包路径内执行任意的命令行，也可以指定参数--scope在某一个包内执行。\nlerna run [script]\n在包含指定script的package内部执行该命令。\nlerna 的局限性\nlerna作为package管理的容器，lerna无法做到高效地管理node_modules：\n\nlerna为每个package单独执行xxx install的操作，并且依赖之间无法共享，所以会导致依赖的重复安装，可以参考上文使用lerna创建的项目内部管理react的安装项。\nlerna必须通过执行lerna bootstrap才能为不同package创建symlink，而如果单独在package内部执行yarn install等命令就会导致symlink被破坏，因此package管理非常受限制。\n\nyarn workspace\n为了解决lerna的局限性，yarn从0.28版本（目前 1.22）以后支持monorepo管理package之间的依赖。\n并且从yarn-1.0版本以后，yarn默认支持，这种方式在yarn内部称为workspace。使用上来说，只需要在monorepo根目录下的package.json中注册workspace的文件夹即可。\n{\n  &quot;private&quot;: true,\n  &quot;workspaces&quot;: [&quot;packages/*&quot;]\n}\nyarn workspace不能取代lerna，主要是为了解决lerna的问题，因此lerna从2.0.0版本以后，支持使用lerna bootstrap --use-workspace来使用yarn引导monorepo依赖的管理和创建，这样monorepo内部所有package的依赖都只会安装在仓库根目录的node_modules下。\nyarn install\n使用了 workspace 后，不再需要 lerna bootstrap 来安装依赖了，可以直接使用 yarn install 进行依赖的安装\n注意，yarn install 无论在顶层运行还是在任意一个子项目运行效果都是可以。\nyarn workspace\n$ yarn workspace &lt;workspace_name&gt; &lt;command&gt;\nyarn workspace命令用于在指定package内部执行命令；例如安装依赖到指定package内部：\n$ yarn workspace package1 add react react-dom --D\nyarn workspaces\n$ yarn workspaces run &lt;command&gt;\n在每个packages内部执行命令，类似于lerna run；运行时会检查每个子项目里面依赖及其版本，如果版本不一致都会保留到自己的 node_modules 中，只有依赖版本号一致的时候才会提升到顶层。\n此外，还需要在 lerna.json 中增加配置：\n{\n    &quot;npmClient&quot;: &quot;yarn&quot;, // 指定 npmClentyarn\n    &quot;useworkspaces&quot;: true // useworkspaces 设置true\n}\n\n\nmonorepo | icodex\n现代前端工程化-基于 Monorepo 的 lerna 详解(从原理到实战) \n"},"front-end/others/linux/init.d":{"title":"init.d","links":[],"tags":[],"content":"/etc/init.d 目录\n目录 /etc/init.d/ 中包含许多系统服务的启动和停止脚本，除了该文件还有许多 rc#.d 形式存在的目录（这里 # 代表一个指定的初始化级别，范围是0~6）。在这些目录之下，包含了许多对进程进行控制的脚本。\n\n以 System V init 或者 Upstart 为初始化系统的 Linux 讨论目录 /etc/init.d/ 才有意义\n\n在这些目录之下，包含了许多对进程进行控制的脚本。这些脚本要么以“K”开头，要么以“S”开头。以“K”开头的脚本运行在以“S”开头的脚本之前。\n使用 init.d 目录下的脚本，需要有 root 权限。每个脚本都将被作为一个命令运行，该命令的结构大致如下：\n/etc/init.d/&lt;command&gt; &lt;start|stop|reload|restart&gt;\n目录 /etc/rcN.d 是符号链接文件，实际上是链接到目录 /etc/init.d，可通过以下命令验证：\n$ ll /etc/rc1.d\nLinux 的每个运行级别，在 /etc 都有一个子目录分别是 rc0.d，rc1.d …… rc6.d，但是这些目录下的脚本都实际存放在  /etc/init.d 中，只是通过链接进行了级别的划分。\n这些符号链接的名称通常遵循 [S|K]XXname 的命名约定。在这里，S 表示要启动服务，K则表示停止服务，XX 是一个数字，表示执行顺序，name 是服务名称。\n当系统启动时，系统启动脚本将按照字母顺序执行 /etc/rc*.d 目录中的所有启动脚本符号链接，这将自动传递 start 命令参数，以便启动系统服务；当系统关机或重启时，则自动传递 stop 命令参数，停止系统服务。\nUbuntu中的运行级别\n\n0（关闭系统）\n1（单用户模式，只允许root用户对系统进行维护。）\n2 到 5（多用户模式，其中3为字符界面，5为图形界面。）\n6（重启系统）\n\n可以通过命令 runlevel，来获取当前系统运行的级别。\nupdate-rc.d 命令\nUbuntu 或者 Debian 系统中update-rc.d命令，是用来更新系统启动项的脚本。这些脚本的链接位于/etc/rcN.d/目录，对应脚本位于/etc/init.d/目录。\nlinux 系统主要启动步骤\n\n读取 MBR 的信息，启动 Boot Manager。\n加载系统内核，启动 init 进程， init 进程是 Linux 的根进程，所有的系统进程都是它的子进程。\ninit 进程读取 /etc/inittab 文件中的信息，并进入预设的运行级别。通常情况下 /etc/rcS.d/ 目录下的启动脚本首先被执行，然后是*/etc/rcN.d/* 目录。\n根据 /etc/rcS.d/ 文件夹中对应的脚本启动 Xwindow 服务器 xorg，Xwindow 为 Linux 下的图形用户界面系统。\n启动登录管理器，等待用户登录。\n\n创建一个启动脚本后，可以将其链接或直接放置到*/etc/init.d* 中，例如一个 ‘pm2`的服务，然后执行命令：\nsudo update-rc.d pm2 defaults\n则会为该服务创建一个启动符号链接（symbolic link）到系统各个不同级别的启动目录，也可以进行手动创建。"},"front-end/others/web/performance":{"title":"performance","links":[],"tags":[],"content":"浅谈前端性能指标\nWeb Vitals 核心指标\nGoogle 推出了 Web Vitals， 定义了指标集，旨在简化和统一衡量网站质量的指标。在 Web Vitals 指标中，Core Web Vitals 是其中最核心的部分，包含三个指标：\nLCP\nLCP（Largest Contentful Paint）是根据页面开始加载的时间报告，可视区域内最大的内容元素（例如图片或文本块）完成渲染的计算时间，用于测验加载性能，衡量网站初次载入速度。 我们应该控制该值在2.5 秒以内\n最大其实就是指元素的尺寸大小，这个大小不包括可视区域之外或者是被裁剪的不可见的溢出。也不包括元素的 Margin / Padding / Border 等。\n计算包括在内的元素有：\n\nimg 标签元素；\n内嵌在&lt;svg&gt;元素内的&lt;image&gt;元素；\nvideo 标签元素的封面元素；\n通过 url() 函数加载的带有背景图像的元素；\n包含文字节点的块级元素 或 行内元素；\n\n一般网页是分批加载的，因此所谓最大元素也是随着时间变化的，浏览器在在绘制第一帧时分发一个largest-contentful-paint类型PerformanceEntry对象，随着时间的渲染，当有更大的元素渲染完成时，就会有另一个PerformanceEntry对象报告。\n利用 PerformanceObserver 构造函数创建一个性能检测对象，可以通过以下代码打印采集数据：\nlet observer = new PerformanceObserver((entryList) =&gt; {\n  for (const entry of entryList.getEntries()) {\n    console.log(&quot;LCP candidate:&quot;, entry.startTime, entry);\n  }\n});\nobserver.observe({ type: &quot;largest-contentful-paint&quot;, buffered: true });\n \n// PerformanceObserver 接受一个回调函数作为参数\n// 回调函数会在每次性能条目（PerformanceEntry）被捕获时被调用\n \n// 回调函数中使用了一个 for 循环来遍历传入的性能条目列表（entryList.getEntries()）。\n// 在循环中，每个性能条目都会被打印到控制台上，包括了 LCP 候选项的开始时间和完整条目对象。\n \n// observer.observe() 方法，将观察者绑定到了 largest-contentful-paint 类型的性能条目上\n// 并设置 buffered: true 以确保可以获取到已经发生的 LCP 事件，而不仅仅是后续发生的事件\n一般来说，通过上面的代码，最新的largest-contentful-paint条目的startTime就是 LCP 值。\nFID\nFID（First Input Delay）首次输入延迟时间，主要为了测量页面加载期间响应度，测量交互性。为了提供良好的用户体验，页面的 FID 应为100 毫秒或更短。\n测量用户第一次与页面交互（单击链接、点按按钮等等）到浏览器对交互作出响应，并实际能够开始处理事件处理程序所经过的时间。FID 只关注不连续操作对应的输入事件，例如点击，轻触，按键等。一般只考虑测量首次输入的延迟。FID 只考虑事件处理过程的延迟，不考虑事件处理花费的时间或者事件处理完成更新页面花费的时间。\n和上面类似，创建 PerformanceObserver 对象监听 first-input 类型的条目，并获取条目的startTime和processingStart时间戳的差值作为结果\nnew PerformanceObserver((entryList) =&gt; {\n  for (const entry of entryList.getEntries()) {\n    const delay = entry.processingStart - entry.startTime;\n    console.log(&quot;FID candidate:&quot;, delay, entry);\n  }\n}).observe({ type: &quot;first-input&quot;, buffered: true });\nCLS\nCLS（Cumulative Layout Shift）累积布局偏移，测量视觉稳定性。为了提供良好的用户体验，页面的 CLS 应保持在 0.1 或更少。\nCLS 是测量整个页面生命周期内发生的所有意外布局偏移中最大一连串的布局偏移分数。\n每当一个可见元素从一个已渲染帧变更到另一个已渲染帧时，就是发生了布局偏移。\n所谓一连串布局偏移，是指一个或者多个的布局偏移，这些偏移相隔少于 1 秒，总持续时间最大为 5 秒。\n而最大一连串就是所有的一连串布局偏移中偏移累计分数最大的一连串。\n具体这个分数是怎么算的呢，首先偏移前后的两个已渲染帧的总的叠加大小（只算可视区域内，重合部分只算一次），占可视区域的百分比，称为影响分数，例如有个元素一开始占可视区域的 50%，然后下一帧往下偏移可视区域的 25%，那么这个元素的影响分数就是 0.75。然后取不稳定元素在一帧中的最大偏移距离（水平或垂直取最大）占对应可视区域（取水平对应宽度，垂直对应高度）的比例，称为距离分数，例如刚刚的例子，距离分数就是 0.25。\n距离分数和影响分数相乘就是偏移分数（例如上面例子相乘就是 0.75 * 0.25 = 0.1875）。\n常见的影响 CLS 分数的有：\n\n没有指定具体尺寸的图片或视频\n自定义字体引发的实际呈现出更大或更小的字体\n动态插入的内容，例如广告等\n\n值得一提的是，布局偏移并不都是不好的，更改元素的起始位置是网页应用用常见的事。布局偏移只有在用户不期望其发生的才是不好的。比如用户自己发起的布局偏移就是没有问题，这些 CLS 不计算在内，CLS 计算的是意外的布局偏移。在用户交互 500 毫秒内发生的布局偏移会带有hadRecentInput标志，CLS 计算会把这些偏移在计算中排除。\njs 测量 CLS 的原理是，创建一个PerformanceObserver对象来侦听意外偏移layout-shift条目：\nlet clsValue = 0;\nlet clsEntries = [];\n \nlet sessionValue = 0;\nlet sessionEntries = [];\n \nnew PerformanceObserver((entryList) =&gt; {\n  for (const entry of entryList.getEntries()) {\n    // 只将不带有最近用户输入标志的布局偏移计算在内。\n    if (!entry.hadRecentInput) {\n      const firstSessionEntry = sessionEntries[0];\n      const lastSessionEntry = sessionEntries[sessionEntries.length - 1];\n \n      // 如果条目与上一条目的相隔时间小于 1 秒且\n      // 与会话中第一个条目的相隔时间小于 5 秒，那么将条目\n      // 包含在当前会话中。否则，开始一个新会话。\n      if (\n        sessionValue &amp;&amp;\n        entry.startTime - lastSessionEntry.startTime &lt; 1000 &amp;&amp;\n        entry.startTime - firstSessionEntry.startTime &lt; 5000\n      ) {\n        sessionValue += entry.value;\n        sessionEntries.push(entry);\n      } else {\n        sessionValue = entry.value;\n        sessionEntries = [entry];\n      }\n \n      // 如果当前会话值大于当前 CLS 值，\n      // 那么更新 CLS 及其相关条目。\n      if (sessionValue &gt; clsValue) {\n        clsValue = sessionValue;\n        clsEntries = sessionEntries;\n \n        // 将更新值（及其条目）记录在控制台中。\n        console.log(&quot;CLS:&quot;, clsValue, clsEntries);\n      }\n    }\n  }\n}).observe({ type: &quot;layout-shift&quot;, buffered: true });\nweb-vitals 库\n上面介绍了三个核心指标简单的 js 测量代码，但是现实情况往往要复杂许多，例如要考虑页面通过往返缓存恢复时，API 不会报告指标相关的条目，而且 API 不考虑 iframe 的元素的问题等等。\n在特殊复杂的页面中，单纯用这种检查方式，结果往往不准。\n所以我们可以使用一些第三库，它已经帮我们把复杂的处理做了，例如使用官方的 web-vitals 库\n$ npm install web-vitals\n具体使用：\nimport { getLCP, getFID, getCLS } from &quot;web-vitals&quot;;\n \ngetCLS((metric) =&gt; console.log(&quot;cls: &quot; + metric.value));\ngetFID((metric) =&gt; console.log(&quot;fid: &quot; + metric.value));\ngetLCP((metric) =&gt; console.log(&quot;lcp: &quot; + metric.value));\n前端性能监控 API——Performance\n先简单了解下这个 API，直接打印这个对象看下\nconsole.log(window.performance);\n这些属性有些是还处于实验性阶段，有些平时比较少用到，常用的有例如\nmemory\n主要是和内存相关，显示此刻的内存占用情况，图中可以发现其有三个属性\n\njsHeapSizeLimit：上下文内可用堆的最大体积\ntotalJSHeapSize：当前 js 堆栈总内存大小\nusedJSHeapSize：当前被使用的内存大小，不能大于totalJSHeapSize，大于就可能有内存泄漏。\n\nnavigation\n表示出现在当前浏览上下文的 navigation 类型，图中可以发现其有两个属性\n\nredirectCount：重定向的次数，表示当前页重定向了几次\ntype：表示页面打开类型，可选值有 0、1、2、255\n\n0：通过常规的导航访问页面，例如点击链接\n1：通过刷新（包括用 js 调用的刷新）访问页面\n2：通过前进或者后退按钮访问页面\n255：除了以上的方式访问页面\n\n\n\ntiming\n因为我们本次讲的是性能，所以其实我们重点要看的就是 timing。\n它统计了从浏览器从网址开始导航到 window.onload事件触发的一系列关键的时间点，具体看下图\n\n\nnavigationStart：表示在同一浏览上下文中上一个文档终止时的时间戳。如果没有以前的文档，这个值将与fetchStart相同；\n\n\nunloadEventStart：表示窗口中的前一个网页（与当前页面同域）unload 的时间戳。如果没有前一个网页，或者前一个网页和当前页面不是同域，则返回值为 0；\nunloadEventEnd：表示当 unload 事件结束时的时间戳。 果没有前一个网页，或者前一个网页和当前页面不是同域，则返回值为 0；\nredirectStart：表示当第一个 HTTP 重定向开始时的时间戳。如果没有重定向，或者其中一个重定向不是同域，则返回值为 0。\nredirectEnd：表示当最后一个 HTTP 重定向完成时，即接收到 HTTP 响应的最后一个字节时的时间戳。如果没有重定向，或者其中一个重定向不是同域，则返回值为 0。\nfetchStart：表示当浏览器准备好使用 HTTP 请求获取文档时的时间戳。这个时刻是发生在检查任何应用程序缓存之前。\ndomainLookupStart：表示当 DNS 域名查询开始时的时间戳。如果使用了持久连接，或者信息存储在缓存或本地资源中（即无 DNS 查询），则该值将与 fetchStart 相同。\ndomainLookupEnd：表示当 DNS 域名查询完成时的时间戳。如果使用了持久连接，或者信息存储在缓存或本地资源中（即无 DNS 查询），则该值将与 fetchStart 相同。\nconnectStart：表示 HTTP TCP 开始建立连接的时间戳。如果传输层报告了一个错误，并且重新开始建立连接，则给出最后一次建立连接的开始时间戳。如果使用持久连接，则该值与 fetchStart 相同。\nconnectEnd：表示 HTTP TCP 完成建立连接（完成握手）的时间戳。如果传输层报告了一个错误，并且重新开始建立连接，则给出最后建立连接的结束时间。如果使用持久连接，则该值与 fetchStart 相同。当所有安全连接握手或 SOCKS 身份验证都被终止时，该连接被视为已打开。\nsecureConnectionStart：表示当安全连接握手（HTTPS 连接）开始时的时间戳。如果没有安全连接，则返回 0。\nrequestStart：表示浏览器发送请求从服务器或本地缓存中获取实际文档的时间戳。如果传输层在请求开始后失败，并且连接重新打开，则此属性将被设置为与新请求对应的时间。\nresponseStart：表示当浏览器从服务器的缓存或本地资源接收到响应的第一个字节时的时间戳。\nresponseEnd：表示当浏览器从服务器、缓存或本地资源接收到响应的最后一个字节时或者当连接被关闭时(如果这是首先发生的)的时间戳。\ndomLoading：表示当解析器开始工作，也就是开始渲染 dom 树的时间戳。这时 document.readyState 变为’loading’，相应的 readystatechange 事件被抛出。\ndomInteractive：表示解析器完成解析 dom 树的时间戳，这时 document.readyState 变为’interactive’，相应的 readystatechange 事件被抛出。这时候只是解析完成 DOM 树，还没开始加载网页内的资源。\ndomContentLoadedEventStart：表示 DOM 解析完成后，网页内的资源开始加载的时间戳。就在解析器发送 DOMContentLoaded 事件之前。\ndomContentLoadedEventEnd：表示 DOM 解析完成后，网页内的资源加载完成的时间戳。即在所有需要尽快执行的脚本(按顺序或不按顺序)被执行之后。\ndomComplete：表示当解析器完成它在主文档上的工作时，也就是 DOM 解析完成，且资源也准备就绪的时间。document.readyState 变为’complete’，相应的 readystatechange 事件被抛出。\nloadEventStart：表示当为当前文档发送 load 事件时，也就是 load 回调函数开始执行的时间。如果这个事件还没有被发送，它将返回 0。\nloadEventEnd：表示当 load 事件的回调函数执行完毕的时间，即加载事件完成时。如果这个事件还没有被发送，或者还没有完成，它将返回 0。\n\n借助这个 performance.timing 里面的各个时间戳，我们可以获取到\n\nDNS 解析耗时 : performance.timing.domainLookupEnd - performance.timing.domainLookupStart\nTCP 连接耗时 : performance.timing.connectEnd - performance.timing.connectStart\nSSL 连接耗时 : performance.timing.connectEnd - performance.timing.secureConnectionStart\nrequest 耗时 : performance.timing.responseEnd - performance.timing.responseStart\n解析 DOM 树耗时 : performance.timing.domComplete - performance.timing.domInteractive\ndomready 时间 : performance.timing.domContentLoadedEventEnd - performance.timing.fetchStart\nonload 时间 : performance.timing.loadEventEnd - performance.timing.fetchStart\n\nperformance 方法\n\n\nperformance.getEntries() ： 以对象数组的方式返回所有资源的数据，包括 css，img，script，xmlhttprequest，link 等等。这个数组就是性能缓存区存储的数据。\n例如我们看图中展开的一条 script 数据，其 duration 属性代表该资源的所需的总时间，和 NetWork Tab 中 对应资源的 Timing 时间差不多。\n\n\nperformance.getEntriesByType(type:string) : 和上面的 getEntries 方法类似，不过是多了一层类型的筛选。\n\n\nperformance.getEntriesByName(name: string, type?:string) : 同上，多了一层名字的筛选，也可以传第二个参数再加一层类型的筛选。\n\n\nperformance.now() ： 返回当前时间与performance.timing.navigationStart的时间差。\n通过打印 performance.now() + performance.timing.navigationStart 和 Date.now() 的值可以发现前者的数据会更精准一些：\nconsole.log(\n  performance.now() + performance.timing.navigationStart,\n  Date.now()\n);\n// 1706705883056.4 1706705879695\n\n\n其他重要指标\n除了以上的 Web Vitals 核心关键指标之外，还有其他的一些重要指标，例如\n\nTTFB（Time to First Byte）\nFCP（First Contentful Paint）\nFP（First Paint）\nSI（Speed Index）\nTTI（Time to Interactive）\nTBT（Total Blocking Time）\n\n接下来我们逐步分析下这几个指标：\nTTFB\n首包时间，资源请求到获取第一个字节之间的时间，包括以下阶段的总和\n\n重定向时间\nService Worker 启动时间（如果适用）\nDNS 查询\n连接和 TLS 协商\n请求，直到响应的第一个字节到达\n\n计算方式为\nconsole.log(\n  &quot;TTFB：&quot; +\n    (performance.timing.responseStart - performance.timing.navigationStart)\n);\n也可以用 PerformanceObserver 采集\nnew PerformanceObserver((entryList) =&gt; {\n  const [pageNav] = entryList.getEntriesByType(&quot;navigation&quot;);\n  console.log(`TTFB: ${pageNav.responseStart}`);\n}).observe({\n  type: &quot;navigation&quot;,\n  buffered: true,\n});\n或者用 web-vitals 库\nimport { getTTFB } from &quot;web-vitals&quot;;\n \n// 当 TTFB 可用时立即进行测量和记录。\ngetTTFB(console.log);\nFCP\n首屏时间，首次内容绘制的时间，指页面从开始加载到页面内容的任何部分在屏幕上完成渲染的时间。\n计算方式\nconsole.log(\n  &quot;FCP：&quot; + performance.getEntriesByName(&quot;first-contentful-paint&quot;)[0].startTime\n);\n上面代码可能不好确定调用时机，可以采用 PerformanceObserver 来监听采集\nnew PerformanceObserver((entryList) =&gt; {\n  for (const entry of entryList.getEntriesByName(&quot;first-contentful-paint&quot;)) {\n    console.log(&quot;FCP candidate:&quot;, entry.startTime, entry);\n  }\n}).observe({ type: &quot;paint&quot;, buffered: true });\n或者用 web-vitals 库\nimport { getFCP } from &quot;web-vitals&quot;;\n \n// 当 FCP 可用时立即进行测量和记录。\ngetFCP(console.log);\nFP\n白屏时间，首次渲染的时间点。FP 和 FCP 有点像，但 FP 一定先于 FCP 发生，例如一个页面加载时，第一个 DOM 还没绘制完成，但是可能这时页面的背景颜色已经出来了，这时 FP 指标就被记录下来了。而 FCP 会在页面绘制完第一个 DOM 内容后记录。\n计算方式\nconsole.log(&quot;FP：&quot; + performance.getEntriesByName(&quot;first-paint&quot;)[0].startTime);\n上面代码可能不好确定调用时机，可以采用 PerformanceObserver 来监听采集\nnew PerformanceObserver((entryList) =&gt; {\n  for (const entry of entryList.getEntriesByName(&quot;first-paint&quot;)) {\n    console.log(&quot;FP:&quot;, entry.startTime, entry);\n  }\n}).observe({ type: &quot;paint&quot;, buffered: true });\nSI\n速度指数衡量页面加载期间内容的视觉显示速度，也就是页面填充快慢的指标。\n良好的 SI 应该控制在3.4以内。\nTTI\n可交互时间，指标测量页面从开始加载到主要子资源完成渲染，并能够快速、可靠地响应用户输入所需的时间。\n良好的 TTI 应该控制在5秒以内。\nTBT\n总阻塞时间，也就是从 FCP 到 TTI 之间的时间。\n性能测试工具\n像上面提到 SI、TTI、TBT 指标想通过代码来测量是比较困难的，测量出来也是不准的。\n所以我们一般需要借助一些性能测试工具。\nLighthouse\nLighthouse 是谷歌官方开发的性能分析工具，目前已经嵌入到 chrome 开发者工具的选项卡中，不需要额外安装，可以直接使用。\n切换到 Lighthouse Tab ，点击 Generate report 可以直接生成报告，其中包含 FCP、TTI、SI、TBT、LCP、CLS 六个指标数据，但是无法测试 FID。\n还有总的性能评分，以及 SEO 的分数和一些其他的优化建议等等，总的来说报告数据算是很齐全的。\nPageSpeed Insights 性能测试网站\n[PageSpeed Insights](PageSpeed Insights (web.dev))\n这是一个输入网址就可以测试性能的网站，基本该有的指标数据都有，包括 Lighthouse 暂不支持的 FID。\n可以选择全球各地进行性能测试，同样提供详细的检查结果报告，包括清晰的瀑布图数据，以及相关的优化建议。\n有个问题就是这个网站测试要排队，往往要等一会才出结果。"},"front-end/others/web/xss":{"title":"xss","links":[],"tags":[],"content":"跨站脚本攻击（Cross-Site Scripting，XSS，区别于层叠样式表 CSS）是一种注入攻击，它将恶意代码注入到本来安全的网站中。攻击者利用目标网站的漏洞，向最终用户发送恶意代码，通常是客户端 JavaScript。与直接针对应用程序主机不同，XSS 攻击通常直接针对应用程序的用户。\n如果 Web 应用程序在没有适当转义或验证的情况下显示来自用户或不受信任来源的内容，就会为 XSS 攻击留下漏洞。XSS 漏洞是当今 OWASP 十大安全问题之一，特别是因为许多组织严重依赖 Web 应用程序进行客户互动和验证。\nReflected XSS\n反射型的 XSS 攻击，主要是由于服务端接收到客户端的不安全输入，在客户端触发执行从而发起 Web 攻击。\n具体而言，反射型 XSS 只是简单地把用户输入的数据 “反射” 给浏览器，这种攻击方式往往需要攻击者诱使用户点击一个恶意链接，或者提交一个表单，或者进入一个恶意网站时，注入脚本进入被攻击者的网站。这是一种非持久型的攻击。\n比如：在某购物网站搜索物品，搜索结果会显示搜索的关键词。搜索关键词填入&lt;script&gt;alert(&#039;handsome boy&#039;)&lt;/script&gt;，点击搜索。页面没有对关键词进行过滤，这段代码就会直接在页面上执行，弹出 alert。\nStored XSS\n基于存储的 XSS 攻击，是通过提交带有恶意脚本的内容存储在服务器上，当其他人看到这些内容时发起 Web 攻击。一般提交的内容都是通过一些富文本编辑器编辑的，很容易插入危险代码。\n比较常见的一个场景是攻击者在社区或论坛上写下一篇包含恶意 JavaScript 代码的文章或评论，文章或评论发表后，所有访问该文章或评论的用户，都会在他们的浏览器中执行这段恶意的 JavaScript 代码。这是一种持久型的攻击。\nDOM XSS\n基于 DOM 的 XSS 攻击是指通过恶意脚本修改页面的 DOM 结构，是纯粹发生在客户端的攻击。\nDOM 型 XSS 跟前两种 XSS 的区别：DOM 型 XSS 攻击中，取出和执行恶意代码由浏览器端完成，属于前端 JavaScript 自身的安全漏洞，而其他两种 XSS 都属于服务端的安全漏洞。举个栗子 ：\n&lt;input type=&quot;text&quot; id=&quot;input&quot;&gt;\n&lt;button id=&quot;btn&quot;&gt;Submit&lt;/button&gt;\n&lt;div id=&quot;div&quot;&gt;&lt;/div&gt;\n&lt;script&gt;\n    const input = document.getElementById(&#039;input&#039;);\n    const btn = document.getElementById(&#039;btn&#039;);\n    const div = document.getElementById(&#039;div&#039;);\n \n    let val;\n    \n    input.addEventListener(&#039;change&#039;, (e) =&gt; {\n        val = e.target.value;\n    }, false);\n \n    btn.addEventListener(&#039;click&#039;, () =&gt; {\n        div.innerHTML = `&lt;a href=${val}&gt;testLink&lt;/a&gt;`\n    }, false);\n&lt;/script&gt;\n点击 Submit 按钮后，会在当前页面插入一个链接，其地址为用户的输入内容。如果用户在输入时构造了如下内容：\n&quot; onclick=alert(/xss/)\n用户提交之后，页面代码就变成了：\n&lt;a href onlick=&quot;alert(/xss/)&quot;&gt;testLink&lt;/a&gt;\n此时，用户点击生成的链接，就会执行对应的脚本。**DOM 型 XSS 攻击，实际上就是网站前端 JavaScript 代码本身不够严谨，把不可信的数据当作代码执行了。**在使用 .innerHTML、.outerHTML、document.write() 时要特别小心，不要把不可信的数据作为 HTML 插到页面上，而应尽量使用 .textContent、.setAttribute() 等。\nDOM 中的内联事件监听器，如 location、onclick、onerror、onload、onmouseover 等，&lt;a&gt; 标签的 href 属性，JavaScript 的 eval()、setTimeout()、setInterval() 等，都能把字符串作为代码运行。如果不可信的数据拼接到字符串中传递给这些 API，很容易产生安全隐患，请务必避免。\nJSONP XSS\nJSONP 的 callback 参数非常危险，他有两种风险可能导致 XSS：\n\ncallback 参数意外截断 js 代码，特殊字符单引号双引号，换行符均存在风险。\ncallback 参数恶意添加标签，造成 XSS 漏洞。\n\n浏览器为了保证跨域访问的安全性，会默认发一个 callback 参数到后台，接口拿到这个参数之后，需要将返回的 JSON 数据外面包上 callback 参数。\n具体的返回格式：\nCALLBACK(JSON)\n如果 ajax 请求是 JSONP 请求，返回的内容浏览器还会自动检测，如果不是按这个格式返回或者 callback 的内容不对，这次请求就算失败了。\n这里有一个机制，那就是请求的 callback 会被放入返回的内容当中，这也是可能出问题的地方。举个栗子，如果返回的页面，那么 Content-Type: text/html，那么 callback 注入的 html 元素都可以直接放到页面上了。那么，html 页面必然不能支持 callback。支持 JSONP 的链接如果直接放到浏览器里面访问，浏览器就不会做 callback 校验了。\n\n\n前端 | XSS 的攻击手段及其防御 - 知乎 (zhihu.com)\n\n\n前端安全系列（一）：如何防止XSS攻击？ - 美团技术团队 (meituan.com)\n\n"},"front-end/others/yarn":{"title":"yarn","links":[],"tags":[],"content":"Yarn 工作区系统性学习\nYarn Workspaces（工作空间/工作区，本文使用工作空间这一名称）是 Yarn 提供的Monorepo依赖管理机制，从 Yarn 1.0 开始默认支持，用于在代码仓库的根目录下管理多个 project的依赖。\nYarn Workspaces 的目标是使使用 Monorepo 变得简单，以一种更具声明性的方式处理yarn link的主要使用场景。\n简而言之，它们允许多个项目共存在同一个代码库中，并相互交叉引用，并且保证一个项目源代码的任何修改都会立即应用到其他项目中。\nMenorepo 的优点是可以在一个仓库里维护多个 package，可统一构建，跨 package 调试、依赖管理、版本发布都十分方便，搭配工具还能统一生成 CHANGELOG；\n代价是即使只开发其中一个 package 也需要安装整个项目的依赖。以 jest 为例，其 Monorepo 代码结构为：\n| jest/\n| ---- package.json\n| ---- packages/\n| -------- babel-jest/\n| ------------ package.json\n| -------- babel-plugin-jest-hoist/\n| ------------ package.json\n| -------- babel-preset-jest/\n| ------------ package.json\n| -------- .../\n\nYour dependencies can be linked together, which means that your workspaces can depend on one another while always using the most up-to-date code available. This is also a better mechanism than yarn link since it only affects your workspace tree rather than your whole system.\n工作区内的依赖关系可以链接在一起，这意味着工作区可以相互依赖，同时始终使用最新的可用代码。这也是一个相对于yarn link更好的机制，因为它只影响你的工作空间树，而不是整个系统。\nAll your project dependencies will be installed together, giving Yarn more latitude to better optimize them.\n所有的项目依赖关系都将被安装在一起，为 Yarn 提供更多的自由度来更好地优化它们。\nYarn will use a single lockfile rather than a different one for each project, which means fewer conflicts and easier reviews.\n对于每个项目，Yarn 将使用一个公共的的锁文件而不是为每个工程使用一个不同的锁文件，这意味着更少的冲突和更容易的版本审查。\n\nYarn Workspaces 配置\n{\n  &quot;private&quot;: true,\n  &quot;workspaces&quot;: [&quot;app1&quot;, &quot;app2&quot;]\n   // 具名 Workspace, 名字任意，但需跟子项目中 package.json 中 name 属性值一致\n}\n// 当Workspace很多时，也可以采用全目录引用的方式\n// 假设项目代码在projects目录下\n{\n  &quot;private&quot;: true,\n  &quot;workspaces&quot;: [&quot;projects/*&quot;]\n}\n\nNote that the private: true is required! Workspaces are not meant to be published, so we’ve added this safety measure to make sure that nothing can accidentally expose them.\n注意：private: true配置是必需的！工作区并不意味着要被发布，所以需要添加了这个安全措施，以确保不会发布到 npm 仓库。\n\n\n使用yarn workspaces info [--json]命令可以获得整个 workspace 的目录结构；\nyarn install 命令既可以在 workspace-root 目录下执行，也可以在任何一个 workspace 目录下执行，效果是一样的；\n工作区目录下的 node_modules 目录不是必然存在的，只有在依赖了不同版本的同一个依赖或者存在自己的特有依赖时才会出现；\nworkspaceDependencies列出了该 workspace 依赖的其他 workspace；\n\nYarn Workspaces 常用 CLI\n在指定的 workspace 下执行 command，即 command 作用域为某个 workspace：\nyarn workspace &lt;workspace_name&gt; &lt;command&gt;\n \n# 为 app1 安装 react\nyarn workspace app1 add react --save\n# 执行 app1 中的 start 脚本\nyarn workspace app1 run start\n# 在 app1 中，将工作区 app2 作为依赖安装 (link\nyarn workspace app1 add app2@1.0.0\n将在每个工作区中运行所选择的 Yarn 命令，即遍历所有 workspace 执行 command 命令：\nyarn workspaces run &lt;command&gt;\n \n# 在所有workspace中执行yarn start命令\nyarn workspaces run start\n# 在所有workspace中执行yarn test命令\nyarn workspaces run test\nYarn 2.x 新增\n在 Yarn 2.x 中删除了 yarn workspaces info 指令\n# 安装单个工作区及其依赖项\nyarn workspaces focus\n\n要使用此命令，请先安装 workspace-tools 插件：yarn plugin import workspace-tools\n\n# 在所有工作空间上运行command命令\nyarn workspaces foreach [command]\nyarn workspaces foreach run start\n\n要使用此命令，请先安装 workspace-tools 插件：yarn plugin import workspace-tools\n\n# 在 workspace-root 下执行，列出所有可用的工作区\nyarn workspaces list\nYarn Workspaces 实践\n|-- node_modules\n|   |-- module-a (link)\n|   |   `-- package.json\n|   |-- module-b (link)\n|   |   |-- node_modules\n|   |   |-- package.json\n|   |   |-- yarn-error.log\n|   |   `-- yarn.lock\n|   |-- plugin-a (link)\n|   |   `-- package.json\n|   `-- plugin-b (link)\n|       `-- package.json\n|-- package.json\n|-- packages\n|   |-- module-a\n|   |   `-- package.json\n|   `-- module-b\n|       |-- node_modules\n|       |-- package.json\n|       |-- yarn-error.log\n|       `-- yarn.lock\n|-- plugins\n|   |-- plugin-a\n|   |   `-- package.json\n|   `-- plugin-b\n|       `-- package.json\n`-- yarn.lock\n执行命令，为工作区 module-a 安装工作区依赖 plugin-a ：\n$ $ yarn workspace module-a add plugin-a@1.0.0\n...\n...\n$ yarn workspaces info --json\nyarn workspaces v1.22.19\n{\n  &quot;module-a&quot;: {\n    &quot;location&quot;: &quot;packages/module-a&quot;,\n    &quot;workspaceDependencies&quot;: [\n      &quot;plugin-a&quot;\n    ],\n    &quot;mismatchedWorkspaceDependencies&quot;: []\n  },\n  &quot;module-b&quot;: {\n    &quot;location&quot;: &quot;packages/module-b&quot;,\n    &quot;workspaceDependencies&quot;: [],\n    &quot;mismatchedWorkspaceDependencies&quot;: []\n  },\n  &quot;plugin-a&quot;: {\n    &quot;location&quot;: &quot;plugins/plugin-a&quot;,\n    &quot;workspaceDependencies&quot;: [],\n    &quot;mismatchedWorkspaceDependencies&quot;: []\n  },\n  &quot;plugin-b&quot;: {\n    &quot;location&quot;: &quot;plugins/plugin-b&quot;,\n    &quot;workspaceDependencies&quot;: [],\n    &quot;mismatchedWorkspaceDependencies&quot;: []\n  }\n}\nWorkspaces 软链过程\n\n判断当前 Monorepo 中，是否存在匹配 module-a 所需版本的 plugin-a；\n若存在，执行 link 操作，module-a 直接使用本地 plugin-a；\n若不存在，从远端 npm 仓库拉取符合版本的 plugin-a 供 module-a 使用；\n若远端 npm 仓库也找不到 plugin-a 组件，则报错：error An unexpected error occurred: &quot;registry.npmjs.org/plugin-a: Not found&quot;.\n\nYarn Workspaces 限制与不足\n\nyarn workspace 并没有像 lerna 那样封装大量的高层 API，整个 workspace 整体上还是依赖于整个 yarn 命令体系；\nworkspace 不支持嵌套（只能有一个 workspace-root）；\nworkspace 采用的是向上遍历，所以 workspace 并不能识别 workspace-root 之外的依赖；\n依赖引用版本不确定性，如上文的 plugins/plugin-a，当开发者将其发布到了 npm 仓库并且 npm 仓库的版本号跟本地版本号不一致时，容易出现此问题；\nyarn workspace link 的依赖需要添加到 webpack/rollup/vite 等构建工具的构建路径中，增加构建时成本，发布变慢；\nyarn.lock 容易出现冲突。\n\nYarn Workspaces 使用规范推荐\n针对 Yarn Workspaces 存在的上述问题，推荐一套项目级别的实施规范。以利用其长处，避免其短处。\n\n\nyarn workspace link 的 Packages 设置为私有\n\n在需要本地依赖的组件的package.json中设置private：true，目的是防止其被误上传至 npm 远程仓库。强制限定只能通过本地源码 link 的方式引用，这样就可以有效避免问题 4。\n\n\n\n所有 workspace 的依赖声明收敛到 workspace-root 中\n\n即各个 workspace 的 pakcage.json 中不再声明 dependencies、devDependencies，依赖的注册全部收敛到 workspace-root 的 package.json 中。\n对于新的项目可以在一开始就只使用yarn -W add [package] [--dev]进行安装，对于历史项目可以手工修改各 workspace 的 package.json，将依赖剪切到根目录的 package.json 里。\n这样做的好处是统一各个子 workspace 的依赖版本，避免同一依赖安装不同版本，保持整个 worktree 下项目里依赖版本的统一，并在各 workspace 间共享依赖。\n对于全局共享依赖带来的项目初始化安装时间的增加，是可以接受的，因为只是首次安装耗时长而已，后续因为有缓存，安装时间将大大缩减。\n\n\n\n禁止 workspace 独立新增依赖\n\n所有新增的依赖需要通过yarn -W add [package] [--dev]进行安装，这一条可以认识是对第二条规范的补充。\n\n\n\nyarn.lock必须提交，冲突必须解决\n\nyarn.lock 是 yarn 依赖版本控制的基础，在全局共享依赖的框架下，yarn.lock 文件的维护变得尤其重要。保证提交是为了确保新增依赖能够纳入到 yarn 版本管控中，正确解决冲突则是确保依赖版本的唯一性、统一性。\n\n\n\n在 Yarn Workspace 跟目录中添加 eslint、prettier 配置，各子 workspace 继承 root 的配置\n\neslint 和 prettier 配置已经成为规范项目代码的标配，既然是配置当然要在整个 Workspace 范围内保持统一。\n\n\n\n日常开发应当在 workspace-root 目录下\n\n这是对规范 5 补充，确保全局代码规范能够生效；\n也能让开发者方便查看 yarn workspace link 的 Packages\n\n\n"},"front-end/react/18":{"title":"18","links":[],"tags":[],"content":"前言\nreact 17 的发布时间是 2020 年 10 月 20 号，距离 React 18 发布足足间隔一年半，并且v17中只有三个小版本，分别是17.0.0、17.0.1、17.0.2：\n\n17.0.0 - React 17 正式版发布\n17.0.1 - 只改动了 1 个文件，修复 ie 兼容问题，同时提升了 V8 内部对数组的执行性能\n17.0.2 - 改动集中于 Scheduler 包, 主干逻辑没有变动，只与性能统计相关\n\n可以看到，在 React 17 的两次迭代中，都是只更新了补丁号，并且都是一些比较细节的更新，直到一年半之后的今天 React 18 正式版发布，React 17 都没有任何更新，所以 React 17 也被称为 垫脚石版本， 可以看出，React 工作组 对新特性的探索相当谨慎。\n\nReact 18 已经放弃了对 ie11 的支持，将于 2022年6月15日 停止支持 ie，如需兼容，需要回退到 React 17 版本。\nReact 18 中引入的新特性是使用现代浏览器的特性构建的，在IE中无法充分 polyfill，比如 micro-tasks。\n\n新特性\nRender API\n为了更好的管理root节点，React 18 引入了一个新的 root API，新的 root API 还支持 new concurrent renderer（并发模式的渲染），它允许你进入concurrent mode（并发模式）。\n// React 17\nimport React from &#039;react&#039;;\nimport ReactDOM from &#039;react-dom&#039;;\nimport App from &#039;./App&#039;;\n \nconst root = document.getElementById(&#039;root&#039;)!;\n \nReactDOM.render(&lt;App /&gt;, root);\n \n// React 18\nimport React from &#039;react&#039;;\nimport ReactDOM from &#039;react-dom/client&#039;;\nimport App from &#039;./App&#039;;\n \nconst root = document.getElementById(&#039;root&#039;)!;\n \nReactDOM.createRoot(root).render(&lt;App /&gt;);\n同时，在卸载组件时，我们也需要将 unmountComponentAtNode 升级为 root.unmount:\n// React 17\nReactDOM.unmountComponentAtNode(root);\n \n// React 18\nroot.unmount();\n\n我们如果在 React 18 中使用旧的 render api，在项目启动后，你将会在控制台中看到一个警告，这表示你可以将项目直接升级到 React 18 版本，而不会直接造成 break change。如果你需要保持着 React 17 版本的特性的话，那么你可以无视这个报错，因为它在整个 18 版本中都是兼容的。\n\n除此之外，React 18 还从 render 方法中删除了回调函数，因为当使用Suspense时，它通常不会有预期的结果。\n在新版本中，如果需要在 render 方法中使用回调函数，我们可以在组件中通过 useEffect 实现：\n// React 17\nconst root = document.getElementById(&#039;root&#039;)!;\nReactDOM.render(&lt;App /&gt;, root, () =&gt; {\n  console.log(&#039;渲染完成&#039;);\n});\n \n// React 18\nconst AppWithCallback: React.FC = () =&gt; {\n  useEffect(() =&gt; {\n    console.log(&#039;渲染完成&#039;);\n  }, []);\n  return &lt;App /&gt;;\n};\nconst root = document.getElementById(&#039;root&#039;)!;\nReactDOM.createRoot(root).render(&lt;AppWithCallback /&gt;);\n最后，如果你的项目使用了ssr服务端渲染，需要把hydrate升级为hydrateRoot：\n// React 17\nimport ReactDOM from &#039;react-dom&#039;;\nconst root = document.getElementById(&#039;root&#039;);\nReactDOM.hydrate(&lt;App /&gt;, root);\n \n// React 18\nimport ReactDOM from &#039;react-dom/client&#039;;\nconst root = document.getElementById(&#039;root&#039;)!;\nReactDOM.hydrateRoot(root, &lt;App /&gt;);\n如果你的项目使用了 TypeScript，最值得注意的变化是，现在在定义props类型时，如果需要获取子组件children，那么你需要显式的定义它，例如这样：\n// React 17\ninterface MyButtonProps {\n  color: string;\n}\n \nconst MyButton: React.FC&lt;MyButtonProps&gt; = ({ children }) =&gt; {\n  // 在 React 17 的 FC 中，默认携带了 children 属性\n  return &lt;div&gt;{children}&lt;/div&gt;;\n};\n \nexport default MyButton;\n \n \n// React 18\ninterface MyButtonProps {\n  color: string;\n  children?: React.ReactNode;\n}\n \nconst MyButton: React.FC&lt;MyButtonProps&gt; = ({ children }) =&gt; {\n  // 在 React 18 的 FC 中，不存在 children 属性，需要手动申明\n  return &lt;div&gt;{children}&lt;/div&gt;;\n};\n \nexport default MyButton;\nsetState 自动批处理\nReact 18 通过在默认情况下执行批处理来实现了开箱即用的性能改进。\n批处理是指为了获得更好的性能，在数据层，将多个状态更新批量处理，合并成一次更新（在视图层，将多个渲染合并成一次渲染）。\n\n批处理：React会尝试将同一上下文中触发的更新合并为一个更新。\n批处理的优势：\n\n合并不必要的更新，减少更新流程调用次数\n状态按顺序保存下来，更新时不会出现**「竞争问题」**\n最终触发的更新是异步流程，减少浏览器掉帧可能性\n\n\n在 React 18 之前\n在React 18 之前，我们只在 React 事件处理函数 中进行批处理更新。默认情况下，在promise、setTimeout、原生事件处理函数中、或任何其它事件内的更新都不会进行批处理：\n情况一：React 事件处理函数\nimport React, { useState } from &#039;react&#039;;\n \n// React 18 之前\nconst App: React.FC = () =&gt; {\n  console.log(&#039;App组件渲染了！&#039;);\n  const [count1, setCount1] = useState(0);\n  const [count2, setCount2] = useState(0);\n  return (\n    &lt;button\n      onClick={() =&gt; {\n        setCount1(count =&gt; count + 1);\n        setCount2(count =&gt; count + 1);\n        // 在 React 事件中被批处理\n      }}\n    &gt;\n      {`count1 is ${count1}, count2 is ${count2}`}\n    &lt;/button&gt;\n  );\n};\n \nexport default App;\n点击 button，打印 console.log：渲染次数和更新次数是一样的，即使我们更新了两个状态，每次更新组件也只渲染一次。\n情况二：setTimeout\nimport React, { useState } from &#039;react&#039;;\n \n// React 18 之前\nconst App: React.FC = () =&gt; {\n  console.log(&#039;App组件渲染了！&#039;);\n  const [count1, setCount1] = useState(0);\n  const [count2, setCount2] = useState(0);\n  return (\n    &lt;div\n      onClick={() =&gt; {\n        setTimeout(() =&gt; {\n          setCount1(count =&gt; count + 1);\n          setCount2(count =&gt; count + 1);\n        });\n        // 在 setTimeout 中不会进行批处理\n      }}\n    &gt;\n      &lt;div&gt;count1：{count1}&lt;/div&gt;\n      &lt;div&gt;count2：{count2}&lt;/div&gt;\n    &lt;/div&gt;\n  );\n};\n \nexport default App;\n点击 button，重新打印 console.log：每次点击更新两个状态，组件都会渲染两次（输出两次 log），不会进行批量更新。\n情况三：原生 js 事件\nimport React, { useEffect, useState } from &#039;react&#039;;\n \n// React 18 之前\nconst App: React.FC = () =&gt; {\n  console.log(&#039;App组件渲染了！&#039;);\n  const [count1, setCount1] = useState(0);\n  const [count2, setCount2] = useState(0);\n  useEffect(() =&gt; {\n    document.body.addEventListener(&#039;click&#039;, () =&gt; {\n      setCount1(count =&gt; count + 1);\n      setCount2(count =&gt; count + 1);\n    });\n    // 在原生js事件中不会进行批处理\n  }, []);\n  return (\n    &lt;&gt;\n      &lt;div&gt;count1： {count1}&lt;/div&gt;\n      &lt;div&gt;count2： {count2}&lt;/div&gt;\n    &lt;/&gt;\n  );\n};\n \nexport default App;\n点击 button：在原生js事件中，结果跟情况二是一样的，每次点击更新两个状态，组件都会渲染两次，不会进行批量更新。\n源码参考\nexport function batchedUpdates&lt;A, R&gt;(fn: A =&gt; R, a: A): R {\n  const prevExecutionContext = executionContext;\n  executionContext |= BatchedContext;\n  try {\n    return fn(a);\n  } finally {\n    executionContext = prevExecutionContext;\n    // If there were legacy sync updates, flush them at the end of the outer\n    // most batchedUpdates-like method.\n    if (executionContext === NoContext) {\n      resetRenderTimer();\n      flushSyncCallbacksOnlyInLegacyMode();\n    }\n  }\n}\n可以看到，传入一个回调函数fn，此时会通过**「位运算」**将代表当前执行上下文状态的变量executionContext中增加BatchedContext状态。拥有这个状态位代表当前执行上下文需要批处理。\n\n\n在fn执行过程中，其获取到的全局变量executionContext都会包含BatchedContext。\n\n\n最终fn执行完后，进入try...finally逻辑，将executionContext恢复为之前的上下文。\n\n\n曾经React源码内部，执行onClick时的逻辑类似如下：\nbatchedUpdates(onClick, e);\n在onClick内部的this.setState中，获取到的executionContext包含BatchedContext，不会立刻进入更新流程。\n等退出该上下文后再统一执行一次更新流程，即**「半自动批处理」**。\n为什么说是**「半自动」**，因为batchedUpdates方法是同步调用的，如果fn有异步流程，如：\nonClick() {\n  setTimeout(() =&gt; {\n    this.setState({a: 3});\n    this.setState({a: 4});\n  })\n}\n么在真正执行this.setState时batchedUpdates早已执行完，executionContext中已经不包含BatchedContext。\n此时触发的更新不会走批处理逻辑。\n所以这种**「只对同步流程中的 this.setState 进行批处理」，只能说是「半自动」**。\n为了弥补**「半自动批处理」**的不灵活，ReactDOM中导出了unstable_batchedUpdates方法供开发者手动调用。\n比如如上例子，可以这样修改：\nonClick() {\n  setTimeout(() =&gt; {\n    ReactDOM.unstable_batchedUpdates(() =&gt; {\n      this.setState({a: 3});\n      this.setState({a: 4});\n    })\n  })\n}\n那么两次this.setState调用时上下文中全局变量executionContext中会包含BatchedContext。\n在 React 18 中\n在 React 18 上面的三个例子只会有一次 render，因为所有的更新都将自动批处理。这样无疑是很好的提高了应用的整体性能。\n不过以下例子会在 React 18 中执行两次 render：\nimport React, { useState } from &#039;react&#039;;\n \n// React 18\nconst App: React.FC = () =&gt; {\n  console.log(&#039;App组件渲染了！&#039;);\n  const [count1, setCount1] = useState(0);\n  const [count2, setCount2] = useState(0);\n  return (\n    &lt;div\n      onClick={async () =&gt; {\n        await setCount1(count =&gt; count + 1);\n        setCount2(count =&gt; count + 1);\n      }}\n    &gt;\n      &lt;div&gt;count1：{count1}&lt;/div&gt;\n      &lt;div&gt;count2：{count2}&lt;/div&gt;\n    &lt;/div&gt;\n  );\n};\n \nexport default App;\n总结：\n\n在 18 之前，只有在 react 事件处理函数中，才会自动执行批处理，其它情况会多次更新\n在 18 之后，任何情况都会自动执行批处理，多次更新始终合并为一次\n\nReact 18是怎么实现在各种上下文环境都能批处理呢？关键在于两点：\n\n增加调度的流程；\n不以全局变量executionContext为批处理依据，而是以更新的**「优先级」**为依据；\n\n优先级\n调用this.setState后源码内部会依次执行：\n\n根据当前环境选择一个**「优先级」**\n创造一个代表本次更新的update对象，赋予其步骤1的优先级\n将update挂载在当前组件对应fiber（虚拟DOM）上\n进入调度流程\n\n以如下例子来说：\nonClick() {\n  this.setState({a: 1});\n  this.setState({a: 2});\n}\n第一次执行this.setState创建的update数据结构如下：\n{\n    callback: null,\n    eventTime: 5891.19999999988079,\n    lane: 1,\n    next: null,\n    payload: { a: 1 },\n    tag: 0\n}\n第二次执行this.setState创造的update数据结构如下：\n{\n    callback: null,\n    eventTime: 34380.3999999997615,\n    lane: 1,\n    next: null,\n    payload: { a: 2 },\n    tag: 0\n}\n\nlane代表该update的优先级\n\n在React 18，不同场景下触发的更新拥有不同**「优先级」**，比如：\n\n如上例子中事件回调中的this.setState会产生同步优先级的更新，这是最高的优先级（lane为1）\n\n为了对比，我们将如上代码放入setTimeout中：\nonClick() {\n  setTimeout(() =&gt; {\n    this.setState({a: 1});\n    this.setState({a: 2});\n  })\n}\n\n第一次执行this.setState创造的update数据结构如下：\n{\n    callback: null,\n    eventTime: 13380.3999999997615,\n    lane: 16,\n    next: null,\n    payload: { a: 1 },\n    tag: 0\n}\n第二次执行this.setState创造的update数据结构如下：\n{\n    callback: null,\n    eventTime: 13380.3999999997615,\n    lane: 16,\n    next: null,\n    payload: { a: 2 },\n    tag: 0\n}\n\nlane为16，代表Normal（即一般优先级）。\n\n调度流程\n在组件对应fiber挂载update后，就会进入**「调度流程」**。\n试想，一个大型应用，在某一时刻，应用的不同组件都触发了更新。\n那么在不同组件对应的fiber中会存在不同优先级的update。\n**「调度流程」**的作用就是：选出这些update中优先级最高的那个，以该优先级进入更新流程。\nfunction ensureRootIsScheduled(root, currentTime) {\n \n  // 获取当前所有优先级中最高的优先级\n  var nextLanes = getNextLanes(root, root === workInProgressRoot ? workInProgressRootRenderLanes : NoLanes);\n  // 本次要调度的优先级\n  var newCallbackPriority = getHighestPriorityLane(nextLanes);\n \n  // 已经存在的调度的优先级\n  var existingCallbackPriority = root.callbackPriority;\n \n  if (existingCallbackPriority === newCallbackPriority) {\n    return;\n  }\n  // 调度更新流程\n  newCallbackNode = scheduleCallback(schedulerPriorityLevel, performConcurrentWorkOnRoot.bind(null, root));\n \n  root.callbackPriority = newCallbackPriority;\n  root.callbackNode = newCallbackNode;\n}\n简化后的调度流程大体是：\n\n获取当前所有优先级中最高的优先级\n将步骤1的优先级作为本次调度的优先级\n看是否已经存在一个调度\n如果已经存在调度，且和当前要调度的优先级一致，则return\n不一致的话就进入调度流程\n\n可以看到，调度的最终目的是在一定时间后执行performConcurrentWorkOnRoot，正式进入更新流程。"},"front-end/react/19":{"title":"19","links":[],"tags":[],"content":"use\nuse 是一个实验性 React Hook，可让您读取 Promise 或 Context 等资源的值。\n与所有其他 React Hooks 不同use 可以在循环和条件语句（如 if）中调用。与其他 React Hooks 一样，调用 use 的函数必须是 Component 或 Hook。\n我们来分别看一下use(Promise)和 use(Context)。\nuse(Promise)"},"front-end/react/code-analysis/React-fiber-root":{"title":"React-fiber-root","links":[],"tags":[],"content":"FiberRoot的含义与作用\n\nFiberRoot是整个React应用的起点\nFiberRoot包含应用挂载的目标节点（&lt;div id=&#039;root&#039;&gt;&lt;/div&gt;）\nFiberRoot记录整个React应用 更新过程中的各种信息\n\n在createFiberRoot()中进行初始化：\n\n通过createHostRootFiber创建了rootFiber对象；\n创建了FiberRoot对象，将current属性赋值为rootFiber；\n将FiberRoot挂载到rootFiber的stateNode属性上；\n\ngraph LR\nFiberRoot --current--&gt; rootFiber\nrootFiber --stateNode--&gt; FiberRoot\n\ncreateFiberRoot 源码\nexport function createFiberRoot(\n  containerInfo: any,\n  isConcurrent: boolean,\n  hydrate: boolean,\n): FiberRoot {\n    \n  const uninitializedFiber = createHostRootFiber(isConcurrent);\n \n  let root;\n  if (enableSchedulerTracing) {\n    root = ({\n      current: uninitializedFiber,\n\t  // ...\n    }: FiberRoot);\n  } else {\n    root = ({\n      current: uninitializedFiber,\n\t  // ...\n    }: BaseFiberRootProperties);\n  }\n  uninitializedFiber.stateNode = root;\n  return ((root: any): FiberRoot);\n}\nFiberRoot 源码\ntype BaseFiberRootProperties = {|\n  // root节点，即 ReactDOM.render(&lt;App/&gt;, document.getElementById(&#039;root&#039;))接收的第二个参数\n  containerInfo: any,\n  // 只有在持久更新中会用到，也就是不支持增量更新的平台，react-dom不会用到\n  pendingChildren: any,\n  // 当前应用对应的 Fiber 对象，是 RootFiber\n  // ReactElement会有一个树结构，同时一个 ReactElement 对应一个 Fiber 对象，\n  // 所以Fiber也会有树结构\n  current: Fiber,\n \n  // 一下的优先级是用来区分\n  // 1) 没有提交(committed)的任务\n  // 2) 没有提交的挂起任务\n  // 3) 没有提交的可能被挂起的任务\n  // 我们选择不追踪每个单独的阻塞登记，为了兼顾性能\n  // 最老和新的在提交的时候被挂起的任务                    \n  earliestSuspendedTime: ExpirationTime,\n  latestSuspendedTime: ExpirationTime,\n  // The earliest and latest priority levels that are not known to be suspended.\n  // 最老和最新的不确定是否会挂起的优先级（所有任务进来一开始都是这个状态）\n  earliestPendingTime: ExpirationTime,\n  latestPendingTime: ExpirationTime,\n  // The latest priority level that was pinged by a resolved promise and can\n  // be retried.\n  // 最新的通过一个promise被reslove并且可以重新尝试的优先级\n  latestPingedTime: ExpirationTime,\n \n  // 如果有错误被抛出并且没有更多的更新存在，我们尝试在处理错误前同步重新从头渲染\n  // 在`renderRoot`出现无法处理的错误时会被设置为`true`\n  didError: boolean,\n \n  // 正在等待提交的任务的`expirationTime`\n  pendingCommitExpirationTime: ExpirationTime,\n  // 已经完成的任务的FiberRoot对象，如果你只有一个Root，那他永远只可能是这个Root对应的Fiber，或者是null\n  // 在commit阶段只会处理这个值对应的任务\n  finishedWork: Fiber | null,\n  // 在任务被挂起的时候通过setTimeout设置的返回内容，用来下一次如果有新的任务挂起时清理还没触发的timeout\n  timeoutHandle: TimeoutHandle | NoTimeout,\n  // 顶层context对象，只有主动调用`renderSubtreeIntoContainer`时才会有用\n  context: Object | null,\n  pendingContext: Object | null,\n  // 用来确定第一次渲染的时候是否需要融合\n  +hydrate: boolean,\n  // 当前root上剩余的过期时间\n  // TODO: 提到renderer里面区处理\n  nextExpirationTimeToWorkOn: ExpirationTime,\n  // 当前更新对应的过期时间\n  expirationTime: ExpirationTime,\n  // List of top-level batches. This list indicates whether a commit should be\n  // deferred. Also contains completion callbacks.\n  // TODO: Lift this into the renderer\n  // 顶层批次（批处理任务？）这个变量指明一个commit是否应该被推迟\n  // 同时包括完成之后的回调\n  // 貌似用在测试的时候？\n  firstBatch: Batch | null,\n  // root之间关联的链表结构\n  nextScheduledRoot: FiberRoot | null,\n|};\nFiber的含义和作用\n\n每一个ReactElement对应一个Fiber对象；\n记录节点的各种状态，比如ClassComponent中的state和props的状态就是记录在Fiber对象上的；\n只有当Fiber对象更新后，才会更新到ClassComponent上的this.state和this.props上；\n\n\nthis上的state和props是根据Fiber对象的state、props更新的。\n这实际上也方便了ReactHooks，因为hooks是为FunctionalComponent服务的。虽然FunctionalComponent没有this，但Fiber上有，是可以拿到state和props的；\n\n\n串联整个应用形成树结构,每个ReactElement通过**props.children**与其他ReactElement连结起来\n\n\nReactElement只会把子节点（props.children）的第一个子节点当做child节点，其余的子节点（也就是第一个子节点的兄弟节点）都是从第一个子节点开始，依次单向连接至后一个兄弟节点；\n每个子节点都会指向父节点（红箭头），也就是Fiber对象的return属性；\n\nFiber 源码\n// Fiber对应一个组件需要被update处理或者已经update处理了，一个组件可以有一个或者多个Fiber\ntype Fiber = {|\n  // 标记不同的组件类型，有原生的DOM节点，有React自己的节点\n  tag: WorkTag,\n \n  // ReactElement里面的key\n  key: null | string,\n \n  // ReactElement.type，也就是我们调用`createElement`的第一个参数\n  elementType: any,\n \n  // 异步组件resolved之后返回的内容，一般是`function`或者`class`\n  type: any,\n \n \n  // 跟当前Fiber相关本地状态（比如浏览器环境就是DOM节点）\n  // 不同类型的实例都会记录在stateNode上\n  // 比如DOM组件对应DOM节点实例\n  // ClassComponent对应Class实例\n  // FunctionComponent没有实例，所以stateNode值为null\n  // state更新了或props更新了均会更新到stateNode上 \n  stateNode: any,\n \n  // 指向他在Fiber节点树中的`parent`，用来在处理完这个节点之后向上返回\n  return: Fiber | null,\n \n  // 单链表树结构\n  // 指向自己的第一个子节点\n  child: Fiber | null,\n  // 指向自己的兄弟结构\n  // 兄弟节点的return指向同一个父节点\n  sibling: Fiber | null,\n  index: number,\n \n  // ref属性\n  ref: null | (((handle: mixed) =&gt; void) &amp; {_stringRef: ?string}) | RefObject,\n \n  // 新的变动带来的新的props\n  pendingProps: any, \n  // 上一次渲染完成之后的props\n  memoizedProps: any,\n \n  // 该Fiber对应的组件产生的Update会存放在这个队列里面\n  updateQueue: UpdateQueue&lt;any&gt; | null,\n \n  // 上一次渲染的时候的state\n  // 新的state由updateQueue计算得出，并覆盖memoizedState\n  memoizedState: any,\n \n  // 一个列表，存放这个Fiber依赖的context\n  firstContextDependency: ContextDependency&lt;mixed&gt; | null,\n \n  // 用来描述当前Fiber和他子树的`Bitfield`\n  // mode有conCurrentMode和strictMode\n  // 共存的模式表示这个子树是否默认是异步渲染的\n  // Fiber被创建的时候他会继承父Fiber\n  // 其他的标识也可以在创建的时候被设置\n  // 但是在创建之后不应该再被修改，特别是他的子Fiber创建之前\n  mode: TypeOfMode,\n \n  // Effect 用来记录Side Effect\n  effectTag: SideEffectTag,\n \n  // 单链表用来快速查找下一个side effect\n  nextEffect: Fiber | null,\n \n  // 子树中第一个side effect\n  firstEffect: Fiber | null,\n  // 子树中最后一个side effect\n  lastEffect: Fiber | null,\n \n  // 代表任务在未来的哪个时间点应该被完成\n  // 不包括该Fiber的子树产生的任务\n  expirationTime: ExpirationTime,\n \n  // 快速确定子树中是否有不在等待的 update\n  childExpirationTime: ExpirationTime,\n \n  // 在Fiber树更新的过程中，每个Fiber都会有一个跟其对应的Fiber\n  // 我们称他为`current &lt;==&gt; workInProgress`\n  // 在渲染完成之后他们会交换位置\n  // doubleBuffer: Fiber在更新后，不用再重新创建对象，\n  // 而是复制自身，并且两者相互复用，用来提高性能\n  alternate: Fiber | null,\n \n  // 下面是调试相关的，收集每个Fiber和子树渲染时间的\n \n  actualDuration?: number,\n \n  // If the Fiber is currently active in the &quot;render&quot; phase,\n  // This marks the time at which the work began.\n  // This field is only set when the enableProfilerTimer flag is enabled.\n  actualStartTime?: number,\n \n  // Duration of the most recent render time for this Fiber.\n  // This value is not updated when we bailout for memoization purposes.\n  // This field is only set when the enableProfilerTimer flag is enabled.\n  selfBaseDuration?: number,\n \n  // Sum of base times for all descedents of this Fiber.\n  // This value bubbles up during the &quot;complete&quot; phase.\n  // This field is only set when the enableProfilerTimer flag is enabled.\n  treeBaseDuration?: number,\n \n  // Conceptual aliases\n  // workInProgress : Fiber -&gt;  alternate The alternate used for reuse happens\n  // to be the same as work in progress.\n  // __DEV__ only\n  _debugID?: number,\n  _debugSource?: Source | null,\n  _debugOwner?: Fiber | null,\n  _debugIsCurrentlyTiming?: boolean,\n|};\nFiber 树例子\n通过图来了解一下这个 fiber 树的结构。\nconst APP = () =&gt; (\n    &lt;div&gt;\n        &lt;span&gt;&lt;/span&gt;\n        &lt;a&gt;&lt;/a&gt;\n    &lt;/div&gt;\n)\nReactDom.render(&lt;APP/&gt;, document.querySelector(&#039;#root&#039;))\n假如说我们需要渲染出以上组件，那么它们对应的 fiber 树应该长这样：\ngraph TD\n      FiberRoot --current--&gt; RootFiber\n      FiberRoot --containerInfo--&gt; root(#root DOM)\n      root --_reactRootContainer--&gt; react(React Root)\n      react --_internalRoot--&gt; FiberRoot\n      RootFiber --stateNode--&gt; FiberRoot\n      RootFiber --child--&gt; App\n      App --return--&gt; RootFiber\n      App --child--&gt; div\n      div --return--&gt; App\n      span --return--&gt; div\n      div --child--&gt; span\n      a --child--&gt; div\n      div --return--&gt; a\n\n"},"front-end/react/code-analysis/react-api":{"title":"react-api","links":[],"tags":[],"content":"React  API\nconst React = {\n  Children: {\n    map,\n    forEach,\n    count,\n    toArray,\n    only,\n  },\n \n  createRef,\n  Component,\n  PureComponent,\n \n  createContext,\n  forwardRef,\n \n  Fragment: REACT_FRAGMENT_TYPE,\n  StrictMode: REACT_STRICT_MODE_TYPE,\n  unstable_AsyncMode: REACT_ASYNC_MODE_TYPE,\n  unstable_Profiler: REACT_PROFILER_TYPE,\n \n  createElement: __DEV__ ? createElementWithValidation : createElement,\n  cloneElement: __DEV__ ? cloneElementWithValidation : cloneElement,\n  createFactory: __DEV__ ? createFactoryWithValidation : createFactory,\n  isValidElement: isValidElement,\n \n  version: ReactVersion,\n \n  __SECRET_INTERNALS_DO_NOT_USE_OR_YOU_WILL_BE_FIRED: ReactSharedInternals,\n};\nChildren\n该对象提供了一堆处理props.children的方法，因为children是一个类似数组但是不是数组的数据结构，如果要对其进行处理可以用React.Children外挂的方法；\ncreateRef\n新的ref用法，React 已抛弃&lt;div ref=&quot;myDiv&quot; /&gt;这种string ref的用法，转而使用createRef，其返回一个对象；\nComponent\n类似的还有 PureComponent，唯一的区别是PureComponent的原型上多了一个标识：\nif (ctor.prototype &amp;&amp; ctor.prototype.isPureReactComponent) {\n  return (\n    !shallowEqual(oldProps, newProps) || !shallowEqual(oldState, newState)\n  );\n}\n这是检查组件是否需要更新的一个判断，ctor是声明的继承自Component / PureComponent的组件类，会判断是否继承自PureComponent，如果是的话就使用shallowEqual比较state和props；\n\nReact中对比一个ClassComponent是否需要更新，只有两个地方：\n\n一是看有没有shouldComponentUpdate方法\n二就是此处的PureComponent判断；\n\n\ncreateContext\n新的 context API\nforwardRef\nforwardRef是用来解决HOC(高阶组件)组件传递ref的问题\n类型\n即Fragment，StrictMode，unstable_AsyncMode等，其实都只是占位符，是一个Symbol；\n在 React 实际检测到时会做一些特殊的处理，比如StrictMode和AsyncMode会让其子节点对应的 Fiber 的mode都变成和他们一样的mode；\ncreateElement …\n用来创建ReactElement，其余还有：\n\ncloneElement，用来克隆一个ReactElement；\ncreateFactory，用来创建专门用来创建某一类ReactElement的工厂函数；\nisValidElement，用来验证是否是一个ReactElement；\n"},"front-end/react/code-analysis/react-children":{"title":"react-children","links":[],"tags":[],"content":"Children 简介\nReact.Children 提供了用于处理 this.props.children 不透明数据结构的实用方法\n\nmap：在 children 里的每个直接子节点上调用一个函数，返回该数组；每个节点的返回的如果是数组，还会递归继续展开；\nforEach：类似，但它不会返回一个数组；\ncount：返回 children 中的组件总数量，等同于通过 map 或 forEach 调用回调函数的次数；\nonly：验证 children 是否只有一个子节点（一个 React 元素），如果有则返回它，否则此方法会抛出错误\n\n源码解析\nconst React = {\n    Children: {\n        map,\n        forEach,\n        count,\n        toArray,\n        only,\n    }\n}\n \nfunction mapChildren(children, func, context) {\n  if (children == null) {\n    return children;\n  }\n  const result = [];\n  mapIntoWithKeyPrefixInternal(children, result, null, func, context);\n  return result;\n}"},"front-end/react/code-analysis/react-component":{"title":"react-component","links":[],"tags":[],"content":"Component 是一个函数基类，设置 react 组件的props，content，refs，updater 等属性：\nfunction Component(props, context, updater) {\n  this.props = props;\n  this.context = context;\n  // If a component has string refs, we will assign a different object later.\n  this.refs = emptyObject;\n  // We initialize the default updater but the real one gets injected by the\n  // renderer.\n  this.updater = updater || ReactNoopUpdateQueue;\n}\n \nComponent.prototype.isReactComponent = {};\n原型上添加属性isReactComponent，还有setState 和forceUpdate两个方法：\n\nsetState：用于改变 Component 类内部的变量，内部使用updater.enqueueSetState这个方法实现更新机制，不同平台机制不同；\nforceUpdate：强制 Component 更新一次，即便 state 表层没有更新；\n\n其次还有PureComponent，使用寄生组合式继承自Component：\n\n减少一次原型链查找次数，节省内存消耗；\n\n内部使用shouldComponentUpdate(nextProps,nextState)方法，通过浅比较（比较一层），来判断是否需要重新render()函数，如果外面传入的props或者是state没有变化，则不会重新渲染，省去了虚拟dom的生成和对比过程：\nfunction ComponentDummy() {}\nComponentDummy.prototype = Component.prototype;\n \nfunction PureComponent(props, context, updater) {\n  this.props = props;\n  this.context = context;\n  // If a component has string refs, we will assign a different object later.\n  this.refs = emptyObject;\n  this.updater = updater || ReactNoopUpdateQueue;\n}\n \nconst pureComponentPrototype = (PureComponent.prototype = new ComponentDummy());\npureComponentPrototype.constructor = PureComponent;\n// Avoid an extra prototype jump for these methods.\nObject.assign(pureComponentPrototype, Component.prototype);\n \npureComponentPrototype.isPureReactComponent = true;  \n\nReact中判断 Component是否需要更新：\n\n\n有没有shouldComponentUpdate方法\n\n\nReactFiberClassComponent.js中的checkShouldComponentUpdate()中对PureComponent的判断\n\n\n"},"front-end/react/code-analysis/react-concurrent":{"title":"react-concurrent","links":[],"tags":[],"content":"Concurrent Mode\n\n深入剖析 React Concurrent - 知乎 (zhihu.com)\n\n这是一个实验性的功能，且是React渐进升级策略中的产物，在 React 18 中，已经整合为 Concurrent Feature 了；\nConcurrent Mode 是 Async Mode 的重新定义，来凸显出 React 在不同优先级上的执行能力，与其它的异步渲染方式进行区分；以下是 React 官方对 Concurrent Mode 的描述：\n\n… a set of new features that help React apps stay responsive and gracefully adjust to the user’s device capabilities and network speed\n\n对该模式的一个感知，可体验 Dan Abramov  在 JSConf Iceland 上演示的 Demo ，Concurrent  能使 React 在长时间渲染的场景下依旧保持良好的交互性，能优先执行高优先级变更，不会使页面处于卡顿或无响应状态，从而提升应用的用户体验。\n浏览器原理\n众所周知，JS 是单线程的，浏览器是多线程的，除了 JS 线程以外，还包括 UI 渲染线程、事件线程、定时器触发线程、HTTP 请求线程等等。\nJS 线程是可以操作 DOM 的，如果在操作 DOM 的同时 UI 线程也在进行渲染的话，就会发生不可预期的展示结果，因此 JS 线程与 UI 渲染线程是互斥的，每当 JS 线程执行时，UI 渲染线程会挂起，UI 更新会被保存在队列中，等待 JS 线程空闲后立即被执行。\n对于事件线程而言，当一个事件被触发时该线程会把事件添加到队列末尾，等待 JS 线程空闲后处理。因此，长时间的 JS 持续执行，就会造成 UI 渲染线程长时间地挂起，触发的事件也得不到响应，用户层面就会感知到页面卡顿甚至卡死了，Sync 模式下的问题就由此引起。\n大多数的设备帧率是 60，即每帧 16.67 ms，其中浏览器每一帧的过程如图：\n\n保证流畅，在一帧中，需要将 JS 执行时间控制在合理的范围内，不影响后续 Layout 与 Paint 的过程。\nrequestIdleCallback 就能够充分利用帧与帧之间的空闲时间来执行 JS，可以根据 callback 传入的 dealine 判断当前是否还有空闲时间（timeRemaining）用于执行。由于浏览器可能始终处于繁忙的状态，导致 callback 一直无法执行，它还能够设置超时时间（timeout），一旦超过时间（didTimeout）能使任务被强制执行。\n\n**window.requestIdleCallback()**方法插入一个函数，这个函数将在浏览器空闲时期被调用。\n这使开发者能够在主事件循环上执行后台和低优先级工作，而不会影响延迟关键事件，如动画和输入响应。函数一般会按先进先调用的顺序执行，然而，如果回调函数指定了执行超时时间timeout，则有可能为了在超时前执行函数而打乱执行顺序。\n\n\n上图可知， requestIdleCallback 是在 Layout 与 Paint 之后执行的，也就是说，requestIdleCallback 中适合做 JS 计算，不建议进行 DOM 更新，因为会重新出发 Layout 和Paint，导致帧的时间不可控；\nrequestIdleCallback 的兼容性也比较差：\n\n“requestAnimationFrame” | Can I use… Support tables for HTML5, CSS3, etc\n”requestIdleCallback” | Can I use… Support tables for HTML5, CSS3, etc\n\n在 React 内部采用 requestAnimationFrame 作为 ployfill，通过 帧率动态调整，计算 timeRemaining，模拟 requestIdleCallback，从而实现时间分片（Time Slicing），一个时间片就是一个渲染帧内 JS 能获得的最大执行时间。requestAnimationFrame 触发在 Layout 与 Paint 之前，更方便做 DOM 变更。\n\nreact 对于 requestIdleCallback 的 polyfill 并不是通过 requestAnimationFrame 实现的，而是通过 setTImeout(no-DOM environment) / postMessage (Dom environment) 实现的。只是说如果某些操作（比如动画）需要帧同步，则推荐使用 requestAnimationFrame。\n\n**注意：**这里把卡顿问题都归结于 JS 长时间执行，这针对 Concurrent 模式所解决的问题而言，卡顿也有可能是大量 Layout 或是 Paint 造成的。\n源码解析\nif (enableStableConcurrentModeAPIs) {\n  React.ConcurrentMode = REACT_CONCURRENT_MODE_TYPE;\n  React.Profiler = REACT_PROFILER_TYPE;\n} else {\n  React.unstable_ConcurrentMode = REACT_CONCURRENT_MODE_TYPE;\n  React.unstable_Profiler = REACT_PROFILER_TYPE;\n}\n \nexport const REACT_CONCURRENT_MODE_TYPE = hasSymbol\n  ? Symbol.for(&#039;react.concurrent_mode&#039;)\n  : 0xeacf;\nflushSync\n强制使用同步更新的新 API，\n\nflushSync 内部的 setState 依然会合并成一次同步更新\nflushSync 会优于同级的 setState 先更新（同步更新，肯定比异步快）\n\nfunction flushSync&lt;A, R&gt;(fn: (a: A) =&gt; R, a: A): R {\n  invariant(\n    !isRendering,\n    &#039;flushSync was called from inside a lifecycle method. It cannot be &#039; +\n      &#039;called when React is already rendering.&#039;,\n  );\n  const previousIsBatchingUpdates = isBatchingUpdates;\n  isBatchingUpdates = true;\n  try {\n    return syncUpdates(fn, a);\n  } finally {\n    isBatchingUpdates = previousIsBatchingUpdates;\n    performSyncWork();\n  }\n}"},"front-end/react/code-analysis/react-context":{"title":"react-context","links":[],"tags":[],"content":"context的使用方式(16.x)\nconst { Provider, Consumer } = React.createContext({ theme: &quot;green&quot; })\n \nclass Parent extends React.Component {\n  render() {\n    //Procider组件遍历子组件，并且有一个属性value用来提供数据\n    return (\n      &lt;Provider value={{ theme: &quot;pink&quot; }}&gt;\n        &lt;Content /&gt;\n      &lt;/Provider&gt;\n    )\n  }\n}\n \nfunction Content() {\n  return (\n    &lt;div&gt;\n      &lt;Button /&gt;\n    &lt;/div&gt;\n  )\n}\n \nfunction Button() {\n  return (\n    &lt;Consumer&gt;\n      {({ theme }) =&gt; (\n        &lt;button style={{ backgroundColor: theme }}&gt;\n          Toggle Theme\n        &lt;/button&gt;\n      )}\n    &lt;/Consumer&gt;\n  )\n}\ncreateContext()源码解析\nexport function createContext&lt;T&gt;(\n    defaultValue: T,\n    calculateChangedBits: ?(a: T, b: T) =&gt; number,\n    ): ReactContext&lt;T&gt; {\n        if (calculateChangedBits === undefined) {\n            calculateChangedBits = null;\n        } else {}\n \n        const context: ReactContext&lt;T&gt; = {\n            $$typeof: REACT_CONTEXT_TYPE,\n            _calculateChangedBits: calculateChangedBits,\n            // As a workaround to support multiple concurrent renderers, we categorize\n            // some renderers as primary and others as secondary. We only expect\n            // there to be two concurrent renderers at most: React Native (primary) and\n            // Fabric (secondary); React DOM (primary) and React ART (secondary).\n            // Secondary renderers store their context values on separate fields.\n            _currentValue: defaultValue,\n            _currentValue2: defaultValue,\n            // These are circular\n            Provider: (null: any),\n            Consumer: (null: any),\n        };\n \n        context.Provider = {\n            $$typeof: REACT_PROVIDER_TYPE,\n            _context: context,\n        };\n \n        let hasWarnedAboutUsingNestedContextConsumers = false;\n        let hasWarnedAboutUsingConsumerProvider = false;\n \n \n        context.Consumer = context;\n \n        return context;\n\t}\n_currentValue 用来记录Provider/Consumer的 value 值，默认为参数 defaultValue；"},"front-end/react/code-analysis/react-core":{"title":"react-core","links":[],"tags":[],"content":"核心部分\n\n更新机制\n什么是Fiber以及作用\nReact 实现路更新任务的调度，如何实现的\n\n调度过程\n\n渲染更新过程\n"},"front-end/react/code-analysis/react-dom-render":{"title":"react-dom-render","links":[],"tags":[],"content":"React更新的方式有三种：\n\nReactDOM.render() || hydrate（ReactDOMServer渲染）\nsetState\nforceUpdate\n\nReactDOM.render(element, container[, callback]) 函数在提供的 Container 内渲染一个 React 元素，并返回对该组件的引用（或者针对无状态组件返回 null）：\nconst ReactDOM: Object = {\n    render(\n    element: React$Element&lt;any&gt;,\n     container: DOMContainer,\n     callback: ?Function,\n    ) {\n        return legacyRenderSubtreeIntoContainer(\n            null,\n            element,\n            container,\n            false,\n            callback,\n        );\n    }\n      hydrate(element: React$Node, container: DOMContainer, callback: ?Function) {\n    // TODO: throw or warn if we couldn&#039;t hydrate?\n    return legacyRenderSubtreeIntoContainer(\n      null,\n      element,\n      container,\n      true,\n      callback,\n    );\n  },\n}\n\n在 React 18 中，render 函数已被 createRoot 函数所取代。\n\nrender()方法本质是返回了函数 legacyRenderSubtreeIntoContainer()，而hydrate方法则是forceHydrate这个参数的区别：\n\nhydrate()为true，表示在服务端尽可能复用节点，提高性能；\nrender()为false，表示在浏览器端不会去复用节点，而是全部替换掉；\n\negacyRenderSubtreeIntoContainer()函数\n// null, element, container, false, callback\nfunction legacyRenderSubtreeIntoContainer(\n  parentComponent: ?React$Component&lt;any, any&gt;,\n  children: ReactNodeList,\n  container: DOMContainer,\n  forceHydrate: boolean,\n  callback: ?Function,\n) {\n  let root: Root = (container._reactRootContainer: any);\n  if (!root) {\n    // Initial mount\n    root = container._reactRootContainer = legacyCreateRootFromDOMContainer(\n      container,\n      forceHydrate,\n    );\n    if (typeof callback === &#039;function&#039;) {\n      const originalCallback = callback;\n      callback = function() {\n        const instance = DOMRenderer.getPublicRootInstance(root._internalRoot);\n        originalCallback.call(instance);\n      };\n    }\n    // Initial mount should not be batched.\n    DOMRenderer.unbatchedUpdates(() =&gt; {\n      if (parentComponent != null) {\n        root.legacy_renderSubtreeIntoContainer(\n          parentComponent,\n          children,\n          callback,\n        );\n      } else {\n        root.render(children, callback);\n      }\n    });\n  } else {\n    if (typeof callback === &#039;function&#039;) {\n      const originalCallback = callback;\n      callback = function() {\n        const instance = DOMRenderer.getPublicRootInstance(root._internalRoot);\n        originalCallback.call(instance);\n      };\n    }\n    // Update\n    if (parentComponent != null) {\n      root.legacy_renderSubtreeIntoContainer(\n        parentComponent,\n        children,\n        callback,\n      );\n    } else {\n      root.render(children, callback);\n    }\n  }\n  return DOMRenderer.getPublicRootInstance(root._internalRoot);\n}\n函数开始会初始化一个将root变量，赋值为container._reactRootContainer，而初始渲染时 container 是DOM 对象并没有该属性；\n之后通过函数legacyCreateRootFromDOMContainer()创建了一个ReactRoot(container, isConcurrent, shouldHydrate)对象返回并赋值；\n构造函数ReactRoot()内部调用了createContainer() ⇒ createFiberRoot()，将返回的值挂载到了_internalRoot属性上；\nfunction ReactRoot(\n  container: Container,\n  isConcurrent: boolean,\n  hydrate: boolean,\n) {\n  const root = DOMRenderer.createContainer(container, isConcurrent, hydrate);\n  this._internalRoot = root;\n}\n \nexport function createContainer(\n  containerInfo: Container,\n  isConcurrent: boolean,\n  hydrate: boolean,\n): OpaqueRoot {\n  return createFiberRoot(containerInfo, isConcurrent, hydrate);\n}\n \nexport function createFiberRoot(\n  containerInfo: any,\n  isConcurrent: boolean,\n  hydrate: boolean,\n): FiberRoot {\n  // Cyclic construction. This cheats the type system right now because\n  // stateNode is any.\n  const uninitializedFiber = createHostRootFiber(isConcurrent);\n \n  let root;\n  if (enableSchedulerTracing) {\n    root = ({\n      current: uninitializedFiber,\n      containerInfo: containerInfo,\n      pendingChildren: null,\n\t  // ...\n    }: FiberRoot);\n  } else {\n    root = ({\n      current: uninitializedFiber,\n      containerInfo: containerInfo,\n      pendingChildren: null,\n\t  // ...\n    }: BaseFiberRootProperties);\n  }\n \n  uninitializedFiber.stateNode = root;\n \n  // The reason for the way the Flow types are structured in this file,\n  // Is to avoid needing :any casts everywhere interaction tracing fields are used.\n  // Unfortunately that requires an :any cast for non-interaction tracing capable builds.\n  // $FlowFixMe Remove this :any cast and replace it with something better.\n  return ((root: any): FiberRoot);\n}\n在其中还会调用shouldHydrateDueToLegacyHeuristic函数，该函数对获取到的rootElement做一个判断（是否有子节点）即是否需要 Hydrate，以确定后面是否删除所有的子元素；\nfunction getReactRootElementInContainer(container: any) {\n  if (!container) {\n    return null;\n  }\n \n  if (container.nodeType === DOCUMENT_NODE) {\n    return container.documentElement;\n  } else {\n    return container.firstChild;\n  }\n}\n \nfunction shouldHydrateDueToLegacyHeuristic(container) {\n  const rootElement = getReactRootElementInContainer(container);\n  return !!(\n    rootElement &amp;&amp;\n    rootElement.nodeType === ELEMENT_NODE &amp;&amp;\n    rootElement.hasAttribute(ROOT_ATTRIBUTE_NAME)\n  );\n}\n再检测回调参数，再调用getPublicRootInstance函数，由于是 React 初始化，所以container.current是没有子节点的，所以该方法返回 null；\n最后，在unbatchedUpdates参数中传入回调，因为parentComponent == null，调用root.render()。\nfunction unbatchedUpdates&lt;A, R&gt;(fn: (a: A) =&gt; R, a: A): R {\n  if (isBatchingUpdates &amp;&amp; !isUnbatchingUpdates) {\n    isUnbatchingUpdates = true;\n    try {\n      return fn(a);\n    } finally {\n      isUnbatchingUpdates = false;\n    }\n  }\n  return fn(a);\n}\n \nReactRoot.prototype.render = function(\n  children: ReactNodeList,\n  callback: ?() =&gt; mixed,\n): Work {\n  const root = this._internalRoot;\n  const work = new ReactWork();\n  callback = callback === undefined ? null : callback;\n  if (callback !== null) {\n    work.then(callback);\n  }\n  DOMRenderer.updateContainer(children, root, null, work._onCommit);\n  return work;\n};\nrender函数内部调用了 updateContainer：\nexport function updateContainer(\n  element: ReactNodeList,\n  container: OpaqueRoot,\n  parentComponent: ?React$Component&lt;any, any&gt;,\n  callback: ?Function,\n): ExpirationTime {\n  const current = container.current;\n  const currentTime = requestCurrentTime();\n  const expirationTime = computeExpirationForFiber(currentTime, current);\n  return updateContainerAtExpirationTime(\n    element,\n    container,\n    parentComponent,\n    expirationTime,\n    callback,\n  );\n}"},"front-end/react/code-analysis/react-hooks":{"title":"react-hooks","links":[],"tags":[],"content":"Hooks 简介\nHook 发布于 React v16.8.0，主要准对 React 开发中以下几个痛点：\n\n在组件之间复用状态逻辑很难；\n复杂组件变得难以理解；\n难以理解的 class 内部；\n\n工作原理\n对于useState Hook，简单使用如下：\nfunction App() {\n  const [num, updateNum] = useState(0);\n \n  return &lt;p onClick={() =&gt; updateNum(num =&gt; num + 1)}&gt;{num}&lt;/p&gt;;\n}\n源码解析\nexport function useState&lt;S&gt;(initialState: (() =&gt; S) | S) {\n  const dispatcher = resolveDispatcher();\n  return dispatcher.useState(initialState);\n}\n \nfunction resolveDispatcher() {\n  const dispatcher = ReactCurrentOwner.currentDispatcher;\n  invariant(\n    dispatcher !== null,\n    &#039;Hooks can only be called inside the body of a function component.&#039;,\n  );\n  return dispatcher;\n}\n \nconst ReactCurrentOwner = {\n  current: (null: null | Fiber),\n  currentDispatcher: (null: null | Dispatcher),\n};"},"front-end/react/code-analysis/react-memo":{"title":"react-memo","links":[],"tags":[],"content":"memo\nReact.memo和PureComponent作用类似，可以用作性能优化，React.memo 是高阶组件，函数组件和类组件都可以使用， 区别于PureComponent， React.memo只能针对 props 的情况确定是否渲染，而PureComponent是针对props和state。\nReact.memo 接受两个参数，第一个参数原始组件本身，第二个参数，是一个函数，可以根据一次更新中props是否相同决定原始组件是否重新渲染。返回一个布尔值，true 表示组件无须重新渲染，false则需要重新渲染，这个和类组件中的shouldComponentUpdate()正好相反 。\nReact.memo参数的函数在一定程度上，可以等价于组件外部使用shouldComponentUpdate ，用于拦截新老props，确定组件是否更新；\n源码解析\nexport default function memo&lt;Props&gt;(\n  type： React$ElementType,\n  compare?： (oldProps： Props, newProps： Props) =&gt; boolean,\n) {\n  return {\n    $$typeof： REACT_MEMO_TYPE,\n    type,\n    compare： compare === undefined ? null ： compare,\n  };\n}\nFragment\nreact不允许一个组件返回多个节点元素，通常解决这个情况，很简单，只需要在外层套一个容器元素；\n但是不期望增加额外的dom节点，所以react提供Fragment碎片概念，能够让一个组件返回多个元素；\n和Fragment区别是，Fragment可以支持key属性。&lt;&gt;&lt;/&gt;不支持key属性；\n\n通过map遍历后的元素，react底层会处理，默认在外部嵌套一个&lt;Fragment&gt;；\n{\n  [1,2,3].map(item=&gt;&lt;span key={item.id} &gt;{ item.name }&lt;/span&gt;)\n}\n\n源码解析\nexport const REACT_FRAGMENT_TYPE = hasSymbol\n  ? Symbol.for(&#039;react.fragment&#039;)\n  ： 0xeacb;\nProfiler\nProfiler这个api一般用于开发阶段，性能检测，检测一次react组件渲染用时，性能开销。\nProfiler 需要两个参数：\n第一个参数：是 id，用于表识唯一性的Profiler。\n第二个参数：onRender回调函数，接受渲染参数，当被分析的渲染树中的组件提交更新时，就会调用它，。\nfiler 的 onRender 回调接收描述渲染内容和所花费时间的参数：\n\nid： 生提交的 Profiler 树的 id。如果有多个 profiler，它能用来分辨树的哪一部分发生了“提交”。\nphase： “mount” (首次挂载) 或 “update” (重新渲染)，判断是组件树的第一次装载引起的重渲染，还是由 props、state 或是 hooks 改变引起的重渲染。\nactualDuration： 次更新在渲染Profiler 和它的子代上花费的时间。\nbaseDuration： 在Profiler 树中最近一次每一个组件render 的持续时间。这个值估计了最差的渲染时间。\nstartTime： 本次更新中 React 开始渲染的时间戳。\ncommitTime：  本次更新中 React commit 阶段结束的时间戳。在一次 commit 中这个值在所有的 profiler 之间是共享的，可以将它们按需分组。\ninteractions： 当更新被制定时，“interactions” 的集合会被追踪。\n\nconst index = () =&gt; {\n  const callback = (...arg) =&gt; console.log(arg)\n \n  return  &lt;Fragment&gt;\n      &lt;Profiler id=&quot;root&quot; onRender={ callback }  &gt;\n          &lt;ComplexComponent/&gt;\n      &lt;/Profiler&gt; \n    &lt;/Fragment&gt;\n}\n\n尽管 Profiler 是一个轻量级组件，我们依然应该在需要时才去使用它。对一个应用来说，每添加一些都会给 CPU 和内存带来一些负担。\n\n可以在控制台查看到打印输出的信息，还可以打开 React DevTools ，转到 Profiler 选项卡并可视化组件渲染时间；\n源码解析\nexport const REACT_PROFILER_TYPE = hasSymbol\n  ? Symbol.for(&#039;react.profiler&#039;)\n  : 0xead2;\nStrictMode\nStrictMode见名知意，严格模式，用于检测react项目中的潜在的问题。\n与 Fragment 一样， StrictMode 不会渲染任何可见的 UI 。它为其后代元素触发额外的检查和警告。\n\n严格模式检查仅在开发模式下运行；它们不会影响生产构建。\n\nStrictMode目前有助于：\n\n识别不安全的生命周期；\n关于使用过时字符串 ref API 的警告；\n关于使用废弃的 findDOMNode 方法的警告；\n检测意外的副作用；\n检测过时的 context API；\n\n源码解析\nexport const REACT_STRICT_MODE_TYPE = hasSymbol\n  ? Symbol.for(&#039;react.strict_mode&#039;)\n  : 0xeacc;"},"front-end/react/code-analysis/react-ref":{"title":"react-ref","links":[],"tags":[],"content":"ref 三种使用用法\nString\ndom 节点或 class 组件上使用，获取真实的dom节点：\n&lt;input ref=&quot;stringRef&quot; /&gt;\n&lt;Comp ref=&quot;compStringRef&quot; /&gt;\n// this.refs.stringRef / compStringRef\nfunction\ndom节点或class 组件上挂载回调函数，函数的入参为 dom节点：\n&lt;input ref={(ref) =&gt; { this.callBackRef = ref }} /&gt;\n&lt;Comp ref={(comp) =&gt; { this.compCallbackRef = comp }} /&gt;\n// this.callBackRef / compCallbackRef\ncreateRef object\nReact.createRef()创建一个 形如{current: null}的对象，赋值给一个变量，挂载到组件上，通过变量的current属性获取组件实例：\n// this.compCreateRef = React.createRef()\n&lt;Child ref={this.myCompCreateRef} /&gt;\n// this.compCreateRef.current\ncreateRef()源码解析\nfunction createRef() {\n  var refObject = {\n    current: null\n  };\n  return refObject;\n}\nforwardRef()源码解析\n对于纯函数组件无法使用 ref，因为其没有实例；但可以通过forwardRef把 ref 传递进去\nforwardRef常用于：\n\n转发 ref 到组件内部的DOM 节点上；\n在高阶组件中转发ref；\n\nexport default function forwardRef&lt;Props, ElementType: React$ElementType&gt;(\n  render: (props: Props, ref: React$Ref&lt;ElementType&gt;) =&gt; React$Node,\n) {\n  return {\n    $$typeof: REACT_FORWARD_REF_TYPE,\n    render,\n  };\n}\n调用forwardRef返回一个对象，该对象作为一个组件会在render()函数中使用，实质上该对象会作为参数传入creactElement函数，并返回一个ReactElement对象；\n其中forwardRef返回的对象赋值给ReactElement对象的type属性，其$$typeof仍然是 REACT_ELEMENT_TYPE：\nconst ReactElement = function(type, key, ref, self, source, owner, props) {\n  const element = {\n    $$typeof: REACT_ELEMENT_TYPE,\n    type: type,\n    // ...\n  };\n  return element;\n};"},"front-end/react/code-analysis/react-summary":{"title":"react-summary","links":[],"tags":[],"content":"\n「React进阶」 React全部api解读+基础实践大全(夯实基础2万字总结) - 掘金 (juejin.cn)\n\n组件类\n组件类，详细分的话有三种类，第一类说白了就是我平时用于继承的基类组件Component,PureComponent，还有就是react提供的内置的组件，比如Fragment,StrictMode，另一部分就是高阶组件forwardRef,memo等；\nComponent\nComponent是class组件的根基。类组件一切始于Component。对于React.Component使用，我们没有什么好讲的。我们这里重点研究一下react对Component做了些什么。\n// react/src/ReactBaseClasses.js\nfunction Component(props, context, updater) {\n  this.props = props;\n  this.context = context;\n  this.refs = emptyObject;\n  this.updater = updater || ReactNoopUpdateQueue;\n}\n这就是Component函数，其中updater对象上保存着更新组件的方法。\n我们声明的类组件是什么时候以何种形式被实例化的呢？\n// react-reconciler/src/ReactFiberClassComponent.js\nfunction constructClassInstance(\n    workInProgress,\n    ctor,\n    props\n){\n   const instance = new ctor(props, context);\n    instance.updater = {\n        isMounted,\n        enqueueSetState(){\n            /* setState 触发这里面的逻辑 */\n        },\n        enqueueReplaceState(){},\n        enqueueForceUpdate(){\n            /* forceUpdate 触发这里的逻辑 */\n        }\n    }\n}\n对于Component， react 处理逻辑还是很简单的，实例化我们类组件，然后赋值updater对象，负责组件的更新。然后在组件各个阶段，执行类组件的render函数，和对应的生命周期函数就可以了。\nPureComponent\nPureComponent和 Component用法，差不多一样，唯一不同的是，纯组件PureComponent会浅比较，props和state是否相同，来决定是否重新渲染组件。所以一般用于性能调优，减少render次数。\n什么叫做浅比较，我这里举个列子：\nclass Index extends React.PureComponent{\n    constructor(props){\n        super(props)\n        this.state = {\n           data: {\n              name:&#039;alien&#039;,\n              age:28\n           }\n        }\n    }\n    handerClick = () =&gt; {\n        const { data } = this.state\n        data.age++\n        this.setState({ data })\n    }\n    render(){\n        const { data } = this.state\n        return &lt;div className=&quot;box&quot; &gt;\n        &lt;div className=&quot;show&quot; &gt;\n            &lt;div&gt; 你的姓名是: { data.name } &lt;/div&gt;\n            &lt;div&gt; 年龄： { data.age  }&lt;/div&gt;\n            &lt;button onClick={ this.handerClick } &gt;age++&lt;/button&gt;\n        &lt;/div&gt;\n    &lt;/div&gt;\n    }\n}\n点击按钮，没有任何反应，因为PureComponent会比较两次data对象（而不会涉及内部的属性），由于都指向同一个data，没有发生改变，所以不更新视图。\n解决这个问题很简单，浅拷贝一下即可；只需要在handerClick事件中这么写：\n this.setState({ data: { ...data } })\nmemo\nReact.memo和PureComponent作用类似，可以用作性能优化，React.memo 是高阶组件，函数组件和类组件都可以使用， 和区别是 React.memo只能对props的情况确定是否渲染，而PureComponent是针对props和state。\nReact.memo 接受两个参数，第一个参数原始组件本身，第二个参数，可以根据一次更新中props是否相同决定原始组件是否重新渲染；需要传入一个返回布尔值的函数，true 证明组件无须重新渲染，false证明组件需要重新渲染，这个和类组件中的shouldComponentUpdate()正好相反 。\n\nReact.memo: 第二个参数 返回 true 组件不渲染 ， 返回 false 组件重新渲染。\nshouldComponentUpdate: 返回 true 组件渲染 ， 返回 false 组件不渲染。\n\n来看一个例子，控制 props 中的 number ：\n代码中只有 number 更改，改变后的 number 小于 5 ，组件才渲染；\nfunction TextMemo(props){\n    console.log(&#039;子组件渲染&#039;)\n    if(props)\n        return &lt;div&gt;hello,world&lt;/div&gt; \n}\nconst controlIsRender = (pre,next)=&gt;{\n    if(pre.number === next.number){ \n        // number 不改变，不渲染组件\n        return true \n    }else if(pre.number !== next.number &amp;&amp; next.number &gt; 5 ) { \n        // number 改变，但值大于5，不渲染组件\n        return true\n    }else { \n        // 否则渲染组件\n        return false\n    }\n}\nconst NewTexMemo = memo(TextMemo,controlIsRender)\n \nclass Index extends React.Component{\n    constructor(props){\n        super(props)\n        this.state={\n            number:1,\n            num:1\n        }\n    }\n    render(){\n        const { num , number }  = this.state\n        return (&lt;div&gt;\n            &lt;div&gt; 改变num：当前值 { num }  \n                &lt;button \n                    onClick={ ()=&gt;this.setState({ num:num + 1 }) } \n                &gt;\n                    num++\n                &lt;/button&gt;\n                &lt;button \n                    onClick={ ()=&gt;this.setState({ num:num - 1 }) } &gt;\n                        num--\n                &lt;/button&gt;  \n\t\t\t&lt;/div&gt;\n            &lt;div&gt; 改变number： 当前值 { number } \n                &lt;button \n                    onClick={ ()=&gt;this.setState({ number:number + 1 }) } &gt; \n                        number ++\n                &lt;/button&gt;\n                &lt;button \n                    onClick={ ()=&gt;this.setState({ number:number - 1 }) } &gt; \n                        number -- \n                &lt;/button&gt;  \n            &lt;/div&gt;\n\t\t\t&lt;NewTexMemo num={ num } number={number}  /&gt;\n    \t&lt;/div&gt;)\n\t}\n}\n完美达到了效果，React.memo一定程度上，可以等价于组件外部使用shouldComponentUpdate ，用于拦截新老props，确定组件是否更新。\nforwardRef\n转发引入Ref\n这个场景实际很简单，比如父组件想获取孙组件，某一个dom元素。这种隔代ref获取引用，就需要forwardRef来助力。\nfunction Son (props){\n    const { grandRef } = props\n    return &lt;div&gt;\n        &lt;div&gt; i am alien &lt;/div&gt;\n        &lt;span ref={grandRef} &gt;这个是想要获取元素&lt;/span&gt;\n    &lt;/div&gt;\n}\n \nclass Father extends React.Component{\n    constructor(props){\n        super(props)\n    }\n    render(){\n        return &lt;div&gt;\n            &lt;Son grandRef={this.props.grandRef}  /&gt;\n        &lt;/div&gt;\n    }\n}\n \nconst NewFather = React.forwardRef((props,ref)=&gt;&lt;Father grandRef={ref}  {...props} /&gt;  )\n \nclass GrandFather extends React.Component{\n    constructor(props){\n        super(props)\n    }\n    node = null \n    componentDidMount(){\n        console.log(this.node)\n    }\n    render(){\n        return &lt;div&gt;\n            &lt;NewFather ref={(node)=&gt; this.node = node } /&gt;\n        &lt;/div&gt;\n    }\n}\nreact不允许ref通过props传递，因为组件上已经有 ref 这个属性，在组件调和过程中，已经被特殊处理，forwardRef出现就是解决这个问题，把ref转发到自定义的forwardRef定义的属性上，让ref，可以通过props传递。\n高阶组件转发Ref\n属性代理的hoc，被包裹一层，所以如果是类组件，是通过ref拿不到原始组件的实例的，不过我们可以通过forWardRef转发ref。\nfunction HOC(Component){\n  class Wrap extends React.Component{\n     render(){\n        const { forwardedRef ,...otherprops  } = this.props\n        return &lt;Component ref={forwardedRef}  {...otherprops}  /&gt;\n     }\n  }\n  return  React.forwardRef((props,ref)=&gt; &lt;Wrap forwardedRef={ref} {...props} /&gt; ) \n}\nclass Index extends React.Component{\n  componentDidMount(){\n      console.log(666)\n  }\n  render(){\n    return &lt;div&gt;hello,world&lt;/div&gt;\n  }\n}\nconst HocIndex =  HOC(Index,true)\nexport default ()=&gt;{\n  const node = useRef(null)\n  useEffect(()=&gt;{\n     /* 就可以跨层级，捕获到 Index 组件的实例了 */ \n    console.log(node.current.componentDidMount)\n  },[])\n  return &lt;div&gt;&lt;HocIndex ref={node}  /&gt;&lt;/div&gt;\n}\nlazy\nReact.lazy和Suspense配合一起用，能够有动态加载组件的效果。React.lazy 接受一个函数，这个函数需要动态调用 import()。它必须返回一个 Promise ，该 Promise 需要 resolve 一个 default export 的 React 组件。\nimport Test from &#039;./test&#039;\nconst LazyComponent =  React.lazy(()=&gt; new Promise((resolve)=&gt;{\n      setTimeout(()=&gt;{\n          resolve({\n              default: ()=&gt; &lt;Test /&gt;\n          })\n      },2000)\n}))\nclass index extends React.Component{   \n    render(){\n        return &lt;div className=&quot;context_box&quot;  style={ { marginTop :&#039;50px&#039; } }   &gt;\n           &lt;React.Suspense fallback={ &lt;div className=&quot;icon&quot; &gt;&lt;SyncOutlined  spin  /&gt;&lt;/div&gt; } &gt;\n               &lt;LazyComponent /&gt;\n           &lt;/React.Suspense&gt;\n        &lt;/div&gt;\n    }\n}\n                                                   \n// test.js                                                   \nclass Test extends React.Component{\n    constructor(props){\n        super(props)\n    }\n    componentDidMount(){\n        console.log(&#039;--componentDidMount--&#039;)\n    }\n    render(){\n        return &lt;div&gt;\n            &lt;img src={alien}  className=&quot;alien&quot; /&gt;\n        &lt;/div&gt;\n    }\n}\nSuspense\n何为Suspense, Suspense 让组件“等待”某个异步操作，直到该异步操作结束即可渲染；\n用于数据获取的 Suspense 是一个新特性，你可以使用 &lt;Suspense&gt; 以声明的方式来“等待”任何内容，包括数据。本文重点介绍它在数据获取的用例，它也可以用于等待图像、脚本或其他异步的操作。\n上面讲到高阶组件lazy时候，已经用 lazy + Suspense模式，构建了异步渲染组件。我们看一下官网文档中的案例：\nconst ProfilePage = \n      React.lazy(() =&gt; import(&#039;./ProfilePage&#039;)); // 懒加载\n \n&lt;Suspense fallback={ &lt;Spinner/&gt; }&gt;\n  &lt;ProfilePage/&gt;\n&lt;/Suspense&gt;\nFragment\nreact不允许一个组件返回多个节点元素，比如说如下情况：\nrender(){\n    return (\n        &lt;li&gt; 🍎🍎🍎 &lt;/li&gt;\n        &lt;li&gt; 🍌🍌🍌 &lt;/li&gt;\n        &lt;li&gt; 🍇🍇🍇 &lt;/li&gt;\n    )\n}\n如果我们想解决这个情况，很简单，只需要在外层套一个容器元素。\nrender(){\n    return &lt;div&gt;\n           &lt;li&gt; 🍎🍎🍎 &lt;/li&gt;\n           &lt;li&gt; 🍌🍌🍌 &lt;/li&gt;\n           &lt;li&gt; 🍇🍇🍇 &lt;/li&gt;\n    &lt;/div&gt;\n}\n但是我们不期望，增加额外的dom节点，所以react提供Fragment碎片概念，能够让一个组件返回多个元素。 所以我们可以这么写\n&lt;React.Fragment&gt;\n    &lt;li&gt; 🍎🍎🍎 &lt;/li&gt;\n    &lt;li&gt; 🍌🍌🍌 &lt;/li&gt;\n    &lt;li&gt; 🍇🍇🍇 &lt;/li&gt;\n&lt;/React.Fragment&gt;\n还可以简写成：\n&lt;&gt;\n    &lt;li&gt; 🍎🍎🍎 &lt;/li&gt;\n    &lt;li&gt; 🍌🍌🍌 &lt;/li&gt;\n    &lt;li&gt; 🍇🍇🍇 &lt;/li&gt;\n&lt;/&gt;\n和Fragment区别是，Fragment可以支持key属性。&lt;&gt;&lt;/&gt;不支持key属性。\n我们通过map遍历后的元素，react底层会处理，默认在外部嵌套一个&lt;Fragment&gt;，例如：\n{\n   [1,2,3].map( item =&gt; &lt;span key={item.id} &gt;{ item.name }&lt;/span&gt; )\n}\nreact底层处理之后，等价于：\n&lt;Fragment&gt;\n   &lt;span&gt;&lt;/span&gt;\n   &lt;span&gt;&lt;/span&gt;\n   &lt;span&gt;&lt;/span&gt;\n&lt;/Fragment&gt;\nProfiler\nProfiler这个api一般用于开发阶段，性能检测，检测一次react组件渲染用时，性能开销。\nProfiler 需要两个参数：\n第一个参数：是 id，用于表识唯一性的Profiler。\n第二个参数：onRender回调函数，用于渲染完成，接受渲染参数。\nconst index = () =&gt; {\n  const callback = (...arg) =&gt; console.log(arg)\n  return &lt;div &gt;\n    &lt;div &gt;\n      &lt;Profiler id=&quot;root&quot; onRender={ callback }  &gt;\n        &lt;Router  &gt;\n          &lt;Meuns/&gt;\n          &lt;KeepaliveRouterSwitch withoutRoute &gt;\n              { renderRoutes(menusList) }\n          &lt;/KeepaliveRouterSwitch&gt;\n        &lt;/Router&gt;\n      &lt;/Profiler&gt; \n    &lt;/div&gt;\n  &lt;/div&gt;\n}\nStrictMode\nStrictMode见名知意，严格模式，用于检测react项目中的潜在的问题，。与 Fragment 一样， StrictMode 不会渲染任何可见的 UI 。它为其后代元素触发额外的检查和警告。\n\n严格模式检查仅在开发模式下运行；它们不会影响生产构建。\n\nStrictMode目前有助于：\n\n①识别不安全的生命周期。\n②关于使用过时字符串 ref API 的警告\n③关于使用废弃的 findDOMNode 方法的警告\n④检测意外的副作用\n⑤检测过时的 context API\n\n识别不安全的生命周期\n对于不安全的生命周期，指的是UNSAFE_componentWillMount，UNSAFE_componentWillReceiveProps , UNSAFE_componentWillUpdate\n// 外层开启严格模式：\n&lt;React.StrictMode&gt; \n    &lt;Router  &gt;\n        &lt;Meuns/&gt;\n        &lt;KeepaliveRouterSwitch withoutRoute &gt;\n            { renderRoutes(menusList) }\n        &lt;/KeepaliveRouterSwitch&gt;\n    &lt;/Router&gt;\n&lt;/React.StrictMode&gt;\n \n// 我们在内层组件中，使用不安全的生命周期:\nclass Index extends React.Component{    \n    UNSAFE_componentWillReceiveProps(){\n    }\n    render(){      \n        return &lt;div className=&quot;box&quot; /&gt;   \n    }\n}\n工具类\ncreateElement\n一提到createElement，就不由得和JSX联系一起。我们写的jsx，最终会被 babel，用createElement编译成react元素形式。我写一个组件，我们看一下会被编译成什么样子，\n如果我们在render里面这么写：\nrender(){\n    return &lt;div className=&quot;box&quot; &gt;\n        &lt;div className=&quot;item&quot;  &gt;生命周期&lt;/div&gt;\n        &lt;Text  mes=&quot;hello,world&quot;  /&gt;\n        &lt;React.Fragment&gt; Flagment &lt;/React.Fragment&gt;\n        { /*  */ }\n        text文本\n    &lt;/div&gt;\n}\n会被编译成这样：\nrender() {\n    return React.createElement(&quot;div&quot;, { className: &quot;box&quot; },\n            React.createElement(&quot;div&quot;, { className: &quot;item&quot; }, &quot;\\u751F\\u547D\\u5468\\u671F&quot;),\n            React.createElement(Text, { mes: &quot;hello,world&quot; }),\n            React.createElement(React.Fragment, null, &quot; Flagment &quot;),\n            &quot;text\\u6587\\u672C&quot;);\n    }\n当然我们可以不用jsx模式，而是直接通过createElement进行开发。\nReact.createElement(\n  type,\n  [props],\n  [...children]\n)\ncreateElement参数：\n\n\n第一个参数：如果是组件类型，会传入组件，如果是dom元素类型，传入div或者span之类的字符串。\n\n\n第二个参数：第二个参数为一个对象，在dom类型中为属性，在组件类型中为props。\n\n\n其他参数：，依次为children，根据顺序排列。\n\n\ncreateElement做了些什么？\n经过createElement处理，最终会形成 $$typeof = Symbol(react.element)对象。对象上保存了该react.element的信息。\ncloneElement\n可能有的同学还傻傻的分不清楚cloneElement和createElement区别和作用。\ncreateElement把我们写的jsx，变成element对象；\n而cloneElement的作用是以 element 元素为样板克隆并返回新的 React 元素。返回元素的 props 是将新的 props 与原始元素的 props 浅层合并后的结果。\n那么cloneElement感觉在我们实际业务组件中，可能没什么用，但是在一些开源项目，或者是公共插槽组件中用处还是蛮大的，比如说，我们可以在组件中，劫持children element，然后通过cloneElement克隆element，混入props。\n经典的案例就是 react-router中的Swtich组件，通过这种方式，来匹配唯一的 Route并加以渲染。\n我们设置一个场景，在组件中，去劫持children，然后给children赋能一些额外的props：\nfunction FatherComponent({ children }){\n    const newChildren = React.cloneElement(children, { age: 18})\n    return &lt;div&gt; { newChildren } &lt;/div&gt;\n}\n \nfunction SonComponent(props){\n    console.log(props)\n    return &lt;div&gt;hello,world&lt;/div&gt;\n}\n \nclass Index extends React.Component{    \n    render(){      \n        return &lt;div className=&quot;box&quot; &gt;\n            &lt;FatherComponent&gt;\n                &lt;SonComponent name=&quot;alien&quot;  /&gt;\n            &lt;/FatherComponent&gt;\n        &lt;/div&gt;   \n    }\n}\ncreateContext\ncreateContext用于创建一个Context对象，createContext对象中，包括用于传递 Context 对象值 value的Provider，和接受value变化订阅的Consumer。\nconst MyContext = React.createContext(defaultValue)\ncreateContext接受一个参数defaultValue，如果Consumer上一级一直没有Provider，则会应用defaultValue作为value。也就是说，只有当组件所处的树中没有匹配到 Provider 时，其 defaultValue 参数才会生效。\n我们来模拟一个 Context.Provider和Context.Consumer的例子：\nfunction ComponentA(){\n    /* 用 Consumer 订阅， 来自 Provider 中 value 的改变  */\n    return &lt;MyContext.Consumer&gt;\n        { (value) =&gt; &lt;ComponentB  {...value} /&gt; }\n    &lt;/MyContext.Consumer&gt;\n}\n \nfunction ComponentB(props){\n    const { name , mes } = props\n    return &lt;div&gt; \n        &lt;div&gt; 姓名： { name }  &lt;/div&gt;\n        &lt;div&gt; 想对大家说： { mes }  &lt;/div&gt;\n    &lt;/div&gt;\n}\n \nfunction index(){\n    const [ value , ] = React.useState({\n        name: &#039;alien&#039;,\n        mes: &#039;let us learn React &#039;\n    })\n    return &lt;div style={{ marginTop:&#039;50px&#039; }} &gt;\n        &lt;MyContext.Provider value={value}  &gt;\n            &lt;ComponentA /&gt;\n        &lt;/MyContext.Provider&gt;\n    &lt;/div&gt;\n}\nProvider和Consumer的良好的特性，可以做数据的存和取，Consumer一方面传递value，另一方面可以订阅value的改变。\ncreateFactory\n返回用于生成指定类型 React 元素的函数。类型参数既可以是标签名字符串（像是 ‘div’ 或 ‘span’），也可以是 React 组件 类型 （ class 组件或函数组件），或是 React fragment 类型。\nconst Text = React.createFactory(()=&gt;&lt;div&gt;hello,world&lt;/div&gt;) \nfunction Index(){  \n    return &lt;div style={{ marginTop:&#039;50px&#039;  }} &gt;\n        &lt;Text/&gt;\n    &lt;/div&gt;\n}\ncreateRef\ncreateRef可以创建一个 ref 元素，附加在react元素上。\n用法：\nclass Index extends React.Component{\n    constructor(props){\n        super(props)\n        this.node = React.createRef()\n    }\n    componentDidMount(){\n        console.log(this.node)\n    }\n    render(){\n        return &lt;div ref={this.node} &gt; my name is alien &lt;/div&gt;\n    }\n}\n个人觉得createRef这个方法，很鸡肋，我们完全可以class类组件中这么写，来捕获ref。\nclass Index extends React.Component{\n    node = null\n    componentDidMount(){\n        console.log(this.node)\n    }\n    render(){\n        return &lt;div ref={(node)=&gt; this.node = node } &gt; my name is alien &lt;/div&gt;\n    }\n}\n或者在function组件中这么写：\nfunction Index(){\n    const node = React.useRef(null)\n    useEffect(()=&gt;{\n        console.log(node.current)\n    },[])\n    return &lt;div ref={node} &gt;  my name is alien &lt;/div&gt;\n}\nisValidElement\n这个方法可以用来检测是否为react element元素，接受待验证对象，返回true或者false。这个 api 可能对于业务组件的开发，作用不大，因为对于组件内部状态，都是已知的，我们根本就不需要去验证，是否是react element 元素。 但是，对于一起公共组件或是开源库，isValidElement就很有作用了。\n实践\n我们做一个场景，验证容器组件的所有子组件，过滤到非react element类型。\n没有用isValidElement验证之前：\nconst Text = () =&gt; &lt;div&gt;hello,world&lt;/div&gt; \nclass WarpComponent extends React.Component{\n    constructor(props){\n        super(props)\n    }\n    render(){\n        return this.props.children\n    }\n}\nfunction Index(){\n    return &lt;div style={{ marginTop:&#039;50px&#039; }} &gt;\n        &lt;WarpComponent&gt;\n            &lt;Text/&gt;\n            &lt;div&gt; my name is alien &lt;/div&gt;\n            Let&#039;s learn react together!\n        &lt;/WarpComponent&gt;\n    &lt;/div&gt;\n}\n我们用isValidElement进行react element验证:\nclass WarpComponent extends React.Component{\n    constructor(props){\n        super(props)\n        this.newChidren = this.props.children.filter(item =&gt; React.isValidElement(item) )\n    }\n    render(){\n        return this.newChidren\n    }\n}\n过滤掉了非react element 的 Let&#039;s learn react together!。\nChildren\nmap\n接下来的五个api都是和react.Chidren相关的，我们来分别介绍一下，我们先来看看官网的描述，React.Children 提供了用于处理 this.props.children 不透明数据结构的实用方法。\n有的同学会问遍历 children用数组方法map ，forEach 不就可以了吗？ 请我们注意一下不透明数据结构，什么叫做不透明结构?\n我们先看一下透明的结构：\nclass Text extends React.Component{\n    render(){\n        return &lt;div&gt;hello,world&lt;/div&gt;\n    }\n}\nfunction WarpComponent(props){\n    console.log(props.children)\n    return props.children\n}\nfunction Index(){\n    return &lt;div style={{ marginTop:&#039;50px&#039; }} &gt;\n        &lt;WarpComponent&gt;\n            &lt;Text/&gt;\n            &lt;Text/&gt;\n            &lt;Text/&gt;\n            &lt;span&gt;hello,world&lt;/span&gt;\n        &lt;/WarpComponent&gt;\n    &lt;/div&gt;\n}\n打印结果显示 children 中包含四个组件；但是我们把Index结构改变一下：\nfunction Index(){\n    return &lt;div style={{ marginTop:&#039;50px&#039; }} &gt;\n        &lt;WarpComponent&gt;\n            { new Array(3).fill(0).map(()=&gt;&lt;Text/&gt;) }\n            &lt;span&gt;hello,world&lt;/span&gt;\n        &lt;/WarpComponent&gt;\n    &lt;/div&gt;\n}\n而此次打印结果则会显示两个元素；也就是这个数据结构，我们不能正常的遍历了，即使遍历也不能遍历到每一个子元素。此时就需要 react.Chidren 来帮忙了。\n我们把WarpComponent组件用react.Chidren.map处理children:\nfunction WarpComponent(props){\n    const newChildren = React.Children.map(props.children,(item)=&gt;item)\n    console.log(newChildren)\n    return newChildren\n} \n此时就能正常遍历了，达到了预期效果。不过注意 如果 children 是一个 Fragment 对象，它将被视为单一子节点的情况处理，而不会被遍历。\nforEach\nChildren.forEach和Children.map 用法类似，Children.map可以返回新的数组，Children.forEach仅停留在遍历阶段。\n我们将上面的WarpComponent方法，用Children.forEach改一下。\nfunction WarpComponent(props){\n    React.Children.forEach(props.children,(item)=&gt;console.log(item))\n    return props.children\n}   \ncount\nchildren 中的组件总数量，等同于通过 map 或 forEach 调用回调函数的次数。对于更复杂的结果，Children.count可以返回同一级别子组件的数量。\n我们还是把上述例子进行改造：\nfunction WarpComponent(props){\n    const childrenCount =  React.Children.count(props.children)\n    console.log(childrenCount,&#039;childrenCount&#039;)\n    return props.children\n}   \nfunction Index(){\n    return &lt;div style={{ marginTop:&#039;50px&#039; }} &gt;\n        &lt;WarpComponent&gt;\n            { new Array(3).fill(0).map((item,index) =&gt; new Array(2).fill(1).map((item,index1)=&gt;&lt;Text key={index+index1} /&gt;)) }\n            &lt;span&gt;hello,world&lt;/span&gt;\n        &lt;/WarpComponent&gt;\n    &lt;/div&gt;\n}\ntoArray\nChildren.toArray返回，props.children扁平化后结果。\nfunction WarpComponent(props){\n    const newChidrenArray =  React.Children.toArray(props.children)\n    console.log(newChidrenArray,&#039;newChidrenArray&#039;)\n    return newChidrenArray\n}   \nfunction Index(){\n    return &lt;div style={{ marginTop:&#039;50px&#039; }} &gt;\n        &lt;WarpComponent&gt;\n            { new Array(3).fill(0).map((item,index)=&gt;new Array(2).fill(1).map((item,index1)=&gt;&lt;Text key={index+index1} /&gt;)) }\n            &lt;span&gt;hello,world&lt;/span&gt;\n        &lt;/WarpComponent&gt;\n    &lt;/div&gt;\n}\nnewChidrenArray ，就是扁平化的数组结构。React.Children.toArray() 在拉平展开子节点列表时，更改 key 值以保留嵌套数组的语义。也就是说， toArray 会为返回数组中的每个 key 添加前缀，以使得每个元素 key 的范围都限定在此函数入参数组的对象内。\nonly\n验证 children 是否只有一个子节点（一个 React 元素），如果有则返回它，否则此方法会抛出错误。\n不唯一\nfunction WarpComponent(props){\n    console.log(React.Children.only(props.children))\n    return props.children\n}   \nfunction Index(){\n    return &lt;div style={{ marginTop:&#039;50px&#039; }} &gt;\n        &lt;WarpComponent&gt;\n            { new Array(3).fill(0).map((item,index)=&gt;&lt;Text key={index} /&gt;) }\n            &lt;span&gt;hello,world&lt;/span&gt;\n        &lt;/WarpComponent&gt;\n    &lt;/div&gt;\n}\n唯一\nfunction WarpComponent(props){\n    console.log(React.Children.only(props.children))\n    return props.children\n}   \nfunction Index(){\n    return &lt;div style={{ marginTop:&#039;50px&#039; }} &gt;\n        &lt;WarpComponent&gt;\n           &lt;Text/&gt;\n        &lt;/WarpComponent&gt;\n    &lt;/div&gt;\n}\nReact.Children.only() 不接受 React.Children.map() 的返回值，因为它是一个数组而并不是 React 元素。\nreact-hooks\nuseState\nuseState可以弥补函数组件没有state的缺陷。useState可以接受一个初识值，也可以是一个函数action，action返回值作为新的state。返回一个数组，第一个值为state读取值，第二个值为改变state的dispatchAction函数。\nconst DemoState = (props) =&gt; {\n   /* number为此时state读取值 ，setNumber为派发更新的函数 */\n   let [number, setNumber] = useState(0) /* 0为初始值 */\n   return (&lt;div&gt;\n       &lt;span&gt;{ number }&lt;/span&gt;\n       &lt;button onClick={ ()=&gt; {\n         setNumber(number + 1) /* 写法一 */\n         setNumber(number =&gt; number + 1 ) /* 写法二 */\n         console.log(number) /* 这里的number是不能够即时改变的  */\n       } } &gt;num++&lt;/button&gt;\n   &lt;/div&gt;)\n}\nuseEffect\nuseEffect可以弥补函数组件没有生命周期的缺点。我们可以在useEffect第一个参数回调函数中，做一些请求数据，事件监听等操作，第二个参数作为dep依赖项，当依赖项发生变化，重新执行第一个函数。\nuseEffect可以用作数据交互。\n/* 模拟数据交互 */\nfunction getUserInfo(a){\n    return new Promise((resolve)=&gt;{\n        setTimeout(()=&gt;{ \n           resolve({\n               name:a,\n               age:16,\n           }) \n        },500)\n    })\n}\nconst DemoEffect = ({ a }) =&gt; {\n    const [ userMessage , setUserMessage ] :any= useState({})\n    const div= useRef()\n    const [number, setNumber] = useState(0)\n    /* 模拟事件监听处理函数 */\n    const handleResize =()=&gt;{}\n    /* useEffect使用 ，这里如果不加限制 ，会是函数重复执行，陷入死循环*/\n    useEffect(()=&gt;{\n        /* 请求数据 */\n       getUserInfo(a).then(res=&gt;{\n           setUserMessage(res)\n       })\n       /* 操作dom  */\n       console.log(div.current) /* div */\n       /* 事件监听等 */\n        window.addEventListener(&#039;resize&#039;, handleResize)\n    /* 只有当props-&gt;a和state-&gt;number改变的时候 ,useEffect副作用函数重新执行 ，如果此时数组为空[]，证明函数只有在初始化的时候执行一次相当于componentDidMount */\n    },[ a ,number ])\n    return (&lt;div ref={div} &gt;\n        &lt;span&gt;{ userMessage.name }&lt;/span&gt;\n        &lt;span&gt;{ userMessage.age }&lt;/span&gt;\n        &lt;div onClick={ ()=&gt; setNumber(1) } &gt;{ number }&lt;/div&gt;\n    &lt;/div&gt;)\n}\n \n复制代码\nuseEffect可以用作事件监听，还有一些基于dom的操作。,别忘了在useEffect第一个参数回调函数，返一个函数用于清除事件监听等操作。\nconst DemoEffect = ({ a }) =&gt; {\n    /* 模拟事件监听处理函数 */\n    const handleResize = () =&gt; {}\n    useEffect(()=&gt;{\n       /* 定时器 延时器等 */\n       const timer = setInterval(()=&gt;console.log(666),1000)\n       /* 事件监听 */\n       window.addEventListener(&#039;resize&#039;, handleResize)\n       /* 此函数用于清除副作用 */\n       return function(){\n           clearInterval(timer) \n           window.removeEventListener(&#039;resize&#039;, handleResize)\n       }\n    },[ a ])\n    return (&lt;div  &gt;\n    &lt;/div&gt;)\n}\nuseMemo\nuseMemo接受两个参数，第一个参数是一个函数，返回值用于产生保存值。 第二个参数是一个数组，作为dep依赖项，数组里面的依赖项发生变化，重新执行第一个函数，产生新的值。\n应用场景：\n1 缓存一些值，避免重新执行上下文\nconst number = useMemo(()=&gt;{\n    /** ....大量的逻辑运算 **/\n   return number\n},[ props.number ]) // 只有 props.number 改变的时候，重新计算number的值。\n2 减少不必要的dom循环\n/* 用 useMemo包裹的list可以限定当且仅当list改变的时候才更新此list，\n * 这样就可以避免selectList重新循环 \n*/\n {useMemo(() =&gt; (\n      &lt;div&gt;{\n          selectList.map((i, v) =&gt; (\n              &lt;span\n                  className={style.listSpan}\n                  key={v} &gt;\n                  {i.patentName} \n              &lt;/span&gt;\n          ))}\n      &lt;/div&gt;\n), [selectList])}\n3 减少子组件渲染\n/* 只有当props中，list 列表改变的时候，子组件才渲染 */\nconst goodListChild = useMemo(()=&gt; &lt;GoodList list={ props.list } /&gt; , [ props.list ])\nuseCallback\nuseMemo 和 useCallback 接收的参数都是一样，都是在其依赖项发生变化后才执行，都是返回缓存的值，区别在于 useMemo 返回的是函数运行的结果， useCallback 返回的是函数。 返回的callback可以作为props回调函数传递给子组件。\n/* 用react.memo */\nconst DemoChildren = React.memo((props)=&gt;{\n   /* 只有初始化的时候打印了 子组件更新 */\n   console.log(&#039;子组件更新&#039;)\n   useEffect(()=&gt;{\n       props.getInfo(&#039;子组件&#039;)\n   },[])\n   return &lt;div&gt;子组件&lt;/div&gt;\n})\nconst DemoUseCallback=({ id })=&gt;{\n    const [number, setNumber] = useState(1)\n    /* 此时usecallback的第一参数 (sonName)=&gt;{ console.log(sonName) }\n       经过处理赋值给 getInfo \n     */\n    const getInfo  = useCallback((sonName)=&gt;{\n          console.log(sonName)\n    },[id])\n    return &lt;div&gt;\n        {/* 点击按钮触发父组件更新 ，但是子组件没有更新 */}\n        &lt;button onClick={ ()=&gt;setNumber(number+1) } &gt;增加&lt;/button&gt;\n        &lt;DemoChildren getInfo={getInfo} /&gt;\n    &lt;/div&gt;\n}\nuseRef\nuseRef的作用：\n\n一 是可以用来获取dom元素，或者class组件实例 。\n二 创建useRef时候，会创建一个原始对象，只要函数组件不被销毁，原始对象就会一直存在，那么我们可以利用这个特性，来通过useRef保存一些数据。\n\nconst DemoUseRef = ()=&gt;{\n    const dom = useRef(null)\n    const handerSubmit = ()=&gt;{\n        /*  &lt;div &gt;表单组件&lt;/div&gt;  dom 节点 */\n        console.log(dom.current)\n    }\n    return &lt;div&gt;\n        {/* ref 标记当前dom节点 */}\n        &lt;div ref={dom} &gt;表单组件&lt;/div&gt;\n        &lt;button onClick={()=&gt;handerSubmit()} &gt;提交&lt;/button&gt; \n    &lt;/div&gt;\n}\nuseLayoutEffect\nuseEffect执行顺序： 组件更新挂载完成 → 浏览器 dom 绘制完成 → 执行 useEffect 回调。\nuseLayoutEffect 执行顺序： 组件更新挂载完成 →  执行 useLayoutEffect 回调 → 浏览器dom绘制完成。\n也就是说 useLayoutEffect 代码可能会阻塞浏览器的绘制 。\n我们写的 useEffect和 useLayoutEffect，react在底层会被分别打上PassiveEffect，HookLayout，在commit阶段区分出，在什么时机执行。\nconst DemoUseLayoutEffect = () =&gt; {\n    const target = useRef()\n    useLayoutEffect(() =&gt; {\n        /*我们需要在dom绘制之前，移动dom到制定位置*/\n        const { x ,y } = getPositon() /* 获取要移动的 x,y坐标 */\n        animate(target.current,{ x,y })\n    }, []);\n    return (\n        &lt;div &gt;\n            &lt;span ref={ target } className=&quot;animate&quot;&gt;&lt;/span&gt;\n        &lt;/div&gt;\n    )\n}\nuseLayoutEffect是来解决什么问题的？\n答：useLayoutEffect的作用是“当页面挂载或渲染完成时，再给你一次机会对页面进行修改”。\n如果你选择使用useLayoutEffect，对页面进行了修改，更改样式不会引发重新渲染，但是修改变量则会触发再次渲染。\n如果你不使用 useLayoutEffect，那么之后就应该调用useEffect。\n补充说明：\n1、优先使用 useEffect，useEffect 无法满足需求时再考虑使用useLayoutEffect。\n2、useLayoutEffect 先触发，useEffect 后触发。\n3、useEffect 和 useLayoutEffect 在服务器端渲染时，都不行，需要寻求别的解决方案。\nuseReducer\nuseState底层其实是一个简单版的useReducer，它接受的第一个参数是一个函数，我们可以认为它就是一个 reducer ，reducer 的参数就是常规 reducer 里面的 state 和  action ，返回改变后的 state , useReducer 第二个参数为 state 的初始值，返回一个数组，数组的第一项就是更新之后 state 的值 ，第二个参数是派发更新的 dispatch 函数。\n我们来看一下useReducer如何使用：\nconst DemoUseReducer = ()=&gt;{\n    /* number为更新后的state值,  dispatchNumbner 为当前的派发函数 */\n   const [ number , dispatchNumbner ] = useReducer((state, action)=&gt;{\n       const { payload , name  } = action\n       /* return的值为新的state */\n       switch(name){\n           case &#039;add&#039;:\n               return state + 1\n           case &#039;sub&#039;:\n               return state - 1 \n           case &#039;reset&#039;:\n             return payload       \n       }\n       return state\n   },0)\n   return &lt;div&gt;\n      当前值：{ number }\n      { /* 派发更新 */ }\n      &lt;button onClick={()=&gt;dispatchNumbner({ name:&#039;add&#039; })} &gt;增加&lt;/button&gt;\n      &lt;button onClick={()=&gt;dispatchNumbner({ name:&#039;sub&#039; })} &gt;减少&lt;/button&gt;\n      &lt;button onClick={()=&gt;dispatchNumbner({ name:&#039;reset&#039; ,payload: 666 })} &gt;赋值&lt;/button&gt;\n      { /* 把dispatch 和 state 传递给子组件  */ }\n      &lt;MyChildren  dispatch={ dispatchNumbner } State={{ number }} /&gt;\n   &lt;/div&gt;\n}\nuseContext\n我们可以使用 useContext ，来获取父级组件传递过来的 context 值，这个当前值就是最近的父级组件 Provider 设置的 value 值，useContext 参数一般是由 createContext 方式引入，也可以父级上下文 context 传递 ( 参数为 context )。useContext 可以代替 context.Consumer 来获取 Provider 中保存的 value 值：\n/* 用useContext方式 */\nconst DemoContext = ()=&gt; {\n    const value:any = useContext(Context)\n    /* my name is alien */\n\treturn &lt;div&gt; my name is { value.name }&lt;/div&gt;\n}\n/* 用Context.Consumer 方式 */\nconst DemoContext1 = ()=&gt;{\n    return &lt;Context.Consumer&gt;\n         {/*  my name is alien  */}\n        { (value)=&gt; &lt;div&gt; my name is { value.name }&lt;/div&gt; }\n    &lt;/Context.Consumer&gt;\n}\n \nexport default ()=&gt;{\n    return &lt;div&gt;\n        &lt;Context.Provider value={{ name:&#039;alien&#039; , age:18 }} &gt;\n            &lt;DemoContext /&gt;\n            &lt;DemoContext1 /&gt;\n        &lt;/Context.Provider&gt;\n    &lt;/div&gt;\n}\nuseImperativeHandle\nuseImperativeHandle ，它的作用是“勾住”子组件中某些函数(方法)供父组件调用，可以配合 forwardRef 自定义暴露给父组件的实例值。\n先回顾一下之前学到的。\n\n\n第1个知识点：react属于单向数据流，父组件可以通过属性传值，将父组件内的函数(方法)传递给子组件，实现子组件调用父组件内函数的目的。\n\n\n第2个知识点：\n\nuseRef可以“勾住”某些本组件挂载完成或重新渲染完成后才拥有的某些对象。\nReact.forwardRef 可以“勾住”某些子组件挂载完成或重新渲染完成后才拥有的某些对象。\n\n\n\n上面无论哪种情况，由于勾住的对象都是渲染后的原生html对象，父组件只能通过ref调用该原生html对象的函数(方法)。\n如果父组件想调用子组件中自定义的方法，该怎么办？答：使用useImperativeHandle()\n这个很有用，我们知道，对于子组件，如果是class类组件，我们可以通过ref获取类组件的实例，但是在子组件是函数组件的情况，如果我们不能直接通过ref的，那么此时useImperativeHandle和 forwardRef配合就能达到效果。\nuseImperativeHandle接受三个参数：\n\n第一个参数 ref：接受 forWardRef 传递过来的 ref。\n第二个参数 createHandle ：处理函数，返回值作为暴露给父组件的ref对象。\n第三个参数 deps：依赖项 deps，依赖项更改形成新的ref对象。\n\n我们来模拟给场景，用useImperativeHandle，使得父组件能调用子组件中的函数。\nimport React,{useState,useImperativeHandle} from &#039;react&#039;\n \nfunction ChildComponent(props,ref) {\n  const [count,setCount] =  useState(0); //子组件定义内部变量count\n  //子组件定义内部函数 addCount\n  const addCount = () =&gt; {\n    setCount(count + 1);\n  }\n  //子组件通过useImperativeHandle函数，将addCount函数添加到父组件中的ref.current中\n  useImperativeHandle(ref,() =&gt; ({addCount}));\n  return (\n    &lt;div&gt;\n        {count}\n        &lt;button onClick={addCount}&gt;child&lt;/button&gt;\n    &lt;/div&gt;\n  )\n}\n \n//子组件导出时需要被React.forwardRef包裹，否则无法接收 ref这个参数\nexport default React.forwardRef(ChildComponent);\n \n \n// 父组件\nimport React,{useRef} from &#039;react&#039;\nimport ChildComponent from &#039;./childComponent&#039;\n \nfunction Imperative() {\n  const childRef = useRef(null); //父组件定义一个对子组件的引用\n \n  const clickHandle = () =&gt; {\n    childRef.current.addCount(); //父组件调用子组件内部 addCount函数\n  }\n \n  return (\n    &lt;div&gt;\n        {/* 父组件通过给子组件添加 ref 属性，将childRef传递给子组件，\n            子组件获得该引用即可将内部函数添加到childRef中 */}\n        &lt;ChildComponent ref={childRef} /&gt;\n        &lt;button onClick={clickHandle}&gt;child component do somting&lt;/button&gt;\n    &lt;/div&gt;\n  )\n}\n \nexport default Imperative;\n思考一下真的有必要使用useImperativeHandle吗？\n从实际运行的结果，无论点击子组件还是父组件内的按钮，都将执行 addCount函数，使 count + 1 。\nreact为单向数据流，如果为了实现这个效果，我们完全可以把需求转化成另外一种说法，即状态提升：\n1、父组件内定义一个变量count 和 addCount函数\n2、父组件把 count 和 addCount 通过属性传值 传递给子组件\n3、点击子组件内按钮时调用父组件内定义的 addCount函数，使 count +1。\n你会发现即使把需求中的 父与子组件 描述对调一下，“最终实际效果”是一样的。所以，到底使用哪种形式，需要根据组件实际需求来做定夺。\nuseDebugValue\nuseDebugValue 可用于在 React 开发者工具中显示自定义 hook 的标签。这个hooks目的就是检查自定义hooks：\nfunction useFriendStatus(friendID) {\n  const [isOnline, setIsOnline] = useState(null);\n  // ...\n  // 在开发者工具中的这个 Hook 旁边显示标签\n  // e.g. &quot;FriendStatus: Online&quot;\n  useDebugValue(isOnline ? &#039;Online&#039; : &#039;Offline&#039;);\n \n  return isOnline;\n}\n\n我们不推荐你向每个自定义 Hook 添加 debug 值。\n当它作为共享库的一部分时才最有价值。在某些情况下，格式化值的显示可能是一项开销很大的操作。除非需要检查 Hook，否则没有必要这么做。\n因此，useDebugValue 接受一个格式化函数作为可选的第二个参数。该函数只有在 Hook 被检查时才会被调用。它接受 debug 值作为参数，并且会返回一个格式化的显示值。\n\nuseTransition\nuseTransition允许延时由state改变而带来的视图渲染。避免不必要的渲染。它还允许组件将速度较慢的数据获取更新推迟到随后渲染，以便能够立即渲染更重要的更新。\nconst TIMEOUT_MS = { timeoutMs: 2000 }\nconst [startTransition, isPending] = useTransition(TIMEOUT_MS)\n\nuseTransition 接受一个对象， timeoutMs代表需要延时的时间。\n返回一个数组。第一个参数：  是一个接受回调的函数。我们用它来告诉 React 需要推迟的 state 。 第二个参数： 一个布尔值。表示是否正在等待，过度状态的完成(延时state的更新)。\n\n下面我们引入官网的列子，来了解useTransition的使用。\nconst SUSPENSE_CONFIG = { timeoutMs: 2000 };\n \nfunction App() {\n  const [resource, setResource] = useState(initialResource);\n  const [startTransition, isPending] = useTransition(SUSPENSE_CONFIG);\n  return (\n    &lt;&gt;\n      &lt;button\n        disabled={isPending}\n        onClick={() =&gt; {\n          startTransition(() =&gt; {\n            const nextUserId = getNextId(resource.userId);\n            setResource(fetchProfileData(nextUserId));\n          });\n        }}\n      &gt;\n        Next\n      &lt;/button&gt;\n      {isPending ? &quot; 加载中...&quot; : null}\n      &lt;Suspense fallback={&lt;Spinner /&gt;}&gt;\n        &lt;ProfilePage resource={resource} /&gt;\n      &lt;/Suspense&gt;\n    &lt;/&gt;\n  );\n}\n在这段代码中，我们使用 startTransition 包装了我们的数据获取。这使我们可以立即开始获取用户资料的数据，同时推迟下一个用户资料页面以及其关联的 Spinner 的渲染 2 秒钟（ timeoutMs  中显示的时间）。\n这个api目前处于实验阶段，没有被完全开放出来。\nreact-dom\n接下来，我们来一起研究react-dom中比较重要的api。\nrender\nrender 是我们最常用的react-dom的 api，用于渲染一个react元素，一般react项目我们都用它，渲染根部容器app。\nReactDOM.render(element, container[, callback])\n使用\nReactDOM.render(\n    &lt; App / &gt;,\n    document.getElementById(&#039;app&#039;)\n)\nReactDOM.render会控制container容器节点里的内容，但是不会修改容器节点本身。\nhydrate\n服务端渲染用hydrate。用法与 render() 相同，但它用于在 ReactDOMServer 渲染的容器中对 HTML 的内容进行 hydrate 操作。\nReactDOM.hydrate(element, container[, callback])\ncreatePortal\nPortal 提供了一种将子节点渲染到存在于父组件以外的 DOM 节点的优秀的方案。createPortal 可以把当前组件或 element 元素的子节点，渲染到组件之外的其他地方。\n那么具体应用到什么场景呢？\n比如一些全局的弹窗组件model，&lt;Model/&gt;组件一般都写在我们的组件内部，倒是真正挂载的dom，都是在外层容器，比如body上。此时就很适合createPortalAPI。\ncreatePortal接受两个参数：\nReactDOM.createPortal(child, container)\n第一个： child 是任何可渲染的 React 子元素；第二个： container是一个 DOM 元素。\n接下来我们实践一下：\nfunction WrapComponent({ children }){\n    const domRef = useRef(null)\n    const [ PortalComponent, setPortalComponent ] = useState(null)\n    React.useEffect(()=&gt;{\n        setPortalComponent( ReactDOM.createPortal(children, domRef.current) )\n    },[])\n    return &lt;div&gt; \n        &lt;div className=&quot;container&quot; ref={ domRef } &gt;&lt;/div&gt;\n        { PortalComponent }\n     &lt;/div&gt;\n}\n \nclass Index extends React.Component{\n    render(){\n        return &lt;div style={{ marginTop:&#039;50px&#039; }} &gt;\n             &lt;WrapComponent&gt;\n               &lt;div  &gt;hello,world&lt;/div&gt;\n            &lt;/WrapComponent&gt;\n        &lt;/div&gt;\n    }\n}\n可以看到，我们children实际在container 之外挂载的，但是已经被createPortal渲染到container中。\nunstable_batchedUpdates\n在react-legacy模式下，对于事件，react事件有批量更新来处理功能,但是这一些非常规的事件中，批量更新功能会被打破。所以我们可以用react-dom中提供的unstable_batchedUpdates 来进行批量更新。\n一次点击实现的批量更新\nclass Index extends React.Component{\n    constructor(props){\n       super(props)\n       this.state={\n           numer:1,\n       }\n    }\n    handerClick=()=&gt;{\n        this.setState({ numer : this.state.numer + 1 })\n        console.log(this.state.numer)\n        this.setState({ numer : this.state.numer + 1 })\n        console.log(this.state.numer)\n        this.setState({ numer : this.state.numer + 1 })\n        console.log(this.state.numer)\n    }\n    render(){\n        return &lt;div  style={{ marginTop:&#039;50px&#039; }} &gt; \n            &lt;button onClick={ this.handerClick } &gt;click me&lt;/button&gt;\n        &lt;/div&gt;\n    }\n}\n渲染次数一次。\n批量更新条件被打破\nhanderClick = () =&gt; {\n    Promise.resolve().then(()=&gt;{\n        this.setState({ numer : this.state.numer + 1 })\n        console.log(this.state.numer)\n        this.setState({ numer : this.state.numer + 1 })\n        console.log(this.state.numer)\n        this.setState({ numer : this.state.numer + 1 })\n        console.log(this.state.numer)\n    })\n}\n渲染次数三次。\nunstable_batchedUpdate助力\n handerClick=()=&gt;{\n        Promise.resolve().then(()=&gt;{\n            ReactDOM.unstable_batchedUpdates(()=&gt;{\n                this.setState({ numer : this.state.numer + 1 })\n                console.log(this.state.numer)\n                this.setState({ numer : this.state.numer + 1 })\n                console.log(this.state.numer)\n                this.setState({ numer : this.state.numer + 1 })\n                console.log(this.state.numer)\n            }) \n        })\n    }\n渲染次数一次,完美解决批量更新问题。\nflushSync\nflushSync 可以将回调函数中的更新任务，放在一个较高的优先级中。我们知道react设定了很多不同优先级的更新任务。如果一次更新任务在flushSync回调函数内部，那么将获得一个较高优先级的更新。比如\nReactDOM.flushSync(()=&gt;{\n    /* 此次更新将设置一个较高优先级的更新 */\n    this.setState({ name: &#039;alien&#039;  })\n})\n为了让大家理解flushSync，我这里做一个demo奉上，\n/* flushSync */\nimport ReactDOM from &#039;react-dom&#039;\nclass Index extends React.Component{\n    state={ number: 0 }\n    handerClick=()=&gt;{\n        setTimeout(()=&gt;{\n            this.setState({ number: 1  })\n        })\n        this.setState({ number: 2  })\n        ReactDOM.flushSync(()=&gt;{\n            this.setState({ number: 3  })\n        })\n        this.setState({ number: 4  })\n    }\n    render(){\n        const { number } = this.state\n        console.log(number) // 打印什么？？\n        return &lt;div&gt;\n            &lt;div&gt;{ number }&lt;/div&gt;\n            &lt;button onClick={this.handerClick} &gt;测试flushSync&lt;/button&gt;\n        &lt;/div&gt;\n    }\n}\n先不看答案，点击一下按钮，打印什么呢？\n我们来点击一下看看\n打印 0 3 4 1 ，相信不难理解为什么这么打印了。\n\n首先 flushSync this.setState({ number: 3  })设定了一个高优先级的更新，所以3 先被打印\n2 4 被批量更新为 4\n\n相信这个demo让我们更深入了解了flushSync。\nfindDOMNode\nfindDOMNode用于访问组件DOM元素节点，react推荐使用ref模式，不期望使用findDOMNode。\nReactDOM.findDOMNode(component)\n注意的是：\n\nfindDOMNode只能用在已经挂载的组件上。\n如果组件渲染内容为 null 或者是 false，那么 findDOMNode返回值也是 null。\nfindDOMNode 不能用于函数组件。\n\n接下来让我们看一下，findDOMNode具体怎么使用的：\nclass Index extends React.Component{\n    handerFindDom=()=&gt;{\n        console.log(ReactDOM.findDOMNode(this))\n    }\n    render(){\n        return &lt;div style={{ marginTop:&#039;100px&#039; }} &gt;\n            &lt;div&gt;hello,world&lt;/div&gt;\n            &lt;button onClick={ this.handerFindDom } &gt;获取容器dom&lt;/button&gt;\n        &lt;/div&gt;\n    }\n}\n效果：\n我们完全可以将外层容器用ref来标记，获取捕获原生的dom节点。\nunmountComponentAtNode\n从 DOM 中卸载组件，会将其事件处理器和 state 一并清除。 如果指定容器上没有对应已挂载的组件，这个函数什么也不会做。如果组件被移除将会返回 true ，如果没有组件可被移除将会返回  false 。\n我们来简单举例看看unmountComponentAtNode如何使用？\nfunction Text(){\n    return &lt;div&gt;hello,world&lt;/div&gt;\n}\n \nclass Index extends React.Component{\n    node = null\n    constructor(props){\n       super(props)\n       this.state={\n           numer:1,\n       }\n    }\n    componentDidMount(){\n        /*  组件初始化的时候，创建一个 container 容器 */\n        ReactDOM.render(&lt;Text/&gt; , this.node )\n    }\n    handerClick=()=&gt;{\n       /* 点击卸载容器 */ \n       const state =  ReactDOM.unmountComponentAtNode(this.node)\n       console.log(state)\n    }\n    render(){\n        return &lt;div  style={{ marginTop:&#039;50px&#039; }}  &gt; \n             &lt;div ref={ ( node ) =&gt; this.node = node  }  &gt;&lt;/div&gt;  \n            &lt;button onClick={ this.handerClick } &gt;click me&lt;/button&gt;\n        &lt;/div&gt;\n    }\n}"},"front-end/react/code-analysis/react-suspense":{"title":"react-suspense","links":[],"tags":[],"content":"代码分割\n一个项目使用打包工具进行打包，随着工程量增加和业务大量引入第三方包，打包后的文件会逐渐增大，页面首次打开时，会加载大量代码包，而有些内容可能是用户并不关心的，会造成页面加载较缓；\n代码分割能够“懒加载”用户所需要的内容，引入代码分割的最佳方式是通过动态 import() 语法；\n如在 Webpack 中，解析到该语法时，会自动进行代码分割；\n在 React 16.6.0 中，也有新的特性是解决这个问题的；\nSuspense\nSuspense 使得组件可以“等待”某些操作结束后，再进行渲染；目前，Suspense 仅支持的使用场景是配合 React.lazy() 实现组件懒加载；\nReact.Suspense 可以指定加载指示器（loading indicator），以防其组件树中的某些子组件尚未具备渲染条件。\nReact.lazy()\n在以往，我们通常使用第三方库 jamiebuilds/react-loadable 进行组件懒加载：\nimport Loadable from &#039;react-loadable&#039;;\n \nconst LoadableBar = Loadable({\n  loader: () =&gt; import(&#039;./components/Bar&#039;),\n  loading() {\n    return &lt;div&gt;Loading...&lt;/div&gt;\n  }\n});\n \nclass MyComponent extends React.Component {\n  render() {\n    return &lt;LoadableBar/&gt;;\n  }\n}\nReact.lazy() 允许你定义一个动态加载的组件。这有助于缩减 bundle 的体积，并延迟加载在初次渲染时未用到的组件；\n依据 Suspense 和 React.lazy() 能像渲染常规组件一样处理动态引入组件：\nimport React, { Suspense } from &#039;react&#039;;\n \nconst OtherComponent = React.lazy(() =&gt; import(&#039;./OtherComponent&#039;));\n \nfunction MyComponent() {\n  return (\n    &lt;div&gt;\n      &lt;Suspense fallback={&lt;div&gt;Loading...&lt;/div&gt;}&gt;\n        &lt;OtherComponent /&gt;\n      &lt;/Suspense&gt;\n    &lt;/div&gt;\n  );\n}\n源码解析\nSuspense 组件依旧是 一个 Symbol ，而 Lazy 函数则是返回了一个对象：\nexport function lazy&lt;T, R&gt;(ctor: () =&gt; Thenable&lt;T, R&gt;): LazyComponent&lt;T&gt; {\n  return {\n    $$typeof: REACT_LAZY_TYPE,\n    _ctor: ctor,\n    // React uses these fields to store the result.\n    _status: -1,\n    _result: null,\n  };\n}"},"front-end/react/code-analysis/react-update":{"title":"react-update","links":[],"tags":[],"content":"Update\n位置\n在render函数中调用了updateContainer()：\n\nupdateContainer() 函数中计算出 expirationTime；\n传入updateContainerAtExpirationTime()函数；\n再调用了scheduleRootUpdate()函数；\n最后传入expirationTime调用createUpdate()；\n\n作用\n\n用来记录组件的状态变化，并存放在UpdateQueue中；\n多个Update可以同时存在；\n\n例如创建了三个setState()，React是不会立即更新的，而是放到UpdateQueue中，再去更新；\n数据结构\nexport function createUpdate(expirationTime: ExpirationTime): Update&lt;*&gt; {\n  return {\n    // 更新的过期时间\n    expirationTime: expirationTime,\n    //0: 更新 1: 替换 2: 强制更新 3: 捕获性的更新\n    tag: UpdateState,\n    // 更新内容和对应的回调，比如 setState({}, callback)\n    payload: null,\n    callback: null,\n\t// 指向下一个更新\n    next: null,\n    // 指向下一个side effect\n    nextEffect: null,\n  };\n}\n源码解析\nexport function updateContainer(\n  element: ReactNodeList,\n  container: OpaqueRoot,\n  parentComponent: ?React$Component&lt;any, any&gt;,\n  callback: ?Function,\n): ExpirationTime {\n  const current = container.current;\n  const currentTime = requestCurrentTime();\n  const expirationTime = computeExpirationForFiber(currentTime, current);\n  return updateContainerAtExpirationTime(\n    element,\n    container,\n    parentComponent,\n    expirationTime,\n    callback,\n  );\n}\n在updateContainer函数中，先拿到了container上的current对象，即rootFiber上的Fiber对象；然后根据requestCurrentTime取得一个currentTime，即当前时间到 js 加载完时间的时间差值；最后通过computeExpirationForFiber计算出expirationTime ，然后使用updateContainerAtExpirationTime更新container。\n// react\\packages\\react-reconciler\\src\\ReactFiberExpirationTime.js\nexport const NoWork = 0;\nexport const Sync = 1;\n// Math.pow(2, 30) - 1\n// 0b111111111111111111111111111111\nexport const Never = MAX_SIGNED_31_BIT_INT;\n \n// react\\packages\\react-reconciler\\src\\ReactFiberScheduler.js\nlet currentRendererTime: ExpirationTime = msToExpirationTime(\n  originalStartTimeMs,\n);\nlet currentSchedulerTime: ExpirationTime = currentRendererTime;\n \nfunction requestCurrentTime() {\n  if (isRendering) {\n    // We&#039;re already rendering. Return the most recently read time.\n    return currentSchedulerTime;\n  }\n  // Check if there&#039;s pending work.\n  findHighestPriorityRoot();\n  if (\n    nextFlushedExpirationTime === NoWork ||\n    nextFlushedExpirationTime === Never\n  ) {\n    recomputeCurrentRendererTime();\n    currentSchedulerTime = currentRendererTime;\n    return currentSchedulerTime;\n  }\n  return currentSchedulerTime;\n}\nUpdateQueue\nfunction scheduleRootUpdate(\n  current: Fiber,\n  element: ReactNodeList,\n  expirationTime: ExpirationTime,\n  callback: ?Function,\n) {\n  const update = createUpdate(expirationTime);\n  update.payload = {element};\n  // ...\n  enqueueUpdate(current, update);\n  scheduleWork(current, expirationTime);\n  return expirationTime;\n}\n在 createUpdate之后，则会调用enqueueUpdate将新创建出来的update入队；UpdateQueue的主要作用则是依次执行队列内部的update；\n数据结构\nexport function createUpdateQueue&lt;State&gt;(baseState: State): UpdateQueue&lt;State&gt; {\n    const queue: UpdateQueue&lt;State&gt; = {\n        baseState,\t\t\t\t\t// 更新后的 state\n        firstUpdate: null,\t\t\t// 队列中的第一个 update\n        lastUpdate: null,\t\t\t// 队列中的最后一个 update\n        firstCapturedUpdate: null,\t// 队列中第一个捕获类型的 update\n        lastCapturedUpdate: null,\t// 队列中最后一个捕获类型的 update\n        firstEffect: null,\t\t\t// 第一个 side effect\n        lastEffect: null,\t\t\t// 最后一个 side effect\n        firstCapturedEffect: null,\n        lastCapturedEffect: null,\n\t};\n\treturn queue;\n}\n源码解析\nexport function enqueueUpdate&lt;State&gt;(fiber: Fiber, update: Update&lt;State&gt;) {\n  // Update queues are created lazily.\n  const alternate = fiber.alternate;\t// alternate 即 workInProgress\n  let queue1;\t// current的队列\n  let queue2;\t// alternate的队列\n  if (alternate === null) {\n    // There&#039;s only one fiber.\n    queue1 = fiber.updateQueue;\n    queue2 = null;\n    if (queue1 === null) {\n      // 初始化更新队列\n      queue1 = fiber.updateQueue = createUpdateQueue(fiber.memoizedState);\n    }\n  } else {\n    // There are two owners. 如果 alternate 不为空，则取各自的更新队列\n    queue1 = fiber.updateQueue;\n    queue2 = alternate.updateQueue;\n    if (queue1 === null) {\n      if (queue2 === null) {\n        // Neither fiber has an update queue. Create new ones. 初始化\n        queue1 = fiber.updateQueue = createUpdateQueue(fiber.memoizedState);\n        queue2 = alternate.updateQueue = createUpdateQueue(\n          alternate.memoizedState,\n        );\n      } else {\n        // Only one fiber has an update queue. Clone to create a new one.\n        queue1 = fiber.updateQueue = cloneUpdateQueue(queue2);\n      }\n    } else {\n      if (queue2 === null) {\n        // Only one fiber has an update queue. Clone to create a new one.\n        queue2 = alternate.updateQueue = cloneUpdateQueue(queue1);\n      } else {\n        // Both owners have an update queue.\n      }\n    }\n  }\n  if (queue2 === null || queue1 === queue2) {\n    // There&#039;s only a single queue.\n    appendUpdateToQueue(queue1, update);\n  } else {\n    // There are two queues. We need to append the update to both queues,\n    // while accounting for the persistent structure of the list — we don&#039;t\n    // want the same update to be added multiple times.\n    if (queue1.lastUpdate === null || queue2.lastUpdate === null) {\n      // One of the queues is not empty. We must add the update to both queues.\n      appendUpdateToQueue(queue1, update);\n      appendUpdateToQueue(queue2, update);\n    } else {\n      // Both queues are non-empty. The last update is the same in both lists,\n      // because of structural sharing. So, only append to one of the lists.\n      appendUpdateToQueue(queue1, update);\n      // But we still need to update the `lastUpdate` pointer of queue2.\n      queue2.lastUpdate = update;\n    }\n  }\n}\nqueue1取的是fiber.updateQueue；queue2取的是alternate.updateQueue；\n\n如果两者均为null，则调用createUpdateQueue()获取初始队列；\n如果两者之一为null，则调用cloneUpdateQueue()从对方中获取队列；\n如果两者均不为null，则将update作为lastUpdate；\n"},"front-end/react/handle-errors":{"title":"handle-errors","links":[],"tags":[],"content":"React 错误处理：最佳实践\n作为一名开发者，我们都希望开发出来的应用程序能够稳定、完美的工作，并且能够满足所有可以想象得到的边缘场景。但是，作为一个人类，我们都会犯一些错误，根本写不出没有 Bug 的代码。无论我们多么小心，无论我们编写多少自动化测试，依然会不可避免地出现错误。但最重要的是，当错误影响到用户体验时，要能够防御这些错误，尽可能地减少影响范围，并以优雅的方式处理它，直到它能够被真正修复。\n因此，本文主要讨论 React 中的错误处理：当发生错误时，我们可以做什么；不同的错误捕获方法有哪些限制，以及如何突破这些限制。\nReact 中错误处理的重要性\n首先，让我们来讨论一个至关重要的问题：为什么在 React 中做一些错误捕获处理？\n答案很简单：自 React 16 起，任何未被错误边界捕获的错误将会导致整个 React 组件树被卸载。在这之前的版本中，即便组件的 UI 是残缺或错误的，组件也会显示在屏幕上。现在，即使是 UI 上的某个无关紧要的部分，甚至是某个无法控制的外部库中，出现了一个微不足道的错误，都有可能导致整个页面受到破坏，并为用户渲染出一个白屏。\n前端开发人员从未有过如此强大的破坏力😅\nJavaScript 中的 try/catch\n在常规的 JavaScript 代码中捕获那些令人讨厌的错误，处理方法通常非常简单。\n我们有一个很好用的 try/catch 语句，它的用法不言自明：尝试做一些事情，如果失败了，就捕获到错误并采取措施处理它：\ntry {\n  // if we&#039;re doing something wrong, this might throw an error\n  doSomething();\n} catch (e) {\n  // if error happened, catch it and do something with it without stopping the app\n  // like sending this error to some logging service\n}\n同样的代码也适用于 async 函数中：\ntry {\n  await fetch(&#039;/bla-bla&#039;);\n} catch (e) {\n  // oh no, the fetch failed! We should do something about it!\n}\n如果我们使用 Promise，我们有专门针对他们的捕获方法。因此，如果我们使用 Promise 的 API 重新编写前面的 fetch 示例，它将如下所示：\nfetch(&#039;/bla-bla&#039;).then((result) =&gt; {\n  // if a promise is successful, the result will be here\n  // we can do something useful with it\n}).catch((e) =&gt; {\n  // oh no, the fetch failed! We should do something about it!\n})\n它们的概念相同，只是实现有点不同，所以在本文的其余部分，我将对所有错误使用 try/catch 语法。\nReact 中的 try/catch\n当捕获到错误时，我们需要对错误做一些处理。除了上报一条错误日志之外，我们还能做什么呢？更准确地说，我们可以为用户做什么呢？让用户看到一个白屏页面或残缺的页面，这样的用户体验极其不友好。\n最直接的做法是，在等待我们修复的过程中，为用户渲染一些有用的内容。幸运的是，我们可以在 catch 语句中做任何想做的事情，包括设置状态。所以我们可以这样做：\nconst SomeComponent = () =&gt; {\n  const [hasError, setHasError] = useState(false);\n\n  useEffect(() =&gt; {\n    try {\n      // do something like fetching some data\n    } catch(e) {\n      // oh no! the fetch failed, we have no data to render!\n      setHasError(true);\n    }\n  })\n\n  // something happened during fetch, lets render some nice error screen\n  if (hasError) return &lt;SomeErrorScreen /&gt;\n\n  // all&#039;s good, data is here, let&#039;s render it\n  return &lt;SomeComponentContent {...datasomething} /&gt;\n}\n\n如果我们请求数据失败了，就把错误状态被置为 true，然后为用户渲染出一个兜底页面，并带有一些附加信息，比如用于「联系我们」的电话号码。\n这种处理错误的方式非常简单，适用于那些简单的、可预测的 以及特定的用户场景，例如处理失败的 fetch 请求。\n但是，如果想要捕获到组件中所有可能发生的错误，我们将不得不面临一些挑战和限制。\n限制1：useEffect 不能被 try/catch 包裹\n如果我们用 try/catch 包裹 useEffect，它将无法工作：\ntry {\n  useEffect(() =&gt; {\n    throw new Error(&#039;Hulk smash!&#039;);\n  }, [])\n} catch(e) {\n  // useEffect throws, but this will never be called\n}\n这是因为 useEffect 在渲染后被异步调用，所以从 try/catch 的角度来看，诸事皆顺利。这点与 Promise 类似：如果我们不等待异步的执行结果，JavaScript 将继续进行其它业务，直到完成 Promise 后返回，并且只执行useEffect（或 Promise）的内部代码。try/catch 内的代码块将被执行，但在那时 try/catch 已经消失很久了。\n为了捕获 useEffect 内部的错误，try/catch 也应放在内部：\nuseEffect(() =&gt; {\n try {\n   throw new Error(&#039;Hulk smash!&#039;);\n } catch(e) {\n   // this one will be caught\n }\n}, [])\n\n这种方案适用于任何使用 useEffect 或其它异步场景。因此，我们不得不将 try/catch 拆分为多个块：每个 Hook 中都要一个 try/catch。\n限制2：try/catch 无法捕获子组件中的错误\ntry/catch 无法捕获子组件中发生的任何事情。很显然，我们不能这样做：\nconst Component = () =&gt; {\n  let child;\n\n  try {\n    child = &lt;Child /&gt;\n  } catch(e) {\n    // useless for catching errors inside Child component, won&#039;t be triggered\n  }\n\n  return child;\n}\n\n或者这样：\nconst Component = () =&gt; {\n  try {\n    return &lt;Child /&gt;\n  } catch(e) {\n    // still useless for catching errors inside Child component, won&#039;t be triggered\n  }\n}\n\n这是因为在我们写了 &lt;Child /&gt; 这个代码时，并没有真正的渲染这个组件。我们只是创建了一个组件的 Element，这仅仅是对组件做的定义。它作为一个包含 type、props 等必要信息的对象，接下来 React 会使用这些信息，并触发组件渲染。组件渲染时，try/catch 已经执行完毕。这个过程与 Promise 和 useEffect 类似。\n限制3：try/catch 无法在渲染期间设置 state\n如果我们要捕获 useEffect 以及 callback 之外的错误（即，在组件渲染期间发生的错误），那么处理它们的方法就不再是那么简单了：因为渲染期间不允许状态更新。\n例如，如果发生错误，像这样更新状态的代码只会导致无限循环的重新渲染：\nconst Component = () =&gt; {\n  const [hasError, setHasError] = useState(false);\n \n  try {\n    doSomethingComplicated();\n  } catch(e) {\n    // don&#039;t do that! will cause infinite loop in case of an error\n    // see codesandbox below with live example\n    setHasError(true);\n  }\n}\n当然，我们可以在这里返回针对错误的兜底内容，而不是设置状态：\nconst Component = () =&gt; {\n  try {\n    doSomethingComplicated();\n  } catch(e) {\n    // this allowed\n    return &lt;SomeErrorScreen /&gt;\n  }\n}\n但是，正如您所看到的那样，这么处理有点麻烦，并迫使我们以不同的方式处理同一组件中的错误：状态为 useEffect 和回调设置 state，以及直接返回兜底内容。\n// while it will work, it&#039;s super cumbersome and hard to maitain, don&#039;t do that\nconst SomeComponent = () =&gt; {\n  const [hasError, setHasError] = useState(false);\n \n  useEffect(() =&gt; {\n    try {\n      // do something like fetching some data\n    } catch(e) {\n      // can&#039;t just return in case of errors in useEffect or callbacks\n      // so have to use state\n      setHasError(true);\n    }\n  })\n \n  try {\n    // do something during render\n  } catch(e) {\n    // but here we can&#039;t use state, so have to return directly in case of an error\n    return &lt;SomeErrorScreen /&gt;;\n  }\n \n  // and still have to return in case of error state here\n  if (hasError) return &lt;SomeErrorScreen /&gt;\n \n  return &lt;SomeComponentContent {...datasomething} /&gt;\n}\n总结本节：如果我们在 React 中仅仅使用 try/catch 来处理错误，要么会错过大部分错误，要么会将每个组件变成一堆无法理解的代码，而且这些代码本身也可能会导致错误。\n幸运的是，还有另一种方法。\n错误边界（Error Boundaries）的使用\n为了突破上述限制，React 为我们提供了所谓的 “错误边界（Error Boundaries）”：错误边界是一种 React 组件，可以捕获发生在其子组件树任何位置的 JavaScript 错误，它以某种方式将常规组件转换为 try/catch 语句。错误边界可以捕获发生在整个子组件树的渲染期间、生命周期方法以及构造函数中的错误，但是它无法捕获其自身的错误。\n错误边界的典型用法，如下所示：\nconst Component = () =&gt; {\n  return (\n    &lt;ErrorBoundary&gt;\n      &lt;SomeChildComponent /&gt;\n      &lt;AnotherChildComponent /&gt;\n    &lt;/ErrorBoundary&gt;\n  )\n}\n在渲染过程中，如果这些组件中的任何一个或其子组件出现问题，都将捕获并处理该错误。\n但是 React 并未提供给我们组件本身，它只是给了我们一个实现它的工具。最简单的实现是这样的：\nclass ErrorBoundary extends React.Component {\n  constructor(props) {\n    super(props);\n    // initialize the error state\n    this.state = { hasError: false };\n  }\n\n  // if an error happened, set the state to true\n  static getDerivedStateFromError(error) {\n    return { hasError: true };\n  }\n\n  render() {\n    // if error happened, return a fallback component\n    if (this.state.hasError) {\n      return &lt;&gt;Oh no! Epic fail!&lt;/&gt;\n    }\n\n    return this.props.children;\n  }\n}\n\n我们创建了一个常规的类组件（这里只能用类组件，因为没有用于错误边界的 Hooks），并定义了getDerivedStateFromError 方法，该方法将组件转换为一个错误边界。\n捕获到错误并将错误信息发送到某个地方，这样可以通知到 on-call（值班）的人，也是一件很重要的事情。为此，错误边界为我们提供了 componentDidCatch 方法：\nclass ErrorBoundary extends React.Component {\n  // everything else stays the same\n \n  componentDidCatch(error, errorInfo) {\n    // send error to somewhere here\n    log(error, errorInfo);\n  }\n}\n在设置了错误边界之后，我们可以对它做任何我们想做的事情，和其他组件没什么两样。例如，我们可以将 fallback 作为 props 来提高它的可复用性：\nrender() {\n  // if error happened, return a fallback component\n  if (this.state.hasError) {\n    return this.props.fallback;\n  }\n \n  return this.props.children;\n}\n然后这样使用它：\nconst Component = () =&gt; {\n  return (\n    &lt;ErrorBoundary fallback={&lt;&gt;Oh no! Do something!&lt;/&gt;}&gt;\n      &lt;SomeChildComponent /&gt;\n      &lt;AnotherChildComponent /&gt;\n    &lt;/ErrorBoundary&gt;\n  )\n}\n或者我们可能需要其他东西，比如在单击按钮时重置 state，区分错误类型，或者将错误推到某个 context 中。\n然而，错误边界也不是万能的，它并不能捕获到所有的错误。\n错误边界的限制\n错误边界仅捕获到 React 生命周期中发生的错误。在生命周期之外发生的错误，比如 resolved promise、带有setTimeout 的异步代码、各种回调和事件处理程序，如果不额外做处理，就不会被捕获到。\nconst Component = () =&gt; {\n  useEffect(() =&gt; {\n    // this one will be caught by ErrorBoundary component\n    throw new Error(&#039;Destroy everything!&#039;);\n  }, [])\n \n  const onClick = () =&gt; {\n    // this error will just disappear into the void\n    throw new Error(&#039;Hulk smash!&#039;);\n  }\n \n  useEffect(() =&gt; {\n    // if this one fails, the error will also disappear\n    fetch(&#039;/bla&#039;)\n  }, [])\n \n  return &lt;button onClick={onClick}&gt;click me&lt;/button&gt;\n}\n \nconst ComponentWithBoundary = () =&gt; {\n  return (\n    &lt;ErrorBoundary&gt;\n      &lt;Component /&gt;\n    &lt;/ErrorBoundary&gt;\n  )\n}\n通常，要使用常规 try/catch 来处理此类错误。至少在这个场景中我们可以安全地（或多或少地）使用 state：处理事件的回调函数通常也是设置 state 的地方。所以从技术上讲，我们可以将两种方法结合起来，于是可以这样做：\nconst Component = () =&gt; {\n  const [hasError, setHasError] = useState(false);\n \n  // most of the errors in this component and in children will be caught by the ErrorBoundary\n \n  const onClick = () =&gt; {\n    try {\n      // this error will be caught by catch\n      throw new Error(&#039;Hulk smash!&#039;);\n    } catch(e) {\n      setHasError(true);\n    }\n  }\n \n  if (hasError) return &#039;something went wrong&#039;;\n \n  return &lt;button onClick={onClick}&gt;click me&lt;/button&gt;\n}\n \nconst ComponentWithBoundary = () =&gt; {\n  return (\n    &lt;ErrorBoundary fallback={&quot;Oh no! Something went wrong&quot;}&gt;\n      &lt;Component /&gt;\n    &lt;/ErrorBoundary&gt;\n  )\n}\n但是我们又回到了原点：每个组件都需要维持 “错误” state，更重要的是还要决定如何去处理它。\n当然，我们可以不在组件级别处理这些错误，而是通过 props 或 Context 将它们传播到具有错误边界的父组件。这样，我们只需要设置一个全局的 “fallback” 组件：\nconst Component = ({ onError }) =&gt; {\n  const onClick = () =&gt; {\n    try {\n      throw new Error(&#039;Hulk smash!&#039;);\n    } catch(e) {\n      // just call a prop instead of maintaining state here\n      onError();\n    }\n  }\n \n  return &lt;button onClick={onClick}&gt;click me&lt;/button&gt;\n}\n \nconst ComponentWithBoundary = () =&gt; {\n  const [hasError, setHasError] = useState();\n  const fallback = &quot;Oh no! Something went wrong&quot;;\n \n  if (hasError) return fallback;\n \n  return (\n    &lt;ErrorBoundary fallback={fallback}&gt;\n      &lt;Component onError={() =&gt; setHasError(true)} /&gt;\n    &lt;/ErrorBoundary&gt;\n  )\n}\n但是，这要额外写很多代码！我们必须为渲染树中的每个子组件执行同样的操作。更不用说，我们现在基本上维护了两个错误状态：父组件和错误边界。错误边界已经有了将错误传播到父组件的所有机制，而我们在这里做了重复的工作。\n难道我们不能用错误边界捕获到异步代码和事件处理函数中的错误吗？\n错误边界捕获异步错误\n有趣的是，我们可以用错误边界捕获到所有的错误！深受大家喜欢的 Dan Abramov 给我们分享了一个很酷的方法来实现这一点： Throwing Error from hook not caught in error boundary · Issue #14981 · facebook/react。\n这里的技巧是先用 try/catch 捕获这些错误，然后在 catch 语句内触发正常的 React 重新渲染，然后将这些错误重新抛出到重新渲染生命周期中。这样，错误边界可以像其它错误一样捕获它们。由于状态更新是触发重新渲染的方式，并且 setState 函数实际上可以接受函数 作为参数，因此该解决方案十分惊艳。\nconst Component = () =&gt; {\n  // create some random state that we&#039;ll use to throw errors\n  const [state, setState] = useState();\n \n  const onClick = () =&gt; {\n    try {\n      // something bad happened\n    } catch (e) {\n      // trigger state update, with updater function as an argument\n      setState(() =&gt; {\n        // re-throw this error within the updater function\n        // it will be triggered during state update\n        throw e;\n      })\n    }\n  }\n}\n最后，我们对这个方案做一些抽象，这样我们就不必在每个组件中创建随机 state。我们可以在这里发挥创意，封装一个 Hook，为我们提供一个异步错误抛出方法：\nconst useThrowAsyncError = () =&gt; {\n  const [state, setState] = useState();\n \n  return (error) =&gt; {\n    setState(() =&gt; throw error)\n  }\n}\n然后这样使用：\nconst Component = () =&gt; {\n  const throwAsyncError = useThrowAsyncError();\n \n  useEffect(() =&gt; {\n    fetch(&#039;/bla&#039;).then().catch((e) =&gt; {\n      // throw async error here!\n      throwAsyncError(e)\n    })\n  })\n}\n或者，我们可以为 callback 回调函数做一些额外处理，如下所示：\nconst useCallbackWithErrorHandling = (callback) =&gt; {\n  const [state, setState] = useState();\n \n  return (...args) =&gt; {\n    try {\n      callback(...args);\n    } catch(e) {\n      setState(() =&gt; throw e);\n    }\n  }\n}\n然后这样使用：\nconst Component = () =&gt; {\n  const onClick = () =&gt; {\n    // do something dangerous here\n  }\n \n  const onClickWithErrorHandler = useCallbackWithErrorHandling(onClick);\n \n  return &lt;button onClick={onClickWithErrorHandler}&gt;click me!&lt;/button&gt;\n}\n已有的工具 react-error-boundary\n对于那些讨厌重新发明轮子或者喜欢使用已有的工具类库的人来说，可以使用这个开源类库：GitHub - bvaughn/react-error-boundar。\n总结\n这就是本文的全部内容，希望从现在开始，如果你的应用程序发生了一些不好的事情，你将能够轻松优雅地处理这种情况。\n本文重点：\n\ntry/catch 不会捕获像 useEffect 这样的 Hooks 以及任何子组件内部的错误；\nErrorBoundary 可以捕获生命周期中的错误，但它不会捕获异步代码和事件处理函数中的错误；\n为了让 ErrorBoundary 捕获到这些错误，只需要先用 try/catch 捕获它们，然后将它们重新抛回到 React 生命周期；\n"},"front-end/react/react-hooks-ref":{"title":"react-hooks-ref","links":[],"tags":[],"content":"React ref 原理\n1. ref 的理解与使用\n对于 Ref 的理解，要从两个角度去分析：\n\nRef 对象的创建：使用 createRef 或 useRef 创建 Ref 对象\nReact 本身对 Ref 的处理：对于标签中的 ref 属性，React 是如何处理的\n\n1.1. ref 对象的创建\n1.1.1. createRef\n在类组件中，我们会通过 createRef 去创建一个 Ref 对象，其会被保存在类组件实例上，它的实现很简单：\n// packages/react/src/ReactCreateRef.js\nexport function createRef(): RefObject {  \n\tconst refObject = {    \n\t\tcurrent: null\n\t}  \n\treturn refObject\n}\n可以看到，就是创建了一个包含 current 属性的对象，仅此而已。\n1.1.2. useRef\n这也就意味着我们不能在函数组件中使用 createRef，因为每次函数组件渲染都是一次新的函数执行，每次执行 createRef 得到的都是一个新的对象，无法保留其原来的引用\n所以在函数组件中，我们会使用 useRef 创建 Ref 对象，React 会将 useRef 和函数组件对应的 fiber 对象关联，将 useRef 创建的 ref 对象挂载到对应的 fiber 对象上。\n这样一来每次函数组件执行，只要函数组件不被销毁，那么对应的 fiber 对象实例也会一直存在，所以 ref 也能够被保留下来。\n1.2. React 对标签中 ref 属性的处理\n首先要明确一个结论，在 React 中获取 DOM 元素或者组件实例并不是只能通过 ref 对象获取！！！\n也就是说并不是只能通过先调用 createRef 创建 ref 对象，然后将它赋值到要获取的元素或组件实例的 ref 属性上，实际上还有别的方式。\n\n只有类组件才有获取组件实例这一说法，函数组件没有实例，不能被 ref 标记，但是可以通过 forwardRef 结合 useImperativeHandle 给函数组件赋予 ref 标记的。\n\n1.2.1. string ref\n当我们给元素或类组件标签中的 ref 属性传递字符串时，能够在组件实例的 this.refs 中访问到：\nclass Child extends React.Component&lt;PropsWithChildren&gt; {  \n    render(): React.ReactNode {  \n        const { children } = this.props  \n \n        return (  \n            &lt;div&gt;  \n                &lt;p&gt;Child&lt;/p&gt;  \n                {children}  \n            &lt;/div&gt;  \n        )  \n    }  \n}  \n \n/** @description ref 属性传递字符串 */  \nclass RefDemo1 extends React.Component {  \n    logger = createLoggerWithScope(&#039;RefDemo1&#039;)  \n \n    componentDidMount(): void {  \n        this.logger.log(this.refs)  \n    }  \n \n    render(): React.ReactNode {  \n        return (  \n            &lt;&gt;  \n            &lt;div ref=&quot;refDemo1DOM&quot;&gt;ref 属性传递字符串获取 DOM 元素&lt;/div&gt;  \n            &lt;Child ref=&quot;refDemo1Component&quot;&gt;ref 属性传递字符串获取类组件实例&lt;/Child&gt;  \n            &lt;/&gt;  \n        )  \n    }  \n}\n\n这种方式已经被 React 官方废弃，尽量不要使用！\n\n1.2.2. callback ref\nref 属性传递函数时，会在 commit 阶段创建真实 DOM 时执行 ref 指定的函数，并将元素作为第一个参数传入，此时我们就可以利用它进行赋值以获取 DOM 元素或组件实例：\n/** \n * @description ref 属性传递函数 \n */\nclass RefDemo2 extends React.Component {\n  logger = createLoggerWithScope(&#039;RefDemo2&#039;)\n \n  refDemo2DOM: HTMLElement | null = null\n  refDemo2Component: Child | null = null\n \n  componentDidMount(): void {\n    this.logger.log(this.refDemo2DOM)\n    this.logger.log(this.refDemo2Component)\n  }\n \n  render(): React.ReactNode {\n    return (\n      &lt;&gt;\n        &lt;div ref={(el) =&gt; (this.refDemo2DOM = el)}&gt;\n          ref 属性传递函数获取 DOM 元素\n        &lt;/div&gt;\n \n        &lt;Child ref={(child) =&gt; (this.refDemo2Component = child)}&gt;\n          ref 属性传递函数获取类组件实例\n        &lt;/Child&gt;\n      &lt;/&gt;\n    )\n  }\n}\n1.2.3. object ref\n这种方式就是我们最常用的方式了，使用 createRef 或者 useRef 创建 Ref 对象，并将其传给标签的 ref 属性即可。\n这种方式获取到的 ref 需要先调用 current 属性才能获取到对应的 DOM 元素或组件实例：\n/** \n * @description  ref 属性传递对象 \n */\nclass RefDemo3 extends React.Component {\n  logger = createLoggerWithScope(&#039;RefDemo3&#039;)\n \n  refDemo3DOM = React.createRef&lt;HTMLDivElement&gt;()\n  refDemo3Component = React.createRef&lt;Child&gt;()\n \n  componentDidMount(): void {\n    this.logger.log(this.refDemo3DOM)\n    this.logger.log(this.refDemo3Component)\n  }\n \n  render(): React.ReactNode {\n    return (\n      &lt;&gt;\n        &lt;div ref={this.refDemo3DOM}&gt;ref 属性传递对象获取 DOM 元素&lt;/div&gt;\n \n        &lt;Child ref={this.refDemo3Component}&gt;\n          ref 属性传递对象获取类组件实例\n        &lt;/Child&gt;\n      &lt;/&gt;\n    )\n  }\n}\n2. ref 高阶用法\n2.1. forwardRef 转发 ref\n2.1.1. 跨层级获取\n想要在爷组件中通过在子组件中传递 ref 获取到孙组件的某个元素，也就是在爷组件中获取到了孙组件的元素，是一种跨层级获取\n/** \n * @description 孙组件 \n */\nconst Child: React.FC&lt;{ grandRef: LegacyRef&lt;HTMLDivElement&gt; }&gt; = (props) =&gt; {\n    const { grandRef } = props\n \n    return (\n        &lt;&gt;\n        &lt;p&gt;Child&lt;/p&gt;\n        &lt;div ref={grandRef}&gt;要获取的目标元素&lt;/div&gt;\n        &lt;/&gt;\n    )\n}\n \n/**\n * @description 父组件\n *\n * 第一个泛型参数是 ref 的类型\n * 第二个泛型参数是 props 的类型\n */\nconst Father = forwardRef&lt;HTMLDivElement, {}&gt;((props, ref) =&gt; {\n    return (\n        &lt;div&gt;\n            &lt;Child grandRef={ref} /&gt;\n        &lt;/div&gt;\n    )\n})\n \n/** @description 爷组件 */\nconst GrandFather: React.FC = () =&gt; {\n    let grandChildDiv: HTMLDivElement | null = null\n \n    useEffect(() =&gt; {\n        logger.log(grandChildDiv)\n    }, [])\n \n    return (\n        &lt;div&gt;\n            &lt;Father ref={(el) =&gt; (grandChildDiv = el)} /&gt;\n        &lt;/div&gt;\n    )\n}\n2.1.2. 合并转发自定义 ref\nforwardRef 不仅可以转发 ref 获取 DOM 元素和组件实例，还可以转发合并后的自定义 ref\n什么是“合并后的自定义 ref”呢？通过一个场景来看看就明白了。\n通过给 Foo 组件绑定 ref，获取多个内容，包括：\n\n子组件 Bar 的组件实例\nBar 组件中的 DOM 元素 button\n孙组件 Baz 的组件实例\n\n这种在一个 ref 里能够访问多个元素和实例的就是“合并后的自定义 ref”：\n/** \n * @description 自定义 ref 的类型 \n */\ninterface CustomRef {\n  bar: Bar\n  barButton: HTMLButtonElement\n  baz: Baz\n}\n \nclass Baz extends React.Component {\n  render(): React.ReactNode {\n    return &lt;div&gt;Baz&lt;/div&gt;\n  }\n}\n \nclass Bar extends React.Component&lt;{\n  customRef: ForwardedRef&lt;CustomRef&gt;\n}&gt; {\n  buttonEl: HTMLButtonElement | null = null\n  bazInstance: Baz | null = null\n \n  componentDidMount(): void {\n    const { customRef } = this.props\n \n    if (customRef) {\n      ;(customRef as MutableRefObject&lt;CustomRef&gt;).current = {\n        bar: this,\n        barButton: this.buttonEl!,\n        baz: this.bazInstance!,\n      }\n    }\n  }\n \n  render() {\n    return (\n      &lt;&gt;\n        &lt;button ref={(el) =&gt; (this.buttonEl = el)}&gt;Bar button&lt;/button&gt;\n        &lt;Baz ref={(instance) =&gt; (this.bazInstance = instance)} /&gt;\n      &lt;/&gt;\n    )\n  }\n}\nconst FowardRefBar = forwardRef&lt;CustomRef&gt;((props, ref) =&gt; (\n  &lt;Bar {...props} customRef={ref} /&gt;\n))\n \nconst Foo: React.FC = () =&gt; {\n  const customRef = useRef&lt;CustomRef&gt;(null)\n \n  useEffect(() =&gt; {\n    logger.log(customRef.current)\n  }, [])\n \n  return &lt;FowardRefBar ref={customRef} /&gt;\n}\n2.1.3. 高阶组件转发 ref\n如果我们在高阶组件中直接使用 ref，它会直接指向 WrapComponent：\nclass TestComponent extends React.Component {\n  render(): React.ReactNode {\n    return &lt;p&gt;TestComponent&lt;/p&gt;\n  }\n}\n \n/** \n * @description 不使用 forwardRef 转发 HOC 中的 ref \n */\nconst HOCWithoutForwardRef = (Component: typeof React.Component) =&gt; {\n  class WrapComponent extends React.Component {\n    render(): React.ReactNode {\n      return (\n        &lt;div&gt;\n          &lt;p&gt;WrapComponent&lt;/p&gt;\n          &lt;Component /&gt;\n        &lt;/div&gt;\n      )\n    }\n  }\n \n  return WrapComponent\n}\n \nconst HOCComponent1 = HOCWithoutForwardRef(TestComponent)\n \nconst RefHOCWithoutForwardRefDemo = () =&gt; {\n  const logger = createLoggerWithScope(&#039;RefHOCWithoutForwardRefDemo&#039;)\n  const wrapRef = useRef(null)\n \n  useEffect(() =&gt; {\n    // wrapRef 指向的是 WrapComponent 实例 而不是 HOCComponent1 实例\n    logger.log(wrapRef.current)\n  }, [])\n \n  return &lt;HOCComponent1 ref={wrapRef} /&gt;\n}\n如果我们希望 ref 指向的是被包裹的 TestComponent 而不是 HOC 内部的 WrapComponent 时该怎么办呢？\n这时候就可以用 forwardRef 进行转发了：\n/** @description HOC 中使用 forwardRef 转发 ref */\nconst HOCWithForwardRef = (Component: typeof React.Component) =&gt; {\n    class WrapComponent extends React.Component&lt;{\n        forwardedRef: LegacyRef&lt;any&gt;\n    }&gt; {\n        render(): React.ReactNode {\n            const { forwardedRef } = this.props\n \n            return (\n                &lt;div&gt;\n                    &lt;p&gt;WrapComponent&lt;/p&gt;\n                    &lt;Component ref={forwardedRef} /&gt;\n                &lt;/div&gt;\n            )\n        }\n}\n \nreturn React.forwardRef((props, ref) =&gt; (\n    &lt;WrapComponent forwardedRef={ref} {...props} /&gt;\n))\n}\n \nconst HOCComponent2 = HOCWithForwardRef(TestComponent)\nconst RefHOCWithForwardRefDemo = () =&gt; {\n    const logger = createLoggerWithScope(&#039;RefHOCWithForwardRefDemo&#039;)\n    const hocComponent2Ref = useRef(null)\n \n    useEffect(() =&gt; {\n        // hocComponent2Ref 指向的是 HOCComponent2 实例\n        logger.log(hocComponent2Ref.current)\n    }, [])\n \n    return &lt;HOCComponent2 ref={hocComponent2Ref} /&gt;\n}\n2.2. ref 实现组件通信\n一般我们可以通过父组件改变子组件 props 的方式触发子组件的更新渲染完成组件间通信。但如果我们不希望通过这种改变子组件 props 的方式的话还能有别的办法吗？\n可以通过 ref 获取子组件实例，然后子组件暴露出通信的方法，父组件调用该方法即可触发子组件的更新渲染。\n对于函数组件，由于其不存在组件实例这样的说法，但我们可以通过 useImperativeHandle 这个 hook 来指定 ref 引用时得到的属性和方法，下面我们分别用类组件和函数组件都实现一遍。\n2.2.1. 类组件 ref 暴露组件实例\n/**\n * 父 -&gt; 子 使用 ref\n * 子 -&gt; 父 使用 props 回调\n */\nclass CommunicationDemoFather extends React.Component&lt;\n  {},\n  CommunicationDemoFatherState\n&gt; {\n  state: Readonly&lt;CommunicationDemoFatherState&gt; = {\n    fatherToChildMessage: &#039;&#039;,\n    childToFatherMessage: &#039;&#039;,\n  }\n \n  childRef = React.createRef&lt;CommunicationDemoChild&gt;()\n \n  /** @description 提供给子组件修改父组件中的状态 */\n  handleChildToFather = (message: string) =&gt; {\n    this.setState((state) =&gt; ({\n      ...state,\n      childToFatherMessage: message,\n    }))\n  }\n \n  constructor(props: {}) {\n    super(props)\n    this.handleChildToFather = this.handleChildToFather.bind(this)\n  }\n \n  render(): React.ReactNode {\n    const { fatherToChildMessage, childToFatherMessage } = this.state\n \n    return (\n      &lt;div className={s.father}&gt;\n        &lt;h3&gt;父组件&lt;/h3&gt;\n        &lt;p&gt;子组件对我说：{childToFatherMessage}&lt;/p&gt;\n        &lt;div className={s.messageInputBox}&gt;\n          &lt;section&gt;\n            &lt;label htmlFor=&quot;to-father&quot;&gt;我对子组件说：&lt;/label&gt;\n            &lt;input\n              type=&quot;text&quot;\n              id=&quot;to-child&quot;\n              onChange={(e) =&gt;\n                this.setState((state) =&gt; ({\n                  ...state,\n                  fatherToChildMessage: e.target.value,\n                }))\n              }\n            /&gt;\n          &lt;/section&gt;\n \n          {/* 父 -&gt; 子 -- 使用 ref 完成组件通信 */}\n          &lt;button\n            onClick={() =&gt;\n              this.childRef.current(\n                fatherToChildMessage,\n              )\n            }\n          &gt;\n            发送\n          &lt;/button&gt;\n        &lt;/div&gt;\n \n        &lt;CommunicationDemoChild\n          ref={this.childRef}\n          onChildToFather={this.handleChildToFather}\n        /&gt;\n      &lt;/div&gt;\n    )\n  }\n}\n \ninterface CommunicationDemoChildProps {\n  onChildToFather: (message: string) =&gt; void\n}\n// 子组件自己维护状态 不依赖于父组件 props\ninterface CommunicationDemoChildState {\n  fatherToChildMessage: string\n  childToFatherMessage: string\n}\nclass CommunicationDemoChild extends React.Component&lt;\n  CommunicationDemoChildProps,\n  CommunicationDemoChildState\n&gt; {\n  state: Readonly&lt;CommunicationDemoChildState&gt; = {\n    fatherToChildMessage: &#039;&#039;,\n    childToFatherMessage: &#039;&#039;,\n  }\n \n  /** @description 暴露给父组件使用的 API -- 修改父到子的消息 fatherToChildMessage */\n  setFatherToChildMessage(message: string) {\n    this.setState((state) =&gt; ({ ...state, fatherToChildMessage: message }))\n  }\n \n  render(): React.ReactNode {\n    const { onChildToFather: emitChildToFather } = this.props\n    const { fatherToChildMessage, childToFatherMessage } = this.state\n \n    return (\n      &lt;div className={s.child}&gt;\n        &lt;h3&gt;子组件&lt;/h3&gt;\n        &lt;p&gt;父组件对我说：{fatherToChildMessage}&lt;/p&gt;\n        &lt;div className={s.messageInputBox}&gt;\n          &lt;section&gt;\n            &lt;label htmlFor=&quot;to-father&quot;&gt;我对父组件说：&lt;/label&gt;\n            &lt;input\n              type=&quot;text&quot;\n              id=&quot;to-father&quot;\n              onChange={(e) =&gt;\n                this.setState((state) =&gt; ({\n                  ...state,\n                  childToFatherMessage: e.target.value,\n                }))\n              }\n            /&gt;\n          &lt;/section&gt;\n \n          {/* 子 -&gt; 父 -- 使用 props 回调完成组件通信 */}\n          &lt;button onClick={() =&gt; emitChildToFather(childToFatherMessage)}&gt;\n            发送\n          &lt;/button&gt;\n        &lt;/div&gt;\n      &lt;/div&gt;\n    )\n  }\n}\n2.2.2. 函数组件 ref 暴露指定方法\n使用 useImperativeHandle hook 可以让我们指定 ref 引用时能获取到的属性和方法，个人认为相比类组件的 ref，使用这种方式能够更加好的控制组件想暴露给外界的 API。\n而不像类组件那样直接全部暴露出去，当然，如果你想在类组件中只暴露部分 API 的话，可以用前面说的合并转发自定义 ref 的方式去完成。\n接下来我们就用 useImperativeHandle hook 改造上面的类组件实现的 demo 吧！\ninterface ChildRef {\n  setFatherToChildMessage: (message: string) =&gt; void\n}\n \n/**\n * 父 -&gt; 子 使用 ref\n * 子 -&gt; 父 使用 props 回调\n */\nconst CommunicationDemoFunctionComponentFather: React.FC = () =&gt; {\n  const [fatherToChildMessage, setFatherToChildMessage] = useState(&#039;&#039;)\n  const [childToFatherMessage, setChildToFatherMessage] = useState(&#039;&#039;)\n \n  const childRef = useRef&lt;ChildRef&gt;(null)\n \n  return (\n    &lt;div className={s.father}&gt;\n      &lt;h3&gt;父组件&lt;/h3&gt;\n      &lt;p&gt;子组件对我说：{childToFatherMessage}&lt;/p&gt;\n      &lt;div className={s.messageInputBox}&gt;\n        &lt;section&gt;\n          &lt;label htmlFor=&quot;to-father&quot;&gt;我对子组件说：&lt;/label&gt;\n          &lt;input\n            type=&quot;text&quot;\n            id=&quot;to-child&quot;\n            onChange={(e) =&gt; setFatherToChildMessage(e.target.value)}\n          /&gt;\n        &lt;/section&gt;\n \n        {/* 父 -&gt; 子 -- 使用 ref 完成组件通信 */}\n        &lt;button\n          onClick={() =&gt;\n            childRef.current(fatherToChildMessage)\n          }\n        &gt;\n          发送\n        &lt;/button&gt;\n      &lt;/div&gt;\n \n      &lt;CommunicationDemoFunctionComponentChild\n        ref={childRef}\n        onChildToFather={(message) =&gt; setChildToFatherMessage(message)}\n      /&gt;\n    &lt;/div&gt;\n  )\n}\n \ninterface CommunicationDemoFunctionComponentChildProps {\n  onChildToFather: (message: string) =&gt; void\n}\nconst CommunicationDemoFunctionComponentChild = forwardRef&lt;\n  ChildRef,\n  CommunicationDemoFunctionComponentChildProps\n&gt;((props, ref) =&gt; {\n  const { onChildToFather: emitChildToFather } = props\n \n  // 子组件自己维护状态 不依赖于父组件 props\n  const [fatherToChildMessage, setFatherToChildMessage] = useState(&#039;&#039;)\n  const [childToFatherMessage, setChildToFatherMessage] = useState(&#039;&#039;)\n \n  // 定义暴露给外界的 API\n  useImperativeHandle(ref, () =&gt; ({ setFatherToChildMessage }))\n \n  return (\n    &lt;div className={s.child}&gt;\n      &lt;h3&gt;子组件&lt;/h3&gt;\n      &lt;p&gt;父组件对我说：{fatherToChildMessage}&lt;/p&gt;\n      &lt;div className={s.messageInputBox}&gt;\n        &lt;section&gt;\n          &lt;label htmlFor=&quot;to-father&quot;&gt;我对父组件说：&lt;/label&gt;\n          &lt;input\n            type=&quot;text&quot;\n            id=&quot;to-father&quot;\n            onChange={(e) =&gt; setChildToFatherMessage(e.target.value)}\n          /&gt;\n        &lt;/section&gt;\n \n        {/* 子 -&gt; 父 -- 使用 props 回调完成组件通信 */}\n        &lt;button onClick={() =&gt; emitChildToFather(childToFatherMessage)}&gt;\n          发送\n        &lt;/button&gt;\n      &lt;/div&gt;\n    &lt;/div&gt;\n  )\n})\n2.3. 函数组件缓存数据\n当我们在函数组件中如果数据更新后不希望视图改变，也就是说视图不依赖于这个数据，这个时候可以考虑用 useRef 对这种数据进行缓存。\n为什么 useRef 可以对数据进行缓存？还记得之前说的 useRef 在函数组件中的作用原理吗？\nReact 会将useRef和函数组件对应的 fiber 对象关联，将useRef` 创建的 ref 对象挂载到对应的 fiber 对象上，这样一来每次函数组件执行，只要函数组件不被销毁，那么对应的 fiber 对象实例也会一直存在，所以 ref 也能够被保留下来。\n利用这个特性，我们可以将数据放到 useRef 中，由于它在内存中一直都是同一块内存地址，所以无论如何变化都不会影响到视图的改变。\n\n一定要看清前提，只适用于与视图无关的数据！\n\n我们通过一个简单的 demo 来更清楚地体会下这个应用场景\n假设我有一个 todoList 列表，视图上会把这个列表渲染出来，并且有一个数据 activeTodoItem 是控制当前选中的是哪个 todoItem。\n点击 todoItem 会切换这个 activeTodoItem，但是并不需要在视图上作出任何变化，如果使用 useState 去保存 activeTodoItem，那么当其变化时会导致函数组件重新执行，视图重新渲染，但在这个场景中我们并不希望更新视图。\n相对的，我们希望这个 activeTodoItem 数据被缓存起来，不会随着视图的重新渲染而导致其作为 useState 的执行结果重新生成一遍，因此我们可以改成用 useRef 实现，因为其在内存中一直都是同一块内存地址，这样就不会因为它的改变而更新视图了。\n同理，在 useEffect 中如果使用到了 useRef 的数据，也不需要将其声明到 deps 数组中，因为其内存地址不会变化，所以每次在 useEffect 中获取到的 ref 数据一定是最新的。\ninterface TodoItem {\n  id: number\n  name: string\n}\n \nconst todoList: TodoItem[] = [\n  {\n    id: 1,\n    name: &#039;coding&#039;,\n  },\n  {\n    id: 2,\n    name: &#039;eating&#039;,\n  },\n  {\n    id: 3,\n    name: &#039;sleeping&#039;,\n  },\n  {\n    id: 4,\n    name: &#039;playing&#039;,\n  },\n]\n \nconst CacheDataWithRefDemo: React.FC = () =&gt; {\n  const activeTodoItem = useRef(todoList[0])\n \n  // 模拟 componentDidUpdate -- 如果改变 activeTodoItem 后组件没重新渲染，说明视图可以不依赖于 activeTodoItem 数据\n  useEffect(() =&gt; {\n    logger.log(&#039;检测组件是否有更新&#039;)\n  })\n \n  return (\n    &lt;div className={s.container}&gt;\n      &lt;div className={s.list}&gt;\n        {todoList.map((todoItem) =&gt; (\n          &lt;div\n            key={todoItem.id}\n            className={s.item}\n            onClick={() =&gt; (activeTodoItem.current = todoItem)}\n          &gt;\n            &lt;p&gt;{todoItem.name}&lt;/p&gt;\n          &lt;/div&gt;\n        ))}\n      &lt;/div&gt;\n \n      &lt;button onClick={() =&gt; logger.log(activeTodoItem.current)}&gt;\n        控制台输出最新的 activeTodoItem\n      &lt;/button&gt;\n    &lt;/div&gt;\n  )\n}\n3. 通过 callback ref 探究 ref 原理\n首先先看一个关于 callback ref 的小 Demo 来引出我们后续的内容：\ninterface RefDemo8State {\n  counter: number\n}\nclass RefDemo8 extends React.Component&lt;{}, RefDemo8State&gt; {\n  state: Readonly&lt;RefDemo8State&gt; = {\n    counter: 0,\n  }\n \n  el: HTMLDivElement | null = null\n \n  render(): React.ReactNode {\n    return (\n      &lt;div&gt;\n        &lt;div\n          ref={(el) =&gt; {\n            this.el = el\n            console.log(&#039;this.el -- &#039;, this.el)\n          }}\n        &gt;\n          ref element\n        &lt;/div&gt;\n        &lt;button\n          onClick={() =&gt; this.setState({ counter: this.state.counter + 1 })}\n        &gt;\n          add\n        &lt;/button&gt;\n      &lt;/div&gt;\n    )\n  }\n}\n为什么会执行两次？为什么第一次 this.el === null？为什么第二次又正常了？\n3.1. ref 的底层原理\n还记得 React 底层是有 render 阶段和 commit 阶段的吗？关于 ref 的处理逻辑就在 commit 阶段进行的\nReact 底层有两个关于 ref 的处理函数 — commitDetachRef 和 commitAttachRef。\n上面的 Demo 中 callback ref 执行了两次正是对应着这两次函数的调用，大致来讲可以理解为 commitDetachRef 在 DOM 更新之前执行，commitAttachRef 在 DOM 更新之后执行。\n这也就不难理解为什么会有上面 Demo 中的现象了，但我们还是要结合源码来看看，加深自己的理解。\n3.1.1. commitDetachRef\n// packages/react-reconciler/src/ReactFiberCommitWork.js\nfunction commitDetachRef(current: Fiber) {\n  // current 是已经调和完了的 fiber 对象\n  const currentRef = current.ref\n \n  if (currentRef !== null) {\n    if (typeof currentRef === &#039;function&#039;) {\n      // callback ref 和 string ref 执行时机\n      currentRef(null)\n    } else {\n      // object ref 处理时机\n      currentRef.current = null\n    }\n  }\n}\n可以看到，就是从 fiber 中取出 ref，然后根据 callback ref、string ref、object ref 的情况进行处理。\n并且也能看到 commitDetachRef 主要是将 ref 置为 null，这也就是为什么 RefDemo8 中第一次执行的 callback ref 中看到的 this.el 是 null 了。\n3.1.2. commitAttachRef\nfunction commitAttachRef(finishedWork: Fiber) {\n  const ref = finishedWork.ref\n  if (ref !== null) {\n    const instance = finishedWork.stateNode\n    let instanceToUse\n \n    // 处理 ref 来源\n    switch (finishedWork.tag) {\n      // HostComponent 代表 DOM 元素类型的 tag\n      case HostComponent:\n        instanceToUse = getPublicInstance(instance)\n        break\n \n      // 类组件使用组件实例\n      default:\n        instanceToUse = instance\n    }\n \n    if (typeof ref === &#039;function&#039;) {\n      // callback ref 和 string ref\n      ref(instanceToUse)\n    } else {\n      // object ref\n      ref.current = instanceToUse\n    }\n  }\n}\n3.2. 为什么 string ref 也是以函数的方式调用？\n从上面的核心源码中能看到，对于 callback ref 和 string ref，都是统一以函数的方式调用，将 null 或 instanceToUse 传入。\ncallback ref 这样做还能理解，但是为什么 string ref 也是这样处理呢？\n因为当 React 检测到是 string ref 时，会自动绑定一个函数用于处理 string ref，核心源码逻辑如下：\n// packages/react-reconciler/src/ReactChildFiber.js\n// 从元素上获取 ref\nconst mixedRef = element.ref\nconst stringRef = &#039;&#039; + mixedRef\nconst ref = function (value) {\n  // resolvedInst 就是组件实例\n  const refs = resolvedInst.refs\n \n  if (value === null) {\n    delete refs[stringRef]\n  } else {\n    refs[stringRef] = value\n  }\n}\n这样一来 string ref 也变成了一个函数了，从而可以在 commitDetachRef 和 commitAttachRef 中被执行，并且也能印证为什么 string ref 会在类组件实例的 refs 属性中获取到。\n3.3. ref 的执行时机\n为什么在 RefDemo8 中我们每次点击按钮时都会触发 commitDetachRef 和 commitAttachRef 呢？这就需要聊聊 ref 的执行时机了，而从上文也能够了解到，ref 底层实际上是由 commitDetachRef 和 commitAttachRef 在处理核心逻辑。\n那么我们就得来看看这两个函数的执行时机才能行：\n3.3.1. commitDetachRef 执行时机\n// packages/react-reconciler/src/ReactFiberCommitWork.js\nfunction commitMutationEffectsOnFiber(\n  finishedWork: Fiber,\n  root: FiberRoot,\n  lanes: Lanes,\n) {\n  const current = finishedWork.alternate\n  const flags = finishedWork.flags\n \n  if (flags &amp; Ref) {\n    if (current !== null) {\n      // 也就是 commitDetachRef\n      safelyDetachRef(current, current.return)\n    }\n  }\n}\n3.3.2. commitAttachRef 执行时机\n// packages/react-reconciler/src/ReactFiberCommitWork.js\nfunction commitLayoutEffectOnFiber(\n  finishedRoot: FiberRoot,\n  current: Fiber | null,\n  finishedWork: Fiber,\n  committedLanes: Lanes,\n) {\n  const flags = finishedWork.flags\n \n  if (flags &amp; Ref) {\n    safelyAttachRef(finishedWork, finishedWork.return)\n  }\n}\n3.3.3. fiber 何时打上 Ref tag?\n可以看到，只有当 fiber 被打上了 Ref 这个 flag tag 时才会去执行 commitDetachRef/commitAttachRef。\n那么什么时候会标记 Ref tag 呢？\n// packages/react-reconciler/src/ReactFiberBeginWork.js\nfunction markRef(current: Fiber | null, workInProgress: Fiber) {\n  const ref = workInProgress.ref\n \n  if (\n    // current === null 意味着是初次挂载，fiber 首次调和时会打上 Ref tag\n    (current === null &amp;&amp; ref !== null) ||\n    // current !== null 意味着是更新，此时需要 ref 发生了变化才会打上 Ref tag\n    (current !== null &amp;&amp; current.ref !== ref)\n  ) {\n    // Schedule a Ref effect\n    workInProgress.flags |= Ref\n  }\n}\n3.3.4. 为什么每次点击按钮 callback ref 都会执行？\n那么现在再回过头来思考 RefDemo8 中为什么每次点击按钮都会执行 commitDetachRef 和 commitAttachRef 呢？\n注意我们使用 callback ref 的时候是如何使用的：\n&lt;div\n  ref={(el) =&gt; {\n    this.el = el\n    console.log(&#039;this.el -- &#039;, this.el)\n  }}\n&gt;\n  ref element\n&lt;/div&gt;\n是直接声明了一个箭头函数，这样的方式会导致每次渲染这个 div 元素时，给 ref 赋值的都是一个新的箭头函数，尽管函数的内容是一样的，但内存地址不同，因而 current.ref !== ref 这个判断条件会成立，从而每次都会触发更新。\n3.3.5. 如何解决？\n那么要如何解决这个问题呢？既然我们已经知道了问题的原因，那么就好说了，只要让每次赋值给 ref 的函数都是同一个就可以了呗~\nconst logger = createLoggerWithScope(&#039;RefDemo9&#039;)\n \ninterface RefDemo9Props {}\ninterface RefDemo9State {\n  counter: number\n}\nclass RefDemo9 extends React.Component&lt;RefDemo9Props, RefDemo9State&gt; {\n  state: Readonly&lt;RefDemo9State&gt; = {\n    counter: 0,\n  }\n \n  el: HTMLDivElement | null = null\n \n  constructor(props: RefDemo9Props) {\n    super(props)\n    this.setElRef = this.setElRef.bind(this)\n  }\n \n  setElRef(el: HTMLDivElement | null) {\n    this.el = el\n    logger.log(&#039;this.el -- &#039;, this.el)\n  }\n \n  render(): React.ReactNode {\n    return (\n      &lt;div&gt;\n        &lt;div ref={this.setElRef}&gt;ref element&lt;/div&gt;\n        &lt;button\n          onClick={() =&gt; this.setState({ counter: this.state.counter + 1 })}\n        &gt;\n          add\n        &lt;/button&gt;\n      &lt;/div&gt;\n    )\n  }\n}\n这样就完美解决啦，既修复了 bug，又搞懂了 ref 的底层原理，一举两得！\n4. 总结\n本篇文章我们学习到了：\n\nref 的理解与使用，包括如何创建 ref 对象，以及除了 object ref 之外的 string ref 和 callback ref 的方式去使用 ref；\nref 的高阶用法，包括 forwardRef 转发 ref、ref 实现组件通信、利用 ref 在函数组件中缓存数据等；\n通过一个简单的 callback ref 的 Demo 研究 ref 的底层原理，string ref 为何也是以函数的方式被调用，以及 ref 的执行时机；\n"},"front-end/react/react-hooks-review":{"title":"react-hooks-review","links":[],"tags":[],"content":"\n搞懂这12个Hooks，保证让你玩转React\n\n自定义Hooks是什么？\nreact-hooks 是 React16.8  以后新增的钩子API，目的是增加代码的可复用性、逻辑性，最主要的是解决了函数式组件无状态的问题，这样既保留了函数式的简单，又解决了没有数据管理状态的缺陷；\n那么什么是自定义hooks呢？\n自定义hooks 是在react-hooks基础上的一个扩展，可以根据业务、需求去制定相应的hooks，将常用的逻辑进行封装，从而具备复用性；\n如何设计一个自定义Hooks\nhooks本质上是一个函数，而这个函数主要就是逻辑复用，我们首先要知道一件事，hooks的驱动条件是什么？\n其实就是 props 的修改，useState、useReducer 的使用是无状态组件更新的条件，从而驱动自定义 hooks；\n通用模式\n自定义 hooks 的名称是以 use 开头，我们设计为：\nconst [ xxx, ...] = useXXX(arg1, arg2...)\n简单的小例子：usePow\n我们先写一个简单的小例子来了解下自定义 hooks：\n// usePow.ts\nconst Index = (list: number[]) =&gt; {\n    return list.map((item: number) =&gt; {\n        console.log(1)\n        return Math.pow(item, 2)\n    })\n}\n \nexport default Index;\n \n// index.tsx\nimport { Button } from &#039;antd-mobile&#039;;\nimport React,{ useState } from &#039;react&#039;;\nimport { usePow } from &#039;@/components&#039;;\n \nconst Index:React.FC&lt;any&gt; = (props)=&gt; {\n    const [flag, setFlag] = useState&lt;boolean&gt;(true)\n    const data = usePow([1, 2, 3])\n \n    return (\n        &lt;div&gt;\n            &lt;div&gt;数字：{JSON.stringify(data)}&lt;/div&gt;\n            &lt;Button color=&#039;primary&#039; onClick={() =&gt; {setFlag(v =&gt; !v)}}&gt;切换&lt;/Button&gt;\n            &lt;div&gt;切换状态：{JSON.stringify(flag)}&lt;/div&gt;\n        &lt;/div&gt;\n    );\n}\n \nexport default Index;\n我们简单的写了个 usePow，我们通过 usePow 给所传入的数字平方, 用切换状态的按钮表示函数内部的状态；\n当点击按钮时，会连续输出打印两次，因为setFlag触发了一次更新，usePow返回的数据变动也会引发一次页面更新；\n这样明显增加了性能开销，我们的理想状态肯定不希望做无关的渲染，所以我们做自定义 hooks的时候一定要注意，需要减少性能开销，我们为组件加入 useMemo试试：\nimport { useMemo } from &#039;react&#039;;\n \nconst Index = (list: number[]) =&gt; {\n    return useMemo(() =&gt; list.map((item:number) =&gt; {\n        console.log(1)\n        return Math.pow(item, 2)\n    }), []) \n}\nexport default Index;\n发现此时只在初次渲染时打印了，之后点击按钮已经没有打印了；完美解决了这个问题，所以要非常注意一点，一个好用的自定义hooks,一定要配合useMemo、useCallback等 Api 一起使用。\n玩转React Hooks\n在上述中我们讲了用 useMemo来处理无关的渲染，接下来我们一起来看看React Hooks的这些钩子的妙用（这里建议先熟知、并使用对应的React Hooks，才能造出好的钩子）\nuseMemo\n当一个父组件中调用了一个子组件的时候，父组件的 state 发生变化，会导致父组件更新，而子组件虽然没有发生改变，但也会进行更新。\n简单的理解下，当一个页面内容非常复杂，模块非常多的时候，函数式组件会从头更新到尾，只要一处改变，所有的模块都会进行刷新，这种情况显然是没有必要的。\n我们理想的状态是各个模块只进行自己的更新，不要相互去影响，那么此时用useMemo是最佳的解决方案。\n这里要尤其注意一点，只要父组件的状态更新，无论有没有对子组件进行操作，子组件都会进行更新，useMemo就是为了防止这点而出现的；\n在讲 useMemo 之前，我们先说说memo，memo的作用是结合了pureComponent纯组件和componentShouldUpdate功能，会对传入的 props 进行一次对比，然后根据第二个函数返回值来进一步判断哪些props需要更新。（具体使用会在下文讲到～）\nuseMemo与memo的理念上差不多，都是判断是否满足当前的限定条件来决定是否执行callback函数，而useMemo的第二个参数是一个数组，通过这个数组来判定是否更新回掉函数\n这种方式可以运用在元素、组件、上下文中，尤其是利用在数组上，先看一个例子：\nuseMemo(() =&gt; (\n    &lt;div&gt;\n        { list.map((item, index) =&gt; (&lt;p key={index}&gt;{item.name}&lt;p/&gt;)) }\n    &lt;/div&gt;\n), [list])\n从上面我们看出 useMemo只有在list发生变化的时候才会进行渲染，从而减少了不必要的开销；\n总结一下useMemo的好处：\n\n可以减少不必要的循环和不必要的渲染；\n可以减少子组件的渲染次数；\n通过特定的依赖进行更新，可以避免很多不必要的开销，但要注意，有时候在配合 useState 拿不到最新的值，这种情况可以考虑使用 useRef解决；\n\nuseCallback\nuseCallback与useMemo极其类似，可以说是一模一样，唯一不同的是useMemo返回的是函数运行的结果，而useCallback返回的是函数；\n注意：这个函数是父组件传递子组件的一个函数，防止做无关的刷新，其次，这个组件必须配合memo，否则不但不会提升性能，还有可能降低性能；\nimport React, { useState, useCallback } from &#039;react&#039;;\nimport { Button } from &#039;antd-mobile&#039;;\n \nconst MockMemo: React.FC&lt;any&gt; = () =&gt; {\n    const [count,setCount] = useState(0)\n    const [show,setShow] = useState(true)\n \n    const  add = useCallback(()=&gt;{ setCount(count + 1) }, [count])\n \n    return (\n        &lt;div&gt;\n            &lt;div style={{display: &#039;flex&#039;, justifyContent: &#039;flex-start&#039;}}&gt;\n                &lt;TestButton title=&quot;普通点击&quot; onClick={() =&gt; setCount(count + 1) }/&gt;\n                &lt;TestButton title=&quot;useCallback点击&quot; onClick={add}/&gt;\n            &lt;/div&gt;\n            &lt;div style={{marginTop: 20}}&gt;count: {count}&lt;/div&gt;\n            &lt;Button onClick={() =&gt; {setShow(!show)}}&gt; 切换&lt;/Button&gt;\n        &lt;/div&gt;\n    )\n}\n \nconst TestButton = React.memo((props:any)=&gt;{\n    console.log(props.title)\n    return &lt;Button \n               color=&#039;primary&#039; \n               onClick={props.onClick} \n               style={props.title === &#039;useCallback点击&#039; \n            \t\t\t? { marginLeft: 20 } \n        \t\t\t\t: undefined }\n           &gt;{props.title}\n    &lt;/Button&gt;\n})\n \nexport default MockMemo;\n我们可以看到，当点击切换按钮的时候，没有经过 useCallback 封装的函数会再次刷新，而进过过 useCallback包裹的函数不会被再次刷新；\nuseRef\nuseRef 可以获取当前元素的所有属性，并且返回一个可变的 ref 对象，并且这个对象只有 current 属性，可设置 initialValue；\n获取属性值\n获取Dom元素对应的属性值，我们先看个案例：\nimport React, { useState, useRef } from &quot;react&quot;;\n \nconst Index = () =&gt; {\n  const scrollRef = useRef(null);\n  const [clientHeight, setClientHeight] = useState(0);\n  const [scrollTop, setScrollTop] = useState(0);\n  const [scrollHeight, setScrollHeight] = useState(0);\n \n  const onScroll = () =&gt; {\n    if (scrollRef?.current) {\n      let clientHeight = scrollRef?.current.clientHeight; //可视区域高度\n      let scrollTop = scrollRef?.current.scrollTop; //滚动条滚动高度\n      let scrollHeight = scrollRef?.current.scrollHeight; //滚动内容高度\n      setClientHeight(clientHeight);\n      setScrollTop(scrollTop);\n      setScrollHeight(scrollHeight);\n    }\n  };\n \n  return (\n    &lt;div&gt;\n      &lt;div&gt;\n        &lt;p&gt;可视区域高度：{clientHeight}&lt;/p&gt;\n        &lt;p&gt;滚动条滚动高度：{scrollTop}&lt;/p&gt;\n        &lt;p&gt;滚动内容高度：{scrollHeight}&lt;/p&gt;\n      &lt;/div&gt;\n      &lt;div\n        style={{ height: 200, overflowY: &quot;auto&quot; }}\n        ref={scrollRef}\n        onScroll={onScroll}\n      &gt;\n        &lt;div style={{ height: 2000 }}&gt;&lt;/div&gt;\n      &lt;/div&gt;\n    &lt;/div&gt;\n  );\n};\n \nexport default Index;\n从上述可知，我们可以通过useRef来获取对应元素的相关属性，以此来做一些操作；\n缓存数据\n除了获取对应的属性值外，useRef 还有一点比较重要的特性，那就是 缓存数据；\n上述讲到我们封装一个合格的自定义 hooks 的时候需要结合useMemo、useCallback等 Api，但我们控制变量的值用 useState 有可能会导致拿到的是旧值，并且如果他们更新会带来整个组件重新执行，这种情况下，我们使用useRef将会是一个非常不错的选择\n在react-redux的源码中，在 hooks 推出后，react-redux用大量的useMemo 重做了 Provide 等核心模块，其中就是运用 useRef 来缓存数据，并且所运用的 useRef() 没有一个是绑定在 dom 元素上的，都是做数据缓存用的；\n可以简单的来看一下：\n// 缓存数据\n// react-redux 用userRef 来缓存 merge 之后的 props\nconst lastChildProps = useRef() \n \n// lastWrapperProps 用 useRef 来存放组件真正的 props 信息 \nconst lastWrapperProps = useRef(wrapperProps) \n \n// 是否储存 props 是否处于正在更新状态 \nconst renderIsScheduled = useRef(false)\n \n// 更新数据\nfunction captureWrapperProps( \n     lastWrapperProps, \n     lastChildProps, \n     renderIsScheduled, \n     wrapperProps, \n     actualChildProps, \n     childPropsFromStoreUpdate, \n     notifyNestedSubs \n) { \n    lastWrapperProps.current = wrapperProps \n    lastChildProps.current = actualChildProps \n    renderIsScheduled.current = false \n}\n我们看到 react-redux 用重新赋值的方法，改变了缓存的数据源，减少了不必要的更新，如过采取useState势必会重新渲染；\nuseLatest\n经过上面的讲解我们知道useRef 可以拿到最新值，我们可以进行简单的封装，这样做的好处是：可以随时确保获取的是最新值，并且也可以解决闭包问题；\nimport { useRef } from &#039;react&#039;;\n \nconst useLatest = &lt;T&gt;(value: T) =&gt; {\n    const ref = useRef(value)\n    ref.current = value\n \n    return ref\n};\n \nexport default useLatest;\nuseCreation\nuseCreation ：是 useMemo 或 useRef的替代品。换言之，useCreation这个钩子增强了 useMemo 和 useRef，让这个钩子可以替换这两个钩子。（来自ahooks-useCreation）\n\nuseMemo的值不一定是最新的值，但useCreation可以保证拿到的值一定是最新的值；\n对于复杂常量的创建，useRef 容易出现潜在的的性能隐患，但useCreation可以避免；\n\n这里的性能隐患是指：\n// 每次重渲染，都会执行实例化 Subject 的过程，即便这个实例立刻就被扔掉了\nconst a = useRef(new Subject()) \n \n// 通过 factory 函数，可以避免性能隐患\nconst b = useCreation(() =&gt; new Subject(), []) \n接下来我们来看看如何封装一个useCreation，首先我们要明白以下三点：\n\n第一点：先确定参数，useCreation 的参数与 useMemo 的一致，第一个参数是函数，第二个参数参数是可变的数组；\n第二点：我们的值要保存在 useRef 中，这样可以将值缓存，从而减少无关的刷新；\n第三点：更新值的判断，怎么通过第二个参数来判断是否更新 useRef里的值；\n\n明白了一上三点我们就可以自己实现一个useCreation：\nimport { useRef } from &#039;react&#039;;\nimport type { DependencyList } from &#039;react&#039;;\n \nconst depsAreSame = (oldDeps: DependencyList, deps: DependencyList): boolean =&gt; {\n  if(oldDeps === deps) return true\n  \n  for(let i = 0; i &lt; oldDeps.length; i++) {\n    // 判断两个值是否是同一个值\n    if(!Object.is(oldDeps[i], deps[i])) return false\n  }\n  return true\n}\n \nconst useCreation = &lt;T&gt;(fn:() =&gt; T, deps: DependencyList)=&gt; {\n  const { current } = useRef({ \n    deps,\n    obj:  undefined as undefined | T ,\n    initialized: false\n  })\n \n  if(current.initialized === false || !depsAreSame(current.deps, deps)) {\n    current.deps = deps;\n    current.obj = fn();\n    current.initialized = true;\n  }\n \n  return current.obj as T\n} \n \nexport default useCreation;\n在useRef判断是否更新值通过initialized 和 depsAreSame来判断，其中depsAreSame通过存储在 useRef下的deps（旧值） 和新传入的 deps（新值）来做对比，判断两数组的数据是否一致，来确定是否更新；\n接下来我们写个小例子，来验证下 useCreation是否能满足我们的要求：\nimport React, { useState } from &#039;react&#039;;\nimport { Button } from &#039;antd-mobile&#039;;\nimport { useCreation } from &#039;@/components&#039;;\n \nconst Index: React.FC&lt;any&gt; = () =&gt; {\n    const [_, setFlag] = useState&lt;boolean&gt;(false)\n \n    const getNowData = () =&gt; {\n        return Math.random()\n    }\n \n    const nowData = useCreation(() =&gt; getNowData(), []);\n \n    return (\n        &lt;div style={{padding: 50}}&gt;\n            &lt;div&gt;正常的函数：{getNowData()}&lt;/div&gt;\n            &lt;div&gt;useCreation包裹后的：{nowData}&lt;/div&gt;\n            &lt;Button color=&#039;primary&#039; onClick={() =&gt; {setFlag(v =&gt; !v)}}&gt; 渲染&lt;/Button&gt;\n        &lt;/div&gt;\n    )\n}\n \nexport default Index;\n我们可以看到，当我们做无关的state改变的时候，正常的函数也会刷新，但useCreation没有刷新，从而增强了渲染的性能；\nuseEffect\nuseEffect相信各位小伙伴已经用的熟的不能再熟了，我们可以使用useEffect来模拟下class的componentDidMount和componentWillUnmount的功能。\nuseMount\n这个钩子不必多说，只是简化了使用useEffect的第二个参数：\nimport { useEffect } from &#039;react&#039;;\n \nconst useMount = (fn: () =&gt; void) =&gt; {\n \n    useEffect(() =&gt; {\n        fn?.();\n    }, []);\n};\n \nexport default useMount;\nuseUnmount\n这个需要注意一个点，就是使用useRef来确保所传入的函数为最新的状态，所以可以结合上述讲的useLatest 结合使用：\nimport { useEffect, useRef } from &#039;react&#039;;\n \nconst useUnmount = (fn: () =&gt; void) =&gt; {\n    const ref = useRef(fn);\n    ref.current = fn;\n    useEffect(\n        () =&gt; () =&gt; {\n            fn?.()\n        },\n        [],\n    );\n};\n \nexport default useUnmount;\n结合useMount和useUnmount做个小例子：\nimport { Button, Toast } from &#039;antd-mobile&#039;;\nimport React,{ useState } from &#039;react&#039;;\nimport { useMount, useUnmount } from &#039;@/components&#039;;\n \nconst Child = () =&gt; {\n \n    useMount(() =&gt; {\n        Toast.show(&#039;首次渲染&#039;)\n    });\n \n    useUnmount(() =&gt; {\n        Toast.show(&#039;组件已卸载&#039;)\n    })\n \n    return &lt;div&gt;你好，我是子组件&lt;/div&gt;\n}\n \nconst Index:React.FC&lt;any&gt; = (props)=&gt; {\n    const [flag, setFlag] = useState&lt;boolean&gt;(false)\n \n    return (\n        &lt;div style={{padding: 50}}&gt;\n            &lt;Button color=&#039;primary&#039; onClick={() =&gt; {setFlag(v =&gt; !v)}}&gt;切换 {flag ? &#039;unmount&#039; : &#039;mount&#039;}&lt;/Button&gt;\n            {flag &amp;&amp; &lt;Child /&gt;}\n        &lt;/div&gt;\n    );\n}\n \nexport default Index;\nuseUpdate\n有的时候我们需要组件强制更新，这个时候就可以使用这个钩子：\nimport { useCallback, useState } from &#039;react&#039;;\n \nconst useUpdate = () =&gt; {\n    const [, setState] = useState({});\n \n    return useCallback(() =&gt; setState({}), []);\n};\n \nexport default useUpdate;\n \n//示例：\nimport { Button } from &#039;antd-mobile&#039;;\nimport React from &#039;react&#039;;\nimport { useUpdate } from &#039;@/components&#039;;\n \n \nconst Index:React.FC&lt;any&gt; = (props)=&gt; {\n    const update = useUpdate();\n \n    return (\n        &lt;div style={{padding: 50}}&gt;\n            &lt;div&gt;时间：{Date.now()}&lt;/div&gt;\n            &lt;Button color=&#039;primary&#039; onClick={update}&gt;更新时间&lt;/Button&gt;\n        &lt;/div&gt;\n    );\n}\n \nexport default Index;\n案例\n1. useReactive\nuseReactive: 一种具备响应式的useState；我们知道用useState可以定义变量其格式为：\nconst [count, setCount] = useState&lt;number&gt;(0)\n通过setCount来设置，count来获取，使用这种方式才能够渲染视图\n来看看正常的操作，像这样 let count = 0; count = 7 ，此时count的值就是 7，也就是说数据是响应式的；\n那么我们可不可以将 useState也写成响应式的呢？我可以自由设置count的值，并且可以随时获取到count的最新值，而不是通过setCount来设置。\n我们来想想怎么去实现一个具备 响应式 特点的 useState 也就是 useRective，提出以下疑问，感兴趣的，可以先自行思考一下：\n\n这个钩子的出入参该怎么设定？\n如何将数据制作成响应式（毕竟普通的操作无法刷新视图）？\n如何使用TS去写，完善其类型？\n如何更好的去优化？\n\n分析\n以上四个小问题，最关键的就是第二个，我们如何将数据弄成响应式，想要弄成响应式，就必须监听到值的变化，在做出更改，也就是说，我们对这个数进行操作的时候，要进行相应的拦截，这时就需要ES6的一个知识点：Proxy\nProxy：接受的参数是对象，所以第一个问题也解决了，入参就为对象。那么如何去刷新视图呢？这里就使用上述的useUpdate来强制刷新，使数据更改。\n至于优化这一块，使用上文说的useCreation就好，再配合useRef来放initialState即可；\nimport { useRef } from &#039;react&#039;;\nimport { useUpdate, useCreation } from &#039;./hooks&#039;;\n \nconst observer = &lt;T extends Record&lt;string, any&gt;&gt;(initialVal: T, callback: () =&gt; void): T =&gt; {\n const proxy = new Proxy&lt;T&gt;(initialVal, {\n    get(target, key, receiver) {\n      const res = Reflect.get(target, key, receiver);\n      return typeof res === &#039;object&#039; ? observer(res, callback) : Reflect.get(target, key);\n    },\n    set(target, key, val) {\n      const ret = Reflect.set(target, key, val);\n      callback();\n      return ret;\n    },\n  });\n \n  return proxy;\n}\n \nconst useReactive = &lt;T extends Record&lt;string, any&gt;&gt;(initialState: T):T =&gt; {\n  const ref = useRef&lt;T&gt;(initialState);\n  const update = useUpdate();\n \n  const state = useCreation(() =&gt; {\n    return observer(ref.current, () =&gt; {\n      update();\n    });\n  }, []);\n \n  return state\n};\n \nexport default useReactive;\n这里先说下TS，因为我们不知道会传递什么类型的initialState所以在这需要使用泛型，我们接受的参数是对象，可就是 key-value 的形式，其中 key 为 string，value 可以是 任意类型，所以我们使用 Record&lt;string, any&gt;；\n再来说下拦截这块，我们只需要拦截设置（set） 和 获取（get） 即可，其中：\n\n设置这块，需要改变视图，也就是说需要使用 useUpdate 来强制刷新；\n获取这块，需要判断其是否为对象，是的话继续递归，不是的话返回就行；\n\n验证\n接下来我们来验证一下我们写的 useReactive，我们将以 字符串、数字、布尔、数组、函数、计算属性几个方面去验证一下：\nimport { Button } from &#039;antd-mobile&#039;;\nimport React from &#039;react&#039;;\nimport { useReactive } from &#039;@/components&#039;\n \nconst Index:React.FC&lt;any&gt; = (props)=&gt; {\n \n    const state = useReactive&lt;any&gt;({\n        count: 0,\n        name: &#039;小杜杜&#039;,\n        flag: true,\n        arr: [],\n        bugs: [&#039;小杜杜&#039;, &#039;react&#039;, &#039;hook&#039;],\n        addBug(bug:string) {\n            this.bugs.push(bug);\n        },\n        get bugsCount() {\n            return this.bugs.length;\n        },\n    })\n \n    return (\n        &lt;div style={{padding: 20}}&gt;\n            &lt;div style={{fontWeight: &#039;bold&#039;}}&gt;基本使用：&lt;/div&gt;\n            &lt;div style={{marginTop: 8}}&gt; 对数字进行操作：{state.count}&lt;/div&gt;\n            &lt;div style={{margin: &#039;8px 0&#039;, display: &#039;flex&#039;,justifyContent: &#039;flex-start&#039;}}&gt;\n                &lt;Button color=&#039;primary&#039; onClick={() =&gt; state.count++ } &gt;加1&lt;/Button&gt;\n                &lt;Button color=&#039;primary&#039; style={{marginLeft: 8}} onClick={() =&gt; state.count-- } &gt;减1&lt;/Button&gt;\n                &lt;Button color=&#039;primary&#039; style={{marginLeft: 8}} onClick={() =&gt; state.count = 7 } &gt;设置为7&lt;/Button&gt;\n            &lt;/div&gt;\n            &lt;div style={{marginTop: 8}}&gt; 对字符串进行操作：{state.name}&lt;/div&gt;\n            &lt;div style={{margin: &#039;8px 0&#039;, display: &#039;flex&#039;,justifyContent: &#039;flex-start&#039;}}&gt;\n                &lt;Button color=&#039;primary&#039; onClick={() =&gt; state.name = &#039;小杜杜&#039; } &gt;设置为小杜杜&lt;/Button&gt;\n                &lt;Button color=&#039;primary&#039; style={{marginLeft: 8}} onClick={() =&gt; state.name = &#039;Domesy&#039;} &gt;设置为Domesy&lt;/Button&gt;\n            &lt;/div&gt;\n            &lt;div style={{marginTop: 8}}&gt; 对布尔值进行操作：{JSON.stringify(state.flag)}&lt;/div&gt;\n            &lt;div style={{margin: &#039;8px 0&#039;, display: &#039;flex&#039;,justifyContent: &#039;flex-start&#039;}}&gt;\n                &lt;Button color=&#039;primary&#039; onClick={() =&gt; state.flag = !state.flag } &gt;切换状态&lt;/Button&gt;\n            &lt;/div&gt;\n            &lt;div style={{marginTop: 8}}&gt; 对数组进行操作：{JSON.stringify(state.arr)}&lt;/div&gt;\n            &lt;div style={{margin: &#039;8px 0&#039;, display: &#039;flex&#039;,justifyContent: &#039;flex-start&#039;}}&gt;\n                &lt;Button color=&quot;primary&quot; onClick={() =&gt; state.arr.push(Math.floor(Math.random() * 100))} &gt;push&lt;/Button&gt;\n                &lt;Button color=&quot;primary&quot; style={{marginLeft: 8}} onClick={() =&gt; state.arr.pop()} &gt;pop&lt;/Button&gt;\n                &lt;Button color=&quot;primary&quot; style={{marginLeft: 8}} onClick={() =&gt; state.arr.shift()} &gt;shift&lt;/Button&gt;\n                &lt;Button color=&quot;primary&quot; style={{marginLeft: 8}} onClick={() =&gt; state.arr.unshift(Math.floor(Math.random() * 100))} &gt;unshift&lt;/Button&gt;\n                &lt;Button color=&quot;primary&quot; style={{marginLeft: 8}} onClick={() =&gt; state.arr.reverse()} &gt;reverse&lt;/Button&gt;\n                &lt;Button color=&quot;primary&quot; style={{marginLeft: 8}} onClick={() =&gt; state.arr.sort()} &gt;sort&lt;/Button&gt;\n            &lt;/div&gt;\n            &lt;div style={{fontWeight: &#039;bold&#039;, marginTop: 8}}&gt;计算属性：&lt;/div&gt;\n            &lt;div style={{marginTop: 8}}&gt;数量：{ state.bugsCount } 个&lt;/div&gt;\n            &lt;div style={{margin: &#039;8px 0&#039;}}&gt;\n                &lt;form\n                    onSubmit={(e) =&gt; {\n                        state.bug ? state.addBug(state.bug) : state.addBug(&#039;domesy&#039;)\n                        state.bug = &#039;&#039;;\n                        e.preventDefault();\n                    }}\n                    &gt;\n                    &lt;input type=&quot;text&quot; value={state.bug} onChange={(e) =&gt; (state.bug = e.target.value)} /&gt;\n                    &lt;button type=&quot;submit&quot;  style={{marginLeft: 8}} &gt;增加&lt;/button&gt;\n                    &lt;Button color=&quot;primary&quot; style={{marginLeft: 8}} onClick={() =&gt; state.bugs.pop()}&gt;删除&lt;/Button&gt;\n                &lt;/form&gt;\n \n            &lt;/div&gt;\n            &lt;ul&gt;\n                {\n                    state.bugs.map((bug:any, index:number) =&gt; (\n                        &lt;li key={index}&gt;{bug}&lt;/li&gt;\n                    ))\n                }\n            &lt;/ul&gt;\n        &lt;/div&gt;\n    );\n}\n \nexport default Index;\n2. useEventListener\n缘由：我们监听各种事件的时候需要做监听，如：监听点击事件、键盘事件、滚动事件等，我们将其统一封装起来，方便后续调用；\n说白了就是在addEventListener的基础上进行封装，我们先来想想在此基础上需要什么？\n首先，useEventListener的入参可分为三个\n\n第一个event是事件名称（如：click、keydown）\n第二个回调函数（所以不需要出参）\n第三个就是目标（是某个节点还是全局）\n\n在这里需要注意一点就是在销毁的时候需要移除对应的监听事件；\nimport { useEffect } from &#039;react&#039;;\n \nconst useEventListener = (event: string, handler: (...e:any) =&gt; void, target: any = window) =&gt; {\n    useEffect(() =&gt; {\n        const targetElement  = &#039;current&#039; in target ? target.current : window;\n        const useEventListener = (event: Event) =&gt; {\n            return handler(event)\n        }\n        targetElement.addEventListener(event, useEventListener)\n        return () =&gt; {\n            targetElement.removeEventListener(event, useEventListener)\n        }\n    }, [event])\n};\n \nexport default useEventListener;\n注：这里把target默认设置成了window，至于为什么要这么写：&#039;current&#039; in target是因为我们用useRef拿到的值都是 ref.current；\n优化\n接下来我们一起来看看如何优化这个组件，这里的优化与 useCreation 类似，但又有不同，原因是这里的需要判断的要比useCreation复杂一点。\n再次强调一下，传递过来的值，优先考虑使用useRef，再考虑用useState，可以直接使用useLatest，防止拿到的值不是最新值；\n这里简单说一下我的思路：\n\n首先需要hasInitRef来存储是否是第一次进入，通过它来判断初始化存储；\n然后考虑有几个参数需要存储，从上述代码上来看，可变的变量有两个，一个是event，另一个是target，其次，我们还需要存储对应的卸载后的函数，所以存储的变量应该有 3 个；\n接下来考虑一下什么情况下触发更新，也就是可变的两个参数：event和 target\n最后在卸载的时候可以考虑使用useUnmount，并执行存储对应的卸载后的函数和把hasInitRef还原；\n\n详细代码\nimport { useEffect } from &#039;react&#039;;\nimport type { DependencyList } from &#039;react&#039;;\nimport { useRef } from &#039;react&#039;;\nimport { useLatest, useUnmount} from &#039;../hooks&#039;;\n \nconst depsAreSame = (oldDeps: DependencyList, deps: DependencyList):boolean =&gt; {\n    for(let i = 0; i &lt; oldDeps.length; i++) {\n        if(!Object.is(oldDeps[i], deps[i])) return false\n    }\n    return true\n}\n \nconst useEffectTarget = (effect: () =&gt; void, deps:DependencyList, target: any) =&gt; {\n    const hasInitRef = useRef(false); \t\t\t\t\t// 一开始设置初始化\n    const elementRef = useRef&lt;(Element | null)[]&gt;([]);\t// 存储具体的值\n    const depsRef = useRef&lt;DependencyList&gt;([]); \t\t// 存储传递的 deps\n    const unmountRef = useRef&lt;any&gt;(); \t\t\t\t\t// 存储对应的 effect\n \n    // 初始化 组件的初始化和更新都会执行\n    useEffect(() =&gt; {\n        const targetElement  = &#039;current&#039; in target ? target.current : window;\n \n        // 第一遍赋值\n        if(!hasInitRef.current){\n            hasInitRef.current = true;\n            elementRef.current = targetElement;\n            depsRef.current = deps;\n            unmountRef.current = effect();\n            return\n        }\n        // 校验变值: 目标的值不同， 依赖值改变\n        if(elementRef.current !== targetElement || !depsAreSame(deps, depsRef.current)){\n            //先执行对应的函数\n            unmountRef.current();\n            //重新进行赋值\n            elementRef.current = targetElement;\n            depsRef.current = deps; \n            unmountRef.current = effect();\n        }\n    })\n \n    useUnmount(() =&gt; {\n        unmountRef.current();\n        hasInitRef.current = false;\n    })\n}\n \nconst useEventListener = (event: string, handler: (...e:any) =&gt; void, target: any = window) =&gt; {\n    const handlerRef = useLatest(handler);\n \n    useEffectTarget(() =&gt; {\n        const targetElement  = &#039;current&#039; in target ? target.current : window;\n \n        //  防止没有 addEventListener 这个属性\n        if(!targetElement?.addEventListener) return;\n \n        const useEventListener = (event: Event) =&gt; {\n            return handlerRef.current(event)\n        }\n        targetElement.addEventListener(event, useEventListener)\n        return () =&gt; {\n            targetElement.removeEventListener(event, useEventListener)\n        }\n    }, [event], target)\n};\n \nexport default useEventListener;\n\n在这里只用useEffect是因为，在更新和初始化的情况下都需要使用\n必须要防止没有 addEventListener这个属性的情况，监听的目标有可能没有加载出来\n\n验证\n验证一下useEventListener是否能够正常的使用，顺变验证一下初始化、卸载的，代码：\nimport React, { useState, useRef } from &#039;react&#039;;\nimport { useEventListener } from &#039;@/components&#039;\nimport { Button } from &#039;antd-mobile&#039;;\n \nconst Index:React.FC&lt;any&gt; = (props)=&gt; {\n \n    const [count, setCount] = useState&lt;number&gt;(0)\n    const [flag, setFlag] = useState&lt;boolean&gt;(true)\n    const [key, setKey] = useState&lt;string&gt;(&#039;&#039;)\n    const ref = useRef(null);\n \n    useEventListener(&#039;click&#039;, () =&gt; setCount(v =&gt; v +1), ref)\n    useEventListener(&#039;keydown&#039;, (ev) =&gt; setKey(ev.key));\n \n    return (\n        &lt;div style={{padding: 20}}&gt;\n            &lt;Button color=&#039;primary&#039; onClick={() =&gt; {setFlag(v =&gt; !v)}}&gt;切换 {flag ? &#039;unmount&#039; : &#039;mount&#039;}&lt;/Button&gt;\n            {\n                flag &amp;&amp; &lt;div&gt;\n                    &lt;div&gt;数字：{count}&lt;/div&gt;\n                    &lt;button ref={ref} &gt;加1&lt;/button&gt;\n                    &lt;div&gt;监听键盘事件：{key}&lt;/div&gt;\n                &lt;/div&gt;\n            }\n \n        &lt;/div&gt;\n    );\n}\n \nexport default Index;\n我们可以利用useEventListener这个钩子去封装其他钩子，如 鼠标悬停，长按事件，鼠标位置等，在这里在举一个鼠标悬停的小例子 useHover，用于监听 DOM 元素是否有鼠标悬停；\n这个就很简单了，只需要通过 useEventListener 来监听 mouseenter 和 mouseleave 即可，在返回布尔值就行了：\nimport { useState } from &#039;react&#039;;\nimport { useEventListener }  from &#039;./hooks&#039;;\n \ninterface Options {\n    onEnter?: () =&gt; void;\n    onLeave?: () =&gt; void;\n}\n \nconst useHover = (target: any, options?: Options): boolean =&gt; {\n    const [flag, setFlag] = useState&lt;boolean&gt;(false)\n    const { onEnter, onLeave } = options || {};\n \n    useEventListener(&#039;mouseenter&#039;, () =&gt; {\n        onEnter?.()\n        setFlag(true)\n    }, target)\n \n    useEventListener(&#039;mouseleave&#039;, () =&gt; {\n        onLeave?.()\n        setFlag(false)\n    }, target)\n \n    return flag\n};\n \nexport default useHover;\n3. 有关时间的Hooks\n在这里主要介绍有关时间的三个 hooks，分别是：useTimeout、useInterval和useCountDown；\nuseTimeout\n一段时间内，执行一次；传递参数只要函数和延迟时间即可，需要注意的是卸载的时候将定时器清除下就OK了；\n详细代码：\nimport { useEffect } from &#039;react&#039;;\nimport { useLatest } from &#039;./hooks&#039;;\n \nconst useTimeout = (fn:() =&gt; void, delay?: number): void =&gt; {\n    const fnRef = useLatest(fn)\n \n    useEffect(() =&gt; {\n        if(!delay || delay &lt; 0) return;\n        const timer = setTimeout(() =&gt; {\n            fnRef.current();\n        }, delay)\n        return () =&gt; {\n            clearTimeout(timer)\n        }\n    }, [delay])\n};\n \nexport default useTimeout;\nuseInterval\n每过一段时间内一直执行，大体上与useTimeout一样，多了一个是否要首次渲染的参数immediate；详细代码：\nimport { useEffect } from &#039;react&#039;;\nimport { useLatest } from &#039;./hooks&#039;;\n \nconst useInterval = (fn: () =&gt; void, delay?: number, immediate?: boolean): void =&gt; {\n    const fnRef = useLatest(fn)\n    useEffect(() =&gt; {\n        if(!delay || delay &lt; 0) return;\n        if(immediate) fnRef.current();\n        const timer = setInterval(() =&gt; {\n            fnRef.current();\n        }, delay)\n        return () =&gt; {\n            clearInterval(timer)\n        }\n    }, [delay])\n};\n \nexport default useInterval;\nuseCountDown\nuseCountDown：简单控制倒计时的钩子\n跟之前一样我们先来想想这个钩子需要什么：\n\n我们要做倒计时的钩子首先需要一个目标时间（targetDate），控制时间变化的秒数（interval默认为1s），然后就是倒计时完成后所触发的函数（onEnd）\n返参就更加一目了然了，返回的是两个时间差的数值（time），再详细点可以换算成对应的天、时、分等（formattedRes）\n\n详细代码\nimport { useState, useEffect, useMemo } from &#039;react&#039;;\nimport { useLatest } from &#039;./hooks&#039;;\nimport dayjs from &#039;dayjs&#039;;\n \ntype DTime = Date | number | string | undefined;\n \ninterface Options {\n    targetDate?: DTime;\n    interval?: number;\n    onEnd?: () =&gt; void;\n}\n \ninterface FormattedRes {\n    days: number;\n    hours: number;\n    minutes: number;\n    seconds: number;\n    milliseconds: number;\n}\n \nconst calcTime = (time: DTime) =&gt; {\n    if(!time) return 0\n \n    const res = dayjs(time).valueOf() - new Date().getTime(); //计算差值\n \n    if(res &lt; 0) return 0\n \n    return res\n}\n \nconst parseMs = (milliseconds: number): FormattedRes =&gt; {\n    return {\n        days: Math.floor(milliseconds / 86400000),\n        hours: Math.floor(milliseconds / 3600000) % 24,\n        minutes: Math.floor(milliseconds / 60000) % 60,\n        seconds: Math.floor(milliseconds / 1000) % 60,\n        milliseconds: Math.floor(milliseconds) % 1000,\n    };\n};\n \nconst useCountDown = (options?: Options) =&gt; {\n    const { targetDate, interval = 1000, onEnd } = options || {};\n    const [time, setTime] = useState(() =&gt;  calcTime(targetDate));\n    const onEndRef = useLatest(onEnd);\n \n    useEffect(() =&gt; {\n        if(!targetDate) return setTime(0)\n        setTime(calcTime(targetDate))\n \n        const timer = setInterval(() =&gt; {\n            const target = calcTime(targetDate);\n \n            setTime(target);\n            if (target === 0) {\n                clearInterval(timer);\n                onEndRef.current();\n            }\n        }, interval);\n        return () =&gt; clearInterval(timer);\n    },[targetDate, interval])\n \n    const formattedRes = useMemo(() =&gt; {\n        return parseMs(time);\n    }, [time]);\n \n    return [time, formattedRes] as const\n    };\n \nexport default useCountDown;\n总结\n简单的做下总结：\n\n一个优秀的 hooks 一定会具备useMemo、useCallback等api优化\n制作自定义 hooks 遇到传递过来的值，优先考虑使用useRef，再考虑用useState，可以直接使用useLatest，防止拿到的值不是最新值；\n在封装的时候，应该将存放的值放入 useRef中，通过一个状态去设置他的初始化，在判断什么情况下来更新所对应的值，明确入参与出参的具体意义，如useCreation和useEventListener；\n"},"front-end/react/state-manage/new-wave-2022":{"title":"new-wave-2022","links":[],"tags":[],"content":"React 状态管理的新浪潮\n\n了解状态管理库需要解决的核心问题。以及大量涌现的现代库是如何用新的方式解决这些问题。\n\n随着 React 应用程序的规模和复杂性的不断增长，如何管理可共享的全局状态已经成为一个挑战。通常建议是仅在真正需要时才引入全局状态管理方案。\n这篇文章将详细讨论全局状态管理库需要解决的核心问题。\n了解这些潜在问题将有助于我们评估这些状态管理「新浪潮」们所做的取舍。对于其他方面，最好从局部开始引入并只在需要时进行扩展。\nReact 本身并没有为如何解决全局应用状态共享提供任何明确的指导方案。因此，随着时间的推移，React 生态圈已经积累了很多的方法和库来解决这个问题。\n因此在评估采用哪个库或模式时，这可能会让人感到困惑。\n常见的方法是把它放在外层，并使用目前最主流的工具来处理。这就是我们看到的，早期大家广泛使用 Redux 就是这种情况，其实许多应用并不需要它。\n通过理解状态管理库使用上的问题，可以帮助我们更好地理解为什么有这么多不同的库采用了不同的方法。\n每个库在解决不同的问题上都做了一些不同的取舍，导致在 API、模式以及思考状态的概念模型上有许多不同。\n我们接下来会看一下在 Recoil、Jotai、Zusand、Valtio 这些库中所用到的现代方法和模式，以及其他类似 React tracked 和 React Query 的库。看看他们是如何适应环境发展的。\n最后当我们需要选择一个对我们的应用真正有用的库时，我们应该对准确评估这个库实现上的取舍有更充分的准备。\n全局状态管理库需要解决的问题\n1、「能够从组件树中的任何位置读取存储状态。」 这是状态管理库最基本的功能。\n它允许开发人员将状态保存在内存中，并避免大量属性传递的问题。在 React 生态系统的早期，我们经常不合适地使用 Redux 来解决这个痛点。\n实际上，当涉及到实际存储状态时，有两种主要方法。\n第一个是在 React 运行时内部。这通常是指利用 React 提供的 useState、useRef 或 useReducer 等 API 并结合 React 上下文来传递共享值。这里最大的挑战是如何正确的优化重复渲染问题。\n第二个是 React 知识体系之外的问题，叫做模块状态。模块状态允许以类似单例的形式存储状态。这样优化重复渲染问题会比较容易，只需要在状态变更时选择性的处理相关的订阅。但因为它是内存中的单个值，所以不同的子树不能有不同的状态。\n2、「能够写入存储状态。」 一个库应该提供一个直观的 API 来读写存储中的数据。\n一个直观的 API 通常是符合现有心智模型的 API。因此这可能有点主观，具体取决于库的使用者是谁。\n通常，心智模型中的冲突会导致使用上的阻力或者增加学习成本。在 React 中常见的心智模型冲突就是可变状态与不可变状态。\nReact 中将 UI 作为状态函数的模型适用于引用相等以及通过不可变更新来检测何时发生变化以便正确进行重新渲染的概念。但是 Javascript 本身是一种可变语言。\n在使用 React 时，我们必须牢记引用相等之类的事情。这对于不习惯函数式概念的 Javascript 开发人员来说，可能是一个混乱的根源，也增加了学习 React 的成本。\nRedux 遵循此模型，并要求所有状态更新都以不可变的方式完成。做这样的选择需要权衡取舍。在这种情况下，一个常见的缺点是对那些习惯于可变方式更新的人来说必须要编写大量样板代码来进行更新。\n这就是为什么像 Immer 这样的库很受欢迎的原因，它允许开发人员编写可变形式的代码（即使在底层更新还是不可变的）。\n在新一波「post-redux」全局状态管理方案中还有一些库，例如 Valtio，允许开发人员使用可变形式的 API。\n3、「提供优化渲染的机制。」 将 UI 作为状态函数的模型应该既简单又高效。\n然而，当大规模的状态发生变化时的协调过程是极其复杂的。这通常导致大型应用的运行时性能问题。\n使用此模型，全局状态管理库需要检测当状态更新时何时进行重新渲染，并且仅重新渲染必要的内容。\n优化这个过程就是状态管理库需要解决的最大挑战之一。\n通常采取两种主要方法。首先是允许开发人员手动优化这个过程。\n手动优化的一个例子是通过选择器函数订阅一小块存储状态。通过该选择器读取状态的组件只会在特定状态更新时重新渲染。\n第二个方法是自动为开发人员处理这个问题，这样就不必考虑手动优化的问题。\nValtio 就是一个示例库，它在后台使用 Proxy 来自动跟踪状态变更并自动管理组件何时重新渲染。\n4、「提供优化内存占用的机制。」 对于大型前端应用，大量不合理地管理内存可能会带来问题。\n特别是当用户用低配置的设备访问这些大型应用。\n挂到 React 生命周期上的状态意味着在组件卸载时更容易利用自动垃圾回收机制。\n对于像 Redux 这样提倡单一全局状态的库，你需要自己管理它。因为它会持续保留对数据的引用，不会自动进行垃圾回收。\n同样，使用状态管理库将状态存储在 React 运行时之外意味着它不依赖于任何特定组件，可能需要手动管理。\n「更多需要解决的问题：」 除了上面这些基础问题，在与 React 集成时还有一些常见问题 需要考虑：\n1、「与并发模式的兼容性。」 并发模式 允许 React 在渲染过程中「暂停」和切换优先级。以前这个过程是完全同步的。\n将并发引入任何地方通常都会带来一些边缘场景。对于状态管理库，如果两个组件从一个外部存储中读值，在渲染过程中这个值发生了变化，那么两个组件可能会读到不同的值。\n这被称为「撕裂」。这个问题导致 React 团队为库创建者开发了 useSyncExternalStore 来解决这个问题。\n2、「数据序列化。」 拥有完全可序列化的状态是很有用的，这样你就可以从某个存储中保存和恢复应用状态。一些库会为你处理这个问题，而其他库可能需要使用者做一些额外工作才能使用此能力。\n3、「上下文丢失问题。」 对于将多个 react 渲染混合在一起的应用程序来说，这是一个问题。例如，你可能有一个同事使用了 react-dom 和 类似 react-three-fiber 的库的应用。React 无法协调两个独立的上下文。\n4、「过期的属性问题。」 Hooks 解决了很多传统类组件的问题。对此的取舍是要接受闭包带来的一系列新问题。\n一个常见问题是闭包里的数据在当前渲染周期中不再是「新鲜的」。这导致渲染到屏幕上的数据不是最新值。当碰到使用了依赖这些属性来计算状态的选择器函数时就会产生问题。\n5、「僵尸子组件问题。」 这是 Redux 的一个老问题，如果子组件首先挂载并在父组件之前连接到存储，同时在父组件挂载之前发生状态变更，就会导致数据不一致。\n状态管理生态系统简史\n正如我们所见，全局状态管理库需要考虑很多问题和边缘场景。\n为了更好地理解 React 状态管理的现代方法。我们可以回忆一下历史，看看过去什么痛点形成了我们今天称之为「最佳实践」的方法。\n通常，这些最佳实践是通在反复试验和试错发现的。并且发现某些解决方案最终无法很好地适用。\n从一开始，React 最初发布时的原始标语就是定位 MVC 模型 中的「视图」。\n它没有包含如何构建或管理状态的观点。这意味着在处理前端应用中最复杂的部分时，开发人员只能靠自己。\n在 Facebook 内部，使用了一种称为「Flux」的模式，它有助于单向数据流和可预测的更新，这与 React 的「总是重新渲染」的模型相一致。\n这种模式非常符合 React 的心智模型，并且在 React 生态系统的早期就流行起来。\nRedux 的原始崛起\nRedux 是被广泛采用的 Flux 模型的首批实现之一。\n它提倡使用单一存储，部分灵感来自 Elm 架构，而不是其他 Flux 实现中常见的多存储。\n在启动一个新项目时，你不会因为选择 Redux 作为状态管理库而被解雇。它还具有很酷的演示能力，例如很方便的实现撤消 / 重做功能和时间旅行调试能力。\n整个模型至今都是简单而优雅的。尤其是与 React 上一代的 MVC 风格框架例如 Backbone（大规模系统）相比。\n虽然 Redux 对特定应用场景来说仍然是一个很棒的状态管理库。但是随着时间的推移，以及整个社区的成长，Redux 遇到了一些常见的问题，导致它不再受欢迎：\n1、小型应用中的问题\n对于早期的很多应用，它解决了第一个问题。从树中的任何位置访问存储状态，避免了层层传递数据和函数来将数据更新到多个层级的痛苦。\n对于获取少量数据并且几乎没什么交互的简单应用来说，这通常太重了。\n2、大型应用中的问题\n随着时间的推移，很多小型应用逐渐变成了大型应用。正如我们在实践中发现的，前端应用中有许多不同类型的状态。每个都有自己的一系列问题。\n比如本地 UI 状态、远程服务器缓存状态、url 状态和全局共享状态，以及更多不同类型的状态。\n例如，对于本地 UI 状态，随着应用的发展，在数据和更新数据的方法中进行属性传递通常很快就会成为一个问题。为了解决这个问题，结合使用 组件组合模式 和 状态提升 可以帮助你更好的度过这段时期。\n对于远程服务器缓存状态，存在一些常见问题，例如请求去重、重试、轮询、处理突变等等。\n随着应用的发展，Redux 倾向于吸收所有状态，无论其是什么类型，因为它提倡使用单一存储。\n这就会导致将所有东西都存储在一个超大的单一存储中。这往往会引出第二个问题，运行时性能优化。\n因为 Redux 通常只处理全局共享状态，所以很多这些子问题都需要反复处理（或者通常无人关注）。\n这导致形成一个大型单一存储，在一个地方管理 UI 和远程实体状态之间的所有内容。\n随着应用的发展，这当然会变得非常难以管理。特别是在前端开发人员需要快速迭代的团队中。解耦的处理独立的复杂组件变得更加有必要。\n不再强调 Redux\n随着我们遇到更多这样的痛点，慢慢的，在启动新项目时默认使用 Redux 变得不受欢迎。\n实际上，很多 Web 应用都是 CRUD（创建、读取、更新和删除）类型的应用，主要做的就是将前端与远程状态数据同步。\n换句话说，值得花时间研究的主要问题是一系列与远程服务器缓存相关的问题。包括如何获取、缓存和同步服务器状态。\n它还包括许多其他问题，例如处理竞态、失效和重新获取过期数据、去重、重试、组件重新聚焦时重新获取数据，以及相比 Redux 的样板代码更方便的改变远程数据。\n这些用例的样板是没必要且过于复杂的。特别是通常需要绑定使用的中间件例如 redux-saga 和 redux-observable。\n就从客户端获取和改变数据的成本而言，这套工具链对于这些类型的应用来说都太重了。并且对这些相对简单的操作来讲也太复杂了。\n转向更简单的方法\n随着 hooks 和新的上下文 API 的出现。风向从使用像 Redux 这样的重度抽象转向使用新的 hooks API 的原生能力已经有一段时间了。通常是简单的使用 useContext 并结合 useState 或者 useReducer。\n对于简单的应用程序，这是一种很好的方法。许多小型应用都可以这么做。但是随着应用的发展，这会带来两个问题：\n\n「再造一个 Redux。」 并且很容易陷入我们之前讨论过的许多问题。与一些致力于解决这些特殊边缘情况的库相比，要么没解决问题，要么只是解决了一点点。导致许多人觉得有必要倡导 React 上下文与状态管理无关 的想法。\n「优化运行时性能。」 另一个核心问题是优化重复渲染。在使用原生上下文时，随着应用的发展，这会很难实现。\n\n值得一提的是一些现代用户侧的库，例如 useContextSelector 旨在帮助解决此问题。同时 React 团队也开始考虑 在未来作为 React 的一部分自动解决这个痛点。\n用于解决远程状态管理问题的专用库的兴起\n对于大多数 CRUD 类型的 Web 应用，本地状态与专用的远程状态管理库相结合可以帮助你很好的解决问题。\n在这趋势中的示例库包括 React query、SWR、Apollo 和 Relay。以及一些「革新」的 Redux 库比如 Redux Toolkit 和 RTK Query。\n这些是专门为解决远程数据问题而构建的，这些问题如果单独使用 Redux 来解处理的话通常会很复杂。\n虽然这些库对于单页应用来说是很好的抽象。就获取和改变数据所需的 Javascript 而言，它们仍然需要很多的开销。作为一个 Web 构建者社区，Javascript 的实际成本 变得越来越重要。\n值得注意的是，像 Remix 这样的新兴元框架已经解决了这个问题。通过提供对服务端优先的数据加载的抽象和声明性突变，它不再需要引入一个专门的库。它把「将 UI 作为状态函数」的概念 扩展到客户端 之外，包括后端远程状态数据。\n全局状态管理库和模式的新浪潮\n对于大型应用，通常不可避免地需要有与远程服务器状态不同的全局状态共享。\n自下而上模式的兴起\n我们可以看到之前的状态管理解决方案（如 Redux）在他们的实现上比较「自上而下」。随着时间的推移，它倾向于吸收组件树顶部的所有状态。状态都在树的顶部，下面的组件通过选择器获取它们需要的状态。\n在 构建面向未来的前端架构 中，我们看到了自下而上的模式在构建具有组合模式的组件方面的作用。\nhooks 既提供也提倡了将可组合部件组合在一起形成更大整体的原则。使用 hooks，标志着巨型单一全局存储的状态管理方法的转变。走向自下而上的「微」状态管理，强调通过 hooks 消费更小的状态片段。\n像 Recoil 和 Jotai 这样的流行库用他们的「原子」状态概念来验证了这种自下而上的方法。\n原子是很小但完整的状态单位。它们是状态的一小块，可以连接在一起形成新的派生状态。这样最终就会形成一个关系图。\n这套模型允许开发者以自下而上的方式逐步构建状态。并可以通过只让关系图中已更新的原子状态无效来优化重复渲染。\n这与直接订阅一个巨型的单一状态形成对比，并可以尽量减少不必要的重复渲染。\n现代库如何解决状态管理的核心问题\n下面是每个「新浪潮」中的库为解决状态管理中的核心问题所采用的不同方法的简单总结。这些是我们在文章开头定义的问题。\n能够从子树中的任何位置读取存储状态\n\n能够写入和更新存储状态\n\n运行时重复渲染性能优化\n「手动优化」 通常意味着创建订阅特定状态片段的选择器函数。这里的好处是消费者可以对如何订阅和优化订阅该状态的组件如何重新渲染进行细粒度控制。一个缺点是这是一个手动过程，容易出错，并且有人可能会质疑这里需要一些不必要的开销，这不应该是 API 的一部分。\n「自动优化」 是让库优化这个过程，该过程仅自动重新渲染必要的内容。这里的优势当然是更加方便，以及开发者能够专注于实现功能而无需关心手动优化的方法。这样做的一个缺点是，对开发者来说优化过程是一个黑盒，没有暴露出口来手动优化某些部分，可能有人会觉得有点魔幻。\n\n内存优化\n内存优化往往只是大型应用的问题。这在很大程度上取决于库是在模块级别存储状态还是在 React 运行时中存储状态。这还取决于你如何构建存储状态。\n与大型单体存储相比，小型独立存储的好处是，当所有订阅的组件卸载时，它们可以自动进行垃圾回收。而大型单体存储在没有做合适的内存管理的情况下更容易出现内存泄漏。\n\n总结\n关于什么是最好的全局状态管理库，目前还没有一个正确答案。这个问题很大程度上取决于你的应用需求以及构建它的人。\n但是了解状态管理库需要解决的核心问题可以帮助我们评估现在和未来将出现的库。\n深入了解具体实现超出了本文的范围。如果你有兴趣深入研究，我推荐 Daishi Kato 的 React 状态管理书，这是一个非常好的资源，它对本文中提到的一些较新的库和方法进行了非常详细的比较。\n参考\n\nGarbage Collection in Redux Applications\nReact without memo\nThe zombie child problem\nuseMutableSource → useSyncExternalStore discussion\nProxy compare\nuseContextSelector\nData flow in Remix\n"},"front-end/reading/01-模块化的发展":{"title":"01-模块化的发展","links":[],"tags":[],"content":"The Evolution of JavaScript Modularity\nWhen Brendan Eich was designing the first version of JavaScript, he probably had no idea how his project will evolve during the last twenty years. At the moment there are already six major releases of specification of the language and work on its improvement still continues.\nLet’s be honest, JavaScript has never been the perfect programming language. One of the weaknesses of JS was modularity, to put it more clear, its absence. Indeed why do you need to care about isolation of the code and dependencies, when you use scripting language only for animations of the falling snowflakes on the page or for the form validation, when everything can live and interact in the same global scope?\nWith the time JavaScript has transformed into a general purpose language, as it began to be used to build a complex applications in the various environments (browser, mobile, server, IoT). The old approaches of the interaction of components of the program through the global scope became unreliable, because the increasing amount of the code tend to make your application too fragile. That is why for simplification of creation JavaScript applications there were created various realizations of modularity.\nIn this article, which is a result of communication with members of TC39, the developers of the different frameworks, reading source code, blogs and books, we will look at the following approaches/formats: Namespace, Module, Detached Dependency Definitions, Sandbox, Dependency Injection, CommonJS, AMD, UMD, Labeled Modules, YModules, ES2015 Modules. And meanwhile we will restore historical context of their emergence.\nDefining the Used Terms\nThe modularity solves next issues: code isolation, dependency definition between modules, and delivering of the code into execution environment. Some approaches solved only one or two issues, we will name this solutions as “patterns”. Some approaches solved all of three, we will name them as “module systems”.\nWe will name particular structure of the source code with definitions of exported entities (objects, functions etc.) and definitions of imported entities as “module format”.\nThe “Detached Dependency Definition” (DDD for short) means such approaches of describing dependencies which can be used independently from the module systems.\nA Little More About Problems\nBefore delve into the world of modularity let’s take a closer look at the problems which we will try to solve.\nThe Name Collision\nFrom the moment of its appearance JavaScript has used the global object window as a storage for all variables defined without the var keyword. In 1995-1999 it was very convenient, because JavaScript code tended to solve small tasks that hadn’t required a lot of lines of code. But when the codebase of applications had became large this feature of the language began to lead to nasty errors because of the name collisions. Let’s look at this example:\n// file greeting.js\nvar helloInLang = {\n    en: &#039;Hello world!&#039;,\n    es: &#039;¡Hola mundo!&#039;,\n    ru: &#039;Привет мир!&#039;\n};\n\nfunction writeHello(lang) {\n    document.write(helloInLang[lang]);\n}\n\n// file hello.js\nfunction writeHello() {\n    document.write(&#039;The script is broken&#039;);\n}\n\nWhen we place the script greeting.js on the page and after it hello.js there will be conflict, that is instead of the greeting we will get the message “The script is broken” in this particular case.\nIt is obvious that in the large projects this can cause a lot of headaches. Moreover you cannot be sure that the third-party scripts on the page won’t break anything in your app.\nThe Support for Large Codebases\nAn another inconvenient moment of JavaScript for the building of large applications is the need to explicitly specify a plugged-in scripts using the script tag in the most common ES5 browser environments.\nIf you care about the fact that the source code of application should be maintainable, then you need to split it into independent parts. Because of this the amount of the files may be a really large. With a large number of files the manual control of the scripts (i.e. the placing scripts on the page via the script tag) becomes very tedious, because firstly you have to remember to put necessary scripts in the page and secondly preserve the proper order of the script tags so that all dependencies between files has been resolved.\nDirectly Defined Dependencies (1999)\nThe first attempt to bring the structure of the modules into JavaScript and the first implementation of the detached dependency definition was pattern “Directly Defined Dependencies”. This pattern firstly was used by Erik Arvidsson (member of TC39 at the present moment) in 1999 year.\nAt that time Erik worked at a startup developing a platform for running gui applications in a browser, it was called WebOS (note that this is not webOS, which was developed by Palm). WebOS was a proprietary platform, so I did not manage to get its source code. Therefore we look at the implementation of this pattern using Dojo Toolkit, which was developed by Alex Russell and Dylan Schiemann in 2004.\nThe gist of directly defined dependencies lied in the getting of the code of the modules (in terms of the Dojo - resources) via explicit invocation of the function dojo.require (which is also used to initialise the loaded module). That is in this approach the dependencies were defined directly in the code at those places, where they should to be used.\nLet’s revise our example using Dojo 1.6:\n// file greeting.js\ndojo.provide(&quot;app.greeting&quot;);\n\napp.greeting.helloInLang = {\n    en: &#039;Hello world!&#039;,\n    es: &#039;¡Hola mundo!&#039;,\n    ru: &#039;Привет мир!&#039;\n};\n\napp.greeting.sayHello = function (lang) {\n    return app.greeting.helloInLang[lang];\n};\n\n// file hello.js\ndojo.provide(&quot;app.hello&quot;);\n\ndojo.require(&#039;app.greeting&#039;);\n\napp.hello = function(x) {\n    document.write(app.greeting.sayHello(&#039;es&#039;));\n};\n\nHere we see that modules are defined using the function dojo.provide, and the process of getting of the code of the module starts when you use dojo.require. It is a fairly simple approach that was used in the Dojo up to version 1.7; Google Closure Library uses it to this day.\nThe Namespace Pattern (2002)\nFor solving the issue with name collisions you may use special code conventions. For example you can add particular prefix to all variables and functions: myApp_: myApp_address, myApp_validateUser(). Also you can use the fact that functions in JavaScript are first class citizens, i.e. you can assign them to variables, to properties of objects and return them from other functions. Therefore you can create objects with properties-methods similar to objects document and window (document.write(), window.alert()).\nThe first significant project that took advantage of this opportunity was a library of ui elements Bindows. Bindows was created by already familiar to us Erik Arvidsson in 2002. Instead of using prefixes in the name of functions and variables, he used a global object whose properties contained the data and logic of the library. That fact has greatly reduced the pollution of the global scope. The pattern for that code organisation is known now as the “namespace” (the Namespace Pattern).\nIf we apply this idea to our example we get something like this:\n// file app.js\nvar app = {};\n\n// file greeting.js\napp.helloInLang = {\n    en: &#039;Hello world!&#039;,\n    es: &#039;¡Hola mundo!&#039;,\n    ru: &#039;Привет мир!&#039;\n};\n\n// file hello.js\napp.writeHello = function (lang) {\n    document.write(app.helloInLang[lang]);\n};\n\nAs we can see the logic and the data resides now in the properties of the object app. Thus we don’t pollute the global scope but continue to have access to the various parts of the application from different files.\nThe Namespace Pattern is probably the most known pattern in JavaScript nowadays. The Bindows was the first but after it there was a lot of other frameworks and libraries which organised logic that way for example Dojo (2005), YUI (2005). Also it should be noted that Erik does not consider himself as the author of this pattern, but he couldn’t remember particular project he was inspired by.\nThe Module Pattern (2003)\nThe Namespace gave some sort of order to the code organisation. But it was evident that it’s not enough, as there was no solution for the isolation of code and data yet.\nThe pioneer in the solution of this problem is the Module pattern. Its main idea is encapsulating data and code with a closure and providing access to them through methods accessible from the outside. Here is a basic example of this type of pattern:\nvar greeting = (function () {\n    var module = {};\n\n    var helloInLang = {\n        en: &#039;Hello world!&#039;,\n        es: &#039;¡Hola mundo!&#039;,\n        ru: &#039;Привет мир!&#039;\n    };\n\n    module.getHello = function (lang) {\n        return helloInLang[lang];\n    };\n\n    module.writeHello = function (lang) {\n        document.write(module.getHello(lang))\n    };\n    \n    return module;\n}());\n\nHere we see the immediately invoked function, which returns a module object, which in turn has a method getHello that accesses the object helloInLang through the closure. Thus helloInLang becomes inaccessible from the outside world and we get an atomic piece of code that can be pasted into any other script without the name collision.\nThe first use of this approach in the wild was seen in 2003, when Richard Cornford gave an example of this pattern in the group comp.lang.javascript to illustrate the use of closures. In 2005-2006, the developers of the YUI framework from Yahoo! under the leadership of Douglas Crockford took this approach for their project. But the greatest impetus to its spread was given in 2008 by Douglas, when he described the “Module” in his book JavaScript the Good Parts.\nAlso there is a good article JavaScript Module Pattern: In-Depth. It describes a lot of various ways of implementation of the Module. I recommend to look at it.\nTemplate Defined Dependencies (2006)\nTemplate defined dependencies is the next pattern in the family of the detached dependency definitions. I was able to find the earliest use of this approach in library Prototype 1.4 (2006). But I have a suspicion that this approach was used in the earlier versions of the library also. (If you have access to the earlier versions of prototype let me know).\nThe development of Prototype started in 2005 by Sam Stephenson. Prototype was the integral part of Ruby on Rails at that time. Because Sam worked a lot with ruby it is not surprising that for the management of the dependencies he had chosen simple erb templates.\nIf we try to generalize we can say, that this pattern defines dependencies via inclusion into the target file the special labels. The resolving this labels into actual code can be performed via templating (erb, jinja, smarty), and special build tools, for example, borshik. In contrast to the previous discussed detached dependency definitions patterns, this pattern only works with pre-build step.\nLet’s transform our example using this style of dependency definition. For that we will use borshik.\n// file app.tmp.js\n\n/*borschik:include:../lib/main.js*/\n\n/*borschik:include:../lib/helloInLang.js*/\n\n/*borschik:include:../lib/writeHello.js*/\n\n// file main.js\nvar app = {};\n\n// file helloInLang.js\napp.helloInLang = {\n    en: &#039;Hello world!&#039;,\n    es: &#039;¡Hola mundo!&#039;,\n    ru: &#039;Привет мир!&#039;\n};\n\n// file writeHello.js\napp.writeHello = function (lang) {\n    document.write(app.helloInLang[lang]);\n};\n\nIn the example file app.tmp.js defines the plugged-in scripts and their order. If you will ponder about this example it will be clear that this approach does not fundamentally changes the life of the developer. Instead of using script tags you just start to use other labels in js file. Thus we can still forget something or screw up the order of the plugged-in scripts. Therefore the main purpose of this approach is a creating a single file from many other scripts.\nComment Defined Dependencies (2006)\nThe comment defined dependencies pattern is also subtype of the detached dependency definitions family. It is very similar to directly defined dependencies, but in this case instead of using some sort of functions we use comments which include the information about all dependencies of the particular module.\nAn application that use this pattern must be either pre-built (this approach was used in 2006 for MooTools which was created by Valerio Proietti), or dynamically parse downloaded code and resolve dependencies at the runtime. The last approach was used in LazyJS which was created by Nicolás Bevacqua.\nOur example will be look like this, if we will rewrite it using this library:\n// file helloInLang.js\nvar helloInLang = {\n    en: &#039;Hello world!&#039;,\n    es: &#039;¡Hola mundo!&#039;,\n    ru: &#039;Привет мир!&#039;\n};\n\n// file sayHello.js\n\n/*! lazy require scripts/app/helloInLang.js */\n\nfunction sayHello(lang) {\n    return helloInLang[lang];\n}\n\n// file hello.js\n\n/*! lazy require scripts/app/sayHello.js */\n\ndocument.write(sayHello(&#039;en&#039;));\n\nIn a nutshell how the library works. When library downloads files it parses their contents, finds the corresponding comments with dependencies, and eventually downloads them (dependencies), repeating the process of parsing of the downloaded files.\nThe most well known library which uses this approach MooTools. LazyJS was an interesting experiment but due to the reason that its emergence happened after CommonJS and AMD, LazyJS didn’t get a big attention of developers.\nExternally Defined Dependencies (2007)\nLet’s look at the last pattern in the family of DDD. In the externally defined dependencies pattern all dependencies are defined outside of the main context, for example in a configuration file or in a code as an object or an array with the list of dependencies. However there is a phase of preparing. The application during this phase initialises itself with loading all dependencies in the correct order.\nThe earliest using of this approach, that I managed to find, dates by 2007 in MooTools 1.1.\nIn the simplest case our example with using this pattern can be done like this (for this example I will use my own experimental loader that use this pattern).\n// file deps.json\n{\n    &quot;files&quot;: {\n        &quot;main.js&quot;: [&quot;sayHello.js&quot;],\n        &quot;sayHello.js&quot;: [&quot;helloInLang.js&quot;],\n        &quot;helloInLang.js&quot;: []\n    }\n}\n\n// file helloInLang.js\nvar helloInLang = {\n    en: &#039;Hello world!&#039;,\n    es: &#039;¡Hola mundo!&#039;,\n    ru: &#039;Привет мир!&#039;\n};\n\n// file sayHello.js\nfunction sayHello(lang) {\n    return helloInLang[lang];\n}\n\n// file main.js\nconsole.log(sayHello(&#039;en&#039;));\n\nFile deps.json is the external context in which you define all dependencies. When you run the application the loader receives this file, reads the list of all dependencies that are defined as an array, and then loads and puts them to the page in the correct order.\nNowadays this approach is used in libraries for creating the custom builds. For example such approach uses lodash.\nThe Sandbox Pattern (2009)\nThe developers at Yahoo, who worked on the new module system in YUI3, was solving the problem of using different versions of the library on one page. Prior YUI3 module system of the framework has been implemented using combination of the Module pattern and Namespace. It’s obvious that by using this approach top-level object which contained code of the library could only be one, and therefore simultaneous using of multiple versions of the library was really difficult.\nAdam Moore (one of the developers of YUI3) suggested to use “Sandbox” for a solution to this problem. A simple implementation of modularity using this pattern may look like this:\n// file sandbox.js\nfunction Sandbox(callback) {\n    var modules = [];\n\n    for (var i in Sandbox.modules) {\n        modules.push(i);\n    }\n\n    for (var i = 0; i &lt; modules.length; i++) {\n        this[modules[i]] = Sandbox.modules[modules[i]]();\n    }\n    \n    callback(this);\n}\n\n// file greeting.js\nSandbox.modules = Sandbox.modules || {};\n\nSandbox.modules.greeting = function () {\n    var helloInLang = {\n        en: &#039;Hello world!&#039;,\n        es: &#039;¡Hola mundo!&#039;,\n        ru: &#039;Привет мир!&#039;\n    };\n\n    return {\n        sayHello: function (lang) {\n            return helloInLang[lang];\n        }\n    };\n};\n\n// file app.js\nnew Sandbox(function(box) {\n    document.write(box.greeting.sayHello(&#039;es&#039;));\n});\n\nThe essence of this approach is that instead of the global object you use a global constructor. The modules can be defined as properties of this constructor.\nThe “Sandbox” is an interesting solution to the problem of modularity, but besides of YUI3 this pattern didn’t get a lot of attention. If you want to know more about the Sandbox I recommend the article the Javascript Sandbox Pattern, and the official YUI documentation about the creation of new modules of the library.\nDependency Injection (2009)\nIn 2004 Martin Fowler introduced the concept of “dependency injection” (DI) for the description of the new mechanism of communication the components in Java. The gist is that all dependencies come from outside of the component, therefore the component is not responsible for initialisation its dependencies it only uses them.\nFive years later Miško Hevery a former employee of Sun and Adobe (where he was mainly engaged in development on Java) began to design for his startup a new JavaScript framework, which used dependency injection as the key mechanism of the communication between components. The business idea has not proved its effectiveness, and source code of the framework was opened and introduced to the world at the domain of his startup getangular.com. We all know what happened next. Google has taken under its wing Miško and his project, and now Angular is one of the most known JavaScript frameworks.\nModules in Angular are implemented via the mechanism of Dependency Injection. By the way the modularity is not the primary purpose of DI, about this also clearly Miško says in the answer to the corresponding question.\nTo illustrate this approach, let’s rewrite our example using the first version of Angular (yes, bear in mind that this example is extremely synthetic):\n// file greeting.js\nangular.module(&#039;greeter&#039;, [])\n    .value(&#039;greeting&#039;, {\n        helloInLang: {\n            en: &#039;Hello world!&#039;,\n            es: &#039;¡Hola mundo!&#039;,\n            ru: &#039;Привет мир!&#039;\n        },\n\n        sayHello: function(lang) {\n            return this.helloInLang[lang];\n        }\n    });\n\n// file app.js\nangular.module(&#039;app&#039;, [&#039;greeter&#039;])\n    .controller(&#039;GreetingController&#039;, [&#039;$scope&#039;, &#039;greeting&#039;, function($scope, greeting) {\n        $scope.phrase = greeting.sayHello(&#039;en&#039;);\n    }]);\n\nIf you will open the page with this example in the browser, then the code will run magically and you will see the result on the page.\nAt the moment the dependency injection is a key mechanism in such frameworks as Angular 2 and Slot. There are also a large number of libraries that simplify the use of this approach in applications that don’t depend on any framework.\nCommonJS Modules (2009)\nAlong with the client-side JavaScript engines (in the browsers) even before Node.JS there were platforms for server-side development with JavaScript as the primary language. The server solutions due to the absence of appropriate specifications did not provided a unified API for communication with operating system and an its environment (file system, network, environment variables, and so on), thus creating problems with the code distribution. For example, scripts written for the old Netscape Enterprise Server did not work in Rhino and vice versa.\nThe turning point occurred in 2009 when an employee of Mozilla Kevin Dangoor published a post about the problems with server-side JavaScript with a call to all interested to join an informal Committee to discuss and develop server-side JavaScript API that was called ServerJS. Half a year later ServerJS was renamed to CommonJS because of new concepts that started to be part of the discussions.\nWork had begun to boil. The most attention from developers and researchers has been given to specification of the modules - CommonJS Modules (sometimes referred to as CJS or just CommonJS), which eventually was implemented in Node.JS.\nAs an example of the CommonJS module let’s adapt our module by this way:\n// file greeting.js\nvar helloInLang = {\n    en: &#039;Hello world!&#039;,\n    es: &#039;¡Hola mundo!&#039;,\n    ru: &#039;Привет мир!&#039;\n};\n\nvar sayHello = function (lang) {\n    return helloInLang[lang];\n}\n\nmodule.exports.sayHello = sayHello;\n\n// file hello.js\nvar sayHello = require(&#039;./lib/greeting&#039;).sayHello;\nvar phrase = sayHello(&#039;en&#039;);\nconsole.log(phrase);\n\nHere we see that for implementation of modularity there are two new entities - require and module that provide the ability to load a module and to export its interface to the outer world. It is worth noting that neither require nor module are some sort of keywords of the language. In Node.JS we can use them due to the auxiliary function. This function wraps every module before sending it to the JavaScript engine:\n(function (exports, require, module, __filename, __dirname) {\n    // ...\n    // Your code injects here!\n    // ...\n});\n\nThe CommonJS specification defines only required minimum for the module interoperability in the different environments. It means that CommonJS is open for an extension. For example Node.JS uses this feature by adding property main to the require function, which points to the module if the file that consists this module was executed directly.\nBabel also extends require during the transpilation of ES2015 Modules (I will talk about this module system in the end of this article) with default export:\nexport default something;\n\nBabel transforms such an export into CommonJS module, where default value is exported with corresponding property. Simply speaking you can get something like this as result of transpilation:\nexport.default = something;\n\nThe bundler Webpack also uses various extensions, for example require.ensure, require.cache, require.context, but their discussion is outside of the context of this article.\nCommonJS is the most common module format at the present moment. You can use it not only on the server-side in Node.JS but also on the client-side using Browserfiy or Webpack, which can transform set of CommonJS modules into one bundle.\nAMD (2009)\nThe work on the CommonJS specification has been in full swing, and meanwhile there were discussions in the mailing list about adding into the specification the possibility of asynchronous loading for the modules. The main motivation lied in the fact that this will help to speed up the loading of web applications without some sort of pre-bundling.\nThe colleague of Kevin another developer from Mozilla James Burke was one of the most active defenders of asynchronous modularity in all that discussions. James at that time could be an expert, as he was the author of the asynchronous modular system in Dojo Framework 1.7 and also he was developing a loader require.js since 2009.\nThe basic idea, which James tried to clarify was the fact that loading of the modules should not be synchronous (i.e. loading of the modules one by one in succession); we must use the browser functionality for the parallel loading of the scripts. For implementation of all requirements James had proposed his own format which was called AMD (Asynchronous Module Definition).\nIf we will rewrite our example using AMD format we will get something like this:\n// file lib/greeting.js\ndefine(function() {\n    var helloInLang = {\n        en: &#039;Hello world!&#039;,\n        es: &#039;¡Hola mundo!&#039;,\n        ru: &#039;Привет мир!&#039;\n    };\n\n    return {\n        sayHello: function (lang) {\n            return helloInLang[lang];\n        }\n    };\n});\n\n// file hello.js\ndefine([&#039;./lib/greeting&#039;], function(greeting) {\n    var phrase = greeting.sayHello(&#039;en&#039;);\n    document.write(phrase);\n});\n\nThe file hello.js is the entry point of the program. In this file there is a function define that declares a module. The first argument of the function is an array of dependencies. The execution of the code of the module, which is defined as a function in the second argument of define, will be launched only after that fact when all dependencies of this module will be loaded. This deferred code execution of the module makes a possibility for the parallel loading of its dependencies.\nIn 2011 there was the turning point of all this discussions, when James announced the creation of a separate mailing list for coordination all works on AMD, because consensus with the CommonJS group for all this time had not been reached.\nBy personal observations I can say that AMD is still relevant for developing of client side applications, however the tendency for the distribution of client-side libraries via npm leads away developers from AMD more and more.\nUMD (2011)\nThe evident confrontation of module formats began even before when AMD was separated from CommonJS Modules. Already at that time the AMD camp had a lot of developers who liked the minimal entry threshold to the working with modular code. The number of supporters of CommonJS Modules also grew very quickly due to the growing popularity Node.JS and the emergence of Browserify.\nSo there were two formats, which could not get along with each other. AMD modules couldn’t be used in the environments that implements the specification of CommonJS Modules without the code modification. CommonJS modules could not be used with loaders which used AMD as main format (require.js, curl.js) also. It was a bad situation for whole JavaScript ecosystem.\nUMD format has been developed for solution of this problem. UMD stands for Universal Module Definition, so this format allows you to use the same module with AMD tools as well as in CommonJS environments.\nIt was quite difficult to find the original author of this format, so I had to do an investigation. To begin, I turned to the author of UMD repository on GitHub Addy Osmani, who in turn told me about James Burke and Kris Kowal. This guys pointed out to the Q’s repository the first implementation of promises in JavaScript.\nSince its inception, the Q library worked in different environments: in the browser (when you put the module on the page via the script tag) and on server-side in Node.JS and Narwhal (CommonJS Modules). James after some time had added the support of AMD into Q. And then Addy had gathered similar patterns in a single repository, which was named UMD. Such a result of adaptation of the code for different module systems is called UMD now.\nAs an example let’s refactor our module greeting.js for the simultaneous support of different environments CommonJS and AMD:\n(function(define) {\n    define(function () {\n        var helloInLang = {\n            en: &#039;Hello world!&#039;,\n            es: &#039;¡Hola mundo!&#039;,\n            ru: &#039;Привет мир!&#039;\n        };\n\n        return {\n            sayHello: function (lang) {\n                return helloInLang[lang];\n            }\n        };\n    });\n}(\n    typeof module === &#039;object&#039; &amp;&amp; module.exports &amp;&amp; typeof define !== &#039;function&#039; ?\n    function (factory) { module.exports = factory(); } :\n    define\n));\n\nIn the heart of this implementation pattern lies the immediately invoked function expression. That function takes different arguments depending on the environment. The passed argument is the following function if the code is used as a CommonJS module:\nfunction (factory) {\n    module.exports = factory();\n} \n\nIf the code is used as an AMD module, the argument of function is define. Due this substitution the code can be used in different environments.\nNow UMD is such a format that is used by most developers when they need to be able to use their module in the browser or in Node.JS. Many popular libraries support the export into UMD format for example moment.js and lodash.\nLabeled Modules (2012)\nSince 2010 TC39 Committee started to work on a new native module system for JavaScript, which was named ES6 Modules at that time. By 2012 it was clear which final look it will take. One of the members of committee Sebastian Markbåge (also lead developer of React at this moment) had prepared an transitive module format by his own initiative. It was assumed that this format could be used even in ES3 environments and then easily adapted for the new module system. This format was named Labeled Modules.\nThe main idea of this format lies in using of labels. The keywords “import” and “export” is reserved in the language, so they couldn’t be used for labels. Therefore the corresponding synonymous was taken for this purpose. The label “exports” was used for export and the label “require” was used for import.\nAs always let’s rework our example to show this format in action.\n// file greeting.js\nvar helloInLang = {\n    en: &#039;Hello world!&#039;,\n    es: &#039;¡Hola mundo!&#039;,\n    ru: &#039;Привет мир!&#039;\n};\n\nexports: var greeting = {\n    sayHello: function (lang) {\n        return helloInLang[lang];\n    }\n};\n\n// file hello.js\nrequire: &#039;./lib/greeting&#039;;\nvar phrase = greeting.sayHello(&#039;es&#039;);\ndocument.write(phrase);\n\nThe example of the config for building of application using Labeled Modules you can take here.\nAs we can see, it was a really elegant solution. But due to the fact that in 2012 CommonJS and AMD were a really popular choice for the most developers, the new format couldn’t overcome that tough competition. Even though the support of this format had appeared in the first version of webpack, this format had not got a lot of attention in JavaScript community nonetheless.\nYModules (2013)\nYModules is a module system that was created at Yandex for solutions of the tasks that neither CommonJS, nor AMD couldn’t solve. There were main requirements for this module system. First is the using of modules with asynchronous nature as transparent as possible, second is the possibility for the redefinition of modules. First requirement was important for implementation of asynchronous API, for example of Yandex.Maps, second was important due to the need of using modules at levels of definitions in BEM.\nThe teams of Yandex.Maps and BEM had created the specification for the new module system in 2013. And then it was implemented by Dmitry Filatov.\nHere is the implementation of our example using YModules:\n// file greeting.js\nmodules.define(&#039;greeting&#039;, function(provide) {\n    provide({\n        helloInLang: {\n            en: &#039;Hello world!&#039;,\n            es: &#039;¡Hola mundo!&#039;,\n            ru: &#039;Привет мир!&#039;\n        },\n\n        sayHello: function (lang) {\n            return this.helloInLang[lang];\n        }\n    });\n});\n\n// file app.js\nmodules.require([&#039;greeting&#039;], function(greeting) {\n    document.write(greeting.sayHello(&#039;ru&#039;));\n});\n// Result: &quot;Привет мир!&quot;\n\nYModules by its structure heavily resembles AMD, but it’s main difference of YModules is an exposing of interface of the module to the consumers via special function provide rather than with return as in AMD.\nThis feature allows you to do provide from the blocks of an asynchronous code, that is it allows to hide the asynchronous nature of the module from the outside world. For example if we will add into our greeting.js some asynchronous logic (e.g. setTimeout) then the whole code using this module will remain untouched:\n// file greeting.js\nmodules.define(&#039;greeting&#039;, function(provide) {\n    // postpone of code execution for 1 second\n    setTimeout(function () {\n        provide({\n            helloInLang: {\n                en: &#039;Hello world!&#039;,\n                es: &#039;¡Hola mundo!&#039;,\n                ru: &#039;Привет мир!&#039;\n            },\n\n            sayHello: function (lang) {\n                return this.helloInLang[lang];\n            }\n        });\n    }, 1000);\n});\n\n// file: app.js\nmodules.require([&#039;greeting&#039;], function(greeting) {\n    document.write(greeting.sayHello(&#039;ru&#039;));\n});\n// result: &quot;Привет мир!&quot;\n\nAs it was said earlier, the main trait of YModules is the possibility of its using with levels of definitions of BEM. Let’s check out how we can to use this feature.\n// file moduleOnLevel1.js\nmodules.define(&#039;greeting&#039;, function(provide) {\n    provide({\n        helloInLang: {\n            en: &#039;Hello world!&#039;,\n            es: &#039;¡Hola mundo!&#039;,\n            ru: &#039;Привет мир!&#039;\n        },\n\n        sayHello: function (lang) {\n            return this.helloInLang[lang];\n        }\n    });\n});\n\n// file moduleOnLevel2.js\nmodules.define(&#039;greeting&#039;, function(provide, module) {\n    // redeclaring of sayHello method\n    module.sayHello = function (lang) {\n        return module.helloInLang[lang].toUpperCase();\n    };\n    provide(module);\n});\n\n// file app.js\nmodules.require([&#039;greeting&#039;], function(greeting) {\n    document.write(greeting.sayHello(&#039;ru&#039;));\n});\n// Result: &quot;ПРИВЕТ МИР!&quot;\n\nIf you run this example, then as the result of redefining the greeting module the ‘sayHello` method will be changed to the new one, and the text of the output message will be converted to uppercase. This is possible due to the fact that in YModules when the module is defined once again, its last argument will contain the previous version of the module.\nAt the moment YModules is used in the various projects in Yandex. Also it’s a main module system in the framework i-bem.js.\nES2015 Modules (2015)\nOf course the Committee TC39 was watching what was happening in JavaScript world. It was obvious that the time has come for major changes in the language.\nThe work on the modular system started in 2010. The design of this system was created by Dave Herman and Sam Tobin-Hochstadt. The work continued in the period of five years. The final design of the module system has been released with specification ES2015.\nBy tradition, let’s adapt our example to show the specification in action:\n// file lib/greeting.js\nconst helloInLang = {\n    en: &#039;Hello world!&#039;,\n    es: &#039;¡Hola mundo!&#039;,\n    ru: &#039;Привет мир!&#039;\n};\n\nexport const greeting = {\n    sayHello: function (lang) {\n        return helloInLang[lang];\n    }\n};\n\n// file hello.js\nimport { greeting } from &quot;./lib/greeting&quot;;\nconst phrase = greeting.sayHello(&quot;en&quot;);\ndocument.write(phrase);\n\nAs we can see the standard introduces the brand new keywords for importing of modules using the keyword import and exporting of the code using the keyword export.\nDue to the fact that we are dealing with new keywords in the language, and also because the Module Loader API specification, which is responsible for supporting loading modules in various environments, is not yet ready, we can’t just pick up and start using the new native module system.\nIn spite of this limitations a lot of projects have started to use the new format of the modules. To start use the new standard in a world where ES5 is most common, you can use the Babel transpilation, which is a fairly common practice.\nConclusion\nThere are other approaches for the modularity in JS. Some of them can intertwine with each other creating bizarre forms, others were created specifically for using in a particular project, and some were created as a transitive format. Describing them all is a fairly non-trivial task, therefore the article has discussed only the most popular approaches and formats. Nevertheless, I think that this article has helped you to learn something new, to systematise the knowledge about modularity in JavaScript and to learn a little more about those people, who stood behind all these technologies.\n内容概要\n直接定义依赖 (1999): 由于当时 js 文件非常简单，模块化方式非常简单粗暴 —— 通过全局方法定义、引用模块。这种定义方式与现在的 commonjs 非常神似，区别是 commonjs 以文件作为模块，而这种方法可以在任何文件中定义模块，模块不与文件关联。\n闭包模块化模式 (2003): 用闭包方式解决了变量污染问题，闭包内返回模块对象，只需对外暴露一个全局变量。\n模版依赖定义 (2006): 这时候开始流行后端模版语法，通过后端语法聚合 js 文件，从而实现依赖加载，说实话，现在 go 语言等模版语法也很流行这种方式，写后端代码的时候不觉得，回头看看，还是挂在可维护性上。\n注释依赖定义 (2006): 几乎和模版依赖定义同时出现，与 1999 年方案不同的，不仅仅是模块定义方式，而是终于以文件为单位定义模块了，通过 lazyjs 加载文件，同时读取文件注释，继续递归加载剩下的文件。\n外部依赖定义 (2007): 这种定义方式在 cocos2d-js 开发中普遍使用，其核心思想是将依赖抽出单独文件定义，这种方式不利于项目管理，毕竟依赖抽到代码之外，我是不是得两头找呢？所以才有通过 webpack 打包为一个文件的方式暴力替换为 commonjs 的方式出现。\nSandbox 模式 (2009): 这种模块化方式很简单，暴力，将所有模块塞到一个 sandbox 变量中，硬伤是无法解决命名冲突问题，毕竟都塞到一个 sandbox 对象里，而 Sandbox 对象也需要定义在全局，存在被覆盖的风险。模块化需要保证全局变量尽量干净，目前为止的模块化方案都没有很好的做到这一点。\n依赖注入 (2009): 就是大家熟知的 angular1.0，依赖注入的思想现在已广泛运用在 react、vue 等流行框架中。但依赖注入和解决模块化问题还差得远。\nCommonJS (2009): 真正解决模块化问题，从 node 端逐渐发力到前端，前端需要使用构建工具模拟。\nAmd (2009): 都是同一时期的产物，这个方案主要解决前端动态加载依赖，相比 commonJs，体积更小，按需加载。\nUmd (2011): 兼容了 CommonJS 与 Amd，其核心思想是，如果在 commonjs 环境（存在 module.exports，不存在 define），将函数执行结果交给 module.exports 实现 Commonjs，否则用 Amd 环境的 define，实现 Amd。\nLabeled Modules (2012): 和 Commonjs 很像了，没什么硬伤，但生不逢时，碰上 Commonjs 与 Amd，那只有被人遗忘的份了。\nYModules (2013): 既然都出了 Commonjs Amd，文章还列出了此方案，一定有其独到之处。其核心思想在于使用 provide 取代 return，可以控制模块结束时机，处理异步结果；拿到第二个参数 module，修改其他模块的定义（虽然很有拓展性，但用在项目里是个搅屎棍）。\nES2015 Modules (2015): 就是我们现在的模块化方案，还没有被浏览器实现，大部分项目已通过 babel 或 typescript 提前体验。\n精读\n从语言层面到文件层面的模块化\n\n从 1999 年开始，模块化探索都是基于语言层面的优化，真正的革命从 2009 年 CommonJS 的引入开始，前端开始大量使用预编译。\n\n这篇文章所提供的模块化历史的方案都是逻辑模块化，从 CommonJS 方案开始前端把服务端的解决方案搬过来之后，算是看到标准物理与逻辑统一的模块化。但之后前端工程不得不引入模块化构建这一步。正是这一步给前端开发无疑带来了诸多的不便，尤其是现在我们开发过程中经常为了优化这个工具带了很多额外的成本。\n从 CommonJS 之前其实都只是封装，并没有一套模块化规范，这个就有些像类与包的概念。我在 10 年左右用的最多的还是 YUI2，YUI2 是用 namespace 来做模块化的，但有很多问题没有解决，比如多版本共存，因此后来 YUI3 出来了。\nYUI().use(&#039;node&#039;, &#039;event&#039;, function (Y) {\n    // The Node and Event modules are loaded and ready to use.\n    // Your code goes here!\n});\nYUI3 的 sandbox 像极了差不多同时出现的 AMD 规范，但早期 yahoo 在前端圈的影响力还是很大的，而 requirejs 到 2011 年才诞生，因此圈子不是用着 YUI 要不就自己封装一套 sandbox，内部使用 jQuery。\n为什么模块化方案这么晚才成型，可能早期应用的复杂度都在后端，前端都是非常简单逻辑。后来 Ajax 火了之后，web app 概念的开始流行，前端的复杂度也呈指数级上涨，到今天几乎和后端接近一个量级。工程发展到一定阶段，要出现的必然会出现。\n前端三剑客的模块化展望\n\n从 js 模块化发展史，我们还看到了 css html 模块化方面的严重落后，如今依赖编译工具的模块化增强在未来会被标准所替代。\n\n原生支持的模块化，解决 html 与 css 模块化问题正是以后的方向。\n再回到 JS 模块化这个主题，开头也说到是为了构建 scope，实则提供了业务规范标准的输入输出的方式。但文章中的 JS 的模块化还不等于前端工程的模块化，Web 界面是由 HTML、CSS 和 JS 三种语言实现，不论是 CommonJS 还是 AMD 包括之后的方案都无法解决 CSS 与 HTML 模块化的问题。\n对于 CSS 本身它就是 global scope，因此开发样式可以说是喜忧参半。近几年也涌现把 HTML、CSS 和 JS 合并作模块化的方案，其中 react/css-modules 和 vue 都为人熟知。当然，这一点还是非常依赖于 webpack/rollup 等构建工具，让我们意识到在 browser 端还有很多本质的问题需要推进。\n对于 css 模块化，目前不依赖预编译的方式是 styled-component，通过 js 动态创建 class。而目前 css 也引入了与 js 通信的机制 与 原生变量支持。未来 css 模块化也很可能是运行时的，所以目前比较看好 styled-component 的方向。\n对于 html 模块化，小尤最近爆出与 chrome 小组调研 html Modules，如果 html 得到了浏览器，编辑器的模块化支持，未来可能会取代 jsx 成为最强大的模块化、模板语言。\n对于 js 模块化，最近出现的 &lt;script type=&quot;module&quot;&gt; 方式，虽然还没有得到浏览器原生支持，但也是我比较看好的未来趋势，这样就连 webpack 的拆包都不需要了，直接把源代码传到服务器，配合 http2.0 完美抛开预编译的枷锁。\n上述三种方案都不依赖预编译，分别实现了 html、css、js 模块化，相信这就是未来。\n模块化标准推进速度仍然缓慢\n\n2015 年提出的标准，在 17 年依然没有得到实现，即便在 nodejs 端。\n\n这几年 TC39 对语言终于重视起来了，慢慢有动作了，但针对模块标准制定的速度，与落实都非常缓慢，与 javascript 越来越流行的趋势逐渐脱节。nodejs 至今也没有实现 ES2015 模块化规范，所有 jser 都处在构建工具的阴影下。\nHttp 2.0 对 js 模块化的推动\n\njs 模块化定义的再美好，浏览器端的支持粒度永远是瓶颈，http 2.0 正是考虑到了这个因素，大力支持了 ES 2015 模块化规范。\n\n幸运的是，模块化构建将来可能不再需要。随着 HTTP/2 流行起来，请求和响应可以并行，一次连接允许多个请求，对于前端来说宣告不再需要在开发和上线时再做编译这个动作。\n几年前，模块化几乎是每个流行库必造的轮子（YUI、Dojo、Angular），大牛们自己爽的同时其实造成了社区的分裂，很难积累。有了 ES2015 Modules 之后，JS 开发者终于可以像 Java 开始者十年前一样使用一致的方式愉快的互相引用模块。\n不过 ES2015 Modules 也只是解决了开发的问题，由于浏览器的特殊性，还是要经过繁琐打包的过程，等 Import，Export 和 HTTP 2.0 被主流浏览器支持，那时候才是彻底的模块化。\nHttp 2.0 后就不需要构建工具了吗？\n\n看到大家基本都提到了 HTTP/2，对这项技术解决前端模块化及资源打包等工程问题抱有非常大的期待。很多人也认为 HTTP/2 普及后，基本就没有 Webpack 什么事情了。\n\n不过 Webpack 作者 @sokra 在他的文章 webpack &amp; HTTP/2 里提到了一个新的 Webpack 插件 AggressiveSplittingPlugin。简单的说，这款插件就是为了充分利用 HTTP/2 的文件缓存能力，将你的业务代码自动拆分成若干个数十 KB 的小文件。后续若其中任意一个文件发生变化，可以保证其他的小 chunk 不需要重新下载。\n可见，即使不断的有新技术出现，也依然需要配套的工具来将前端工程问题解决方案推向极致。\n模块化是大型项目的银弹吗？\n\n只要遵循了最新模块化规范，就可以使项目具有最好的可维护性吗？ Js 模块化的目的是支持前端日益上升的复杂度，但绝不是唯一的解决方案。\n\n分析下 JavaScript 为什么没有模块化，为什么又需要模块化：这个 95 年被设计出来的时候，语言的开发者根本没有想到它会如此的大放异彩，也没有将它设计成一种模块化语言。按照文中的说法，99 年也就是 4 年后开始出现了模块化的需求。如果只有几行代码用模块化是扯，初始的 web 开发业务逻辑都写在 server 端，js 的作用小之又小。而现在 spa 都出现了，几乎所有的渲染逻辑都在前端，如果还是没有模块化的组织，开发过程会越来越难，维护也是更痛苦。\n文中已经详细说明了模块化的发展和优劣，这里不准备做过多的讨论。我想说的是，在模块化之后还有一个模块间耦合的问题，如果模块间耦合度大也会降低代码的可重用性或者说复用性。所以也出现了降低耦合的观察者模式或者发布/订阅模式。这对于提升代码重用，复用性和避免单点故障等都很重要。说到这里，还想顺便提一下最近流行起来的响应式编程（RxJS），响应式编程中有一个很核心的概念就是 observable，也就是 Rx 中的流（stream）。它可以被 subscribe，其实也就是观察者设计模式。\n补充阅读\n\nJavaScript 模块化七日谈\nJavaScript 模块化编程简史（2009-2016）\n\n总结\n未来前端复杂度不断增加已成定论，随着后端成熟，自然会将焦点转移到前端领域，而且服务化、用户体验越来越重要，前端体验早不是当初能看就行，任何网页的异常、视觉的差异，或文案的模糊，都会导致用户流失，支付中断。前端对公司营收的影响，渐渐与后端服务宕机同等严重，所以前端会越来越重，异常监控，性能检测，工具链，可视化等等都是这几年大家逐渐重视起来的。\n我们早已不能将 javascript 早期玩具性质的模块化方案用于现代越来越重要的系统中，前端界必然出现同等重量级的模块化管理方案，感谢 TC39 制定的 ES2015 模块化规范，我们已经离不开它，哪怕所有人必须使用 babel。\n话说回来，标准推进的太慢，我们还是把编译工具当作常态，抱着哪怕支持了 ES2015 所有特性，babel 依然还有用的心态，将预编译进行到底。一句话，模块化仍在路上。js 模块化的矛头已经对准了 css 与 html，这两位元老也该向前卫的 js 学习学习了。\n未来 css、html 的模块化会自立门户，还是赋予 js 更强的能力，让两者的模块化依附于 js 的能力呢？目前 html 有自立门户的苗头（htmlModules），而 css 迟迟没有改变，社区出现的 styled-component 已经用 js 将 css 模块化得很好了，最新 css 规范也支持了与 js 的变量通信，难道希望依附于 js 吗？这里希望得到大家更广泛的讨论。\n我也认同，毕竟压缩、混淆、md5、或者利用 nonce 属性对 script 标签加密，都离不开本地构建工具。\n据说 http2 的优化中，有个最佳文件大小与数量的比例，那么还是脱离不了构建工具，前端未来会越来越复杂，同时也越来越美好。\n至此，对于 javascript 模块化讨论已接近尾声，对其优缺点也基本达成了一致。前端复杂度不断提高，促使着模块化的改进，代理（浏览器、node） 的支持程度，与前端特殊性（流量、缓存）可能前端永远也离不开构建工具，新的标准会让这些工作做的更好，同时取代、增强部分特征，前端的未来是更加美好的，复杂度也更高。"},"front-end/reading/02-模态框的最佳实践":{"title":"02-模态框的最佳实践","links":[],"tags":[],"content":"Best Practices for Modals / Overlays / Dialog Windows\nModals, Overlays, Dialogs, whatever you call them it’s time to revisit this UI pattern. When they first came on the scene, modal windows were an elegant solution to a UI problem. The first being that it simplifies the UI, the second, it saves screen real estate. Since then designers have readily adopted the modal window and some have taken it to the extreme. Modals have become the today’s version of the dreaded popup window. Users find modals annoying and have been trained to instinctively and automatically dismiss these windows.\nDefinition:\nA modal window is an element that sits on top of an application’s main window. It creates a mode that disables the main window but keeps it visible with the modal window as a child window in front of it. Users must interact with the modal window before they can return to the parent application. — Wikipedia\nUsage\nYou may consider using a modal window when you need to:\nGrab the user’s attention\nUse when you want to interrupt a user’s current task to catch the user’s full attention to something more important.\nNeed user input\nUse when you want to get information from the user. Ex. sign up or login form.\nShow additional information in context.\nUse when you want to show additional information without losing the context of the parent page. Ex. showing larger images or videos.\nShow additional information (not in context)\nUse when you want to show information that is not directly related to the parent page or other options that are “independent” from other pages. Ex. notifications.\n\nNote: Do not use to show error, success, or warning messages. Keep them on the page.\n\nAnatomy of a Modal Window\nPoorly implemented overlays can hinder task completion. To ensure your modal doesn’t get in the way make sure to include the following。\n1. Escape Hatch\nGive users a way to escape by giving them a way to close the modal. This can be achieved in the following ways:\n\nCancel button\nClose button\nEscape key\nClick outside the window\n\n\nAccessibility Tip: each modal window must have a keyboard accessible control to close that window. Ex. escape key should close the window.\n\n2. Descriptive Title\nGive context to the user with the modal title. This allows the user to know where he/she is because they haven’t left the original page.\n\nTip: button label (which launches modal) and modal title should match\n\n3. Button\nButton labels should have actionable, understandable names. This applies to a button in any instance. For modals, a ‘close’ button should be present in the form of a labeled ‘close’ button or an ‘x’.\n\nNote: Don’t make the button labels confusing. If the user is trying to cancel and a modal appears with ANOTHER cancel button, confusion occurs. “Am I cancelling the cancel? Or continuing my cancel?”\n\n4. Sizing &amp; Location\nA modal window should not be too big or too small, you want it juuuuust right. The goal is to keep context, therefore a modal should not take up the whole screen view. Content should fit the modal. If a scrollbar is needed, you may consider creating a new page instead.\n\nLocation — upper half of the screen because in mobile view modal may be lost if placed lower.\nSize — Don’t use more than 50% of the screen for the overlay\n\n5. Focus\nWhen you open a modal use a lightbox effect (darken the background). This draws attention to the modal and indicates that the user cannot interact with the parent page.\n\nAccessibility Tip: put the keyboard focus on the modal\n\n6. User Initiated\nDon’t surprise users by popping up a modal. Let a user’s action, such as a button click, following a link or selecting an option, trigger the modal. Uninvited modals may surprise the user and result in a quick dismissal of the window.\nModals in Mobile\nModals and mobile devices usually don’t play well together. Viewing the content is difficult because modals either are too large, taking up too much screen space or too small. Add in elements like the device keyboard and nested scrollbars; users are left pinching and zooming trying to catch the fields of a modal window. There are better alternatives for modals and shouldn’t be used on mobile devices.\nAccessibility\nKEYBOARD\nWhen creating modals remember to add in keyboard accessibility. Consider the following:\nOpening modal — The element which triggers the dialog must be keyboard accessible\nMoving focus into the Dialog — Once the modal window is open, the keyboard focus needs to be moved to the top of that\nManaging Keyboard Focus — Once the focus is moved into the dialog, it should be “trapped” inside it until the dialog is closed.\nClosing the Dialog — Each overlay window must have a keyboard accessible control to close that window.\nFor more information on the list above check out Nomensa’s blog article\nARIA\nAccessible Rich Internet Applications (ARIA) defines ways to make Web content and Web applications more accessible.\nThe following ARIA tags can be helpful in creating an accessible modal: Role = “dialog” , aria-hidden, aria-label\nfor more information on ARIA, check out Smashing’s Magazine article\nAlso, remember low-vision users. They may use screen magnifiers on monitors to enlarge the screen content. Once zoomed in the user can only see part of the screen. Here modals will have the same effect as they do in mobile.\nConclusion\n\nIf people have been trained to automatically try to close modals, why would you want to use them?\n\nGetting the user’s attention, keeping context and simplifying the UI are great benefits of modals. However, there are downsides as they interrupt the user flow and make it impossible to interact with the parent page by hiding the content behind the modal. Modal may not always be the answer. Consider the following when making your choice:\nChecklist\n\nWhen do we show the modal?\nHow do we show the modal?\nWhat does the modal look like?\nWhat information do we present and collect?\n\nThere is an alternative UI component to modals: non-modal or a.ka. toast (term used by Google in Material Design &amp; Microsoft). Check out my next post to learn more.\n内容概要\n来自 Wikipedia 的定义：模态框是一个定位于应用视窗顶层的元素。它创造了一种模式让自身保持在一个最外层的子视察下显示，并让主视窗失效。用户必须在回到主视窗前在它上面做交互动作。\n模态框用处\n\n抓住用户的吸引力\n需要用户输入\n在上下文下显示额外的信息\n不在上下文下显示额外的信息\n\n不要用模态框显示错误、成功或警告的信息。保持它们在页面上。\n模态框的组成\n\n退出的方式。可以是模态框上的一个按钮，可以是键盘上的一个按键，也可以是模态框外的区域。\n描述性的标题。标题其实给了用户一个上下文信息。让用户知道他现在在哪个位置作操作。\n按钮的内容。它一定要是可行动的，可以理解的。不要试图让按钮的内容让用户迷惑，如果你尝试做一个取消动作，但框内有一个取消的按钮，那么我是要取消一个取消呢，还是继续我的取消。\n大小与位置。模态框的大小不要太大或太小，不应该。模态框的位置建议在视窗中间偏上的位置，因为在移动端如果太低的话会失去很多信息。\n焦点。模态框的出现一定要吸引你的注意力，建议键盘的焦点也切换到框内。\n用户发起。不要对用户造成惊吓。用用户的动作，比如一个按钮的点击来触发模态框的出现。\n\n模态框在移动端\n模态框在移动端总是不是玩转得很好。其中一个原因是一般来说模态框都太大了，占用了太多空间。建议增加设备的按键或内置的滚动条来操作，用户可以左移或放大缩小来抓住模态框。\n无障碍访问\n\n快捷键。我们应该考虑在打开，移动，管理焦点和关闭时增加对模态框的快捷键。\nARIA。在前端代码层面加上 aria 的标识，如 Role = “dialog” , aria-hidden, aria-label\n\n精读\n模态框定位\n首先，Modal 与 Toast、Notification、Message 以及 Popover 都会在某个时间点被触发弹出一个浮层，但与 Modal（模态框）还是有所不同的。定义上看，上述组件都不属于模态框，因为模态框有一个重要的特性，即阻塞原来主视窗下的操作，只能在框内作后续动作。也就是说模态框从界面上彻底打断了用户心流。\n当然，这也是我们需要讨论的问题，如果只是一般的消息提醒，可以用信息条、小红点等交互形式，至少是不阻塞用户操作的。在原文末引用的 10 Guidelines to Consider when using Overlays 一文中，第 8 条强调了模态框不到万不得以不应该使用。这时我们应该思考什么情况下你非常希望他不要离开页面，来读框内的信息或作操作呢？\n反过来说，模态框有什么优点呢？要知道比起页面跳转来说，模态框的体验还是要轻量的多。例如，用户在淘宝上看中了一款商品，想登陆购买，此时弹出登陆模态框的体验就要远远好于跳转到登陆页面，因为用户在模态框中登陆后，就可以直接购买了。其次，模态框的内容对于当前页面来说是一种衍生或补充，可以让用户更为专注去阅读或者填写一些内容。\n也就是说，当我们设计好模态框出现的时机，流畅的弹出体验，必要的上下文信息，以及友好的退出反馈，还是完全可以提升体验的。模态框的目的在于吸引注意，但一定需要提供额外的信息，或是一个重要的用户操作，或是一份重要的协议确认。在本页面即可完成流程或信息告知。\n合理的使用模态框\n我们也总结了一些经验，更好地使用模态框。\n\n内容是否相关。模态框是作为当前页面的一种衍生或补充，如果其内容与当前内容毫不相干，那么可以使用其他操作（如新页面跳转）来替代模态框；\n模态框内部应该避免有过多的操作。模态框应该给用户一种看完即走，而且走的流畅潇洒的感觉，而不是利用繁杂的交互留住或牵制住用户；\n避免出现一个以上的模态框。出现多个模态框会加深了产品的垂直深度，提高了视觉复杂度，而且会让用户烦躁起来；\n不要突然打开或自动打开模态框，这个操作应该是用户主动触发的；\n\n还有两种根据实际情况来定义：\n\n大小。对于模态框的大小应该要有相对严格的限制，如果内容过多导致模态框或页面出现滚动条，一般来说这种体验很糟糕，但如果用于展示一些明细内容，我们可能还是会考虑使用滚动条来做；\n开启或关闭动画。现在有非常多的设计倾向于用动画完成流畅的过渡，让 Modal 变得不再突兀，dribble 上有很多相关例子。但在一些围绕数据来做复杂处理的应用中，如 ERP、CRM 产品中用户通常关注点都在一个表单和围绕表单做的一系列操作，页面来回切换或复杂的看似酷炫的动画可能都会影响效率。用户需要的是直截了当的完成操作，这时候可能就不需要动画，用户想要的就是快捷的响应。\n\n举两个例子，Facebook 在这方面给我们很好的 demo，它的分享模态框与主视窗是在同一个位置，给人非常流畅的体验。还看到一个细节，从主视窗到模态框焦点上的字体会变大。对比微博，它就把照片等分享形式直接展示出来，焦点在输入框上时也没有变化。\n第二个例子是 Quora，Quora 主页呈现的是 Feed 流，点击标题就会打开一个模态框展示它回答的具体内容，内容里面是带有滚动条的，按 ESC 键就可以关闭。非常流畅的体验。相比较之下知乎首页想要快速看内容得来回切换。\n可访问性的反思\nAccessibility 翻译过来是『无障碍访问』，是对不同终端用户的体验完善。每一个模态框，都要有通过键盘关闭的功能，通常使用 ESC 键。似乎我们程序员多少总会把我们自我的惯性思维带进实现的产品，尤其是当我们敲着外置的键盘，用着 PC 的时候。\n下面的这些问题都是对可访问性的反思：\n\n用户可能没有鼠标，或者没有键盘，甚至可能既没有鼠标也没有键盘，只使用的是语音控制？你让这些用户如何退出\n很多的 Windows PC 都已经获得了很好的触屏支持，而你的网页依旧只支持了键盘跟鼠标？\n在没有苹果触摸板的地方，横向滚动条是不是一个逆天的设计？\n在网页里，使用 Command(Ctrl) and +/- 和使用触摸板的缩放事件是两个不同的表现？\n如果你的终端用户没有好用的触摸板，但是他的确看不清你的网页上的内容。如果他用了前者，你能不能保证你的网页依然能够正常展示内容？\n\n可访问性一直都是产品极其忽视的，在文章的最佳实践最后特别强调了它是怎么做的，对我们这些开发者是很好的督促。\n模态框代码实现层面\n前端开发还是少不了代码层面的实现，业务代码对于有状态或无状态模态框的使用方式存在普遍问题。\n对有状态模态框来说，很多库会支持 .show 直接调用的方式，那么模态框内部渲染逻辑，会在此方法执行时执行，没有什么问题。不过现在流行无状态模态框(Stateless Modal)，模态框的显示与否交由父级组件控制，我们只要将模态框代码预先写好，由外部控制是否显示。\n这种无状态模态框的方式，在模态框需要显示复杂逻辑的场景中，会自然将初始化逻辑写在父级，当模态框出现在循环列表中，往往会引发首屏触发 2-30 次模态框初始化运算，而这些运算最佳状态是模态框显示时执行一次，由于模态框同一时间只会出现一个，最次也是首屏初始化一次，但下面看似没问题的代码往往会引发性能危机：\nconst TdElement = data.map(item =&gt; {\n  return (\n    &lt;Td&gt;\n      &lt;Button&gt;详情&lt;/Button&gt;\n      &lt;Modal show={item.show} /&gt;\n    &lt;/Td&gt;\n  )\n});\n上面代码初始化执行了 N 个模态框初始化代码，显然不合适。对于 table 操作列中触发的模态框，所有行都复用同一个模态框，通过父级中一个状态变量来控制展示的内容：\nclass Table extends Component {\n  static state = {\n    activeItem: null, \n  };\n \n  render() {\n    const { activeItem } = this.state;\n \n    return (\n      &lt;div&gt;\n        &lt;Modal show={!!activeItem} data={activeItem} /&gt;\n      &lt;/div&gt;\n    );\n  }\n}\n这种方案减少了节点数，但是可能会带来的问题是，每次模态框被展示的时候，触发是会是模态框的更新 (componentDidUpdate) 而不是新增。当然结合 table 中操作的特点，我们可以这样优化：\n{activeItem ? &lt;Modal show={true} data={activeItem} /&gt; : null}\n\n总结\n这篇讲的是最佳实践，而且是 UX 层面的。但我们还是看到一些同学提出了相反的意见，我总结下就是不同的产品或不同的用户带给我们不同的认识。这时候是不是要死守着『最佳实践』呢？这时候，对于产品而言，我们可以采集用户研究的方法去判断，用数据结论代替感官上的结论。\n另外，可访问性在这两年时不时会在一些文章中看到，但非常少。这是典型的长尾需求，很多研发在做产品只考虑 90% 的用户，不清楚我们放弃的一部分用户的需求。这是从产品到研发整体的思考的缺失。"},"front-end/reading/03-用-JS-实现一个-LRU-缓存":{"title":"03-用 JS 实现一个 LRU 缓存","links":["tags/算法/LRU"],"tags":["算法/LRU"],"content":"用 JS 实现一个 LRU 缓存\nLRU\n前言\nLRU 缓存算法是一个非常经典的算法，在很多面试中经常问道，不仅仅包括前端面试。小伙伴们如果刷过 Leetcode 算法题，相信你一定遇到过 LRU 算法的题，那么 LRU 算法到底是一个怎样的算法呢？今天我们就给大家好好讲讲，顺便使用 JS 把它实现出来！\n1. 什么是 LRU？\nLRU 英文全称是 Least Recently Used，英译过来就是”**最近最少使用“**的意思。 它是页面置换算法中的一种，我们先来看一段百度百科的解释。\n百度百科：\n\nLRU 是一种常用的页面置换算法，选择最近最久未使用的页面予以淘汰。该算法赋予每个页面一个访问字段，用来记录一个页面自上次被访问以来所经历的时间 t，当须淘汰一个页面时，选择现有页面中其 t 值最大的，即最近最少使用的页面予以淘汰。\n\n百度百科解释的比较窄，它这里只使用了页面来举例，我们通俗点来说就是：假如我们最近访问了很多个页面，内存把我们最近访问的页面都缓存了起来，但是随着时间推移，我们还在不停的访问新页面，这个时候为了减少内存占用，我们有必要删除一些页面，而删除哪些页面呢？我们可以通过访问页面的时间来决定，或者说是一个标准：在最近时间内，最久未访问的页面把它删掉。\n百度百科的解释只是单纯的解释算法，而我们这里可以结合我们的前端和实际应用场景来给大家解释一下。\n通俗的解释：\n\n假如我们有一块内存，专门用来缓存我们最近发访问的网页，访问一个新网页，我们就会往内存中添加一个网页地址，随着网页的不断增加，内存存满了，这个时候我们就需要考虑删除一些网页了。这个时候我们找到内存中最早访问的那个网页地址，然后把它删掉。\n这一整个过程就可以称之为 LRU 算法。\n\n虽然上面的解释比较好懂了，但是我们还有很多地方没有考虑到，比如如下几点：\n\n当我们访问内存中已经存在了的网址，那么该网址是否需要更新在内存中的存储顺序。\n当我们内存中还没有数据的时候，是否需要执行删除操作。\n\nLRU 算法就是我们往内存里面添加或者删除元素的时候，遵循最近最少使用原则。\n2. 使用场景\nLRU 算法使用的场景非常多，这里简单举几个例子即可：\n\n我们操作系统底层的内存管理，其中就包括有 LRU 算法\n常见的缓存服务，比如 redis 等等\n比如浏览器的最近浏览记录存储\n\n总之 LRU 算法的运用场景还是蛮多的，所以我们很有必要掌握它。\n3. 梳理实现 LRU 思路\n我们学习了 LRU 算法的基本概念和使用场景之后，那么我们就应该考虑如何实现它了。要想实现一个算法，我们很有必要梳理一下思路，这样才能让我们更好更快的编写出代码。\n首先我们来梳理一下 LRU 算法的特点。\n特点分析：\n\n我们需要一块有限的存储空间，因为无限的化就没必要使用 LRU 算法删除数据了。\n我们这块存储空间里面存储的数据需要是有序的，因为我们必须要顺序来删除数据，所以可以考虑使用 Array、Map 数据结构来存储，不能使用 Object，因为它是无序的。\n我们能够删除或者添加以及获取到这块存储空间中的指定数据。\n存储空间存满之后，在添加数据时，会自动删除上一次读取时间最久远的那条数据。\n\n实现需求：\n\n实现一个 LRUCache 类型，用来充当存储空间\n采用 Map 数据结构存储数据，因为它的存取时间复杂度为 O(1)，数组为 O(n)\n实现 get 和 set 方法，用来获取和添加数据\n我们的存储空间有长度限制，所以无需提供删除方法，存储满之后，自动删除最久远的那条数据\n当使用 get 获取数据后，该条数据需要更新到最前面\n\n现在我们已经把 LRU 算法的特点以及实现思路列了出来，那么接下来就然我们一起去实现它吧！\n4. 具体实现\n首先我们定义一个 LRUCache 类，封装所有的方法和变量。\nclass LRUCache {\n    constructor(lenght) {\n        this.length = lenght; // 存储长度\n        this.data = new Map(); // 存储数据\n    }\n    // 存储数据，通过键值对的方式\n    set(key, value) {\n        const data = this.data;\n        if (data.has(key)) {\n            data.delete(key)\n        }\n        data.set(key, value);\n \n \n        // 如果超出了容量，则需要删除最久的数据\n        if (data.size &gt; this.length) {\n            const delKey = data.keys().next().value;\n            data.delete(delKey);\n        }\n    }\n    // 获取数据\n    get(key) {\n        const data = this.data;\n        // 未找到\n        if (!data.has(key)) {\n            return null;\n        }\n        const value = data.get(key); // 获取元素\n        data.delete(key); // 删除元素\n        data.set(key, value); // 重新插入元素\n    }\n}\nconst lruCache = new LRUCache(5);\n\nset 方法：往 map 里面添加新数据，如果添加的数据存在了，则先删除该条数据，然后再添加。如果添加数据后超长了，则需要删除最久远的一条数据。data.keys().next().value 便是获取最后一条数据的意思。\nget 方法：首先从 map 对象中拿出该条数据，然后删除该条数据，最后再重新插入该条数据，确保将该条数据移动到最前面。\n\n\n这里主要的一点就是，Map 会存储每个元素的插入顺序，那么直接可以通过 data.keys() 拿到数据插入顺序的键；\n\n总结\nLRU 算法其实逻辑非常的简单，明白了原理之后实现起来非常的简单。最主要的是我们需要使用什么数据结构来存储数据，因为 map 的存取非常快，所以我们采用了它，当然数组其实也可以实现的。还有一些小伙伴使用链表来实现 LRU，这当然也是可以的。"},"front-end/reading/04-关于-V8-中-Map-数据结构的实现":{"title":"理解 Map 内部实现","links":["cant/hot-code"],"tags":[],"content":"Understanding Map Internals 理解 Map 内部实现\n前言\nWith this blog post, I am starting V8 Deep Dives series dedicated to my experiments and findings in V8, which is, no doubt, a well-engineered and sophisticated software. Hopefully, you will find this blog post valuable and share your ideas for the next topic.\nECMAScript 2015，也被称为 ES6，其引入了许多内置的集合类型，例如 Map，Set，WeakMap 及 WeakSet。它们似乎是 JS 标准库的优秀补充，并在库、应用程序和 Node.js 核心中被广泛采用。今天我们将专注于 Map，并尝试理解 V8 的实现细节，同时得出一些实际的结论。\nThe spec does not dictate a precise algorithm used to implement Map support, but instead gives some hints for possible implementations and expected performance characteristics:\n该规范没有规定用于实现 Map 支持的精确算法，而是给出了一些可能实现和预期性能特征的提示：\n\nMap object must be implemented using either hash tables or other mechanisms that, on average, provide access times that are sublinear on the number of elements in the collection. The data structures used in this Map objects specification is only intended to describe the required observable semantics of Map objects. It is not intended to be a viable implementation model.\n\nAs we see here, the spec leaves a lot of room for each implementer, i.e., JS engine, but does not give a lot of certainty on the exact algorithm, its performance, or memory footprint of the implementation. If your application deals with Maps on its hot path or you store a lot of data in a Map, such details may be certainly of great help.\n正如我们在这里看到的，规范为每个实现者(即 JS 引擎)留下了很大的空间，但没有给出关于确切的算法、性能或实现的内存占用的很多确定性。如果您的应用程序在其热点路径上处理 Map，或者您在 Map 中存储了大量数据，那么这些细节肯定会有很大帮助。\nAs a developer with a Java background, I got used to Java collections, where one can choose between multiple implementations of Map interface and even fine-tune it if the selected class supports that. Moreover, in Java it is always possible to the open source code of any class from the standard library and get familiar with the implementation (which, of course, may change across versions, but only in a more efficient direction). So, that is why I could not stand not to learn how Maps work in V8.\n作为一个有着 Java 背景的开发者，我习惯了 Java 集合，在 Java 中可以选择多个 Map 接口的实现，甚至可以在所选类支持的情况下进行微调。此外，在 Java 中，总是可以查看标准库中任何类的开源代码，并熟悉其实现（当然，这些实现可能会随着版本的更新而改变，但只会变得更高效）。因此，这就是为什么我无法忍受不去了解 V8 中 Maps 的工作原理。\nNow, let’s start the dive.\n现在，让我们开始深入。\nDisclaimer. What’s written below is implementation details specific to V8 8.4 bundled with a recent dev version of Node.js (commit 238104c to be more precise). You should not expect any behavior beyond the spec.\n在开始之前，我想指出的是，下面将要讨论的是 V8 8.4 引擎，该引擎内置在 Node.js 的最新开发版本中（更确切地说，我们正在谈论 commit 238104c）。您无需期望超出规范。\n底层算法\nFirst of all, Maps in V8 are built on top of hash tables. The subsequent text assumes that you understand how hash tables work. If you are not familiar with the concept, you should learn it first (e.g., by reading this wiki page) and then return here.\n首先，V8 中的 Maps 是基于哈希表构建的。接下来的内容假设你已经了解哈希表的工作原理。如果你不熟悉这个概念，应该先学习它（例如，通过阅读对应的维基页面），然后再回来阅读本文。\nIf you have substantial experience with Maps, you might already notice a contradiction here. Hash tables do not provide any order guarantees for iteration, while ES6 spec requires implementations to keep the insertion order while iterating over a Map. So, the “classical” algorithm is not suitable for Maps. But it appears that it is still possible to use it with a slight variation.\n如果你有丰富的 Maps 使用经验，可能已经注意到这里的一个矛盾。哈希表在迭代时不提供任何顺序保证，而 ES6 规范要求实现必须在迭代 Map 时保持插入顺序。因此，“经典”的算法不适用于 Maps。但看起来，通过一些小的变动，仍然可以使用它。\nV8 uses the so-called deterministic hash tables algorithm proposed by Tyler Close. The following TypeScript-based pseudo-code shows main data structures used by this algorithm:\nV8 使用了 Tyler Close 提出的所谓 deterministic hash tables algorithm（确定性哈希表算法）。以下基于 TypeScript 的伪代码展示了该算法使用的主要数据结构：\ninterface Entry {\n  key: any;\n  value: any;\n  chain: number;\n}\n \ninterface CloseTable {\n  hashTable: number[];\n  dataTable: Entry[];\n  nextSlot: number;\n  size: number;\n}\nHere CloseTable interface stands for the hash table. It contains hashTable array, which size is equal to the number of buckets. The Nth element of the array stands for the Nth bucket and holds an index of the bucket’s head element in the dataTable array. In its turn, dataTable array contains entries in the insertion order. Finally, each Entry has chain property, which points to the next entry in the bucket’s chain (or singly linked list, to be more precise).\n在这个代码中，CloseTable接口代表哈希表。它包含一个hashTable数组，其大小等于桶的数量，数组的第 N 个元素代表第 N 个桶，并保存该桶的头部元素在dataTable数组中的索引。dataTable数组按插入顺序存储 entry。最后，每个Entry都有一个chain属性，指向桶链（或者更确切地说是单链表）中的下一个 entry。\n\n这里桶可能一开始不好理解，很抽象。\n它是由 dataTable 中的实际存储的 entry 组成的链表，在上述的实际的数据结构中，并没有体现出来。\n每个桶都是一个链表的起点，链表中的每个节点（即entry）存储在dataTable中。每个entry有一个chain属性，这个属性指向同一桶中的下一个条目，从而形成一个链表。\n\nEach time when a new entry is inserted into the table, it is stored in the dataTable array under the nextSlot index. This process also requires an update in the chain of the corresponding bucket, so the inserted entry becomes the new tail.\n每次插入一个新 entry 时，它会存储在dataTable数组的nextSlot索引处。这个过程还需要更新相应桶链的链条，以便插入的entry成为单链表的新的最后一个元素。\nWhen an entry is deleted from the hash table, it is removed from the dataTable (e.g., by setting both key and value to undefined). As you might notice, this means that all deleted entries still occupy space in the dataTable.\n从哈希表中删除 entry 时，会将其从dataTable中删除（例如，通过写入其属性key和value值undefined）。您可能已经注意到，这意味着所有已删除的 entries 继续占据dataTable中的空间。\nAs the last piece of the puzzle, when a table gets full of entries (both present and deleted), it needs to be rehashed (rebuilt) with a bigger (or smaller) size.\n最后，当表中充满了 entries（包括现存的和已删除的），它需要通过重新哈希（重建）来调整为更大（或更小）的空间大小。\nWith this approach, iteration over a Map is just a matter of looping through the dataTable. That guarantees the insertion order requirement for iteration. Considering this, I expect most JS engines (if not all of them) to use deterministic hash tables as the building block behind Maps.\n通过这种方法，迭代一个 Map 只是循环遍历dataTable数组的问题。这保证了迭代时的插入顺序要求。考虑到这一点，我预计大多数（如果不是全部）JS 引擎都会使用确定性哈希表作为 Maps 背后的构建机制。\nAlgorithm in Practice 算法实践\nLet’s go through more examples to see how the algorithm works. Say, we have a CloseTable with 2 buckets (hashTable.length) and total capacity of 4 (dataTable.length) and the hash table is populated with the following contents:\n让我们通过更多示例来看看该算法如何工作。假设我们有一个包含 2 个桶（hashTable.length）的CloseTable，总容量为 4（dataTable.length），哈希表填充了以下内容：\n// let&#039;s assume that we use identity hash function,\n// i.e. function hashCode(n) { return n; }\ntable.set(0, &quot;a&quot;); // =&gt; bucket 0 (0 % 2)\ntable.set(1, &quot;b&quot;); // =&gt; bucket 1 (1 % 2)\ntable.set(2, &quot;c&quot;); // =&gt; bucket 0 (2 % 2)\n\n插入时：\n\n计算键的哈希码并确定桶的索引。\n检查该桶是否已有条目，如果有，则通过链找到链尾并添加新条目。\n更新dataTable和hashTable，并在dataTable中存储新条目。\n如果容量超过负载因子，进行重新哈希。\n\n以下是伪代码实现：\nfunction set(table: CloseTable, key: any, value: any) { \n    let index = hashCode(key) % table.hashTable.length; \n    let newEntry: Entry = { key, value, chain: null }; \n    if (table.hashTable[index] === null) { \n        table.hashTable[index] = table.nextSlot; \n    } else { \n        let current = table.hashTable[index]; \n        while (table.dataTable[current].chain !== null) { \n            current = table.dataTable[current].chain; \n        } \n        table.dataTable[current].chain = table.nextSlot; \n    } \n    table.dataTable[table.nextSlot] = newEntry; \n    table.nextSlot++; \n    if (table.nextSlot &gt;= table.dataTable.length / 2) { \n        rehash(table); \n    } \n}\n\nIn this example, the internal table representation can be expressed like the following:\n在这个例子中，内部表表示可以如下表达：\nconst tableInternals = {\n  hashTable: [0, 1],\n  dataTable: [\n    {\n      key: 0,\n      value: &quot;a&quot;,\n      chain: 2, // index of &lt;2, &#039;c&#039;&gt;\n    },\n    {\n      key: 1,\n      value: &quot;b&quot;,\n      chain: -1, // -1 means tail entry\n    },\n    {\n      key: 2,\n      value: &quot;c&quot;,\n      chain: -1,\n    },\n    // empty slot\n  ],\n  nextSlot: 3, // points to the empty slot\n  size: 3,\n};\n\n删除时：\n\n计算键的哈希码并确定桶的索引。\n遍历桶链，找到目标条目并将其标记为已删除（通常通过将其从链中移除）。\n\n以下是伪代码实现：\nfunction deleteEntry(table: CloseTable, key: any) {\n let index = hashCode(key) % table.hashTable.length;\n let current = table.hashTable[index];\n let prev = null;\n \n while (current !== null) {\n   if (table.dataTable[current].key === key) {\n     if (prev === null) {\n       table.hashTable[index] = table.dataTable[current].chain;\n     } else {\n       table.dataTable[prev].chain = table.dataTable[current].chain;\n     }\n     break;\n   }\n   prev = current;\n   current = table.dataTable[current].chain;\n }\n}\n\nIf we delete an entry by calling table.delete(0), the table turns into this one:\n如果我们通过调用table.delete(0)删除一个 entry，表会变成这样：\nconst tableInternals = {\n  hashTable: [0, 1],\n  dataTable: [\n    {\n      key: undefined, // deleted entry\n      value: undefined,\n      chain: 2,\n    },\n    {\n      key: 1,\n      value: &quot;b&quot;,\n      chain: -1,\n    },\n    {\n      key: 2,\n      value: &quot;c&quot;,\n      chain: -1,\n    },\n    // empty slot\n  ],\n  nextSlot: 3,\n  size: 2, // new size\n};\nIf we insert two more entries, the hash table will require rehashing. We will discuss this process in more detail a bit later.\n如果我们将更多记录添加到表中，则需要对其重新进行哈希处理。我们将在下面详细讨论此过程。\nThe same algorithm can be applied to Sets. The only difference is that Set entries do not need value property.\n实现Set数据结构时可以应用相同的方法。唯一的区别是Set的entries不需要属性value。\nNow, when we have an understanding of the algorithm behind Maps in V8, we are ready to take a deeper dive.\n现在我们已经弄清了 V8 中的Map背后的算法，已经准备进一步深入了。\nImplementation Details 实现细节\nThe Map implementation in V8 is written in C++ and then exposed to JS code. The main part of it is defined in OrderedHashTable and OrderedHashMap classes. We already learned how these classes work, but if you want to read the code yourself, you may find it here, here, and, finally, here.\nV8 中Map的实现是用 C++ 编写的，允许 JS 代码访问相应的机制。与之相关的大多数代码Map在OrderedHashTable和OrderedHashMap类中。我们已经知道这些类如何工作。如果您想自己看看他们的代码，那么可以在这里，这里和这里找到。\nAs we are focused on the practical details of V8’s Map implementation, we need to understand how table capacity is selected.\n由于我们专注于 V8 中Map的实现的实际细节，因此我们首先需要了解如何设置表的容量。\nCapacity 容量\nIn V8, hash table (Map) capacity is always equal to a power of two. As for the load factor, it is a constant equal to 2, which means that max capacity of a table is 2 * number_of_buckets. When you create an empty Map, its internal hash table has 2 buckets. Thus the capacity of such a Map is 4 entries.\n在 V8 中，哈希表（Map）的容量总是等于 2 的幂。至于负载因子，它是一个常数，等于 2，这意味着表的最大容量是2 * number_of_buckets。当你创建一个空的 Map 时，它的内部哈希表有 2 个桶。因此，这样一个 Map 的容量是 4 个entries。\nThere is also a limit for the max capacity. On a 64-bit system that number would be 2²⁷, which means that you can not store more than around 16.7M entries in a Map. This restriction comes from the on-heap representation used for Maps, but we will discuss this aspect a bit later.\n还有一个最大容量限制。在 64 位系统上，这个数字是 2²⁷，这意味着你不能在一个 Map 中存储超过大约 1670 万个条目。这一限制来自于 Map 使用的堆内表示，但我们稍后会讨论这一方面。\nFinally, the grow/shrink factor used for rehashing is equal to 2. So, as soon as a Map gets 4 entries, the next insert will lead to a rehashing process where a new hash table of a twice as big (or less) size will be built.\n最后，用于重新哈希的增长/缩减因子等于 2。因此，一旦一个 Map 达到 4 个entries，下一次插入将导致重新哈希过程，其中将构建一个容量大一倍（或更小）的新哈希表。\nTo have a confirmation of what may be seen in the source code, I have modified V8 bundled in Node.js to expose the number of buckets as a custom buckets property available on Maps. You may find the result here. With this custom Node.js build we can run the following script:\n为了确认这些在源代码中看到的内容，我修改了 Node.js 中捆绑的 V8，使其在 Map 上通过自定义buckets属性公开桶的数量。你可以在此处找到结果。使用这个自定义的 Node.js 构建，我们可以运行以下脚本：\nconst map = new Map();\nlet prevBuckets = 0;\nfor (let i = 0; i &lt; 100; i++) {\n  if (prevBuckets !== map.buckets) {\n    console.log(`size: ${i}, buckets: ${map.buckets}, capacity: ${map.buckets * 2}`);\n    prevBuckets = map.buckets;\n  }\n  map.set({}, {});\n}\nThe above script simply inserts 100 entries into an empty Map. It produces the following output:\n上述的脚本简单的插入 100 个 entries 到空的 Map 中。以下是脚本的输出：\n$ ./node /home/puzpuzpuz/map-grow-capacity.js\nsize: 0, buckets: 2, capacity: 4\nsize: 5, buckets: 4, capacity: 8\nsize: 9, buckets: 8, capacity: 16\nsize: 17, buckets: 16, capacity: 32\nsize: 33, buckets: 32, capacity: 64\nsize: 65, buckets: 64, capacity: 128\nAs we see here, the Map grows as a power of two when map capacity is reached. So, our theory is now confirmed. Now, let’s try to shrink a Map by deleting all items from it:\n正如我们所看到的，当表被填充到容量上限时，它都会增加 2 倍。所以我们的观点现在被确定了。现在，让我们尝试通过从表中删除元素来缩小表的大小：\nconst map = new Map();\nfor (let i = 0; i &lt; 100; i++) {\n  map.set(i, i);\n}\nconsole.log(\n  `initial size: ${map.size}, buckets: ${map.buckets}, capacity: ${\n    map.buckets * 2\n  }`\n);\n \nlet prevBuckets = 0;\nfor (let i = 0; i &lt; 100; i++) {\n  map.delete(i);\n  if (prevBuckets !== map.buckets) {\n    console.log(\n      `size: ${map.size}, buckets: ${map.buckets}, capacity: ${map.buckets * 2}`\n    );\n    prevBuckets = map.buckets;\n  }\n}\nThis script produces the following output:\n这是此脚本将输出的内容：\n$ ./node /home/puzpuzpuz/map-shrink-capacity.js\ninitial size: 100, buckets: 64, capacity: 128\nsize: 99, buckets: 64, capacity: 128\nsize: 31, buckets: 32, capacity: 64\nsize: 15, buckets: 16, capacity: 32\nsize: 7, buckets: 8, capacity: 16\nsize: 3, buckets: 4, capacity: 8\nsize: 1, buckets: 2, capacity: 4\nAgain, we see that the Map shrinks as a power of two, once there are fewer remaining entries than number_of_buckets / 2.\n在这里，我们可以再次看到，一旦表中的剩余元素少于 number_of_buckets / 2时，表的大小都会以 2 的幂进行收缩。\nHash Function 哈希函数\nSo far, we did not discuss how V8 calculates hash codes for keys stored in Maps, while this is a good topic.\n到目前为止，我们还没有涉及 V8 如何为存储在 Map 中的键计算哈希码的问题。这是一个不错的话题。\nFor number-like values (Smis and heap numbers, BigInts, and other similar internal stuff), it uses one or another well-known hash function with low collision probability.\n对于类数字值（Smis 和堆数字、BigInts 以及其他类似的内部内容），它使用一种或另一种众所周知的哈希函数，这些函数具有低碰撞概率。\nFor string-like values (strings and symbols), it calculates hash code based on the string contents and then caches it in the internal header.\n对于类字符串值（字符串和符号），它根据字符串内容计算哈希码，然后将其缓存到内部头部中。\nFinally, for objects, V8 calculates the hash code based on a random number and then caches it in the internal header.\n最后，对于对象，V8 根据一个随机数计算哈希码，然后将其缓存到内部头部中。\nTime Complexity 时间复杂度\nMost Map operations, like set or delete, require a lookup. Just like with the “classical” hash table, the lookup has O(1) time complexity.\n大多数 Map 操作（如set或delete）都需要查找。与“经典”哈希表一样，查找的时间复杂度为 O(1)。\nLet’s consider the worst-case when the table has N out of N entries (it is full), all entries belong to a single bucket, and the required entry is located at the tail. In such a scenario, a lookup requires N moves through the chain elements.\n让我们考虑最坏的情况：表中有 N 个entries（已满），所有条目都属于一个桶，而所需的entry位于链表的尾部。在这种情况下，查找需要通过链表元素进行 N 次移动。\nOn the other hand, in the best possible scenario when the table is full, but each bucket has 2 entries, a lookup will require up to 2 moves.\n另一方面，在最好的情况下，当表已满但每个桶只有 2 个entries时，查找最多需要进行 2 次移动。\nIt is a well-known fact that while individual operations in hash tables are “cheap”, rehashing is not. Rehashing has O(N) time complexity and requires allocation of the new hash table on the heap. Moreover, rehashing is performed as a part of insertion or deletion operations, when necessary. So, for instance, a map.set() call could be more expensive than you would expect. Luckily, rehashing is a relatively infrequent operation.\n众所周知，虽然哈希表中的单个操作“廉价”，但重新哈希却不是。重新哈希的时间复杂度为 O(N)，并且需要在堆上分配新的哈希表。此外，重新哈希作为插入或删除操作的一部分，在必要时执行。因此，例如，map.set()调用可能比你预期的更昂贵。幸运的是，重新哈希是相对不频繁的操作。\nMemory Footprint 内存占用\nOf course, the underlying hash table has to be somehow stored on the heap, in a so-called “backing store”. And here comes another interesting fact. The whole table (and thus, Map) is stored as a single array of fixed length. The array layout may be illustrated with the below diagram.\n当然，底层哈希表必须以某种方式存储在堆上的一个所谓的“后备存储”中。这里有一个有趣的事实。整个表（以及 Map）作为一个固定长度的单一数组存储。数组的布局可以通过下面的图示来说明。\n\nSpecific fragments of the backing store array correspond to the header (contains necessary information, like bucket count or deleted entry count), buckets, and entries. Each entry of a bucket chain occupies three elements of the array: one for the key, one for the value, and one for the “pointer” to the next entry in the chain.\n后备存储数组的特定片段对应于头部（包含必要的信息，如桶数量或已删除entries数量）、桶和 entries。桶链的每个entry占据数组中的三个元素：一个用于键，一个用于值，一个用于指向链中下一个entry的“指针”。\nAs for the array size, we can roughly estimate it as N * 3.5, where N is the table capacity. To have an understanding of what it means in terms of memory footprint, let’s assume that we have a 64-bit system, and pointer compression feature of V8 is disabled. In this setup, each array element requires 8 bytes, and a Map with the capacity of 2²⁰ (~1M) should take around 29 MB of heap memory.\n至于数组大小，我们可以大致估算为N * 3.5，其中N是表的容量。为了理解这在内存占用方面的意义，假设我们有一个 64 位系统，并且 V8 的 指针压缩 功能被禁用。在这种设置下，每个数组元素需要 8 字节，而一个容量为 2²⁰（约 100 万个条目）的 Map 大约需要 29 MB 的堆内存。\n\n估算方法如下：\n\nN 个桶，每个桶占用 3 个数组元素（一个键、一个值、一个指针）。\n头部占用的额外空间可以忽略不计。\n\n因此，总的数组元素数大约为N * 3.5 ，每个元素 8 字节，总内存占用约为N * 3.5 * 8字节。对于 N = 2²⁰，这意味着： 2^{20}×3.5×8=2^{20}×28=2^{20}×2^{5}=2^{25} 字节=32MB。\n所以，更精确地说，大约需要 28MB 到 32MB 之间的内存。\n\nSummary 总结\nGosh, that was a long journey. To wraps things up, here is a shortlist of what we have learned about Maps in V8:\n天啊，这真是一段漫长的旅程。总结一下，我们已经了解了关于 V8 中 Maps 的内容：\n\nV8 uses deterministic hash table algorithm to implement Maps, and it is very likely that other JS engines do so.\nMaps are implemented in C++ and exposed via JS API.\nJust like with “classical” hash maps, lookups required for Map operations are O(1) and rehashing is O(N).\nOn a 64-bit system, when pointer compression is disabled, a Map with 1M entries occupies ~29 MB on the heap.\nMost of the things described in this blog post can also be applied to Sets.\n\n\nV8 使用确定性哈希表算法来实现 Maps，很可能其他 JS 引擎也是如此。\nMaps 用 C++实现，通过 JS API 暴露出来。\n就像“经典”哈希表一样，Map 操作所需的查找是 O(1)的，重新哈希是 O(N)的。\n在 64 位系统上，当指针压缩被禁用时，一个包含 100 万个条目的 Map 在堆上占用大约 29MB 的内存。\n本文中描述的大部分内容也适用于 Sets。\n\nThat’s it for this time. Please share your ideas for the next V8 Deep Dive.\n这次就到这里。请分享你对下一次 V8 深度探讨的想法。"},"front-end/vite/README":{"title":"README","links":[],"tags":[],"content":"vite 是新兴的构建工具，它相比 webpack 最大的特点就是快。\n那它是如何做到这么快的呢？\n因为 vite 在开发环境并不做打包。\n我们创建个 vite 项目：\nnpx create-vite\n安装依赖，然后把服务跑起来：\nnpm install\nnpm run dev\n浏览器访问下，本地是 main.tsx 引入了 App.tsx，并且还有 react 和 react-dom/client 的依赖；\n打开浏览器的控制台，可以看到，main.tsx、App.tsx 还有 react 和 react-dom/client 的依赖都是直接引入的，做了编译，但是并没有打包。\n这是基于浏览器的 type 为 module 的 script 实现的：\n&lt;srcipt type=&quot;module&quot; src=&quot;/src/main.tsx&quot;&gt;&lt;/script&gt; \n当然，正常的 js 文件没有做编译，如果有 ts 或者 jsx 的语法，需要做一次编译。\n那我们是不是可以起个服务器，请求的时候根据 url 找到对应的文件，编译之后返回呢？\n没错，如果你这样想了，那你也可以写一个 vite。\nvite 在开发环境下就是起了一个做编译的服务器，根据请求的 URL 找到对应的模块做编译之后返回。\n当你执行 npm run dev 时，vite 会跑一个开发服务：\nconst server = await createServer({\n\troot, \n\tbase: options.base, \n\tmode: options.mode, \n\tconfigFile: options.config, \n\tlogLevel: options.logLevel, \n\tclearScreen: options.clearScreen, \n\toptimizeDeps: { force: options.force }, \n\tserver: cleanOptions(options),\n});\nif (!server.httpServer) { \n\tthrow new Error(&#039;HTTP server not available&#039;);\n}\nawait server.listen():\n这个开发服务是基于 connect 实现的，vite 给它加了很多中间件来处理请求，如：\n\nviteHtmlFallbackMiddleware\nviteServeStaticMiddleware\nviteTransformMiddleware\n\n当你请求 index.html 的时候，它会通过 Dom 树遍历，找到其中所有的 script：\nexport async function traverseHtml(html, filePath, visitor)\n\t// lazy load compiler\n\tconst { parse } = await import(&#039;parse5&#039;); \n\tconst ast = parse(html, {\n\t\tscriptingEnabled: false,\n\t\tsourceCodeLocationInfo: true,\n\t\tonParseError: (e) =&gt; {\n\t\t\thandleParseError(e, html, filePath); \n\t\t},\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\ttraverseNodes(ast, visitor);\n\t}\n}\n然后提前对这些文件做编译：\nif (preTransformUrl) {\n\t// &#039;/src/main.tsx&#039;\n\tpreTransformRequest(server, preTransformUrl, config.base);\n}\n编译是通过不同插件完成的：\nfor (const plugin of getSortedPlugins(&#039;transform&#039;))  {\n\tif(closed &amp;&amp; !ssr)\n\t\tthrowClosedServerError();\n\tif (!plugin.transform) \n\t\tcontinue;\n\tctx._activePlugin = plugin;\n\tctx._activeId = id;\n\tctx._activeCode = code;\n\tconst start = debugPluginTransform ? performance.now() : 0; \n\tlet result;\n\tconst handler = getHookHandler(plugin.transform);\n\ttry {\n\t\tresult = \n\t\t\tawait handleHookPromise(handler.call(ctx, code, id, { ssr }));\n\t} \n// ...\n}\n插件就是一个对象，它导出了 transform 方法的话，就会在 transform 的时候被调用。如 css 插件来编译 css、esbuild 插件来编译 ts/js 等。\n每个插件都会判断下，只处理对应的资源：\nasync transform(raw, id) {\n\tif (!isCSSRequest(id) || \n\t\tcommonjsProxyRE.test(id) || \n\t\tSPECIAL_QUERY_RE.test(id)) { \n\t\treturn;\n\t}\n\t// ...\n}\nasync transform(code, id, options) {\n\tif (id.includes(&quot;/node_modules/&quot;))\n\t\treturn;\n\tconst [filepath] = id.split(&quot;?&quot;);\n\tif (!filter(filepath))\n\t\treturn;\n\t}\n\t// ...\n}\n比如 vite:esbuild 插件，就是对 js/ts 做编译，然后返回编译后的 code 和 sourcemap：\nasync transform(code, id) {\n\tif (filter(id) || filter(cleanUrl(id))) {\n\tconst result = await transformWithEsbuild(code, id, transformOptions);\n\tif (result.warnings.length) {\n\t\tresult.warnings.forEach((m) =&gt; {\n\t\t\tthis.warn(prettifyMessage(m, code));\n\t\t});\n\tif (jsxInject &amp;&amp; jsxExtensionsRE.test(id)) { \n\t\tresult.code = jsxInject + &#039;;&#039; + result.code;\n\t}\n\treturn { \n\t\tcode: result.code,\n\t\tmap: result.map,\n\t}\n}\n还有个 import-anlysis 插件，在 esbuild 完成编译之后，分析模块依赖，继续处理其它模块的 transform。\n这样，浏览器只要访问了 index.html，那么你依赖的所有的 js 模块，就都给你编译了。\n这就是 vite 为什么叫 no bundle 方案，它只是基于浏览器的 module import，在请求的时候对模块做下编译。\n但不知道大家有没有想过一个问题：\n浏览器支持 es module 的 import，那如果 node_modules 下的依赖有用 commonjs 模块规范的代码呢？\n是不是就不行了？\n这种就需要提前做一些转换，把 commonjs 转成 import。\n还有一个问题，如果每个模块都是请求时编译，那向 lodash-es 这种包，它可是有几百个模块的 import 呢：\n这样跑起来，一个 node_modules 下的包就有几百个请求，依赖多了以后，很容易就几千个请求。\n这谁受的了？\n所以我们要提前处理下，不但要把 node_modules 下代码的 commonjs 提前转成 es module，还有提前对这些包做一次打包，变成一个 es module 模块。\n所以，vite 加了一个预构建功能 pre bunle。\n在启动完开发服务器的时候，就马上对 node_modules 下的代码做打包，这个也叫 deps optimize，依赖优化。\n如何优化呢？\n首先，扫描出所有的依赖来，这一步是用 esbuild 做的：\nreturn await esbuild.context({\n\tabsWorkingDir: process.cwd(), \n\twrite: false, \n\tstdin: {\n\t\tcontents: entries.map((e) =&gt; `import·${JSON.stringify(e)}`).join(&#039;\\n&#039;),\n\t\tloader: &#039;js&#039;,\n\t},\n\tbundle: true,\n\tformat: &#039;esm&#039;,\n\tlogLevel: &#039;silent&#039;,\n\tplugins: [...plugins, plugin],.\n\t..esbuildoptions,\n\ttsconfigRaw,\n});\nesbuild.context 和 esbuild.build 差不多的功能。\n可以看到，用 esbuild 对入口 index.html 开始做打包，输出格式为 esm，但是 write 为 false，不写入磁盘。\n有同学说，esbuild 支持 import html 么？\n这里用到了一个 esbuildScanPlugin，vite 实现的，用来记录依赖的，它会在每种模块路径解析的时候做处理，其中支持了 html 的处理。\n这样用 esbuild 处理完一遍，是不是就知道预打包哪些包了？\n从每个依赖包作为入口打包，输出 esm 格式的模块到 node_modules/.vite 下。\n之后还会生成一个 _metadata.json 文件写入 node_modules/.vite 下。\n这个 metadata.json 是干啥的呢？\n其中包含了项目配置依赖的 hash 以及每个依赖快照的 hash。\nvite 会在这些预打包的模块后加一个 query 字符串带上 hash，然后用 max-age 强缓存。\n因为这些依赖一般不会变，不用每次都请求，强缓存就行。\n但是在 lock 文件变化或者 config 有一些变化的时候也需要重新 build。\n重新预编译，然后在资源请求时带上新的 query，这样就让强缓存失效了。\n这里强缓存的用法很典型，面试官们可以记一下作为考点。\n这样，vite 的开发服务的请求时编译，再就是预构建就都完成了。\n有的同学可能会问，为啥预构建要用 esbuild 呢？\nvite 在 dev 时的核心原理我们理清了，但是在 build 的时候总要打包的吧。\n那肯定，在 build 的时候 vite 会用 rollup 做打包。\n那不会导致开发时的代码和生产环境不一致么？\n不会。\n能做到这一点也很巧妙。\n看下 build 时的 rollup 插件，对比下 dev 时跑的 vite 插件，没错，vite 插件时兼容 rollup 插件的，这样在开发的时候，在生产环境打包的时候，都可以用同样的插件对代码做 transform 等处理。\n处理用的插件都一样，又怎么会开发和生产不一致呢？\n这也是 vite 的巧妙之处。\n在 dev 的时候，它实现了一个 PluginContainer，用和 rollup 插件同样的参数来调用 vite 插件，然后 build 的时候，可以把这些插件直接作为 rollup 插件用。\n对了，vite 在 dev 的时候还支持热更新，也就是本地改了代码能够自动同步到浏览器。\n这个就是基于 chokidar 监听了本地文件变动，然后在模块变动的时候通过 websocket 通知浏览器端，浏览器端接受之后做相应处理就好了。\n总结\n今天我们分析了下 rollup 的实现原理。\n它是基于浏览器的 type 为 module 的 script 可以直接下载 es module 模块实现的。\n做了一个开发服务，根据请求的 url 来对模块做编译，调用 vite 插件来做不同模块的 transform。\n但是 node_modules 下的文件有的包是 commonjs 的，并且可能有很多个模块，这时 vite 做了预构建也叫 deps optimize。\n它用 esbuild 分析依赖，然后用 esbuild 打包成 esm 的包之后输出到 node_modules/.vite 下，并生成了一个 metadata.json 来记录 hash。\n浏览器里用 max-age 强缓存这些预打包的模块，但是带了 hash 的query。这样当重新 build 的时候，可以通过修改 query 来触发更新。\n在开发时通过 connect 起了一个服务器，调用 vite 插件来做 transform，并且对 node_modules 下的模块做了预构建，用 esbuild 打包。\n在生产环境用 rollup 来打包，因为 vite 插件兼容了 rollup 插件，所以也是用同样的插件来处理，这样能保证开发和生产环境代码一致。\n此外，vite 还基于 chokidar 和 websocket 来实现了模块热更新。\n这就是 vite 的实现原理。\n回想下，不管是基于浏览器 es module import 实现的编译服务，基于 esbuild 做的依赖预构建，基于 hash query 做的强缓存和缓存更新，还是兼容 rollup 的 vite 插件可以在开发服务和 rollup 里同时跑，这些功能实现都挺巧妙的。"},"front-end/vue/defineProps":{"title":"defineProps","links":[],"tags":[],"content":"从 defineProps 深入浅出了解 vue3 中的宏\n从vue3开始vue引入了宏，比如defineProps、defineEmits等。我们每天写vue代码时都会使用到这些宏，但是你有没有思考过vue中的宏到底是什么？\n\n为什么这些宏不需要手动从vue中import？\n为什么只能在setup顶层中使用这些宏？\n\nvue 文件如何渲染到浏览器上\n要回答上面的问题，我们先来了解一下从一个vue文件到渲染到浏览器这一过程经历了什么？\n我们的vue代码一般都是写在后缀名为vue的文件上，显然浏览器是不认识vue文件的，浏览器只认识html、CSS、js 等文件。所以第一步就是通过webpack或者vite将一个vue文件编译为一个包含render函数的js文件。然后执行render函数生成虚拟DOM，再调用浏览器的DOM API根据虚拟DOM生成真实DOM挂载到浏览器上。\nvue3 的宏是什么？\n我们先来看看vue官方的解释：\n\n宏是一种特殊的代码，由编译器处理并转换为其他东西。它们实际上是一种更巧妙的字符串替换形式。\n\n宏是在哪个阶段运行？\n通过前面我们知道了vue 文件渲染到浏览器上主要经历了两个阶段。\n第一阶段是编译时，也就是从一个vue文件经过webpack或者vite编译变成包含render函数的js文件。此时的运行环境是nodejs环境，所以这个阶段可以调用nodejs相关的api，但是没有在浏览器环境内执行，所以不能调用浏览器的API。\n第二阶段是运行时，此时浏览器会执行js文件中的render函数，然后依次生成虚拟DOM和真实DOM。此时的运行环境是浏览器环境内，所以可以调用浏览器的API，但是在这一阶段中是不能调用nodejs相关的api。\n而宏就是作用于编译时，也就是从 vue 文件编译为js文件这一过程。\n举个defineProps的例子：在编译时defineProps宏就会被转换为定义props相关的代码，当在浏览器运行时自然也就没有了defineProps宏相关的代码了。\n所以才说宏是在编译时执行的代码，而不是运行时执行的代码。\n一个defineProps宏的例子\n\n\n在使用 &lt;script setup&gt; 的单文件组件中，props 可以使用 defineProps() 宏来声明\n\n\n在没有使用 &lt;script setup&gt; 的组件中，prop 可以使用 props选项来声明；\n\n\nexport default {\n  props: [&#039;foo&#039;],\n  setup(props) {\n    // setup() 接收 props 作为第一个参数\n    console.log(props.foo)\n  }\n}\n我们来看一个实际的例子，下面这个是我们的源代码：\n&lt;template&gt;\n    &lt;div&gt;content is {{ content }}&lt;/div&gt;\n    &lt;div&gt;title is {{ title }}&lt;/div&gt;\n&lt;/template&gt;\n \n&lt;script setup lang=&quot;ts&quot;&gt;\n    import {ref} from &quot;vue&quot;\n    const props = defineProps({\n        content: String,\n    });\n    const title = ref(&quot;title&quot;)\n&lt;/script&gt;\n在这个例子中我们使用defineProps宏定义了一个类型为String，属性名为content的props，并且在template中渲染content的内容。\n我们接下来再看看编译成js文件后的代码，代码我已经进行过简化：\nimport { defineComponent as _defineComponent } from &quot;vue&quot;;\nimport { ref } from &quot;vue&quot;;\n \nconst __sfc__ = _defineComponent({\n  props: {\n    content: String,\n  },\n  setup(__props) {\n    const props = __props;\n    const title = ref(&quot;title&quot;);\n    const __returned__ = { props, title };\n    return __returned__;\n  },\n});\n \nimport {\n  toDisplayString as _toDisplayString,\n  createElementVNode as _createElementVNode,\n  Fragment as _Fragment,\n  openBlock as _openBlock,\n  createElementBlock as _createElementBlock,\n} from &quot;vue&quot;;\n \nfunction render(_ctx, _cache, $props, $setup) {\n  return (\n    _openBlock(),\n    _createElementBlock(\n      _Fragment,\n      null,\n      [\n        _createElementVNode(\n          &quot;div&quot;,\n          null,\n          &quot;content is &quot; + _toDisplayString($props.content),\n          1 /* TEXT */\n        ),\n        _createElementVNode(\n          &quot;div&quot;,\n          null,\n          &quot;title is &quot; + _toDisplayString($setup.title),\n          1 /* TEXT */\n        ),\n      ],\n      64 /* STABLE_FRAGMENT */\n    )\n  );\n}\n__sfc__.render = render;\nexport default __sfc__;\n我们可以看到编译后的js文件主要由两部分组成，第一部分为执行defineComponent函数生成一个 __sfc__ 对象，第二部分为一个render函数。render函数不是我们这篇文章要讲的，我们主要来看看这个__sfc__对象。\n看到defineComponent是不是觉得很眼熟，没错这个就是vue提供的API中的 definecomponent函数。这个函数在运行时没有任何操作，仅用于提供类型推导。这个函数接收的第一个参数就是组件选项对象，返回值就是该组件本身。所以这个__sfc__对象就是我们的vue文件中的script代码经过编译后生成的对象，后面再通过__sfc__.render = render将render函数赋值到组件对象的render方法上面。\n我们这里的组件选项对象经过编译后只有两个了，分别是props属性和setup方法。明显可以发现我们原本在setup里面使用的defineProps宏相关的代码不在了，并且多了一个props属性。没错这个props属性就是我们的defineProps宏生成的。\n我们再来看一个不在setup顶层调用defineProps的例子：\n&lt;script setup lang=&quot;ts&quot;&gt;\n    import {ref} from &quot;vue&quot;\n    const title = ref(&quot;title&quot;)\n \n    if (title.value) {\n        const props = defineProps({\n            content: String,\n        });\n    }\n&lt;/script&gt;\n运行这个例子会报错：defineProps is not defined\n我们来看看编译后的js代码：\nimport { defineComponent as _defineComponent } from &quot;vue&quot;;\nimport { ref } from &quot;vue&quot;;\n \nconst __sfc__ = _defineComponent({\n  setup(__props) {\n    const title = ref(&quot;title&quot;);\n    if (title.value) {\n      const props = defineProps({\n        content: String,\n      });\n    }\n    const __returned__ = { title };\n    return __returned__;\n  },\n});\n明显可以看到由于我们没有在setup的顶层调用defineProps宏，在编译时就不会将defineProps宏替换为定义props相关的代码，而是原封不动的输出回来。在运行时执行到这行代码后，由于我们没有任何地方定义了defineProps函数，所以就会报错defineProps is not defined。\n总结\n现在我们能够回答前面提的三个问题了。\n\n\nvue中的宏到底是什么？\nvue3的宏是一种特殊的代码，在编译时会将这些特殊的代码转换为浏览器能够直接运行的指定代码，根据宏的功能不同，转换后的代码也不同。\n\n\n为什么这些宏不需要手动从vue中import？\n因为在编译时已经将这些宏替换为指定的浏览器能够直接运行的代码，在运行时已经不存在这些宏相关的代码，自然不需要从vue中import。\n\n\n为什么只能在setup顶层中使用这些宏？\n因为在编译时只会去处理setup顶层的宏，其他地方的宏会原封不动的输出回来。在运行时由于我们没有在任何地方定义这些宏，当代码执行到宏的时候当然就会报错。\n\n\n如果想要在vue中使用更多的宏，可以使用 vue macros。这个库是用于在vue中探索更多的宏和语法糖，作者是vue的团队成员 三咲智子 。"},"front-end/vue/page-cache":{"title":"page-cache","links":[],"tags":[],"content":"Vue3 除了 keep-alive，还有哪些页面缓存的实现方案\n引言\n有这么一个需求：列表页进入详情页后，切换回列表页，需要对列表页进行缓存，如果从首页进入列表页，就要重新加载列表页。\n对于这个需求，我的第一个想法就是使用 keep-alive 来缓存列表页，列表和详情页切换时，列表页会被缓存；从首页进入列表页时，就重置列表页数据并重新获取新数据来达到列表页重新加载的效果。\n但是，这个方案有个很不好的地方就是：如果列表页足够复杂，有下拉刷新、下拉加载、有弹窗、有轮播等，在清除缓存时，就需要重置很多数据和状态，而且还可能要手动去销毁和重新加载某些组件，这样做既增加了复杂度，也容易出 bug。\n接下来说说我的想到的新实现方案（代码基于 Vue3）。\nkeep-alive 缓存和清除\n\nkeep-alive 缓存原理：进入页面时，页面组件渲染完成，keep-alive 会缓存页面组件的实例；离开页面后，组件实例由于已经缓存就不会进行销毁；当再次进入页面时，就会将缓存的组件实例拿出来渲染，因为组件实例保存着原来页面的数据和 Dom 的状态，那么直接渲染组件实例就能得到原来的页面。\n\nkeep-alive 最大的难题就是缓存的清理，如果能有简单的缓存清理方法，那么 keep-alive 组件用起来就很爽。\n但是，keep-alive 组件没有提供清除缓存的 API，那有没有其他清除缓存的办法呢？答案是有的。我们先看看 keep-alive 组件的 props：\ninclude - string | RegExp | Array 只有名称匹配的组件会被缓存\nexclude - string | RegExp | Array 任何名称匹配的组件都不会被缓存\nmax - number | string 最多可以缓存多少组件实例\n\n从 include 描述来看，我发现 include 是可以用来清除缓存，做法是：将组件名称添加到 include 里，组件会被缓存；移除组件名称，组件缓存会被清除。根据这个原理，用 hook 简单封装一下代码：\nimport { ref, nextTick } from &#039;vue&#039;\n \nconst caches = ref&lt;string[]&gt;([])\n \nexport default function useRouteCache () {\n  // 添加缓存的路由组件\n  function addCache (componentName: string | string []) {\n    if (Array.isArray(componentName)) {\n      componentName.forEach(addCache)\n      return\n    }\n \n    if (!componentName || caches.value.includes(componentName)) return\n \n    caches.value.push(componentName)\n  }\n \n  // 移除缓存的路由组件\n  function removeCache (componentName: string) {\n    const index = caches.value.indexOf(componentName)\n    if (index &gt; -1) {\n      return caches.value.splice(index, 1)\n    }\n  }\n \n  // 移除缓存的路由组件的实例\n  async function removeCacheEntry (componentName: string) {\n    if (removeCache(componentName)) {\n      await nextTick()\n      addCache(componentName)\n    }\n  }\n \n  return {\n    caches,\n    addCache,\n    removeCache,\n    removeCacheEntry\n  }\n}\nhook 的用法如下：\n&lt;router-view v-slot=&quot;{ Component }&quot;&gt;\n  &lt;keep-alive :include=&quot;caches&quot;&gt;\n    &lt;component :is=&quot;Component&quot; /&gt;\n  &lt;/keep-alive&gt;\n&lt;/router-view&gt;\n \n&lt;script setup lang=&quot;ts&quot;&gt;\nimport useRouteCache from &#039;./hooks/useRouteCache&#039;\nconst { caches, addCache } = useRouteCache()\n \n&lt;!-- 将列表页组件名称添加到需要缓存名单中 --&gt;\naddCache([&#039;List&#039;])\n&lt;/script&gt;\n清除列表页缓存如下：\nimport useRouteCache from &quot;@/hooks/useRouteCache&quot;;\n \nconst { removeCacheEntry } = useRouteCache();\nremoveCacheEntry(&quot;List&quot;);\n\n此处removeCacheEntry方法清除的是列表组件的实例，‘List’ 值仍然在 组件的 include 里，下次重新进入列表页会重新加载列表组件，并且之后会继续列表组件进行缓存。\n\n列表页清除缓存的时机\n进入列表页后清除缓存\n在列表页路由组件的beforeRouteEnter勾子中判断是否是从其他页面（Home）进入的，是则清除缓存，不是则使用缓存。\ndefineOptions({\n  name: &quot;List1&quot;,\n  beforeRouteEnter(to: RouteRecordNormalized, from: RouteRecordNormalized) {\n    if (from.name === &quot;Home&quot;) {\n      const { removeCacheEntry } = useRouteCache();\n      removeCacheEntry(&quot;List1&quot;);\n    }\n  },\n});\n这种缓存方式有个不太友好的地方：当从首页进入列表页，列表页和详情页来回切换，列表页是缓存的；但是在首页和列表页间用浏览器的前进后退来切换时，我们更多的是希望列表页能保留缓存，就像在多页面中浏览器前进后退会缓存原页面一样的效果。但实际上，列表页重新刷新了，这就需要使用另一种解决办法，点击链接时清除缓存清除缓存。\n点击链接跳转前清除缓存\n在首页点击跳转列表页前，在点击事件的时候去清除列表页缓存，这样的话在首页和列表页用浏览器的前进后退来回切换，列表页都是缓存状态，只要当重新点击跳转链接的时候，才重新加载列表页，满足预期。\n// 首页 Home.vue\n \n&lt;li&gt;\n  &lt;router-link to=&quot;/list&quot; @click=&quot;removeCacheBeforeEnter&quot;&gt;列表页&lt;/router-link&gt;\n&lt;/li&gt;\n \n&lt;script setup lang=&quot;ts&quot;&gt;\nimport useRouteCache from &quot;@/hooks/useRouteCache&quot;;\n \ndefineOptions({\n  name: &quot;Home&quot;,\n});\n \nconst { removeCacheEntry } = useRouteCache();\n \n// 进入页面前，先清除缓存实例\nfunction removeCacheBeforeEnter() {\n  removeCacheEntry(&quot;List&quot;);\n}\n&lt;/script&gt;\n状态管理实现缓存\n通过状态管理库存储页面的状态和数据也能实现页面缓存。此处状态管理使用的是 pinia。\n首先使用 pinia 创建列表页 store：\nimport { defineStore } from &quot;pinia&quot;;\n \ninterface Item {\n  id?: number;\n  content?: string;\n}\n \nconst useListStore = defineStore(&quot;list&quot;, {\n  // 推荐使用 完整类型推断的箭头函数\n  state: () =&gt; {\n    return {\n      isRefresh: true,\n      pageSize: 30,\n      currentPage: 1,\n      list: [] as Item[],\n      curRow: null as Item | null,\n    };\n  },\n  actions: {\n    setList(data: Item[]) {\n      this.list = data;\n    },\n    setCurRow(data: Item) {\n      this.curRow = data;\n    },\n    setIsRefresh(data: boolean) {\n      this.isRefresh = data;\n    },\n  },\n});\n \nexport default useListStore;\n然后在列表页中使用 store：\n&lt;div&gt;\n  &lt;el-page-header @back=&quot;goBack&quot;&gt;\n    &lt;template #content&gt;状态管理实现列表页缓存&lt;/template&gt;\n  &lt;/el-page-header&gt;\n  &lt;el-table v-loading=&quot;loading&quot; :data=&quot;tableData&quot; border style=&quot;width: 100%; margin-top: 30px;&quot;&gt;\n    &lt;el-table-column prop=&quot;id&quot; label=&quot;id&quot; /&gt;\n    &lt;el-table-column prop=&quot;content&quot; label=&quot;内容&quot;/&gt;\n    &lt;el-table-column label=&quot;操作&quot;&gt;\n      &lt;template v-slot=&quot;{ row }&quot;&gt;\n        &lt;el-link type=&quot;primary&quot; @click=&quot;gotoDetail(row)&quot;&gt;进入详情&lt;/el-link&gt;\n        &lt;el-tag type=&quot;success&quot; v-if=&quot;row.id === listStore.curRow刚点击&lt;/el-tag&gt;\n      &lt;/template&gt;\n    &lt;/el-table-column&gt;\n  &lt;/el-table&gt;\n  &lt;el-pagination\n    v-model:currentPage=&quot;listStore.currentPage&quot;\n    :page-size=&quot;listStore.pageSize&quot;\n    layout=&quot;total, prev, pager, next&quot;\n    :total=&quot;listStore.list.length&quot;\n  /&gt;\n&lt;/div&gt;\n \n&lt;script setup lang=&quot;ts&quot;&gt;\nimport useListStore from &#039;@/store/listStore&#039;\nconst listStore = useListStore()\n \n...\n&lt;/script&gt;\n通过 beforeRouteEnter 钩子判断是否从首页进来，是则通过 listStore.$reset() 来重置数据，否则使用缓存的数据状态；之后根据 listStore.isRefresh 标示判断是否重新获取列表数据。\ndefineOptions({\n  beforeRouteEnter(to: RouteLocationNormalized, from: RouteLocationNormalized) {\n    if (from.name === &quot;Home&quot;) {\n      const listStore = useListStore();\n      listStore.$reset();\n    }\n  },\n});\n \nonBeforeMount(() =&gt; {\n  if (!listStore.useCache) {\n    loading.value = true;\n    setTimeout(() =&gt; {\n      listStore.setList(getData());\n      loading.value = false;\n    }, 1000);\n    listStore.useCache = true;\n  }\n});\n缺点\n通过状态管理去做缓存的话，需要将状态数据都存在 store 里，状态多起来的话，会有点繁琐，而且状态写在 store 里肯定没有写在列表组件里来的直观；状态管理由于只做列表页数据的缓存，对于一些非受控组件来说，组件内部状态改变是缓存不了的，这就导致页面渲染后跟原来有差别，需要额外代码操作。\n页面弹窗实现缓存\n将详情页做成全屏弹窗，那么从列表页进入详情页，就只是简单地打开详情页弹窗，将列表页覆盖，从而达到列表页 “缓存”的效果，而非真正的缓存。\n这里还有一个问题，打开详情页之后，如果点后退，会返回到首页，实际上我们希望是返回列表页，这就需要给详情弹窗加个历史记录，如列表页地址为 /list，打开详情页变为 /list?id=1。\n弹窗组件实现：\n// PopupPage.vue\n \n&lt;template&gt;\n  &lt;div class=&quot;popup-page&quot; :class=&quot;[!dialogVisible &amp;&amp; &#039;hidden&#039;]&quot;&gt;\n    &lt;slot v-if=&quot;dialogVisible&quot;&gt;&lt;/slot&gt;\n  &lt;/div&gt;\n&lt;/template&gt;\n \n&lt;script setup lang=&quot;ts&quot;&gt;\nimport { useLockscreen } from &quot;element-plus&quot;;\nimport { computed, defineProps, defineEmits } from &quot;vue&quot;;\nimport useHistoryPopup from &quot;./useHistoryPopup&quot;;\n \nconst props = defineProps({\n  modelValue: {\n    type: Boolean,\n    default: false,\n  },\n  // 路由记录\n  history: {\n    type: Object,\n  },\n  // 配置了history后，初次渲染时，如果有url上有history参数，则自动打开弹窗\n  auto: {\n    type: Boolean,\n    default: true,\n  },\n  size: {\n    type: String,\n    default: &quot;50%&quot;,\n  },\n  full: {\n    type: Boolean,\n    default: false,\n  },\n});\nconst emit = defineEmits([&quot;update:modelValue&quot;, &quot;autoOpen&quot;, &quot;autoClose&quot;]);\n \nconst dialogVisible = computed&lt;boolean&gt;({\n  // 控制弹窗显示\n  get() {\n    return props.modelValue;\n  },\n  set(val) {\n    emit(&quot;update:modelValue&quot;, val);\n  },\n});\n \nuseLockscreen(dialogVisible);\n \nuseHistoryPopup({\n  history: computed(() =&gt; props.history),\n  auto: props.auto,\n  dialogVisible: dialogVisible,\n  onAutoOpen: () =&gt; emit(&quot;autoOpen&quot;),\n  onAutoClose: () =&gt; emit(&quot;autoClose&quot;),\n});\n&lt;/script&gt;\n \n&lt;style lang=&quot;less&quot;&gt;\n.popup-page {\n  position: fixed;\n  left: 0;\n  right: 0;\n  top: 0;\n  bottom: 0;\n  z-index: 100;\n  overflow: auto;\n  padding: 10px;\n  background: #fff;\n \n  &amp;.hidden {\n    display: none;\n  }\n}\n&lt;/style&gt;\n弹窗组件调用：\n&lt;popup-page v-model=&quot;visible&quot; full :history=&quot;{ id: id }&quot;&gt;\n  &lt;Detail&gt;&lt;/Detail&gt;\n&lt;/popup-page&gt;\n\nhook：useHistoryPopup 参考文章：\n\n缺点\n弹窗实现页面缓存，局限比较大，只能在列表页和详情页中才有效，离开列表页之后，缓存就会失效，比较合适一些简单缓存的场景。\n父子路由实现缓存\n该方案原理其实就是页面弹窗，列表页为父路由，详情页为子路由，从列表页跳转到详情页时，显示详情页子路由，且详情页全屏显示，覆盖住列表页。\n声明父子路由：\n{\n  path: &#039;/list&#039;,\n  name: &#039;list&#039;,\n  component: () =&gt; import(&#039;./views/List.vue&#039;),\n  children: [\n    {\n      path: &#039;/detail&#039;,\n      name: &#039;detail&#039;,\n      component: () =&gt; import(&#039;./views/Detail.vue&#039;),\n    }\n  ]\n}\n列表页代码：\n// 列表页\n&lt;template&gt;\n  &lt;el-table\n    v-loading=&quot;loading&quot;\n    :data=&quot;tableData&quot;\n    border\n    style=&quot;width: 100%; margin-top: 30px;&quot;\n  &gt;\n    &lt;el-table-column prop=&quot;id&quot; label=&quot;id&quot; /&gt;\n    &lt;el-table-column prop=&quot;content&quot; label=&quot;内容&quot; /&gt;\n    &lt;el-table-column label=&quot;操作&quot;&gt;\n      &lt;template v-slot=&quot;{ row }&quot;&gt;\n        &lt;el-link type=&quot;primary&quot; @click=&quot;gotoDetail(row)&quot;&gt;进入详情&lt;/el-link&gt;\n        &lt;el-tag type=&quot;success&quot; v-if=&quot;row.id === curRow?.id&quot;&gt;刚点击&lt;/el-tag&gt;\n      &lt;/template&gt;\n    &lt;/el-table-column&gt;\n  &lt;/el-table&gt;\n  &lt;el-pagination\n    v-model:currentPage=&quot;currentPage&quot;\n    :page-size=&quot;pageSize&quot;\n    layout=&quot;total, prev, pager, next&quot;\n    :total=&quot;list.length&quot;\n  /&gt;\n \n  &lt;!-- 详情页 --&gt;\n  &lt;router-view class=&quot;popyp-page&quot;&gt;&lt;/router-view&gt;\n&lt;/template&gt;\n \n&lt;style lang=&quot;less&quot; scoped&gt;\n.popyp-page {\n  position: fixed;\n  top: 0;\n  bottom: 0;\n  left: 0;\n  right: 0;\n  z-index: 100;\n  background: #fff;\n  overflow: auto;\n}\n&lt;/style&gt;"},"front-end/webgl/1.1-初识-WebGL":{"title":"初识 WebGL","links":[],"tags":[],"content":"1. 初识WebGL\nWebGL 是什么？\n维基百科是这样定义 WebGL 的：\n\nWebGL是一种JavaScript API，用于在不使用插件的情况下在任何兼容的网页浏览器中呈现交互式2D和3D图形。WebGL完全集成到浏览器的所有网页标准中，可将影像处理和效果的GPU加速使用方式当做网页Canvas的一部分。WebGL程序由JavaScript编写的句柄和OpenGL Shading Language（GLSL）编写的着色器代码组成，该语言类似于C或C++，并在电脑的图形处理器（GPU）上执行。\n\n也就是说，我们可以通过编写 JavaScript + GLSL 代码就可以在浏览器中实现 2D、3D 效果。直接就能用，无需安装各种环境，搞各种配置！这也是作为前端开发者的好处（食物链底端的原因）之一！\n关于 WebGL 的发展历史，它的前身 OpenGL 的相关内容，感兴趣的同学自行了解，本文将不会展开。回到主题，我们继续聚焦于 WebGL 的零基础上车，go go go！\nWebGL 三要素\n首次接触 WebGL，非常有必要了解 WebGL 程序是怎么运行起来的，它的运行机制将贯穿我们整个 WebGL 的学习之旅。\n上文引用 维基百科 对 WebGL 的介绍中，好像提到了canvas？还有JavaScript？还有GLSL？那这个几个大佬他们是…\nok，不卖关子了，正是 WebGL 程序运行三要素：\n\nHTML5标签 —— canvas（超文本标记语言）\nJavaScript（脚本语言）\nGLSL ES（着色器语言）\n\n\n也就是说，只要具备这三要素，我们就能愉快地在浏览器上实现各种三维图形的网页了。\n\n当然，刚开始了解到 GLSL 这门语言的我们一定倍感陌生，不必紧张，通过逐步深入地学习，我们会慢慢地熟悉它。目前我们简单地将其理解成一门似于C或C++的 “画图语言”即可。\n\ncanvas\n相信 &lt;canvas&gt; 这个标签大家一定不会陌生，WebGL 正是基于它来绘制 3D 图形的！\n我认为最简单理解 canvas 的方式就是它的直译——画布。它就好比一张白纸，允许我们通过 JavaScript 这支画笔在上面动态的绘制图形。\n多说无益，我们直接实战画图来贴切地了解它吧：\n&lt;template&gt;\n  &lt;canvas id=&quot;ice-1_1&quot; width=&quot;600&quot; height=&quot;100&quot;&gt;&lt;/canvas&gt;\n&lt;/template&gt;\n \n&lt;script setup lang=&quot;ts&quot;&gt;\nimport { onMounted } from &#039;vue&#039;\n \nonMounted(() =&gt; {\n  const canvas = document.querySelector(&#039;#ice-1_1&#039;)\n  const ctx = canvas.getContext(&#039;2d&#039;)\n \n  ctx.fillStyle = &#039;rgba(0, 0 , 240, 1)&#039;\n  // 矩形\n  ctx.fillRect(0, 0, 100, 100)\n  // 圆形\n  ctx.arc(240, 50, 50, 0, Math.PI * 360 / 180)\n  ctx.fill();\n})\n \n&lt;/script&gt;\n \n&lt;script lang=&quot;ts&quot;&gt;\nimport { defineComponent } from &#039;vue&#039;\n \nexport default defineComponent({\n  name: &#039;Second1_1&#039;\n})\n \n&lt;/script&gt;\n如上示例程序，我们通过简单的几行代码便在 canvas 中绘制了一个蓝色的正方形和圆形。总结出三点：\n\n设置 canvas 的 width 、 height 属性指定绘制的像素区域\n获取 canvas 绘图环境：getContext(&#039;2d&#039;)\n设置颜色值 RGBA；设置绘图坐标、尺寸\n\n观察其中核心的画图代码，我们直接调用了 api 并传入参数（坐标、尺寸）。\n// 矩形\nctx.fillRect(0, 0, 100, 100)\n// 圆形\nctx.arc(240, 50, 50, 0, Math.PI * 360 / 180)\nok，这就是简单的 canvas 绘制 2d 图形的程序（本文将默认你有一定的 canvas 基础，不会对其详细展开）。\n接下来，我们将直接使用 WebGL 编写第一个绘图程序以便和 canvas 2d 绘图形成一个对比！到此，我们可以先留意一下 getContext(&#039;2d&#039;) 、 RGBA（第二节中介绍） 和 坐标 ，因为这几个在 WebGL 绘图中也会用到，但是稍有不同。\n第一个 WebGL 程序\n如果按照上文 canvas 2d 的绘图方式来实现 WebGL 的绘制，你是否会想到如下实现：\n// 绘图环境\nconst gl = canvas.getContext(&#039;WebGL&#039;)\n// 调用绘制 api\ngl.fillRect(x, y, z, length, width, height)\n哈哈哈，想法非常好，但是现实很残酷。WebGL 并没有直接提供对应的绘图 api 给我们调用，而是需要我们自己编写一个叫 “着色器” 的程序，也就是 GLSL。\n这里，我们不抠细节，直接通过一个实战案例来过一遍 WebGL 程序的所有”执行要素”。再次强调！当前你无需仔细关注每一行代码实现，只要关注绘制流程即可。\n首先回顾一下 WebGL 程序的三要素！\n\ncanvas\n\n获取 canvas 元素\n获取绘图环境 getContext(&#039;WebGL&#039;)\n\n\n\n// html 标签\n&lt;canvas id=&quot;ice-canvas&quot;&gt;&lt;/canvas&gt;\n \n// 获取 canvas \nconst canvas = document.querySelector(&#039;#ice-canvas&#039;)\n// 获取 WebGL 的绘图上下文（传入的参数是 WebGL）\nconst gl = canvas.getContext(&#039;WebGL&#039;)\n\nJavaScript\n\n创建顶点着色器\n创建片元着色器\n创建 GLSL 着色程序\n\n\n\n// 创建顶点着色器\nconst vertexShader = createShader(gl, gl.VERTEX_SHADER, vertexCode)\n// 创建片元着色器\nconst fragmentShader = createShader(gl, gl.FRAGMENT_SHADER, fragmentCode)\n// 创建 GLSL 着色程序\ncreateProgram(gl, vertexShader, fragmentShader)\n\nGLSL ES （着色器）\n\n顶点着色器函数\n片元着色器函数\n\n\n\nconst vertexCode = `\n  void main () {\n    // 顶点坐标\n    gl_Position = vec4(0.0, 0.0, 0.0, 1.0);\n    // 顶点渲染像素大小\n    gl_PointSize = 24.0;\n  }\n`\nconst fragmentCode = `\n  void main () {\n    // 顶点颜色——蓝色\n    gl_FragColor = vec4(0.0, 0.0, 0.9, 1.0);\n  }\n`\n没错，你完全可以理解为，我们写 WebGL 程序时，GLSL 就是以字符串的形式”嵌入” JavaScript 中的。这段着色器代码最终将会交由 GPU 去执行。\n接下来通过一张图来加深我们对整个执行阶段的理解：\n\n了解了一个基本的 WebGL 程序要素后，我们通过一个实战代码来看到实现的效果（如下示例程序）。\n&lt;template&gt;\n \n  &lt;canvas id=&quot;ice-1_2&quot; width=&quot;600&quot; height=&quot;100&quot;&gt;&lt;/canvas&gt;\n \n&lt;/template&gt;\n \n  \n \n&lt;script setup lang=&quot;ts&quot;&gt;\n \nimport { onMounted } from &#039;vue&#039;\n \n  \n \nconst createShader = (gl, type, sourceCode) =&gt; {\n \n  const shader = gl.createShader(type) // 创建着色器对象\n \n  gl.shaderSource(shader, sourceCode) // 提供着色器代码\n \n  gl.compileShader(shader) // 编译 -&gt; 生成着色器\n \n  const success = gl.getShaderParameter(shader, gl.COMPILE_STATUS)\n \n  if (success) return shader\n \n  console.error(&#039;shader err &gt;&gt;&gt;&#039;, type, gl.getShaderInfoLog(shader))\n \n  gl.deleteShader(shader);\n \n}\n  \n \nconst createProgram = (gl, vertexShader, fragmentShader) =&gt; {\n \n  const program = gl.createProgram();\n  gl.attachShader(program, vertexShader);\n  gl.attachShader(program, fragmentShader);\n  gl.linkProgram(program);\n  gl.useProgram(program);\n \n  const success = gl.getProgramParameter(program, gl.LINK_STATUS);\n \n  if (success) {\n    return program;\n  }\n \n  console.error(&#039;program err &gt;&gt;&gt;&#039;, gl.getProgramInfoLog(program));\n  gl.deleteProgram(program);\n}\n \n \nonMounted(() =&gt; {\n \n  const canvas = document.querySelector(&#039;#ice-1_2&#039;)\n  const gl = canvas.getContext(&#039;webgl&#039;)\n \n  const vertexCode = `\n    void main () {\n      gl_Position = vec4(0, 0.0, 0.0, 1.0);\n      gl_PointSize = 24.0;\n    }\n  `\n \n  const fragmentCode = `\n    void main () {\n      gl_FragColor = vec4(0.0, 0.0, 0.9, 1.0);\n    }\n  `\n \n  const vertexShader = createShader(gl, gl.VERTEX_SHADER, vertexCode)\n  const fragmentShader = createShader(gl, gl.FRAGMENT_SHADER, fragmentCode)\n  createProgram(gl, vertexShader, fragmentShader)\n  gl.drawArrays(gl.POINTS, 0, 1)\n \n})\n \n&lt;/script&gt;\n \n&lt;script lang=&quot;ts&quot;&gt;\n \nimport { defineComponent } from &#039;vue&#039;\n \nexport default defineComponent({\n  name: &#039;Second1_2&#039;\n})\n \n&lt;/script&gt;\n当你点开示例程序源码的时候，你会发现实现一个小小的像素点就需要大量的代码！这是因为 WebGL 是比较底层的，它没有像 canvas 2d 那样有一些成型的 api 来调用，很多地方都需要自己实现。\n在接下来的学习过程中，我会将一些比较基础的实现（每次绘制的必要代码）进行封装，比如示例程序中的 createShader、createProgram 这种常用的函数。这部分将在下一篇文章中进行，我们先接着本文往下走！\n初步接触了 WebGL 的程序了，我们用它来绘制了一个二维的像素点。但是大家有没有发现者像素点所处的位置跟我们直接用 canvas 2d 绘制图形的位置有点小不同呢？用 WebGL 绘制的像素点明显偏向示例程序的中间，我们简单来看看它的坐标数据：\n// 顶点着色器\ngl_Position = vec4(0.0, 0.0, 0.0, 1.0);\n通过上述代码，我们看到 gl_Position 的值的前三个位置分别都是 0.0（暂时不用管第四个），也就是说当前的坐标 (x, y, z) 对应的是 (0, 0, 0)，也就是坐标轴的原点！\n从表象来看，貌似坐标轴的原点处于画布的中心？回顾一下 canvas 2d 中绘制的第一个矩形，它的 (x, y) 值也是设置的 (0, 0)，但却是在示例程序的最左边出现的。难道说他们之间的坐标轴是不同的？\nWebGL 坐标\n讲到 WebGL 坐标，那一定是要跟 canvas 2d 进行一个对比的。所以这里我们先看看 canvas 2d 的坐标系。如图所示，canvas 2d 的默认坐标系中，原点是在左上角的。\n\n相比之下，WebGL 的坐标系会更加符合我们的认知（如下图所示），大家在学生时代的数学、物理课程中肯定经常使用。\n\n这里我们除了关注 WebGL 的坐标原点外，我们还需要关注它的坐标范围。没错，我已经在图中将其表示出来了，它的坐标范围是 (-1, 1)，如果说我们习惯使用 canvas 2d 直接使用宽高的像素来绘制图像，那在使用 WebGL 的时候我们需要进行一定的转换。\n将坐标范围设计成 (-1, 1) 有什么好处呢？其相当于一个百分比单位，我们可以不用关注 canvas 的具体宽高了，canvas 的大小伸缩里面的内容都能”等比例”的展示。\n光说太晦涩了，我们通过一个示例程序来探究 WebGL 的坐标值吧。\n首先看看示例中的相关绘图信息：\n\ncanvas 宽高分别为 600 * 300\n在坐标系的第一象限绘制一个直角三角形（直角边占满x，y轴）\n三角形的三个坐标分别为 (0, 0)、(0, 1)、(1, 0)\n换算下来，直角边的长度分别为 300px、150px\n\n\n那接下来，我们通过 WebGL 程序将其实现：\n&lt;template&gt;\n  &lt;canvas id=&quot;ice-1_3&quot; width=&quot;600&quot; height=&quot;300&quot;&gt;&lt;/canvas&gt;\n&lt;/template&gt;\n \n&lt;script setup lang=&quot;ts&quot;&gt;\n \nimport { onMounted } from &#039;vue&#039;\nimport { createShader, createProgram, createBuffer } from &#039;@ice-webgl/utils&#039;\n \nonMounted(() =&gt; {\n \n  const canvas = document.querySelector(&#039;#ice-1_3&#039;)\n  const gl = canvas.getContext(&#039;webgl&#039;)\n \n  const vertexCode = `\n    attribute vec4 a_Position;\n    void main () {\n      gl_Position = a_Position;\n    }\n  `\n  const fragmentCode = `\n    void main () {\n      gl_FragColor = vec4(0.0, 0.0, 0.9, 1.0);\n    }\n  `\n  const vertexShader = createShader(gl, gl.VERTEX_SHADER, vertexCode)\n  const fragmentShader = createShader(gl, gl.FRAGMENT_SHADER, fragmentCode)\n  const program = createProgram(gl, vertexShader, fragmentShader)\n  const vertices = new Float32Array([0., 0., 0., 1., 1., 0.])\n  const a_Position = gl.getAttribLocation(program, &#039;a_Position&#039;)\n  createBuffer(gl, gl.ARRAY_BUFFER, vertices, a_Position, 2)\n \n  gl.drawArrays(gl.TRIANGLES, 0, 3)\n})\n \n&lt;/script&gt;\n \n&lt;script lang=&quot;ts&quot;&gt;\n \nimport { defineComponent } from &#039;vue&#039;\n \nexport default defineComponent({\n  name: &#039;Second1_3&#039;\n})\n \n&lt;/script&gt;\n还是老规矩，这里我们不关注代码实现，只需要看示例程序的运行结果和关注它的顶点坐标即可：\n// 三个顶点坐标的值：(0, 0)、(0, 1)、(1, 0)\nconst vertices = new Float32Array([0., 0., 0., 1., 1., 0.])\n上面代码块中 两两成对 的就是我们这次示例中的三个顶点的坐标了。经过本示例，相信你已经对坐标值范围有一定的理解了，但我们仿佛漏了一点一直没说，那就是 Z 轴。\n因为 WebGL 是处理三维图形的，所以它使用三维坐标系统，自然会比普通的二维图形多了个 Z 轴。默认情况下，WebGL 采用右手坐标系统，所以我们就关注右手坐标系统即可，本书的所有案例都遵循右手坐标系统。（注意：WebGL本身既不是右手坐标系，也不是左手坐标系，感兴趣的同学可以自行查阅相关资料）\n如果使用右手坐标系统的话，WebGL 中的 Z 轴是垂直于屏幕，正方向朝外，负方向朝内。 这里借助 Cocos 的一张图来给大家加深理解：\n\n相信到这一步，你应该深入理解了 WebGL 的坐标系统了！有了它，在后续的 WebGL 图形绘制中你将如鱼得水。\n总结\n本文的最后，跟大家一起回顾本文的主要内容：\n\nWebGL 程序运行三要素：canvas + JavaScript + GLSL\nWebGL 绘制二维图形需要编写 GLSL 着色器代码，没有像 canvas 2d 直接的 api 调用。\nWebGL 的坐标轴原点在中心，并且坐标值的范围是 (-1, 1)，本文使用 右手坐标系统。\n"},"front-end/webgl/1.2.-WebGL-绘制点":{"title":"WebGL 绘制点","links":[],"tags":[],"content":"2. WebGL 绘制点\n相信经过上一小节的学习，你已经具备一定理解 WebGL 程序的能力了（三要素、坐标系）。上一小节中，我们已经看到两个 WebGL 绘制的二维图形了，但是并没有展开具体的实现，那这一小节，我们将走进 WebGL 程序的代码实现，深入着色器的实现细节，let’s go！\n\n关于 GLSL 这门语言的学习建议，我认为可以先通过实战中用到的代码一步一步学习（用到什么学什么），纸上得来终觉浅，代码一定要自己敲一下，相信经过一定量的代码编写，你便会逐渐熟悉。\n\n什么是着色器？\n在上一小节中，我们都了解到了 WebGL 程序有着色器这个角色，但我们还没有正式的跟它见面。我们通过下图回顾一下着色器在 WebGL 中的角色：\n\n图中，我们清晰得知 WebGL 需要两种着色器：\n\n顶点着色器。用来描述顶点属性，比如坐标位置。其中，顶点我们可以理解为他是三维空间中的一个点(x, y, z)。\n片元着色器。逐片元处理颜色。片元是 WebGL 的术语，它其实指的是每一个像素，逐片元的意思就是计算出当前绘制的每个像素的颜色值。\n\n当我们把 顶点着色器 和 片元着色器 组合起来使用（成对使用），那么就形成了一个 着色程序（program）。着色程序将在 GPU 中运行，根据我们设置的一系列状态值，再使用 gl.drawArrays 这类着色方法便可以绘制出各种图形。\n为了加深大家对两个着色器的理解，我们通过一个 WebGL 绘制三角形 的细分图解来看看两个着色器之间是如何工作的：\n\n如上如所示，当我们画一个三角形的时候：\n\n顶点着色器会被调用三次完成三个顶点的处理，接着会有一个 “图形装配” 、 “光栅化” 的过程（上图虚线部分，这一块会在后续讲到颜色的时候深入介绍）。其中光栅化的意思就是将装配后的图形转换成每一个像素点。\n片元着色器根据 gl_FragColor 的配置信息对光栅化后的每一个像素进行着色处理。如果说是蓝色，那么片元着色器就会将每一个像素点的涂成蓝色。\n\n简单来说，其实就是运行三次顶点着色器画了三个顶点，三个顶点进行连接后产生了一个三角形的图形区域，再运行 n 次（n个像素点）片元着色器将每个像素点进行上色，最终就画成了一个蓝色三角形。\n其实，我们看到的所有图像，它的背后都是一个一个五颜六色的像素点组合起来的，所以我们可以很好的理解着色器为什么是 成对工作 的原理。一方面通过顶点着色器（各种坐标点）就可以把图形的形状描述出来，另一方面再通过片元着色器将整个图形形状内的所有像素点进行上色，最终就可以呈现出一个完整的图像了。\n编写简单的着色器代码\n首先，我们先了解一下本次代码中用到的 GLSL 语言的 类型 和 内置变量。\n1. 顶点着色器\n用到的数据类型\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n类型描述float浮点数vec4由4个浮点数组成的矢量 (float, float, float, float)\n顶点着色器的内置变量\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n变量名类型描述默认值gl_Positionvec4顶点位置、坐标-gl_PointSizefloat点的尺寸（像素）1.0\n内置函数\n\n\n\n\n\n\n\n\n\n\n\n\n\n函数名描述vec4用法：vec4(v0, v1, v2, v3)。根据 v0 - v4 创建 vec4 对象\n接下来我们深入看看 gl_Position，它的类型—— vec4 明显比 gl_PointSize 的 float 要特别。如果说我们需要的顶点坐标数据是 (x, y, z)，那么好像也才只有 3 个浮点数，那第 4 个数是什么呢？\n通常，我们添加 1.0 作为第四个参数 w，也就是 (x, y, z, 1.0)。由四个数组成的矢量叫做 齐次坐标，齐次坐标 (x, y, z, w) 其实等价于三维坐标 (x/w, y/w, z/w) 。抛开这么多复杂的概念，我们当前只需要明确一点：当我们使用齐次坐标表示三维顶点坐标时，最后一个值传 1.0 即可。\n2. 片元着色器\n片元着色器的内置变量\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n变量名类型描述默认值gl_FragColorvec4指定片元（像素）颜色，格式为 RGBA-\n当然，片元着色器中 gl_FragColor 的值类型是 vec4 就很好理解了，因为其一一对应 RGBA 中的每一位。当然，我们在这里还是有一点需要注意的，就是颜色值范围。\n作为前端开发的我们，对于 RGBA 的取值应该更熟悉 (0, 255)，其中值越高颜色就越亮。但是 WebGL 继承 OpenGl 的颜色取值，它的范围是 (0.0, 1.0)，RGB 的值越高颜色越亮，而对于透明度 A 来说，值越高就越不透明。\n3. 着色器代码\n在了解了 GLSL 的一些基础知识后，我们再来看上一小节的顶点着色器代码：\nconst vertexCode = `\n  void main () {\n    // 顶点坐标\n    gl_Position = vec4(0.0, 0.0, 0.0, 1.0);\n    // 顶点渲染像素大小\n    gl_PointSize = 24.0;\n  }\n`\n\n定义了一个 main 函数\n设置 gl_Position 顶点的三维坐标对应为 (0, 0, 0)\n设置 gl_PointSize 大小为 24 像素\n\n片元着色器：\nconst fragmentCode = `\n  void main () {\n    // 顶点颜色——蓝色 (R, G, Bule, A)\n    gl_FragColor = vec4(0.0, 0.0, 0.9, 1.0);\n  }\n`\n\n同样定义了一个 main 函数\n设置 gl_FragColor 的值为蓝色 (R=0, G=0, B=0.9, A=1)\n\n这样看下来非常简单有没有！不过你也许发现了它跟 JavaScript 有点不同，GLSL 是一门强类型语言，也就是我们需要定义好一个变量的类型。不过相信大家写过 TypeScript 也不会对变量类型感到陌生。所以我们在后续写 GLSL 代码的时候要注意一下变量类型，不能像写 js 一样任性了。\n清空绘图区\n了解完着色器代码后，我们可以进入点的绘制实现了。不过为了先让大家热身热身，了解 WebGL 程序中 JavaScript 要用来做什么，我们先从一个更简单的小案例开始——清空绘图区，也可以理解成是给 canvas 上一层背景色！\n我们先来思考一下，如果要让 canvas 有一个背景色，我们需要做什么：\n\n紧接着，我们看看一些需要用到的 api：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\napi参数值参数值说明返回值gl.clearColor(r, g, b, a)r: 红色g: 绿色b: 蓝色a: 透明度注意值的范围是(0, 1)，超出将会被截断到 0 或 1-gl.clear(buffer)gl.COLOR_BUFFER_BIT 颜色缓冲区，默认透明背景gl.DEPTH_BUFFER_BIT 深度缓冲区，默认值是 1.0gl.STENCIL_BUFFER_BIT 模板缓冲区，默认值是 0-\n因为我们清空绘图区其实就是清空颜色缓冲区，所以上述清除接口 gl.clear 的参数中，我们仅需要使用 gl.COLOR_BUFFER_BIT，其他的可以先不用管。\n将上图的步骤转换成核心代码，我们只需要简单的几行就可以实现清空绘图区了：\n// 绘图环境\ngl = getContext(&#039;WebGL&#039;)\n// 传入背景色\ngl.clearColor(r, g, b, a)\n// 清除颜色缓冲区\ngl.clear(gl.COLOR_BUFFER_BIT)\n这里我们注意一点，gl.clearColor(r, g, b, a) 是有记忆的，如果我们后续清空绘图区的颜色不需要改变，那我们只需要 指定一次 clearColor 即可。\n我们可以通过以下示例程序亲自感受一下清空绘图区：\n&lt;template&gt;\n  &lt;el-button type=&quot;danger&quot; @click=&quot;redFn&quot;&gt;红色&lt;/el-button&gt;\n  &lt;el-button type=&quot;success&quot; @click=&quot;greenFn&quot;&gt;绿色&lt;/el-button&gt;\n  &lt;el-button type=&quot;primary&quot; @click=&quot;blueFn&quot;&gt;蓝色&lt;/el-button&gt;\n  &lt;el-button type=&quot;info&quot; @click=&quot;blackFn&quot;&gt;黑色&lt;/el-button&gt;\n  &lt;el-button @click=&quot;transparentFn&quot;&gt;透明&lt;/el-button&gt;\n  \n  &lt;canvas id=&quot;ice-2_1&quot; width=&quot;600&quot; height=&quot;100&quot;&gt;&lt;/canvas&gt;\n&lt;/template&gt;\n \n  \n \n&lt;script setup lang=&quot;ts&quot;&gt;\n \nimport { onMounted } from &#039;vue&#039;\nimport { createGl } from &#039;@ice-webgl/utils&#039;\n \nlet gl\n \nconst redFn = () =&gt; {\n  gl.clearColor(.9, 0., 0., .8)\n  gl.clear(gl.COLOR_BUFFER_BIT)\n}\n  \nconst greenFn = () =&gt; {\n  gl.clearColor(0., .9, 0., .8)\n  gl.clear(gl.COLOR_BUFFER_BIT)\n}\n \nconst blueFn = () =&gt; {\n  gl.clearColor(0., 0., .9, .8)\n  gl.clear(gl.COLOR_BUFFER_BIT)\n}\n \n \nconst blackFn = () =&gt; {\n  gl.clearColor(0., 0., .0, .8)\n  gl.clear(gl.COLOR_BUFFER_BIT)\n}\n \nconst transparentFn = () =&gt; {\n  gl.clearColor(0., 0., .0, .0)\n  gl.clear(gl.COLOR_BUFFER_BIT)\n}\n \nonMounted(() =&gt; {\n  gl = createGl(&#039;#ice-2_1&#039;)\n})\n \n&lt;/script&gt;\n \n&lt;script lang=&quot;ts&quot;&gt;\nimport { defineComponent } from &#039;vue&#039;\n  \nexport default defineComponent({\n  name: &#039;Second2_1&#039;\n})\n&lt;/script&gt;\n \n&lt;style scoped lang=&quot;scss&quot;&gt;\n#ice-2_1 {\n  margin-top: 16px;\n}\n&lt;/style&gt;\n绘制一个点\n到这一阶段，终于所有的准备工作都做完了，我们开始用 WebGL 一步一步的把像素点绘制出来把！\n1. 绘图环境\n老规矩，第一步一定是获取绘图环境上下文的。直接上代码：\nconst canvas = document.querySelector(&#039;#ice-2_2&#039;)\nconst gl = canvas.getContext(&#039;WebGL&#039;)\n2. 创建着色器\n我们需要创建顶点、片元两个着色器。具体的着色器代码我们复用上文所提到的[着色器代码块](/content/二、WebGL基础/2 .WebGL绘制点.html#_3-着色器代码)，他们分别放在 JavaScript 变量 vertexCode 和 fragmentCode 中。\n接下来，我们看看如何创建着色器，首先看顶点着色器：\n// 创建顶点着色器\nconst vertexShader = gl.createShader(gl.VERTEX_SHADER)\n// 传入我们编写好的顶点着色器字符串代码\ngl.shaderSource(vertexShader, vertexCode)\n// 编译着色器\ngl.compileShader(vertexShader)\n当然了，片元着色器也是按照如此流程进行生成，只是 createShader 传的参数不一样：\n// 除了一些参数不一样，整体流程均可参考上述顶点着色器\nconst fragmentShader = gl.createShader(gl.FRAGMENT_SHADER)\n// 传入我们编写好的顶点着色器字符串代码\ngl.shaderSource(fragmentShader, fragmentCode)\n// 编译着色器\ngl.compileShader(fragmentShader)\n3. 创建着色器程序\n前文介绍着色器的时候有提到，会有一个 着色程序 将 顶点着色器 和 片元着色器 组合起来，成对使用。\n// 创建着色器程序\nconst program = gl.createProgram();\n// 为程序添加 顶点着色器\ngl.attachShader(program, vertexShader);\n// 为程序添加 片元着色器\ngl.attachShader(program, fragmentShader);\n// 连接 顶点着色器 和 片元着色器，也就是组合成对\ngl.linkProgram(program);\n// 应用着色器程序，告诉 WebGL 绘制的时候使用这个着色程序\ngl.useProgram(program);\nok，到这里所有的准备工作就已经完成了，我们仅剩最后一步绘制了。在调用绘制函数之前，我们先来简单回顾一下我们做了什么：\n\n获取绘图上下文 gl\n编写着色器代码 vertexCode 、 fragmentCode\n创建着色器 createShader\n创建着色器程序 createProgram 连接顶点、片元着色器\n\n接下来，我们仅需要调用一个绘制函数 gl.drawArrays 并传入一定参数即可完成点的绘制。我们先来看看这个 api 的相关点：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\napi参数值参数值说明返回值gl.drawArrays(mode, first, count)1. mode：gl.POINTS 绘制单个点2. first：指定开始绘制的点3. count：指定绘制多少个点-\n当然，mode 总共有七种参数值，包括且不限于 gl.POINTS、gl.LINE_STRIP 等等，这些我们都不着急马上就看，等后面实现其他图形绘制的时候我们会学到的。因为看完不用马上就忘了，所以我们现在只需要关注画点的 gl.POINTS 就够了。\ngl.drawArrays(gl.POINTS, 0, 1)\n其实看到这里，有的小伙伴会觉得整个 WebGL 的程序会有点复杂，我们需要调用好多个 gl.xxx 的 api 去做很多事情，又是写 GLSL 的、又要创建着色器、编译着色器、创建着色程序…\n不知道你们有没有发现，我并没有把所有的 api 都罗列成表格去详细介绍他们的参数、用法。这是因为我认为学习 WebGL 不应该重点背 api 的参数、用法，我们更多的是掌握流程、会用核心的 api 即可。\n其实像 创建着色器、创建 program 这种常用的方法函数，我们可以把它封装起来，后面就直接调用了。所以，我也只有在这篇文章中会一行一行的写各种 gl.xxx，后面的示例程序都会直接使用封装好的工具函数。\n总结\n本文的最后，跟大家一起回顾本文的主要内容：\n\n了解顶点、片元着色器的基本工作原理。\n了解如何写着色器代码，一些基本的 GLSL 语法、类型、内置变量。\n实现了清空绘图区，并且知道 gl.clearColor 指定颜色会一直复用不用重复设置。\n如何绘制一个像素点：获取绘图环境；编写着色器代码；创建着色器；创建着色程序；使用 gl.drawArrays 绘制\n"},"front-end/webgl/1.3.-WebGL-绘制动态点":{"title":"WebGL 绘制动态点","links":[],"tags":[],"content":"3. WebGL 绘制动态点\n经过上一小节的学习，你已经掌握了如何使用 WebGL 绘制一个像素点。但是你有没有注意到，我们点的坐标是提前写好在顶点着色器中的，是一个静态的数据。那我们如何让顶点的数据变起来呢？\n动态传递顶点坐标\n我们要绘制动态点，那么就要有一个动态获取顶点坐标的途径，更直接地说，我们需要进行 JavaScript 和 GLSL 之间的信息交互。那我们首先来回顾一下之前的顶点着色器代码：\nconst vertexCode = `\n  void main () {\n    // 顶点坐标\n    gl_Position = vec4(0.0, 0.0, 0.0, 1.0);\n    // 顶点渲染像素大小\n    gl_PointSize = 24.0;\n  }\n`\n上面实现顶点着色器代码的时候，我们是直接将内置变量 gl_Position 复制给了一个固定的 vec4 类型的值。现因我们需要绘制动态顶点，所以我们的赋值应该是需要通过变量来实现，而不是直接使用一个静态的数值。\n所以，我们需要这样实现顶点着色器的代码：\nconst vertexCode = `\n  // 定义了一个名为 a_Position，类型为 vec4 的 attribute 变量\n  attribute vec4 a_Position;\n \n  void main () {\n    // 将变量赋值给顶点坐标\n    gl_Position = a_Position;\n    // 顶点渲染像素大小\n    gl_PointSize = 24.0;\n  }\n`\n对比旧的代码块，我们不难发现新增了一个 a_Position 的变量，并且将其赋值给了内置变量 gl_Position。除此之外，代码中还出现了一个我们没见过的 attribute 的字样，那我们先来了解一下它。\nattribute 变量\nGLSL 中有三种类型的变量，而 attribute 就是其中之一。详细介绍如下表：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n存储限定符描述attribute在顶点着色器中使用varying在顶点、片元着色器中定义，用于从顶点着色器向片元着色器传递数据uniform可理解为全局变量，在顶点着色器、片元着色器中都能对其访问\n对于以上这些变量，我们都可以在 JavaScript 中获取到他们引用地址，并对他们设置值。于是乎～ JavaScript 到 GLSL 之间的数据传递桥梁就被搭建起来了。\n另外提一点命名小规范，我们可以通过 类型前缀+变量名 的方式。比如说我们的一个 attribute 变量，我们以 a_Xxx 的方式来命名。放到案例中既为变量 a_Position。\nok，我们回到主题。接下来，我们只需在 JavaScript 中获取这个变量 a_Position 再赋值就能实现动态传递顶点坐标了。所以，我们先来看看这两个 api：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\napi参数值参数值说明返回值gl.getAttribLocation(program, name)1. program： WebGL program 对象2. name：获取的变量名属性位置的下标数字gl.vertexAttrib[1234]f[v](index, v0, v1) 以 vertexAttrib2f 为例1. index：attribute 变量的存储位置2. v0、v1：浮点数-\n紧接着马上进入实战！我们把上一小节的绘制点绘制到画布的左上角，并且在 JavaScript 对其进行赋值。按照上述 api 的用法，我们先获取变量位置，再对变量进行赋值 (-.9, .7) 这个靠近左上角的坐标位置。\n// 获取 a_Position 的变量地址\nconst a_Position = gl.getAttribLocation(program, &#039;a_Position&#039;)\n// 对 a_Position 变量赋值\ngl.vertexAttrib2f(a_Position, -.9, .7)\n&lt;template&gt;\n  &lt;canvas id=&quot;ice-3_1&quot; width=&quot;600&quot; height=&quot;100&quot;&gt;&lt;/canvas&gt;\n&lt;/template&gt;\n \n&lt;script setup lang=&quot;ts&quot;&gt;\nimport { onMounted, ref } from &#039;vue&#039;\nimport { createGl, createShader, createProgram } from &#039;@ice-webgl/utils&#039;\n \nconst vertexCode = `\n  // 定义了一个名为 a_Position，类型为 vec4 的 attribute 变量\n  attribute vec4 a_Position;\n  void main () {\n    // 将变量赋值给顶点坐标\n    gl_Position = a_Position;\n    // 顶点渲染像素大小\n    gl_PointSize = 24.0;\n  }\n`\n \nconst fragmentCode = `\n  void main () {\n    // 顶点颜色——蓝色 (R, G, Bule, A)\n    gl_FragColor = vec4(0.0, 0.0, 0.9, 1.0);\n  }\n`\n \nconst initGl = () =&gt; {\n  const gl = createGl(&#039;#ice-3_1&#039;)\n  const vertexShader = createShader(gl, gl.VERTEX_SHADER, vertexCode)\n  const fragmentShader = createShader(gl, gl.FRAGMENT_SHADER, fragmentCode)\n  const program = createProgram(gl, vertexShader, fragmentShader)\n  const a_Position = gl.getAttribLocation(program, &#039;a_Position&#039;)\n \n  gl.vertexAttrib2f(a_Position, -.9, .7)\n  gl.drawArrays(gl.POINTS, 0, 1)\n}\n \nonMounted(() =&gt; {\n  initGl()\n})\n \n&lt;/script&gt;\n \n&lt;script lang=&quot;ts&quot;&gt;\nimport { defineComponent } from &#039;vue&#039;\nexport default defineComponent({\n  name: &#039;Second3_1&#039;\n})\n&lt;/script&gt;\n注意观察这个示例程序的实现代码，跟之前比较有明显不同的是我们这次的顶点着色器并没有直接写死静态数据，而是通过 a_Position 这个 attribute 变量来给他赋值。好，那么在此我们已经掌握了动态传递顶点坐标的实现了，接下来我们再实现一个示例程序——鼠标点击生成点。\n鼠标交互绘制点\n对于熟悉前端开发的同学来说，这个根本不在话下，毕竟这可是饭碗啊。不过为了更熟悉 GLSL 我们还是可以拿这个小需求来练手练手。\n简单分析实现方式，其实我只要获取到鼠标点击的坐标值，并将其成功转换成 WebGL 的坐标值，再通过上述动态传递顶点坐标的方式实现点的绘制即可。\n所以代码实现对我们来说并不难，稍微麻烦一点的就是坐标转换了。于是我们可以借助图来帮助我们理清坐标点的转换关系：\n\n由上图所示，我们可以得出这个数学等式：\n\nx轴坐标：(offsetX - 1/2宽度) / 1/2宽度\ny轴坐标：(1/2高度 - offsetY) / 1/2高度\n\n因为目前我们要绘制的是二维点，所以我们无需关注 z 轴的情况，就让它为 0 即可。\n接下来，我在示例程序中把功能实现出来（为了方便大家看出画布的边框范围，设置了黑色的背景色）：\n&lt;template&gt;\n  &lt;el-row :gutter=&quot;8&quot;&gt;\n    &lt;el-col :span=&quot;6&quot;&gt;\n      &lt;el-button type=&quot;primary&quot; @click=&quot;clear&quot;&gt;清空画布&lt;/el-button&gt;\n    &lt;/el-col&gt;\n    &lt;el-col :span=&quot;6&quot;&gt;\n      &lt;el-switch v-model=&quot;isClear&quot; active-text=&quot;每次清空绘图区&quot; /&gt;\n    &lt;/el-col&gt;\n  &lt;/el-row&gt;\n  &lt;canvas id=&quot;ice-3_2&quot; @click=&quot;drawFn&quot; width=&quot;600&quot; height=&quot;200&quot;&gt;&lt;/canvas&gt;\n&lt;/template&gt;\n \n&lt;script setup lang=&quot;ts&quot;&gt;\n \nimport { onMounted, ref } from &#039;vue&#039;\n \nimport { createGl, createShader, createProgram } from &#039;@ice-webgl/utils&#039;\n \nconst isClear = ref(true)\n \nconst vertexCode = `\n  // 定义了一个名为 a_Position，类型为 vec4 的 attribute 变量\n  attribute vec4 a_Position;\n  void main () {\n    // 将变量赋值给顶点坐标\n    gl_Position = a_Position;\n    // 顶点渲染像素大小\n    gl_PointSize = 24.0;\n  }\n`\n \nconst fragmentCode = `\n  void main () {\n    // 顶点颜色——蓝色 (R, G, Bule, A)\n    gl_FragColor = vec4(0.0, 0.0, 0.9, 1.0);\n  }\n`\n \nlet gl, a_Position, canvas\n \nconst initGl = () =&gt; {\n  gl = createGl(&#039;#ice-3_2&#039;)\n  const vertexShader = createShader(gl, gl.VERTEX_SHADER, vertexCode)\n  const fragmentShader = createShader(gl, gl.FRAGMENT_SHADER, fragmentCode)\n  const program = createProgram(gl, vertexShader, fragmentShader)\n  a_Position = gl.getAttribLocation(program, &#039;a_Position&#039;)\n  gl.clearColor(0., 0., 0., .9)\n  gl.clear(gl.COLOR_BUFFER_BIT)\n}\n  \nconst drawFn = (e: MouseEvent) =&gt; {\n  const halfW = canvas.width / 2\n  const halfH = canvas.height / 2\n  const glX = parseFloat((e.offsetX - halfW ) / halfW + &#039;&#039;)\n  const glY = parseFloat((halfH - e.offsetY) / halfH + &#039;&#039;)\n  isClear.value &amp;&amp; gl.clear(gl.COLOR_BUFFER_BIT)\n  gl.vertexAttrib2f(a_Position, glX, glY)\n  gl.drawArrays(gl.POINTS, 0, 1)\n}\n \nconst clear = () =&gt; {\n  gl.clear(gl.COLOR_BUFFER_BIT)\n}\n \nonMounted(() =&gt; {\n  initGl()\n  canvas = document.querySelector(&#039;#ice-3_2&#039;)\n})\n \n&lt;/script&gt;\n \n&lt;script lang=&quot;ts&quot;&gt;\nimport { defineComponent } from &#039;vue&#039;\n \nexport default defineComponent({\n  name: &#039;Second3_2&#039;\n})\n&lt;/script&gt;\n \n&lt;style lang=&quot;scss&quot; scoped&gt;\n#ice-3_2 {\n  margin-top: 16px;\n}\n&lt;/style&gt;\n我们直接在示例上操作鼠标即可实现在点击的位置绘制出一个蓝色的像素点。\n通过这个示例（当打开”每次清空绘图区”时），我们也顺便印证了之前提到的清空绘图区的一个细节点，当我们指定了一次背景色后，我们下次调用 gl.clear(gl.COLOR_BUFFER_BIT) 清空颜色缓冲区就可以恢复之前的纯色背景了，无需重新指定颜色值了。\n既然我放了个 switch开关 在示例中，那当然是可以选择关闭的！当我们关闭 “每次清空绘图区” 功能时，我们在每次点击后背景直接消失了。其实这个开关只是控制是否调用 gl.clear 而已，具体实现在 drawFn 里：\n// 当打开 switch 时，每次绘制前都执行一次清空绘图区\nisClear.value &amp;&amp; gl.clear(gl.COLOR_BUFFER_BIT)\n其实在绘制点之后，颜色缓冲区就被 WebGL 重置为默认颜色了，也就是 (0.0, 0.0, 0.0, 0.0) 透明度为 0 的透明背景。所以，如果我们希望保持一个背景色不变，需要在每次绘制前都调用一次 gl.clear 。\n之所以要把这一点拿出来说，因为我认为大家读到这里的时候一定会有一个疑问，那就是既然我绘制前调用不调用 gl.clear 绘制点都会被清空，那我想让每一次绘制的点都保留下来要怎么做？我们接着往下看。\n缓存颜色缓冲区\n针对上一小节的问题，我们可以这样想：当我们每次点击重新绘制时WebGL 会清除掉上次的颜色缓冲区。因为表象告诉我们，当没打开 “每次清空绘图区” 时，不光是蓝色的像素点没了，更是连黑色的背景色也没了。\n其实 WebGL 系统的绘制操作是在颜色缓冲区中进行的，绘制结束后再将颜色缓冲区中的结果显示到屏幕上，然后默认情况下的颜色缓冲区就会被重置，所以内容会丢失。\n那我们想缓存每一次的绘制操作，我们应该怎样做呢？关于这一点，我们可以在 MDN canvas.getContext 中可以找到答案——preserveDrawingBuffer。关于这个配置项，MDN 是这样描述的：\n\nIf the value is true the buffers will not be cleared and will preserve their values until cleared or overwritten by the author.\n\n也就是说，当我们设置 preserveDrawingBuffer: true 时，颜色缓冲区就不会被清除，我们马上通过下文的示例程序试试效果:\n&lt;template&gt;\n  &lt;el-row :gutter=&quot;8&quot;&gt;\n    &lt;el-col :span=&quot;6&quot;&gt;\n      &lt;el-button type=&quot;primary&quot; @click=&quot;clear&quot;&gt;清空画布&lt;/el-button&gt;\n    &lt;/el-col&gt;\n    &lt;el-col :span=&quot;6&quot;&gt;\n      &lt;el-switch v-model=&quot;isClear&quot; active-text=&quot;每次清空绘图区&quot; /&gt;\n    &lt;/el-col&gt;\n  &lt;/el-row&gt;\n  &lt;canvas id=&quot;ice-3_3&quot; @click=&quot;drawFn&quot; width=&quot;600&quot; height=&quot;200&quot;&gt;&lt;/canvas&gt;\n&lt;/template&gt;\n \n  \n \n&lt;script setup lang=&quot;ts&quot;&gt;\nimport { onMounted, ref } from &#039;vue&#039;\nimport { createShader, createProgram } from &#039;@ice-webgl/utils&#039;\n \nconst isClear = ref(false)\n \nconst vertexCode = `\n \n  // 定义了一个名为 a_Position，类型为 vec4 的 attribute 变量\n  attribute vec4 a_Position;\n  void main () {\n    // 将变量赋值给顶点坐标\n    gl_Position = a_Position;\n    // 顶点渲染像素大小\n    gl_PointSize = 24.0;\n  }\n \n`\n \nconst fragmentCode = `\n  void main () {\n    // 顶点颜色——蓝色 (R, G, Bule, A)\n    gl_FragColor = vec4(0.0, 0.0, 0.9, 1.0);\n  }\n`\n  \nlet gl, a_Position, canvas\n \nconst initGl = () =&gt; {\n  canvas = document.querySelector(&#039;#ice-3_3&#039;)\n  gl = canvas.getContext(&#039;webgl&#039;, { preserveDrawingBuffer: true })\n  const vertexShader = createShader(gl, gl.VERTEX_SHADER, vertexCode)\n  const fragmentShader = createShader(gl, gl.FRAGMENT_SHADER, fragmentCode)\n  const program = createProgram(gl, vertexShader, fragmentShader)\n  a_Position = gl.getAttribLocation(program, &#039;a_Position&#039;)\n  gl.clearColor(0., 0., 0., .9)\n  gl.clear(gl.COLOR_BUFFER_BIT)\n}\n \n  \n \nconst drawFn = (e: MouseEvent) =&gt; {\n  const halfW = canvas.width / 2\n  const halfH = canvas.height / 2\n  const glX = parseFloat((e.offsetX - halfW ) / halfW + &#039;&#039;)\n  const glY = parseFloat((halfH - e.offsetY) / halfH + &#039;&#039;)\n  isClear.value &amp;&amp; gl.clear(gl.COLOR_BUFFER_BIT)\n  gl.vertexAttrib2f(a_Position, glX, glY)\n  gl.drawArrays(gl.POINTS, 0, 1)\n}\n \nconst clear = () =&gt; {\n  gl.clear(gl.COLOR_BUFFER_BIT)\n}\n \nonMounted(() =&gt; {\n  initGl()\n})\n&lt;/script&gt;\n&lt;script lang=&quot;ts&quot;&gt;\nimport { defineComponent } from &#039;vue&#039;\nexport default defineComponent({\n  name: &#039;Second3_3&#039;\n})\n&lt;/script&gt;\n \n&lt;style lang=&quot;scss&quot; scoped&gt;\n#ice-3_3 {\n  margin-top: 16px;\n}\n&lt;/style&gt;\n根据示例程序我们可以知道，当我们不打开 “每次清空绘制区” 功能时，每次点击绘制的点都被缓存下来了，并且背景色也不会变成透明，这样符合我们的预期。而对于代码的实现，我们仅仅通过配置 preserveDrawingBuffer 这个属性就可以了：\ncanvas = document.querySelector(&#039;#ice-2_5&#039;)\n// getContext 中配置 preserveDrawingBuffer 为 true\ngl = canvas.getContext(&#039;WebGL&#039;, { preserveDrawingBuffer: true })\n总结\n本文的最后，跟大家一起回顾本文的主要内容：\n\n在 GLSL 顶点着色器代码中使用 attribute变量 动态接收值\nJavaScript 通过获取变量位置 getAttribLocation 和设置变量值 vertexAttrib[1234]f[v] 实现数据传递\n通过换算坐标为 (-1, 1) 实现了鼠标绘制像素点\n通过在 canvas.getContext 中配置 preserveDrawingBuffer 属性实现颜色缓冲区的缓存\n"},"front-end/webgl/1.4.-绘制动态颜色点":{"title":"绘制动态颜色点","links":[],"tags":[],"content":"4. 绘制动态颜色点\n经过上一小节的学习，我们已经掌握了通过 attribute 变量传递动态值给顶点着色器实现动态点的绘制。但其实我们的点都只有蓝色这一种颜色，那么这一节，我们来实现动态改变点的颜色！\nuniform 变量\n上节讲到 attribute 变量时有提到一下 uniform 变量，不过没有展开讲。我们上节讲到 attribute 变量时，特别提了它只能在顶点着色器中使用，而我们要实现动态颜色绘制的话，我们得对 片元着色器 下手，于是乎我们就找来了 uniform。\nuniform 变量可以在顶点着色器和片元着色器中被访问，而我们用其来声明变量的方式跟 attribute 是一样的，比如：\n// 存储限定符 类型 变量名\nuniform vec4 u_FragCOlor\n在着色器中声明变量后，我们就可以改造一下片元着色器的代码了，那首先我们回顾一下之前的代码：\nconst fragmentCode = `\n  void main () {\n    // 顶点颜色——蓝色 (R, G, Bule, A)\n    gl_FragColor = vec4(0.0, 0.0, 0.9, 1.0);\n  }\n`;\n可以看到，我们给内置变量 gl_FragColor 赋值了一个固定的 vec4 类型的颜色值，那么我们现在使用 uniform 对其进行改造：\nconst fragmentCode = `\n  precision mediump float;\n  uniform vec4 u_FragColor;\n  \n  void main () {\n    gl_FragColor = u_FragColor;\n  }\n`;\n注意一点！上面代码中使用 precision mediump float; 精度限定词来指定变量的范围和精度。不加的话，在创建片元着色器的时候会出现如下错误：\n\n其实就是告诉我们未为指定浮点精度，详细大家可以看看这个 stackoverflow。所以新手上路自己敲代码的时候得注意一下这点。\n接下来，我们跟 attribute 变量赋值一样，先通过 api 获取变量的存储位置，再给其设值就可以了。整体是非常相似的，只是 api 有点区别：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\napi参数值参数值说明返回值gl.getUniformLocation(program, name)1. program： WebGL program 对象2. name：获取的变量名属性位置的下标数字gl.uniform[1234]f[v](index, v0, v1, v2, v3) 以 uniform4f 为例1. index：attribute 变量的存储位置2. v0-v3：代表 rgba 每位值的浮点数-\n我们根据 attribute 变量的用法方式，可以将上一节的 示例程序 进行一个小的改造：\n// 获取 unfirom 变量存储位置\nconst u_FragColor = gl.getUniformLocation(program, &quot;u_FragColor&quot;);\n// 通过 随机数 对 rgb 进行赋值，透明度固定为 0.8\ngl.uniform4f(u_FragColor, Math.random(), Math.random(), Math.random(), 0.8);\n在原本示例程序的基础上加上这几行代码，我们再来看看这个示例程序的运行效果：\n&lt;template&gt;\n   \n  &lt;el-row :gutter=&quot;8&quot;&gt;\n       \n    &lt;el-col :span=&quot;6&quot;&gt;\n            &lt;el-button type=&quot;primary&quot; @click=&quot;clear&quot;&gt;清空画布&lt;/el-button&gt;    \n    &lt;/el-col&gt;\n       \n    &lt;el-col :span=&quot;6&quot;&gt;\n            &lt;el-switch v-model=&quot;isClear&quot; active-text=&quot;每次清空绘图区&quot; /&gt;    \n    &lt;/el-col&gt;\n     \n  &lt;/el-row&gt;\n    &lt;canvas id=&quot;ice-4_1&quot; @click=&quot;drawFn&quot; width=&quot;600&quot; height=&quot;200&quot;&gt;&lt;/canvas&gt;\n&lt;/template&gt;\n \n&lt;script setup lang=&quot;ts&quot;&gt;\nimport { onMounted, ref } from &quot;vue&quot;;\nimport { createShader, createProgram } from &quot;@ice-webgl/utils&quot;;\nconst isClear = ref(false);\nconst vertexCode = `\n  // 定义了一个名为 a_Position，类型为 vec4 的 attribute 变量\n  attribute vec4 a_Position;\n  void main () {\n    // 将变量赋值给顶点坐标\n    gl_Position = a_Position;\n    // 顶点渲染像素大小\n    gl_PointSize = 24.0;\n  }\n`;\n \nconst fragmentCode = `\n  precision mediump float;\n  uniform vec4 u_FragColor;\n  void main () {\n    gl_FragColor = u_FragColor;\n  }\n`;\nlet gl, a_Position, canvas, u_FragColor;\nconst initGl = () =&gt; {\n  canvas = document.querySelector(&quot;#ice-4_1&quot;);\n  gl = canvas.getContext(&quot;webgl&quot;, { preserveDrawingBuffer: true });\n  const vertexShader = createShader(gl, gl.VERTEX_SHADER, vertexCode);\n  const fragmentShader = createShader(gl, gl.FRAGMENT_SHADER, fragmentCode);\n  const program = createProgram(gl, vertexShader, fragmentShader);\n  a_Position = gl.getAttribLocation(program, &quot;a_Position&quot;);\n  u_FragColor = gl.getUniformLocation(program, &quot;u_FragColor&quot;);\n  gl.clearColor(0, 0, 0, 0.9);\n  gl.clear(gl.COLOR_BUFFER_BIT);\n};\n \nconst drawFn = (e: MouseEvent) =&gt; {\n  const halfW = canvas.width / 2;\n  const halfH = canvas.height / 2;\n  const glX = parseFloat((e.offsetX - halfW) / halfW + &quot;&quot;);\n  const glY = parseFloat((halfH - e.offsetY) / halfH + &quot;&quot;);\n  isClear.value &amp;&amp; gl.clear(gl.COLOR_BUFFER_BIT);\n  gl.vertexAttrib2f(a_Position, glX, glY);\n  gl.uniform4f(u_FragColor, Math.random(), Math.random(), Math.random(), 0.8);\n  gl.drawArrays(gl.POINTS, 0, 1);\n};\nconst clear = () =&gt; {\n  gl.clear(gl.COLOR_BUFFER_BIT);\n};\nonMounted(() =&gt; {\n  initGl();\n});\n&lt;/script&gt;\n \n&lt;script lang=&quot;ts&quot;&gt;\nimport { defineComponent } from &quot;vue&quot;;\n \nexport default defineComponent({\n  name: &quot;Second4_1&quot;,\n});\n&lt;/script&gt;\n&lt;style lang=&quot;scss&quot; scoped&gt;\n#ice-4_1 {\n  margin-top: 16px;\n}\n&lt;/style&gt;\n在示例程序中点击鼠标，可以看到有五颜六色的像素点。这一步，我们成功实现了像素点的随机颜色。那么接下来，我们再认识另外一个变量 varying。\nvarying 变量\nvarying 变量也可以帮助我们实现绘制动态变化的颜色点，它的作用是从顶点着色器向片元着色器传输数据。如果说顶点着色器和片元着色器有 类型和变量名 都完全相同的 varying 变量，那我们可以把变化的数据传递到顶点着色器，顶点着色器中的同名同类型 varying 变量会被传入到片元着色器中。\n这么说可能有点绕，我们通过代码来进一步理解 varying 变量。代码中注意变量的命名，按照之前所说的规则 a_Xxx 代表 attribute 变量、v_Xxx 代表 varying 变量。\nconst vertexCode = `\n  attribute vec4 a_Position;\n  // 定义 a_Color 动态接受值\n  attribute vec4 a_Color;\n  // 定义 v_Color 接收、传递颜色值（跟片元着色器一致）\n  varying vec4 v_Color;\n \n  void main () {\n    gl_Position = a_Position;\n    gl_PointSize = 24.0;\n    v_Color = a_Color;\n  }\n`;\n \nconst fragmentCode = `\n  precision mediump float;\n  // 定义 v_Color，注意类型、变量名跟顶点着色器的一致，用于接收变量\n  varying vec4 v_Color;\n \n  void main () {\n    gl_FragColor = v_Color;\n  }\n`;\n上述代码我们可以发现，先通过 a_Color 接收 JavaScript 的传值，再将其赋值给顶点着色器的 v_Color 变量，这时候，片元着色器中的同名同类型 v_Color 变量就能动态接收到颜色值了。\n这里，再通过一张图来详细了解 varying 变量获得值的一个数据流向：\n\n那最后一步，我们当然是还是通过实现一个示例程序来实战一下 varying 变量的使用。其实代码并不复杂，我们也是直接对着上一个示例程序进行一定的修改即可。首先我们要使用这一小节提到的着色器代码，然后在 JavaScript 中获取 a_Color 并对其传值即可。\n&lt;template&gt;\n   \n  &lt;el-row :gutter=&quot;8&quot;&gt;\n       \n    &lt;el-col :span=&quot;6&quot;&gt;\n            &lt;el-button type=&quot;primary&quot; @click=&quot;clear&quot;&gt;清空画布&lt;/el-button&gt;    \n    &lt;/el-col&gt;\n       \n    &lt;el-col :span=&quot;6&quot;&gt;\n            &lt;el-switch v-model=&quot;isClear&quot; active-text=&quot;每次清空绘图区&quot; /&gt;    \n    &lt;/el-col&gt;\n     \n  &lt;/el-row&gt;\n    &lt;canvas id=&quot;ice-4_2&quot; @click=&quot;drawFn&quot; width=&quot;600&quot; height=&quot;200&quot;&gt;&lt;/canvas&gt;\n&lt;/template&gt;\n \n&lt;script setup lang=&quot;ts&quot;&gt;\nimport { onMounted, ref } from &quot;vue&quot;;\nimport { createShader, createProgram } from &quot;@ice-webgl/utils&quot;;\nconst isClear = ref(false);\nconst vertexCode = `\n  attribute vec4 a_Position;\n  // 定义 a_Color 动态接受值\n  attribute vec4 a_Color;\n  // 定义 v_Color 接收、传递颜色值（跟片元着色器一致）\n  varying vec4 v_Color;\n  void main () {\n    gl_Position = a_Position;\n    gl_PointSize = 24.0;\n    v_Color = a_Color;\n  }\n \n`;\n \nconst fragmentCode = `\n  precision mediump float;\n  // 定义 v_Color，注意类型、变量名跟顶点着色器的一致，用于接收变量\n  varying vec4 v_Color;\n \n  void main () {\n    gl_FragColor = v_Color;\n  }\n`;\nlet gl, a_Position, canvas, a_Color;\nconst initGl = () =&gt; {\n  canvas = document.querySelector(&quot;#ice-4_2&quot;);\n  gl = canvas.getContext(&quot;webgl&quot;, { preserveDrawingBuffer: true });\n  const vertexShader = createShader(gl, gl.VERTEX_SHADER, vertexCode);\n  const fragmentShader = createShader(gl, gl.FRAGMENT_SHADER, fragmentCode);\n  const program = createProgram(gl, vertexShader, fragmentShader);\n  a_Position = gl.getAttribLocation(program, &quot;a_Position&quot;);\n  a_Color = gl.getAttribLocation(program, &quot;a_Color&quot;);\n  gl.clearColor(0, 0, 0, 0.9);\n  gl.clear(gl.COLOR_BUFFER_BIT);\n};\n \nconst drawFn = (e: MouseEvent) =&gt; {\n  const halfW = canvas.width / 2;\n  const halfH = canvas.height / 2;\n  const glX = parseFloat((e.offsetX - halfW) / halfW + &quot;&quot;);\n  const glY = parseFloat((halfH - e.offsetY) / halfH + &quot;&quot;);\n  isClear.value &amp;&amp; gl.clear(gl.COLOR_BUFFER_BIT);\n  gl.vertexAttrib2f(a_Position, glX, glY);\n  gl.vertexAttrib4f(a_Color, Math.random(), Math.random(), Math.random(), 0.8);\n  gl.drawArrays(gl.POINTS, 0, 1);\n};\nconst clear = () =&gt; {\n  gl.clear(gl.COLOR_BUFFER_BIT);\n};\n \nonMounted(() =&gt; {\n  initGl();\n});\n&lt;/script&gt;\n \n&lt;script lang=&quot;ts&quot;&gt;\nimport { defineComponent } from &quot;vue&quot;;\n \nexport default defineComponent({\n  name: &quot;Second4_2&quot;,\n});\n&lt;/script&gt;\n \n&lt;style lang=&quot;scss&quot; scoped&gt;\n#ice-4_2 {\n  margin-top: 16px;\n}\n&lt;/style&gt;\n如上示例程序，效果跟 uniform 中的一模一样！但是原理稍有不同而已。建议大家都动手敲一敲代码，便会更深刻的记住到他们的用法。\nuniform 、 varying 之间的区别\n好，那么相信大家看完 varying 变量之后就会有一个疑问：uniform 、 varying 之间有区别吗？什么时候要用哪个变量呢？\n有这样的疑问证明你跟我一样是个好奇宝宝，因为到这一章节为止我们还没有讲到”缓冲区”的概念，所以并不是很好地阐述他们的区别。我打算通过举例描述和图片来讲解他们之间的区别，如果还是没太懂也没关系，看完缓冲区之后再回来看这一小节就一定可以理解！\nuniform 的英文意思有 “一致的”、“统一的”；而 varying 的英文翻译过来是 “不同的”、“易变的”（还有一个”内插”的过程，后续会提到）。其实我们从他们的意思就可以大概知道他们之间的区别，那接下来我们通过一个例子来理解他们的区别。\n现在我们绘制点的时候，每次调用一次 gl.drawArrays 来绘制一个点，那当我们使用”缓冲区”的时候，我们可以实现一次 gl.drawArrays 绘制多个点。\n基于此，因为我们可以理解为 unifrom 变量是全局的，所以当我们绘制的时候，颜色值只有一个 gl_Color = u_Color，如果我们不断给 u_Color 赋值，那新的值就会覆盖旧的值，最后绘制的时候就以最后的颜色值为准。\n而 varying 变量是可变的，我们通过缓冲区不断地给顶点着色器中的 a_Color 赋值（其实也是给 v_Color 赋值了，因为v_Color = a_Color），那对应这个点的片元着色器也会接收到当前从顶点着色器中传递下来的 v_Color 值。以此就可以在一次的绘制中，多个点绘制不同的颜色。\n如果还是有点疑惑我们可以借助下图来帮助理解：\n\n当然，这里并不需要你立马就理解他们之间的区别，我们可以学完缓冲区之后，再回来看这一节，那么你一定会恍然大悟。\n总结\n本文的最后，跟大家一起回顾本文的主要内容：\n\nuniform 变量可以被顶点、片元着色器共同访问，我们可以理解为一个全局变量。\n获取 uniform 变量位置再进行赋值操作的流程跟 attribute 变量的一致，只是 api 稍有不同。\n通过 varying 变量可以实现从顶点着色器向片元着色器中传递值，依旧可以实现绘制动态颜色的需求。\nuniform 跟 varying 变量的核心区别就是前者是不变的，全局的；后者是可变的，具体表现在由每个顶点着色器传入片元着色器中可以有不同的值。\n"},"front-end/webgl/1.5.-WebGL-绘制线和三角":{"title":"WebGL 绘制线和三角","links":["front-end/webgl/1.2.-WebGL-绘制点","front-end/webgl/1.3.-WebGL-绘制动态点"],"tags":[],"content":"5. WebGL 绘制线和三角\n经过前面几个小节的学习，我们已经学习了点的绘制；一些相关的 GLSL 语法、内置变量和写法，那么从这一节开始，我们将继续深入了解缓冲区对象，通过 WebGL 来绘制线和面。\n虽说是用 WebGL 绘制线和面，但其实大家应该早就知道了 3D 图形的基本单位是三角形，也就是三角形是所有面、3D 图形的基础。我们可以直接在 three.js 的这个 demo，很显然立体图形是通过拼合多个三角形构成的，所以说三角形是 3D 图形的基础。\n\n缓冲区对象\n我们想一想，缓冲区对象是什么？为什么需要缓冲区对象？\n回顾之前我们绘制点的做法，我们都是通过 gl.drawArrays() 来实现单个点的绘制，而且当时我们还简单介绍了一下这个 api 的用法（WebGL 绘制点）。我们在这里简单回顾一下：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\napi参数值参数值说明返回值gl.drawArrays(mode, first, count)1. mode：gl.POINTS 绘制单个点2. first：指定开始绘制的点3. count：指定绘制多少个点-\n可以看到参数值说明，我们之前只了解了其中一个 mode 值——gl.POINTS。那其实 mode 还有其他的参数值，比如：\n\ngl.LINE_STRIP\ngl.LINE_LOOP\ngl.TRIANGLES\n\n等等…我们通过它的英文名称不难发现 points 、line 、triangles 不就是 点、线、三角形吗？没错，其实我们改变 gl.drawArrays 这个 api 的 mode 的参数值，WebGL 就帮我们绘制对应的图形。\n那么问题来了，之前我们绘制一个点的时候只需要传入一个点的坐标位置给到 gl_Position 即可，但是我们现在绘制线和三角形，最少一次调用 gl.drawArrays 之前都得设置两个以上的顶点坐标值对吧？所以，这个时候我们就需要缓冲区对象了。\n缓冲区对象可以一次性传入多个顶点数据（包括但不限于坐标数据，还可以有颜色和其他的），保存在缓冲区中，后续顶点着色器、片元着色器就可以使用里面的数据。\n我们通过下图来大概了解缓冲区的应用过程：\n\njs 中定义了 Float32Array 类型的数组（我们可以简单理解为普通 js 数组）\n将 js 数组传递并存储于缓冲区对象中\ngl.drawArrays() 绘制时，顶点、片元着色器可以通过缓冲区读取多个顶点数据\n\n\n图画得比较简单，一时没看懂没关系，我们接着往下走，当你使用缓冲区成功绘制出线、三角形的时候再回来看这个图会有更深的理解。\n使用 WebGL 缓冲区\n缓冲区的使用遵循一个步骤，其中也会涉及到一些新的 api ，我们一步一步来看：\n\n通过 gl.createBuffer 创建缓冲区对象\n通过 gl.bindBuffer 绑定缓冲区对象（无法直接操作缓冲区对象）\n通过 gl.bufferData 写入缓冲区数据，如上图中的 Float32Array 数据\n通过 gl.vertexAttribPointer 将缓冲区数据分配到 attribute 变量\n通过 gl.enableVertexAttribArray 开启 attribute 变量\n\n好像是稍微有那么一点复杂，涉及各种 api 的使用和参数传递，但是其实我们可以在学习之后自行将其进行一定的封装，沉淀为一个工具函数。处于学习阶段的我们需要掌握它，所以还是有必要了解每一个步骤。那接下来，我们一步一步的来展开说说吧！\n1. 创建缓冲区对象\n首先是创建缓冲区对象，我们可以在 MDN-gl.createBuffer 看看这个 api 的具体用法，这个算是非常简单了，因为我们不需要管任何参数！\n// 直接调用创建缓冲区对象\nconst buffer = gl.createBuffer();\n当我们执行了这行代码，相当于在 WebGL 中创建了一个缓冲区对象：\n\n顺带提一下，有来就有回，有创建就有删除！我们可以通过 gl.deleteBuffer 来删除对应的缓冲区（了解一下，不属于本节重点）。\n2. 绑定缓冲区对象\n关于这一步，我们可以这样理解：上文有提到一点不能直接操作缓冲区对象，所以我们需要把缓冲区对象需要绑定到一个 target 上，然后我们去操作 target。其实可以类比成 es6 的 Proxy，将这一步理解为一个代理的概念。\n我们可以先通过 MDN-gl.bindBuffer 来了解这个 api 的基本用法。\n\n它的第一个参数——target。\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntarget参数值说明gl.ARRAY_BUFFER包含顶点属性的 Buffer，如坐标数据、颜色数据gl.ELEMENT_ARRAY_BUFFER包含顶点的索引值 BufferWebGL2 相关参数（感兴趣可以去 MDN 里看，本节暂时不涉及）\n我们可以发现有 target 的类型有很多，本节我们只关注 gl.ARRAY_BUFFER 即可。根据 MDN 对他的描述，我们可以知道他是作为包含顶点属性 Buffer 的一个 target，又因为我们目前通过 Buffer 存放我们 N 个顶点的坐标，所以我们将 Buffer 绑定到它身上。\n\n它的第二个参数——buffer\n\n这个就没什么好说的了，他就是我们创建的 Buffer ，也就是上文提到的 gl.createBuffer() 的返回值。\n相应的代码实现如下：\n// 第一个参数 target；第二个参数 buffer\ngl.bindBuffer(gl.ARRAY_BUFFER, buffer);\n那么此时，我们将刚才创建的一个缓冲区对象绑定到了 gl.ARRAY_BUFFER 这个 target 上：\n\n3. 缓冲区写入数据\n老规矩，我们先来看看 MDN-gl.bufferData 的 api 用法：bufferData(target, srcData, usage)（看 WebGL1 的即可）。\n\n第一个参数是 target，跟上一小节是一样的（可参考上小节的表格）。还记得我们不能直接操作缓冲区对象吗，所以我们需要通过 target 来给它赋值。\n第二个参数是 srcData，我们可以传入一个类型化数组，如 Float32Array\n第三个参数是 usage，这里有几个可选值，我们目前用 gl.STATIC_DRAW（数据写入缓冲区一次，但可用于多次绘制） 即可。\n\n有些参数我们暂时用不着的，我也不会都罗列出来，反正没用到的我们看了也记不住。有需要的自行查 MDN 详细看吧。这里我再提一点就是第二个参数中提到的类型化数组。\n前端开发中我从没用过除了 Array 外的数组，但为什么 WebGL 这里使用了类型化数组呢？就是为了性能优化。平时我们用的 Array，我们可以往里面放任何类型的数据，如 number、 string、甚至是个对象（树形数组）。但 WebGL 绘制 3D 图像的时候是要处理很多个顶点数据（各种浮点数），所以用类型化数组能让其处理起来更有效率。\n那么关于类型化数组，我们依然可以通过 MDN-typed arrays 来了解它，里面不仅有提到 Float32Array 、 Float64Array…太多了，大家自己去看吧。反正在 WebGL 的开发中，我们应该都要常用这种类型化数组的了。\n接下来，我们通过一个图来把我们的坐标数据搞出来。还是老规矩画 2D 的，我们先不管 Z 轴：\n\n如上图所示，这三个点就是我们一会要绘制线、三角形用到的点，我们将其成对放到类型化数组中，然后再将其写入缓冲区对象中。\n// 成对放置顶点数据 [&lt;x, y&gt;, &lt;x, y&gt;]\nconst vertices = new Float32Array([0, 0.8, -0.6, -0.6, 0.6, -0.6]);\n// 写入缓冲区\ngl.bufferData(gl.ARRAY_BUFFER, vertices, gl.STATIC_DRAW);\n到这一步我们已经将数据写入缓冲区对象中了：\n\n4. 分配缓冲区数据给 attribute\n其实这一步我们并不陌生，回顾1.3. WebGL 绘制动态点，之前我们是通过 gl.vertexAttrib2f 将数据动态传递到 a_Position 中的，然后再赋值给 gl_Position。但是这个 api 一次只能分配一个值，我们现在却有一整个数组的顶点数据，所以这里我们需要 gl.vertexAttribPointer 这个 api。\n老规矩，我们先看 MDN-gl.vertexAttribPointer 对其的介绍。其作用是将绑定到 gl.ARRAY_BUFFER 的缓冲区对象传递到顶点着色器的 attribute 变量。（我理解为将一个指针给到顶点着色器中的 attribute）\n可能首次看到这个 api 的语法的同学都被吓到了，参数是真的多：\ngl.vertexAttribPointer(index, size, type, normalized, stride, offset);\n不过其实没关系，我们这一节只需要注意前两个参数即可。那我们直接来看看前两个参数：\n\n第一个参数 index 其实就是 “index of the vertex attribute”，所以它就是顶点着色器中的 attribute 变量而已\n第二个参数 size，指的是每个顶点分配到的缓冲区数据的个数，值范围是[1-4]（因为我们的顶点变量是 vec4 类型的数据）。如果这个值为 1，那剩下的数据将会进行一个补 0，最后一个值补 1。\n\n关于第二个参数直接可能有点晦涩，我们接着往下走，通过本文的示例程序实现来理解会更深刻。直接看代码：\n// 第一个参数顶点着色器的 attribute 变量 a_Position，第二个参数值是 2\ngl.vertexAttribPointer(a_Position, 2, gl.FLOAT, false, 0, 0);\n那么此时的整个缓冲区的状态到了下图：\n\n由上图可以看到，我们已经将缓冲区中的值分配到 attribute 变量 a_Position 中了，但是顶点着色器现在还不能访问到缓冲区中的数据。\n5. 开启 attribute 变量\n在前面所有准备工作就绪后，我们最后需要通过 gl.enableVertexAttribArray 来开启 attribute 变量。\n直接看 MDN-gl.enableVertexAttribArray 对其的介绍。\n这个 api 的用法相比前面的就非常简单了，接收一个 index 参数，而这个 index 就是顶点着色器中的 attribute 变量。\ngl.enableVertexAttribArray(a_Position);\n此时，我们的所有缓冲区创建、激活流程终于走完了，现在的顶点着色器可以使用分配到 attribute 中的缓冲区数据了：\n\n到这一步，我们关于缓冲区的所有操作就完成了，接下来就可以开始绘制我们的线段、三角形了！\n绘制线和三角\n因为绘制线、三角，我们不绘制点了，所以可以不用去设置 gl_PointSize 的值了。针对绘制线、面，我们重新搞个最简单的顶点着色器、片元着色器代码块如下：\nconst vertexCode = `\n  // 待分配缓冲区的 attribute 变量\n  attribute vec4 a_Position;\n \n  void main () {\n    gl_Position = a_Position;\n  }\n`;\n \nconst fragmentCode = `\n  void main () {\n    // 颜色固定为蓝色\n    gl_FragColor = vec4(0.0, 0.0, 0.9, 1.0);\n  }\n`;\n好，那接下来跟之前绘制点的流程一样，我们需要获取绘图上下文、创建着色器、创建 program ，最后再进行绘制。那稍微需要我们注意的只有一个，那就是绘制的 api ——gl.drawArrays，我们先简单回顾一下：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\napi参数值参数值说明返回值gl.drawArrays(mode, first, count)1. mode：gl.POINTS 绘制单个点2. first：指定开始绘制的点3. count：指定绘制多少个点-\n首先我们关注第一个参数 mode。是的，之前绘制点的时候，我们的 mode 传入的是 gl.POINTS，因为我们这次需要绘制线和三角，所以我们需要用到其他的 mode。我们看 MDN 中的 mode 值有很多种，这个我们下一节再进行分析，本节我们使用如下 mode：\n\ngl.LINE_STRIP 绘制到下一个顶点的直线\ngl.TRIANGLES 为三个点绘制一个三角形\n\n关于第二个参数 first，这里我们依旧传 0 （可理解为数组下标 0）即可，表示我们从缓冲区数据的第一个数据开始绘制。\n那 最后一个参数 count 也是需要我们注意的，因为这里我们不传 1 了，这里我们需要传 3，相当于告诉 WebGL 我们这次绘制需要绘制三个点。\n// 绘制直线\ngl.drawArrays(gl.LINE_STRIP, 0, 3);\n// 绘制三角形\ngl.drawArrays(gl.TRIANGLES, 0, 3);\nok，一切都准备就绪，我们可以直接绘制出线和三角了。接下来，直接通过示例程序来给大家展示一下最后的绘制效果把：\n&lt;template&gt;\n    &lt;el-button type=&quot;primary&quot; @click=&quot;drawLine&quot;&gt;线&lt;/el-button&gt;  \n  &lt;el-button type=&quot;primary&quot; @click=&quot;drawTriangle&quot;&gt;三角&lt;/el-button&gt;  \n  &lt;canvas id=&quot;ice-5_1&quot; width=&quot;600&quot; height=&quot;300&quot;&gt;&lt;/canvas&gt;\n&lt;/template&gt;\n \n&lt;script setup lang=&quot;ts&quot;&gt;\nimport { onMounted } from &quot;vue&quot;;\nimport { createGl, createShader, createProgram } from &quot;@ice-webgl/utils&quot;;\nconst vertexCode = `\n  attribute vec4 a_Position;\n  void main () {\n    gl_Position = a_Position;\n  }\n`;\nconst fragmentCode = `\n  void main () {\n    gl_FragColor = vec4(0.0, 0.0, 1., .8);\n  }\n`;\nlet gl, a_Position, canvas;\nconst initGl = () =&gt; {\n  gl = createGl(&quot;#ice-5_1&quot;);\n  const vertexShader = createShader(gl, gl.VERTEX_SHADER, vertexCode);\n  const fragmentShader = createShader(gl, gl.FRAGMENT_SHADER, fragmentCode);\n  const program = createProgram(gl, vertexShader, fragmentShader);\n  a_Position = gl.getAttribLocation(program, &quot;a_Position&quot;);\n  const vertices = new Float32Array([0, 0.8, -0.6, -0.6, 0.6, -0.6]);\n  const buffer = gl.createBuffer();\n  gl.bindBuffer(gl.ARRAY_BUFFER, buffer);\n  gl.bufferData(gl.ARRAY_BUFFER, vertices, gl.STATIC_DRAW);\n  gl.vertexAttribPointer(a_Position, 2, gl.FLOAT, false, 0, 0);\n  gl.enableVertexAttribArray(a_Position);\n  gl.clearColor(0, 0, 0, 0.9);\n  gl.clear(gl.COLOR_BUFFER_BIT);\n  gl.drawArrays(gl.LINE_STRIP, 0, 3);\n};\nconst drawLine = () =&gt; {\n  gl.clear(gl.COLOR_BUFFER_BIT);\n  gl.drawArrays(gl.LINE_STRIP, 0, 3);\n};\n \nconst drawTriangle = () =&gt; {\n  gl.clear(gl.COLOR_BUFFER_BIT);\n  gl.drawArrays(gl.TRIANGLES, 0, 3);\n};\n \nonMounted(() =&gt; {\n  initGl();\n});\n&lt;/script&gt;\n \n&lt;script lang=&quot;ts&quot;&gt;\nimport { defineComponent } from &quot;vue&quot;;\nexport default defineComponent({\n  name: &quot;Second5_1&quot;,\n});\n&lt;/script&gt;\n \n&lt;style lang=&quot;scss&quot; scoped&gt;\n#ice-5_1 {\n  margin-top: 16px;\n}\n&lt;/style&gt;\n总结\n本文的最后，跟大家一起回顾本文的主要内容：\n\n了解通过缓冲区对象可一次性传入多个顶点数据，实现多个点、线段、三角形的绘制\n使用缓冲区的五个步骤：创建、绑定、写入数据、赋值 attribute 变量、attribute 变量\n实战绘制线和三角，学习 gl.drawArrays 的不同参数用法\n"},"front-end/webgl/1.6.-WebGL-绘制基本图形":{"title":"WebGL 绘制基本图形","links":[],"tags":[],"content":"6. WebGL 绘制基本图形\n经过上个小节的学习，我们已经掌握了 WebGL 中如何绘制线和三角，学习了缓冲区对象，那这一节，我们继续深入 WebGL 的绘制能力，掌握如何用 WebGL 绘制出更多的基础图形。\n上一节有提到，所有的 3D 图形的基础都是三角形，但是抛开实现复杂的 3D 图形，我们需要知道如何利用 gl.drawArrays 的不同 mode 和不同顶点的组合来绘制一些基本图形，这将会是本文的重点内容。\n绘制LINE的组合图形\n说到 LINE 其实我们并不陌生，因为上一小节我们通过 gl.LINE_STRIP 绘制了一个小锐角。\n那本节，将在之前的基础上，使用不同的绘制 mode 来看看都能实现怎么样的图形效果。\n为了更加体现出每个 mode 的区别，本文的示例程序采用 6 个顶点来绘制，但是基本代码跟上一小节是一致的，也是会使用到缓冲区，所以对于具体的代码实现本文不会再赘述了，我们更多要关注是每个 mode 的绘制效果即可～\n还是跟之前一样，我们先通过一幅图来看看本文所用到的顶点和坐标：\n\n本文的示例程序都会以上述的顶点坐标来实现各种基本图形的绘制。\n// 本节的顶点坐标\nconst vertices = new Float32Array([\n  -0.5, 0.5, -0.5, -0.5, 0, 0.5, 0, -0.5, 0.5, 0.5, 0.5, -0.5,\n]);\n关于 LINES 的相关 mode，我们先大概了解一下他们的定义：\n\ngl.LINES 绘制单独的线段\ngl.LINE_STRIP 绘制连接的线段\ngl.LINE_LOOP 绘制连接的线段，最后一个点会和第一个点连接\n\n光说不够直观，我们直接通过示例程序亲自来感受一下他们之间的区别：\n&lt;template&gt;\n   \n  &lt;div&gt;\n        &lt;el-button type=&quot;primary&quot; @click=&quot;lines&quot;&gt;gl.LINES&lt;/el-button&gt;    \n    &lt;el-button type=&quot;primary&quot; @click=&quot;lineStrip&quot;&gt;gl.LINE_STRIP&lt;/el-button&gt;    \n    &lt;el-button type=&quot;primary&quot; @click=&quot;lineLoop&quot;&gt;gl.LINE_LOOP&lt;/el-button&gt;  \n  &lt;/div&gt;\n    &lt;canvas id=&quot;ice-6_1&quot; width=&quot;600&quot; height=&quot;300&quot;&gt;&lt;/canvas&gt;\n&lt;/template&gt;\n \n&lt;script setup lang=&quot;ts&quot;&gt;\nimport { onMounted } from &quot;vue&quot;;\nimport { createGl, createShader, createProgram } from &quot;@ice-webgl/utils&quot;;\nconst vertexCode = `\n  attribute vec4 a_Position;\n  void main () {\n    gl_Position = a_Position;\n  }\n`;\n \nconst fragmentCode = `\n  void main () {\n    gl_FragColor = vec4(0.0, 0.0, 1., .8);\n  }\n`;\n \nlet gl, a_Position, canvas;\n \nconst initGl = () =&gt; {\n  gl = createGl(&quot;#ice-6_1&quot;);\n  const vertexShader = createShader(gl, gl.VERTEX_SHADER, vertexCode);\n  const fragmentShader = createShader(gl, gl.FRAGMENT_SHADER, fragmentCode);\n  const program = createProgram(gl, vertexShader, fragmentShader);\n  a_Position = gl.getAttribLocation(program, &quot;a_Position&quot;);\n  const vertices = new Float32Array([\n    -0.5, 0.5, -0.5, -0.5, 0, 0.5, 0, -0.5, 0.5, 0.5, 0.5, -0.5,\n  ]);\n  const buffer = gl.createBuffer();\n  gl.bindBuffer(gl.ARRAY_BUFFER, buffer);\n  gl.bufferData(gl.ARRAY_BUFFER, vertices, gl.STATIC_DRAW);\n  gl.vertexAttribPointer(a_Position, 2, gl.FLOAT, false, 0, 0);\n  gl.enableVertexAttribArray(a_Position);\n  gl.clearColor(0, 0, 0, 0.9);\n  gl.clear(gl.COLOR_BUFFER_BIT);\n};\n \nconst lines = () =&gt; {\n  gl.clear(gl.COLOR_BUFFER_BIT);\n  gl.drawArrays(gl.LINES, 0, 6);\n};\n \nconst lineStrip = () =&gt; {\n  gl.clear(gl.COLOR_BUFFER_BIT);\n  gl.drawArrays(gl.LINE_STRIP, 0, 6);\n};\n \nconst lineLoop = () =&gt; {\n  gl.clear(gl.COLOR_BUFFER_BIT);\n  gl.drawArrays(gl.LINE_LOOP, 0, 6);\n};\n \nonMounted(() =&gt; {\n  initGl();\n});\n&lt;/script&gt;\n \n&lt;script lang=&quot;ts&quot;&gt;\nimport { defineComponent } from &quot;vue&quot;;\n \nexport default defineComponent({\n  name: &quot;Second6_1&quot;,\n});\n&lt;/script&gt;\n \n&lt;style lang=&quot;scss&quot; scoped&gt;\n#ice-6_1 {\n  margin-top: 16px;\n}\n&lt;/style&gt;\n根据示例程序，我们可以发现不同的 mode 会绘制出不同的线段效果，那以后我们可以灵活的通过组合使用不同的 mode 来实现各种线段图形了。不过在这里需要提醒一下大家，我们的顶点顺序有可能会影响最终的绘制结果，具体表现在点与点之间的连接顺序不同导致出现不同的图形结果。\n比如我修改一下缓冲区数据中点的顺序，将每一对点的前后顺序改变一下，看看改变点顺序后的示例程序：\n&lt;template&gt;\n   \n  &lt;div&gt;\n        &lt;el-button type=&quot;primary&quot; @click=&quot;lines&quot;&gt;gl.LINES&lt;/el-button&gt;    \n    &lt;el-button type=&quot;primary&quot; @click=&quot;lineStrip&quot;&gt;gl.LINE_STRIP&lt;/el-button&gt;    \n    &lt;el-button type=&quot;primary&quot; @click=&quot;lineLoop&quot;&gt;gl.LINE_LOOP&lt;/el-button&gt;  \n  &lt;/div&gt;\n    &lt;canvas id=&quot;ice-6_2&quot; width=&quot;600&quot; height=&quot;300&quot;&gt;&lt;/canvas&gt;\n&lt;/template&gt;\n \n&lt;script setup lang=&quot;ts&quot;&gt;\nimport { onMounted } from &quot;vue&quot;;\nimport { createGl, createShader, createProgram } from &quot;@ice-webgl/utils&quot;;\nconst vertexCode = `\n  attribute vec4 a_Position;\n  void main () {\n    gl_Position = a_Position;\n  }\n`;\nconst fragmentCode = `\n  void main () {\n    gl_FragColor = vec4(0.0, 0.0, 1., .8);\n  }\n`;\n \nlet gl, a_Position, canvas;\nconst initGl = () =&gt; {\n  gl = createGl(&quot;#ice-6_2&quot;);\n  const vertexShader = createShader(gl, gl.VERTEX_SHADER, vertexCode);\n  const fragmentShader = createShader(gl, gl.FRAGMENT_SHADER, fragmentCode);\n  const program = createProgram(gl, vertexShader, fragmentShader);\n  a_Position = gl.getAttribLocation(program, &quot;a_Position&quot;);\n  const vertices = new Float32Array([\n    -0.5,\n    -0.5,\n    -0.5,\n    0.5, // 每两个为一组，改变前后两组的顺序\n    0,\n    -0.5,\n    0,\n    0.5, // 每两个为一组，改变前后两组的顺序\n    0.5,\n    -0.5,\n    0.5,\n    0.5, // 每两个为一组，改变前后两组的顺序\n  ]);\n  const buffer = gl.createBuffer();\n  gl.bindBuffer(gl.ARRAY_BUFFER, buffer);\n  gl.bufferData(gl.ARRAY_BUFFER, vertices, gl.STATIC_DRAW);\n  gl.vertexAttribPointer(a_Position, 2, gl.FLOAT, false, 0, 0);\n  gl.enableVertexAttribArray(a_Position);\n  gl.clearColor(0, 0, 0, 0.9);\n  gl.clear(gl.COLOR_BUFFER_BIT);\n};\n \nconst lines = () =&gt; {\n  gl.clear(gl.COLOR_BUFFER_BIT);\n  gl.drawArrays(gl.LINES, 0, 6);\n};\n \nconst lineStrip = () =&gt; {\n  gl.clear(gl.COLOR_BUFFER_BIT);\n  gl.drawArrays(gl.LINE_STRIP, 0, 6);\n};\n \nconst lineLoop = () =&gt; {\n  gl.clear(gl.COLOR_BUFFER_BIT);\n  gl.drawArrays(gl.LINE_LOOP, 0, 6);\n};\n \nonMounted(() =&gt; {\n  initGl();\n});\n&lt;/script&gt;\n \n&lt;script lang=&quot;ts&quot;&gt;\nimport { defineComponent } from &quot;vue&quot;;\nexport default defineComponent({\n  name: &quot;Second6_2&quot;,\n});\n&lt;/script&gt;\n \n&lt;style lang=&quot;scss&quot; scoped&gt;\n#ice-6_2 {\n  margin-top: 16px;\n}\n&lt;/style&gt;\n可以发现 LINE_STRIP、LINE_LOOP 绘制出的线段图形跟上一个的示例程序呈镜面对称关系，顶点数据除了顺序改变其余都没改变：\nconst vertices = new Float32Array([\n  -0.5,\n  -0.5,\n  -0.5,\n  0.5, // 每两个为一组，改变前后两组的顺序\n  0,\n  -0.5,\n  0,\n  0.5, // 每两个为一组，改变前后两组的顺序\n  0.5,\n  -0.5,\n  0.5,\n  0.5, // 每两个为一组，改变前后两组的顺序\n]);\n绘制TRIANGLE的组合图形\n学完了线段的基本图形绘制，我们到”面”的基本图形绘制了。与其说是面，不如说是通过三角形组合起来的基本二维图形而已。\n我们这一节接着沿用本文的最开始的顶点坐标：\nconst vertices = new Float32Array([\n  -0.5, 0.5, -0.5, -0.5, 0, 0.5, 0, -0.5, 0.5, 0.5, 0.5, -0.5,\n]);\n好吧，没什么好说的，我们还是一样先了解一下每个 mode 的基本概念：\n\ngl.TRIANGLES 绘制多个单独的三角形\ngl.TRIANGLE_STRIP 绘制组合的三角形，从第二个点开始，每三个点构成一个三角形。比如下文逆时针绘制的图片 v1（就是第二个点） 跟 v2、v3 就组成一个新的三角形。\ngl.TRIANGLE_FAN 绘制组合的三角形（扇形），全部三角共用同一个点，每下一个点和前一个三角形的最后一条边组成新的三角形\n\n注意一点，三角形的绘制是按照 逆时针 的顺序绘制，比如我们看下图：\n\n该图按照本示例的坐标，展示了 gl.TRIANGLE_STRIP 时前四个顶点之间的绘制关系，可以发现第一个三角形是 (v0, v1, v2) 的顺序绘制的（逆时针），而第二个三角形则是 (v2, v1, v3) 也是一个逆时针顺序。\n光说肯定不直观，我们接着上示例程序给大家体验一下，加深理解（为了让大家看出区别，我这里通过不同的颜色去绘制了三个三角形。如果大家看示例代码的话，不用深究缓冲区的顶点坐标数据，这个涉及到步进参数的知识，暂时还没讲到那一块）：\n&lt;template&gt;\n   \n  &lt;div&gt;\n       \n    &lt;el-button type=&quot;primary&quot; @click=&quot;triangles&quot;&gt;\n            gl.TRIANGLES    \n    &lt;/el-button&gt;\n       \n    &lt;el-button type=&quot;primary&quot; @click=&quot;triangleStrip&quot;&gt;\n            gl.TRIANGLE_STRIP    \n    &lt;/el-button&gt;\n       \n    &lt;el-button type=&quot;primary&quot; @click=&quot;triangleFan&quot;&gt;\n            gl.TRIANGLE_FAN    \n    &lt;/el-button&gt;\n     \n  &lt;/div&gt;\n    &lt;canvas id=&quot;ice-6_3&quot; width=&quot;600&quot; height=&quot;300&quot;&gt;&lt;/canvas&gt;\n&lt;/template&gt;\n \n&lt;script setup lang=&quot;ts&quot;&gt;\nimport { onMounted } from &quot;vue&quot;;\nimport { createGl, createShader, createProgram } from &quot;@ice-webgl/utils&quot;;\nconst vertexCode = `\n  attribute vec4 a_Position;\n  attribute vec4 a_Color;\n  varying vec4 v_Color;\n  void main () {\n    gl_Position = a_Position;\n    v_Color= a_Color;\n  }\n`;\nconst fragmentCode = `\n  precision mediump float;\n  varying vec4 v_Color;\n  void main () {\n    gl_FragColor = v_Color;\n  }\n`;\n \nlet gl, a_Position, canvas, a_Color;\nconst initGl = () =&gt; {\n  gl = createGl(&quot;#ice-6_3&quot;);\n  const vertexShader = createShader(gl, gl.VERTEX_SHADER, vertexCode);\n  const fragmentShader = createShader(gl, gl.FRAGMENT_SHADER, fragmentCode);\n  const program = createProgram(gl, vertexShader, fragmentShader);\n  a_Position = gl.getAttribLocation(program, &quot;a_Position&quot;);\n  a_Color = gl.getAttribLocation(program, &quot;a_Color&quot;);\n  const verticesColors = new Float32Array([\n    -0.5, 0.5, 1, 0, 0, 1, -0.5, -0.5, 1, 0, 0, 1, 0, 0.5, 0, 1, 0, 1, 0, -0.5,\n    0, 1, 0, 1, 0.5, 0.5, 0, 0, 1, 1, 0.5, -0.5, 0, 0, 1, 1,\n  ]);\n \n  const FSIZE = verticesColors.BYTES_PER_ELEMENT;\n  const buffer = gl.createBuffer();\n  gl.bindBuffer(gl.ARRAY_BUFFER, buffer);\n  gl.bufferData(gl.ARRAY_BUFFER, verticesColors, gl.STATIC_DRAW);\n  gl.vertexAttribPointer(a_Position, 2, gl.FLOAT, false, FSIZE * 6, 0);\n  gl.vertexAttribPointer(a_Color, 4, gl.FLOAT, false, FSIZE * 6, FSIZE * 2);\n  gl.enableVertexAttribArray(a_Position);\n  gl.enableVertexAttribArray(a_Color);\n  gl.clearColor(0, 0, 0, 0.9);\n  gl.clear(gl.COLOR_BUFFER_BIT);\n};\n \nconst triangles = () =&gt; {\n  gl.clear(gl.COLOR_BUFFER_BIT);\n  gl.drawArrays(gl.TRIANGLES, 0, 6);\n};\n \nconst triangleStrip = () =&gt; {\n  gl.clear(gl.COLOR_BUFFER_BIT);\n  gl.drawArrays(gl.TRIANGLE_STRIP, 0, 6);\n};\n \nconst triangleFan = () =&gt; {\n  gl.clear(gl.COLOR_BUFFER_BIT);\n  gl.drawArrays(gl.TRIANGLE_FAN, 0, 6);\n};\n \nonMounted(() =&gt; {\n  initGl();\n});\n&lt;/script&gt;\n \n&lt;script lang=&quot;ts&quot;&gt;\nimport { defineComponent } from &quot;vue&quot;;\nexport default defineComponent({\n  name: &quot;Second6_3&quot;,\n});\n&lt;/script&gt;\n \n&lt;style lang=&quot;scss&quot; scoped&gt;\n#ice-6_3 {\n  margin-top: 16px;\n}\n&lt;/style&gt;\n从示例程序的 TRIANGLE_STRIP 中，我们”不明不白”地就画了个长方形，由于当前的坐标点不太能体现 TRIANGLE_FAN 的能力，所以我们换一组坐标来看看 TRIANGLE_FAN 怎么来发挥它的优势绘制一些基础图形。\n我把顶点坐标改成如下图所示的位置（根据v0-v5的顺序写入缓冲区）：\n\n对应的缓冲区坐标点数据如下：\nconst vertices = new Float32Array([\n  0,\n  0,\n  -0.5,\n  0.3, // v0, v1\n  -0.3,\n  0.6,\n  0,\n  0.8, // v2, v3\n  0.3,\n  0.6,\n  0.5,\n  0.3, // v4, v5\n]);\n整理好坐标后，我们通过 gl.TRIANGLE_FAN 再次进行绘制，绘制结果图下：\n&lt;template&gt;  &lt;canvas id=&quot;ice-6_4&quot; width=&quot;600&quot; height=&quot;300&quot;&gt;&lt;/canvas&gt;&lt;/template&gt;\n&lt;script setup lang=&quot;ts&quot;&gt;\nimport { onMounted } from &quot;vue&quot;;\nimport { createGl, createShader, createProgram } from &quot;@ice-webgl/utils&quot;;\nconst vertexCode = `\n  attribute vec4 a_Position;\n  void main () {\n    gl_Position = a_Position;\n  }\n`;\nconst fragmentCode = `\n  precision mediump float;\n  void main () {\n    gl_FragColor = vec4(0.0, 0.0, 1., .8);\n  }\n`;\nlet gl, a_Position, canvas;\nconst initGl = () =&gt; {\n  gl = createGl(&quot;#ice-6_4&quot;);\n  const vertexShader = createShader(gl, gl.VERTEX_SHADER, vertexCode);\n  const fragmentShader = createShader(gl, gl.FRAGMENT_SHADER, fragmentCode);\n  const program = createProgram(gl, vertexShader, fragmentShader);\n  a_Position = gl.getAttribLocation(program, &quot;a_Position&quot;);\n  const vertices = new Float32Array([\n    0, 0, -0.5, 0.3, -0.3, 0.6, 0, 0.8, 0.3, 0.6, 0.5, 0.3,\n  ]);\n  const buffer = gl.createBuffer();\n  gl.bindBuffer(gl.ARRAY_BUFFER, buffer);\n  gl.bufferData(gl.ARRAY_BUFFER, vertices, gl.STATIC_DRAW);\n  gl.vertexAttribPointer(a_Position, 2, gl.FLOAT, false, 0, 0);\n  gl.enableVertexAttribArray(a_Position);\n  gl.clearColor(0, 0, 0, 0.9);\n  gl.clear(gl.COLOR_BUFFER_BIT);\n  gl.drawArrays(gl.TRIANGLE_FAN, 0, 6);\n};\nonMounted(() =&gt; {\n  initGl();\n});\n&lt;/script&gt;\n \n&lt;script lang=&quot;ts&quot;&gt;\nimport { defineComponent } from &quot;vue&quot;;\nexport default defineComponent({\n  name: &quot;Second6_4&quot;,\n});\n&lt;/script&gt;\n可以看到示例程序中画出了一个类似扇形的蓝色图形！这下，你应该对 TRIANGLE_FAN 这个绘制 mode 有所体验了把。\n总结\n本文的最后，跟大家一起回顾本文的主要内容：\n\n了解不同 mode 的 LINE 组合绘制出不同的线段图形，并且我们要注意顶点顺序不同带来的绘制结果不同的可能\n了解不同 mode 的 TRIANGLE 组合绘制出不同的图形，有长方形、扇形，当然我们也需要注意点顺序的\n\n最后，因为本文涉及的绘制内容比较多，我建议大家都自己敲一下代码实现一下效果，这样可以加深你对不同 mode 参数的理解。"},"front-end/webgl/2.1.-绘制彩色的三角":{"title":"绘制彩色的三角","links":["front-end/webgl/1.4.-绘制动态颜色点"],"tags":[],"content":"1. 绘制彩色的三角\n回顾上个章节的学习，我们了解如何用 GLSL 写基本的着色器，并且了解了如何绘制一些基础的 2D 图形了。那在上一章的最后一节，我在演示 TRIANGLE 绘制效果的时候采用了混色的三角形去实现一些基础图形的绘制。所以！这一节我们将沿着这个方向，探索如何绘制出一个渐变色的三角形。\n多个缓冲区对象\n回顾一下我们上一章节的示例程序：\n&lt;template&gt;\n   \n  &lt;div&gt;\n    &lt;el-button type=&quot;primary&quot; @click=&quot;triangles&quot;&gt;\n            gl.TRIANGLES    \n    &lt;/el-button&gt;\n       \n    &lt;el-button type=&quot;primary&quot; @click=&quot;triangleStrip&quot;&gt;\n            gl.TRIANGLE_STRIP    \n    &lt;/el-button&gt;\n    \n    &lt;el-button type=&quot;primary&quot; @click=&quot;triangleFan&quot;&gt;\n            gl.TRIANGLE_FAN    \n    &lt;/el-button&gt;\n  &lt;/div&gt;\n \n    &lt;canvas id=&quot;ice-6_3&quot; width=&quot;600&quot; height=&quot;300&quot;&gt;&lt;/canvas&gt;\n&lt;/template&gt;\n \n&lt;script setup lang=&quot;ts&quot;&gt;\nimport { onMounted } from &quot;vue&quot;;\n \nimport { createGl, createShader, createProgram } from &quot;@ice-webgl/utils&quot;;\n \nconst vertexCode = `\n  attribute vec4 a_Position;\n  attribute vec4 a_Color;\n  varying vec4 v_Color;\n \n  void main () {\n    gl_Position = a_Position;\n    v_Color= a_Color;\n  }\n`;\n \nconst fragmentCode = `\n  precision mediump float;\n  varying vec4 v_Color;\n \n  void main () {\n    gl_FragColor = v_Color;\n  }\n`;\n \nlet gl, a_Position, canvas, a_Color;\n \nconst initGl = () =&gt; {\n  gl = createGl(&quot;#ice-6_3&quot;);\n  const vertexShader = createShader(gl, gl.VERTEX_SHADER, vertexCode);\n  const fragmentShader = createShader(gl, gl.FRAGMENT_SHADER, fragmentCode);\n  const program = createProgram(gl, vertexShader, fragmentShader);\n \n  a_Position = gl.getAttribLocation(program, &quot;a_Position&quot;);\n  a_Color = gl.getAttribLocation(program, &quot;a_Color&quot;);\n \n  const verticesColors = new Float32Array([\n    -0.5, 0.5, 1, 0, 0, 1,\n    -0.5, -0.5, 1, 0, 0, 1,\n    0, 0.5, 0, 1, 0, 1,\n    0, -0.5, 0, 1, 0, 1,\n    0.5, 0.5, 0, 0, 1, 1,\n    0.5, -0.5, 0, 0, 1, 1,\n  ]);\n \n  const FSIZE = verticesColors.BYTES_PER_ELEMENT;\n  const buffer = gl.createBuffer();\n  gl.bindBuffer(gl.ARRAY_BUFFER, buffer);\n  gl.bufferData(gl.ARRAY_BUFFER, verticesColors, gl.STATIC_DRAW);\n  gl.vertexAttribPointer(a_Position, 2, gl.FLOAT, false, FSIZE * 6, 0);\n  gl.vertexAttribPointer(a_Color, 4, gl.FLOAT, false, FSIZE * 6, FSIZE * 2);\n  gl.enableVertexAttribArray(a_Position);\n  gl.enableVertexAttribArray(a_Color);\n  gl.clearColor(0, 0, 0, 0.9);\n  gl.clear(gl.COLOR_BUFFER_BIT);\n};\n \nconst triangles = () =&gt; {\n  gl.clear(gl.COLOR_BUFFER_BIT);\n  gl.drawArrays(gl.TRIANGLES, 0, 6);\n};\n \nconst triangleStrip = () =&gt; {\n  gl.clear(gl.COLOR_BUFFER_BIT);\n  gl.drawArrays(gl.TRIANGLE_STRIP, 0, 6);\n};\n \nconst triangleFan = () =&gt; {\n  gl.clear(gl.COLOR_BUFFER_BIT);\n  gl.drawArrays(gl.TRIANGLE_FAN, 0, 6);\n};\n \nonMounted(() =&gt; {\n  initGl();\n});\n&lt;/script&gt;\n \n&lt;script lang=&quot;ts&quot;&gt;\nimport { defineComponent } from &quot;vue&quot;;\n \nexport default defineComponent({\n  name: &quot;Second6_3&quot;,\n});\n&lt;/script&gt;\n \n&lt;style lang=&quot;scss&quot; scoped&gt;\n \n#ice-6_3 {\n  margin-top: 16px;\n}\n&lt;/style&gt;\n很明显，这个示例程序中，我们需要动态传递给着色器的数据不仅仅是顶点坐标，还有颜色值。而之前我们学习缓冲区对象的时候，只有一种数据类型（顶点坐标）分配到着色器的 attribute 变量中，那显然是不足以满足我们现在的需求的，所以我们可以通过创建多个缓冲区对象来实现这样的需求。\n首先分析一下着色器的代码：\nconst vertexCode = `\n  // 顶点坐标数据\n  attribute vec4 a_Position;\n  // 颜色数据\n  attribute vec4 a_Color;\n  // varying 变量传递到片元着色器\n  varying vec4 v_Color;\n \n  void main () {\n    gl_Position = a_Position;\n    v_Color= a_Color;\n  }\n`;\n \nconst fragmentCode = `\n  precision mediump float;\n  // 颜色值变量\n  varying vec4 v_Color;\n \n  void main () {\n    gl_FragColor = v_Color;\n  }\n`;\n简单来说，顶点着色器中不仅动态接收坐标数据，并且接收了颜色数据，再通过 varying 变量将颜色值传递到片元着色器。（有需要回顾varying 变量 的内容可以先回顾一下再接着看本文）\n那既然知道我们现在需要传递两种类型的顶点数据给到着色器，那我们需要怎么做呢？第二章我们学习缓冲区对象的时候只给顶点着色器分配了一个缓冲区对象（顶点坐标），那现在我们尝试给它分配第二个缓冲区对象！\n示例我们简单一点，就画个三角形就好了，沿用第二章第 5 小节的坐标，如下图：\n\n首先这是本次绘制的顶点坐标数据：\nconst vertices = new Float32Array([-0.6, -0.6, 0, 0.8, 0.6, -0.6]);\n接着，我们给颜色值也指定一个缓冲区数据，本次绘制我们就按照 rgb 的顺序给颜色值就好了，这是颜色值的数据：\nconst colors = new Float32Array([\n  1,\n  0,\n  0,\n  1, // 红色\n  0,\n  1,\n  0,\n  1, // 绿色\n  0,\n  0,\n  1,\n  1, // 蓝色\n]);\n在定义好坐标、颜色的数据后，我们就可以着手缓冲区对象了，那我们简单回顾一下使用缓冲区对象的五步骤：\n\n创建缓冲区对象\n绑定缓冲区对象到 target\n分配缓冲区数据\n将缓冲区分配到 attribute 变量\n开启 attribute 变量\n\n其实多个缓冲区对象，也就是按照上述步骤，多次执行而已。简单来说，我们可以把上述步骤进行一个封装，比如封装成一个 createBuffer 的函数，分多次调用。下面是实现的伪代码：\n// 创建缓冲区封装\nconst createBuffer = () =&gt; {\n  const buffer = gl.createBuffer(); // 创建缓冲区对象\n  gl.bindBuffer(target, buffer); // 绑定缓冲区对象到 target\n  gl.bufferData(target, bufferData, gl.STATIC_DRAW); // 分配缓冲区数据\n  gl.vertexAttribPointer(attribute, size, gl.FLOAT, false, 0, 0); // 将缓冲区分配到 attribute 变量\n  gl.enableVertexAttribArray(attribute); // 开启 attribute 变量\n};\n \n// 创建顶点坐标数据的缓冲区\ncreateBuffer(vertex);\n// 创建颜色数据的缓冲区\ncreateBuffer(color);\n// 创建 xxx 的缓冲区\ncreateBuffer(xxx);\n由此一来，我们通过多种缓冲区对象实现了不同种类数据的传递。每当我们执行 gl.drawArrays 进行绘制时，各种数据将按照其在缓冲区中的顺序一一传递到对应顺序的顶点着色器的 attribute 变量中。我们可以通过下图将其表示出来：\n\n那么接下来，我们直接通过示例程序来看看绘制的效果把：\n&lt;template&gt;\n  &lt;canvas id=&quot;ice-1_1&quot; width=&quot;600&quot; height=&quot;300&quot;&gt;&lt;/canvas&gt;\n&lt;/template&gt;\n \n&lt;script setup lang=&quot;ts&quot;&gt;\nimport { onMounted } from &#039;vue&#039;\nimport {\n  createGl,\n  createShader,\n  createProgram,\n  createBuffer\n} from &#039;@ice-webgl/utils&#039;\n \nconst vertexCode = `\n  attribute vec4 a_Position;\n  attribute vec4 a_Color;\n  varying vec4 v_Color;\n \n  void main () {\n    gl_Position = a_Position;\n    v_Color= a_Color;\n  }\n`\n \nconst fragmentCode = `\n  precision mediump float;\n  varying vec4 v_Color;\n \n  void main () {\n    gl_FragColor = v_Color;\n  }\n`\n \nlet gl, a_Position, canvas, a_Color\n \nconst initGl = () =&gt; {\n  gl = createGl(&#039;#ice-1_1&#039;)\n \n  const vertexShader = createShader(gl, gl.VERTEX_SHADER, vertexCode)\n  const fragmentShader = createShader(gl, gl.FRAGMENT_SHADER, fragmentCode)\n \n  const program = createProgram(gl, vertexShader, fragmentShader)\n \n  a_Position = gl.getAttribLocation(program, &#039;a_Position&#039;)\n  a_Color = gl.getAttribLocation(program, &#039;a_Color&#039;)\n  const vertices = new Float32Array([\n    -.6, -.6,\n    0., .8,\n    .6, -.6,\n  ])\n  const colors = new Float32Array([\n    1., 0., 0., 1.,\n    0., 1., 0., 1.,\n    0., 0., 1., 1.,\n  ])\n \n  // 顶点坐标\n  createBuffer(gl, gl.ARRAY_BUFFER, vertices, a_Position, 2)\n  // 颜色值\n  createBuffer(gl, gl.ARRAY_BUFFER, colors, a_Color, 4)\n \n  gl.clearColor(0., 0., 0., .9)\n  gl.clear(gl.COLOR_BUFFER_BIT)\n  gl.drawArrays(gl.TRIANGLES, 0, 3)\n}\n \nonMounted(() =&gt; {\n  initGl()\n})\n&lt;/script&gt;\n \n&lt;script lang=&quot;ts&quot;&gt;\nimport { defineComponent } from &#039;vue&#039;\n \nexport default defineComponent({\n  name: &#039;Third1_1&#039;\n})\n&lt;/script&gt;\n \n由上述示例程序可以看到，我们成功地实现了一个红绿蓝的三色三角形，所以我们可以通过多个缓冲区对象来实现多种顶点数据到顶点着色器之间的分配和传递！并且举一反三，我们不管是坐标数据、颜色数据、还是说尺寸数据等等，都可以通过存放到多个缓冲区对象中一一传递到顶点着色器对应的 attribute 变量里。\n那么，除了创建多个缓冲区对象来实现这样的需求，还有没有其他的方案呢？我们接着往下看。\ngl.vertexAttribPointer的神奇参数\n还记得上一章最后一节的一个示例程序中我提到的步进参数吗？这里我们就开始讲讲它。回顾之前我们讲缓冲区的时候，使用了 gl.vertexAttribPointer 这一个 api 讲缓冲区的数据分配到 attribute 变量，但是当时我们仅仅只介绍了前两个参数，那接下来我们继续了解其他的参数！\n为什么说是神奇的参数？因为这些参数，是决定了我们可以将多种类数据都统一存放在一个 缓冲区对象 中的因素。此时，我再次贴出 MDN-gl.vertexAttribPointer api 用法地址，这次我们将认识它的全部参数用法！\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n参数参数值说明indexattribute 变量size每个顶点分配到的缓冲区数据的个数，值范围是[1-4]type数据格式，如 gl.FLOAT、gl.BYTEnormalizeboolean 值，指是否将非浮点数转换时归一化到[0, 1] 或者[-1, 1]区间（对于 gl.FLOAT 无效）stride指定两个顶点之间的字节数，默认 0offset指定缓冲区数据的偏移量(单位是字节)，如果是最开始的位置则为 0\n从表格中的参数值说明中，我们大概都可以猜到，本节的重点是 stride 和 offset 这两个参数值，只要我们理解了它们的作用，就很好上手写代码实现彩色的三角形了。emm，表格中的简短描述可能比较难懂，我们借助图文来进一步理解！\n1. stride参数详解\n我们首先看看描述：\n\n指定两个顶点之间的字节数(步进参数)，默认 0。\n\n何为两个顶点之间的字节数？我们通过一个图来将其进行表示：\n\n如上图所示，buffer 中有三个顶点数据，每个顶点数据不仅有坐标数据，还有颜色值 rgb 数据。然后我用虚线将 vertex 2 圈起来了，因为它处于另外两个顶点的中间，所以它的字节数就等于两个顶点之间的字节数！我们不难发现，这个字节数其实就是等于每个顶点自身的字节数。\n好了，那既然明确了两个顶点之间，那怎么求字节数呢？这里我们同样先来看一个新的属性：TypedArray.BYTES_PER_ELEMENT 的介绍。\n其实我们只看它文档的第一句介绍就能明白了：\n\nThe TypedArray.BYTES_PER_ELEMENT static data property represents the size in bytes of each element in a typed array.\n\n这个 强类型数组中 每个元素所占用的字节数 不正是我们需要找的东西吗？那回到上面的图例中，我们的 stride 参数不就是等于 顶点数据个数 * 每个元素所占用的字节数 吗？我们将上述图示的案例转化成代码表述，大家就能有很深刻的理解了：\nconst verticesColors = new Float32Array([\n  0.0,\n  0.0,\n  1.0,\n  0.0,\n  0.0, // 第一个点包括坐标、颜色rgb\n  0.1,\n  0.1,\n  1.0,\n  0.0,\n  0.0, // 第二个点包括坐标、颜色rgb\n  0.2,\n  0.2,\n  1.0,\n  0.0,\n  0.0, // 第三个点包括坐标、颜色rgb\n]);\n// 每个元素占用的字节数\nconst FSIZE = verticesColors.BYTES_PER_ELEMENT;\n// 每个顶点数据总共有 5 个浮点数\nstride = FSIZE * 5;\n首先我们看 verticesColors 这个类型数组，里面每一行就是一个顶点的所有数据，其中包括了坐标数据（前两个）、颜色数据（后三个）。\n再看我定义的常量 FSIZE，它就是 TypedArray.BYTES_PER_ELEMENT 的结果值，所以它代表了 verticesColors 里平均单个元素所占用的字节数。\n最后，stride 步进参数是两个顶点之间的字节数，所以它的值就等于 FSIZE  * 5。\n2. offset参数详解\noffset 参数，顾名思义偏移距离，指的就是距离首个顶点数据元素的距离。\n对于理解 offset 参数，我们直接通过一个实际例子来看就很清晰了。还是用回我们的图来当案例，现在有如下代码：\n// 获取坐标数据\ngl.vertexAttribPointer(a_Position, 2, gl.FLOAT, false, FSIZE * 5, 0);\n// 获取颜色数据\ngl.vertexAttribPointer(a_Color, 3, gl.FLOAT, false, FSIZE * 5, FSIZE * 2);\n我们可以看到获取坐标数据的（a_Position） offset 是 0，而获取颜色数据的（a_Color） offset 是 FSIZE * 2，这两个 offset 再配合 size 的使用，就能明确地告诉 WebGL 系统，它们需要的数据在哪里。\n我们将其用图来进行表示：\n\n如上如所示，我们通过 offset 参数就可以实现在一堆数据中进行数据类型分块（比如坐标在前两个，颜色的在后三个）。着色器运行的时候，WebGL 系统根据 步进参数stride、偏移参数offset 从缓冲区数据中找到正确的位置并读取对应的数据，再根据 size 的值来看要读取多少个数据，最后将其分配到每个 attribute 变量中。\n那么，我们就将前文 多个缓冲区对象 中实现的渐变色三角形通过一个缓冲区对象外加 stride 和 offset 来实现吧。示例程序如下：\n&lt;template&gt;\n  &lt;canvas id=&quot;ice-1_2&quot; width=&quot;600&quot; height=&quot;300&quot;&gt;&lt;/canvas&gt;\n&lt;/template&gt;\n \n&lt;script setup lang=&quot;ts&quot;&gt;\nimport { onMounted } from &#039;vue&#039;\nimport {\n  createGl,\n  createShader,\n  createProgram,\n  createBuffer\n} from &#039;@ice-webgl/utils&#039;\n \nconst vertexCode = `\n  attribute vec4 a_Position;\n  attribute vec4 a_Color;\n  varying vec4 v_Color;\n \n  void main () {\n    gl_Position = a_Position;\n    v_Color= a_Color;\n  }\n`\n \nconst fragmentCode = `\n  precision mediump float;\n  varying vec4 v_Color;\n \n  void main () {\n    gl_FragColor = v_Color;\n  }\n`\n \nlet gl, a_Position, canvas, a_Color\n \nconst initGl = () =&gt; {\n  gl = createGl(&#039;#ice-1_2&#039;)\n \n  const vertexShader = createShader(gl, gl.VERTEX_SHADER, vertexCode)\n  const fragmentShader = createShader(gl, gl.FRAGMENT_SHADER, fragmentCode)\n \n  const program = createProgram(gl, vertexShader, fragmentShader)\n \n  a_Position = gl.getAttribLocation(program, &#039;a_Position&#039;)\n  a_Color = gl.getAttribLocation(program, &#039;a_Color&#039;)\n \n  const verticesColors = new Float32Array([\n    -.6, -.6, 1., 0., 0., 1.,\n    0., .8, 0., 1., 0., 1.,\n    .6, -.6, 0., 0., 1., 1.,\n  ])\n \n  const FSIZE = verticesColors.BYTES_PER_ELEMENT\n \n  const buffer = gl.createBuffer()\n  gl.bindBuffer(gl.ARRAY_BUFFER, buffer)\n  gl.bufferData(gl.ARRAY_BUFFER, verticesColors, gl.STATIC_DRAW)\n  gl.vertexAttribPointer(a_Position, 2, gl.FLOAT, false, FSIZE * 6, 0)\n  gl.enableVertexAttribArray(a_Position)\n \n  gl.vertexAttribPointer(a_Color, 4, gl.FLOAT, false, FSIZE * 6, FSIZE * 2)\n  gl.enableVertexAttribArray(a_Color)\n \n  gl.clearColor(0., 0., 0., .9)\n  gl.clear(gl.COLOR_BUFFER_BIT)\n  gl.drawArrays(gl.TRIANGLES, 0, 3)\n}\n \nonMounted(() =&gt; {\n  initGl()\n})\n&lt;/script&gt;\n \n&lt;script lang=&quot;ts&quot;&gt;\nimport { defineComponent } from &#039;vue&#039;\n \nexport default defineComponent({\n  name: &#039;Third1_2&#039;\n})\n&lt;/script&gt;\n我们简单看看 这个示例程序 跟 多个缓冲区示例程序 的实现的核心区别是什么：\n// 顶点 坐标数据、颜色数据放在一起\nconst verticesColors = new Float32Array([\n  -0.6, -0.6, 1, 0, 0, 1, 0, 0.8, 0, 1, 0, 1, 0.6, -0.6, 0, 0, 1, 1,\n]);\n \n// 分配坐标数据，注意看 size分配个数、 stride步进参数 和 offset偏移参数 的值\ngl.vertexAttribPointer(a_Position, 2, gl.FLOAT, false, FSIZE * 6, 0);\ngl.enableVertexAttribArray(a_Position);\n \n// 分配颜色数据，注意看 size分配个数、 stride步进参数 和 offset偏移参数 的值\ngl.vertexAttribPointer(a_Color, 4, gl.FLOAT, false, FSIZE * 6, FSIZE * 2);\ngl.enableVertexAttribArray(a_Color);\n好的，那么到这一步，我们成功通过 gl.vertexAttribPointer 的参数设置，实现了单缓冲区对象存放多种顶点数据以绘制三色三角形的需求。\n总结\n本文的最后，跟大家一起回顾本文的主要内容：\n\n通过多缓冲区实现彩色三角形的绘制\n通过设置 gl.vertexAttribPointer 步进参数、偏移参数，实现单缓冲区存放多种顶点数据，以绘制彩色三角形\n\n这一节的内容需要大家理解的还是比较多的，特别是步进参数、偏移参数的用法。所以我建议大家最好可以自己动手敲敲代码，这样印象更深刻一点。"},"front-end/webgl/2.2.-为什么会出现颜色渐变":{"title":"为什么会出现颜色渐变","links":["front-end/webgl/1.4.-绘制动态颜色点"],"tags":[],"content":"2. 为什么会出现颜色渐变\n经过上一小节的学习，我们掌握了同时给顶点着色器传入多种类型的顶点数据以实现了彩色三角形的绘制。那么，相信代码实现大家是都没问题了，不过不知道大家是否会有个疑问？\n为什么我们给三个顶点各传入一个颜色值，却出现了一个渐变色的三角形？\n图形装配和光栅化\n对于图形装配和光栅化可能在之前的章节中并没有太多提及，但其实在第二章第2节讲绘制点的时候有画过这么一张图：\n\n虽然我们之前的内容主要都是集中在顶点着色器和片元着色器之间，中间图形装配和光栅化并没有怎么提及，但其实他们之间是有这么两个步骤的。\n为了让大家理解这两个步骤存在的意义，我举一个具体的案例。比如我们现在需要画一个 100px * 100px 的纯色正方形，我们需要提供 4 个顶点坐标，并通过 gl.TRIANGLE_STRIP 的绘制 mode 就可以绘制出来了。所以，我们先通过一张图来讲坐标确定下来（坐标点不是特别精确，大概画出 100 * 100 的效果）：\n\n那么根据这 4 个坐标点，我们画出一个纯黄色的正方形看看效果：\n&lt;template&gt;\n  &lt;canvas id=&quot;ice-2_1&quot; width=&quot;600&quot; height=&quot;300&quot;&gt;&lt;/canvas&gt;\n&lt;/template&gt;\n \n&lt;script setup lang=&quot;ts&quot;&gt;\nimport { onMounted } from &#039;vue&#039;\nimport {\n  createGl,\n  createShader,\n  createProgram,\n  createBuffer\n} from &#039;@ice-webgl/utils&#039;\n \nconst vertexCode = `\n  attribute vec4 a_Position;\n \n  void main () {\n    gl_Position = a_Position;\n  }\n`\n \nconst fragmentCode = `\n  void main () {\n    gl_FragColor = vec4(1., 1., 0., .9);\n  }\n`\n \nlet gl, a_Position, canvas\n \nconst initGl = () =&gt; {\n  gl = createGl(&#039;#ice-2_1&#039;)\n \n  const vertexShader = createShader(gl, gl.VERTEX_SHADER, vertexCode)\n  const fragmentShader = createShader(gl, gl.FRAGMENT_SHADER, fragmentCode)\n \n  const program = createProgram(gl, vertexShader, fragmentShader)\n \n  a_Position = gl.getAttribLocation(program, &#039;a_Position&#039;)\n \n  const vertices = new Float32Array([\n    -.17, .33,\n    -.17, -.33,\n    .17, .33,\n    .17, -.33,\n  ])\n \n  const buffer = gl.createBuffer()\n  gl.bindBuffer(gl.ARRAY_BUFFER, buffer)\n  gl.bufferData(gl.ARRAY_BUFFER, vertices, gl.STATIC_DRAW)\n  gl.vertexAttribPointer(a_Position, 2, gl.FLOAT, false, 0, 0)\n  gl.enableVertexAttribArray(a_Position)\n \n  gl.clearColor(0., 0., 0., .9)\n  gl.clear(gl.COLOR_BUFFER_BIT)\n  gl.drawArrays(gl.TRIANGLE_STRIP, 0, 4)\n}\n \nonMounted(() =&gt; {\n  initGl()\n})\n&lt;/script&gt;\n \n&lt;script lang=&quot;ts&quot;&gt;\nimport { defineComponent } from &#039;vue&#039;\n \nexport default defineComponent({\n  name: &#039;Third2_1&#039;\n})\n&lt;/script&gt;\nok，我们提供了4个顶点坐标，并将 gl_FragColor 设置成黄色，就可以绘制出一个黄色的正方形！那就是说，我们的片元着色器将 4 个坐标点区间范围内的全部像素点都绘制成黄色了。这里，我们不难想象到，绘制一个 100px * 100px 的纯色正方形，需要对区间内的每个像素点进行着色！\n基于这一点，图形装配和光栅化的步骤存在的意义就很明显了。他们需要将顶点坐标装配成几何图形，再将装配好的几何图形转化成一个一个真实的像素，再给到片元着色器对其进行逐片元操作（对每个像素着色）！所以说，绘制一个 100 * 100 的正方形，片元着色器需要执行 10000 次！\n那我们就以这个案例作为我们的分析对象，看看顶点着色器、片元着色器具体是怎么工作的！\n\n首先，我们通过 gl.drawArrays(gl.TRIANGLE_STRIP, 0, 4) 进行图形的绘制。这里的 count 参数为 4，那就意味着顶点着色器将会执行 4 次\n执行第一个顶点着色器，第一个坐标点的数据 (-.17, .33) 分配给到 attribute 变量 —— a_Position。然后这个变量会赋值给到 WebGL 内置变量 —— gl_Position，然后进入了图形装配阶段，数据被缓存起来了\n执行第二个顶点着色器，同样流程，(-.17, -.33) 坐标数据被缓存在图形装配阶段。（这里注意，我们的坐标是 vec4 类型，我们没传后两位，所以它们使用的是默认值，整个 gl_Position 其实是 (x, y, 0.0, 1.0)）\n执行第三、第四个顶点着色器，同样流程，(.17, .33,) 、(.17, -.33) 传入并缓存在图形装配区\n开始图形装配。执行完 4 次顶点着色器，开始根据传入的顶点坐标 和 mode本例是(gl.TRIANGLE_STRIP) 进行图元装配过程。因此这里会装配出一个 正方形\n最后一步是光栅化。光栅化的作用是将我们装配好的图形转化成片元（像素）来显示在显示器上，因此光栅化步骤后我们就得到了组成整个正方形的片元（像素）\n\n以下，我画了个图来表示整个图形装配到光栅化的过程：\n\n上图中可以看到，光栅化后我们得到了一个由 10000个 像素点组成的 100px * 100px 的正方形。最后只需要再通过片元着色器进行一个”逐片元”操作，就会出现我们示例程序中的黄色正方形了！\n这里我们应该能想到，我们 gl.drawArrays 传入不同的 mode 和 count，图形装配的结果是不一样的。就比如我们传的 mode 不是 TRIANGLE类 而是 LINE类型的，那装配出来的图形就是一个空心的图形，中间并不会填满像素点。\n片元着色器是如何工作的？\n上一小节的图形装配、光栅化流程后，就到调用片元着色器进行”逐片元”操作了！在本文的案例中，片元着色器会被调用 10000 次！\n其实对于每一个片元，片元着色器都会计算出它的颜色值，然后将结果写到颜色缓冲区中。（这个颜色缓冲区就是绘制结果，最终呈现到屏幕当中的，或者我们可以回忆一下清除背景色的时候，不正是清除掉颜色缓冲区吗？）\n那在这个案例中，因为是个纯色（黄）的正方形，所以每个片元（像素）的颜色都是黄色，如此一来，最后呈现到我们面前的就是一个 100px * 100px 的黄色正方形！不过到现在为止，我们对 片元着色器 的工作过程只是在纸面意义上的了解，那有没有办法来印证一下 片元着色器 的工作过程呢，也就是印证这 10000 次执行的过程呢？\n内置变量—— gl_FragCoord\n简单认识一下 gl_FragCoord 这个内置变量， 它是片元着色器中的一个内置变量，是一个 vec4 类型的变量，并且它的前两个分量（数值）代表 x 、 y 坐标值。\n其中在文档的 description 中有一句这样的描述：\n\nBy default, gl_FragCoord assumes a lower-left origin for window coordinates and assumes pixel centers are located at half-pixel centers.\n\n它告诉我们 gl_FragCoord 中所用到的坐标系统默认左下角为坐标原点！所以这样我们就需要注意他的 x，y 的取值了。这里我们通过两幅图来对比，方便大家更好记忆 gl_FragCoord 的坐标原点。首先是之前讲 canvas 2d 坐标的一张图：\n\n接下来是 gl_FragCoord 的坐标图：\n\nok，那相信大家对 gl_FragCoord 的坐标有一定了解了，我们接下来就去使用它。接着前文提到的，我们要印证 片元着色器 执行了 100 * 100 次，所以我们可以让每个像素点的颜色都有所不同来印证这一点！\n那现在我们知道可以通过 gl_FragCoord.x 、 gl_FragCoord.y 来获取当前每个像素点的 x 、 y 值，所以我们只需要根据每个像素点的 x 、 y 值的不同来稍微改变一下当前像素点的颜色即可。\n为了更加清晰坐标点的计算，我们还是直接通过图片来看！（记得中学时期，老师告诉我涉及坐标点的计算一定要画坐标系！）\n\n由图示很清楚的就能看出来，我们示例程序画的居中正方形，以canvas左下角为原点的时候，正方形最左边的 x 值大概是 250px （计算公式：(600px - 100px) / 2）的样子。所以我们现在这样改造之前的片元着色器代码：\n// 这是原本的着色程序代码\nconst fragmentCode = `\n  void main () {\n    gl_FragColor = vec4(1., 1., 0., .9); // 纯黄色\n  }\n`\n \n// 现在我们对 r 、 g 两个值通过 gl_FragCoord 来进行修改\nconst fragmentCode = `\n  void main () {\n    // 将 r 的位置换成坐标 x 动态计算\n    gl_FragColor = vec4((gl_FragCoord.x - 250.) / 100., 1., 0., .9);\n  }\n`\n根据这个片元着色器的 gl_FragColor 赋值，我们大概猜测一下绘制出来的图形是什么样子的？首先，r 的位置一开始应该是 0。因为 (gl_FragCoord.x - 250.) / 100. 这个计算公式，当在处于正方形最左边的时候， gl_FragCoord.x 为 250，相减后值为 0。\n所以，一开始正方形的最左侧的所有片元应该是 r 为 0， g 为 1 的 rgb 值，那颜色应该是绿色！从左往右，随着 gl_FragCoord.x 的不断增加，r 值也逐渐增加，正方形应该逐渐呈现出黄色！到了正方形的最右侧，应该是纯黄色！\n那么接下来，我们就通过示例程序来验证一下我们的猜想：\n&lt;template&gt;\n  &lt;canvas id=&quot;ice-2_2&quot; width=&quot;600&quot; height=&quot;300&quot;&gt;&lt;/canvas&gt;\n&lt;/template&gt;\n \n&lt;script setup lang=&quot;ts&quot;&gt;\nimport { onMounted } from &#039;vue&#039;\nimport {\n  createGl,\n  createShader,\n  createProgram,\n  createBuffer\n} from &#039;@ice-webgl/utils&#039;\n \nconst vertexCode = `\n  attribute vec4 a_Position;\n \n  void main () {\n    gl_Position = a_Position;\n  }\n`\n \nconst fragmentCode = `\n  void main () {\n    gl_FragColor = vec4((gl_FragCoord.x - 250.) / 100., 1., 0., .9);\n  }\n`\n \nlet gl, a_Position, canvas\n \nconst initGl = () =&gt; {\n  gl = createGl(&#039;#ice-2_2&#039;)\n \n  const vertexShader = createShader(gl, gl.VERTEX_SHADER, vertexCode)\n  const fragmentShader = createShader(gl, gl.FRAGMENT_SHADER, fragmentCode)\n \n  const program = createProgram(gl, vertexShader, fragmentShader)\n \n  a_Position = gl.getAttribLocation(program, &#039;a_Position&#039;)\n \n  const vertices = new Float32Array([\n    -.17, .33,\n    -.17, -.33,\n    .17, .33,\n    .17, -.33,\n  ])\n \n  const buffer = gl.createBuffer()\n  gl.bindBuffer(gl.ARRAY_BUFFER, buffer)\n  gl.bufferData(gl.ARRAY_BUFFER, vertices, gl.STATIC_DRAW)\n  gl.vertexAttribPointer(a_Position, 2, gl.FLOAT, false, 0, 0)\n  gl.enableVertexAttribArray(a_Position)\n \n  gl.clearColor(0., 0., 0., .9)\n  gl.clear(gl.COLOR_BUFFER_BIT)\n  gl.drawArrays(gl.TRIANGLE_STRIP, 0, 4)\n}\n \nonMounted(() =&gt; {\n  initGl()\n})\n&lt;/script&gt;\n \n&lt;script lang=&quot;ts&quot;&gt;\nimport { defineComponent } from &#039;vue&#039;\n \nexport default defineComponent({\n  name: &#039;Third2_2&#039;\n})\n&lt;/script&gt;\n \n果不其然，正方形呈现出一个以 x 为轴的左右渐变的颜色。到这里，我们可以证实片元着色器对于光栅化后的每一个片元，都需要执行一次上色操作！所以，对于一个 100 * 100 的矩形来说，片元着色器逐片元的操作需要执行 10000 次片元着色器的代码！\nvarying 变量的内插过程\n当我们了解完 顶点着色器、图形装配、光栅化、片元着色器是怎么工作之后，我们终于可以开始探讨为什么会出现一个三色渐变的三角形了。当然，这一步的理解依赖于上文提到的知识点，所以碰到不懂的可以立马回看前文内容～\n我们回顾之前的渐变色三角形，固然是没有像上个示例程序一样通过 gl_FragCoord.x 计算颜色值来实现渐变效果的。我们只传入了三个顶点坐标和颜色值，是 WebGL 自己将其绘制成了三色渐变的三角形而已。那么接下来，我们就来揭秘这个神奇的过程——内插。\n&lt;template&gt;\n  &lt;canvas id=&quot;ice-1_2&quot; width=&quot;600&quot; height=&quot;300&quot;&gt;&lt;/canvas&gt;\n&lt;/template&gt;\n \n&lt;script setup lang=&quot;ts&quot;&gt;\nimport { onMounted } from &#039;vue&#039;\nimport {\n  createGl,\n  createShader,\n  createProgram,\n  createBuffer\n} from &#039;@ice-webgl/utils&#039;\n \nconst vertexCode = `\n  attribute vec4 a_Position;\n  attribute vec4 a_Color;\n  varying vec4 v_Color;\n \n  void main () {\n    gl_Position = a_Position;\n    v_Color= a_Color;\n  }\n`\n \nconst fragmentCode = `\n  precision mediump float;\n  varying vec4 v_Color;\n \n  void main () {\n    gl_FragColor = v_Color;\n  }\n`\n \nlet gl, a_Position, canvas, a_Color\n \nconst initGl = () =&gt; {\n  gl = createGl(&#039;#ice-1_2&#039;)\n \n  const vertexShader = createShader(gl, gl.VERTEX_SHADER, vertexCode)\n  const fragmentShader = createShader(gl, gl.FRAGMENT_SHADER, fragmentCode)\n \n  const program = createProgram(gl, vertexShader, fragmentShader)\n \n  a_Position = gl.getAttribLocation(program, &#039;a_Position&#039;)\n  a_Color = gl.getAttribLocation(program, &#039;a_Color&#039;)\n \n  const verticesColors = new Float32Array([\n    -.6, -.6, 1., 0., 0., 1.,\n    0., .8, 0., 1., 0., 1.,\n    .6, -.6, 0., 0., 1., 1.,\n  ])\n \n  const FSIZE = verticesColors.BYTES_PER_ELEMENT\n \n  const buffer = gl.createBuffer()\n  gl.bindBuffer(gl.ARRAY_BUFFER, buffer)\n  gl.bufferData(gl.ARRAY_BUFFER, verticesColors, gl.STATIC_DRAW)\n  gl.vertexAttribPointer(a_Position, 2, gl.FLOAT, false, FSIZE * 6, 0)\n  gl.enableVertexAttribArray(a_Position)\n \n  gl.vertexAttribPointer(a_Color, 4, gl.FLOAT, false, FSIZE * 6, FSIZE * 2)\n  gl.enableVertexAttribArray(a_Color)\n \n  gl.clearColor(0., 0., 0., .9)\n  gl.clear(gl.COLOR_BUFFER_BIT)\n  gl.drawArrays(gl.TRIANGLES, 0, 3)\n}\n \nonMounted(() =&gt; {\n  initGl()\n})\n&lt;/script&gt;\n \n&lt;script lang=&quot;ts&quot;&gt;\nimport { defineComponent } from &#039;vue&#039;\n \nexport default defineComponent({\n  name: &#039;Third1_2&#039;\n})\n&lt;/script&gt;\n回顾 varying 变量，我们之前就有介绍过这个关键字，它的作用是将顶点着色器中的 varying 变量传入到片元着色器同名同类型的 varying 变量中。我们那时候通过 varying 变量实现了动态颜色点的绘制。\n其实 varying 变量在顶点着色器传入片元着色器之间，还有一个步骤就是内插（在光栅化步骤中）。所以到片元着色器中真正接收到的 varying 变量并不完全等同于 顶点着色器的 varying 变量的值。具体流程可参考下图进行理解：\n\n那么彩色三角形的内插过程具体发生了什么呢？varying变量会经历怎么样的变化呢？我们再看下一张图：\n\n图中，每一个顶点的 varying 值经过内插后数值都等比例变化。虽然图中简单表示成单色的变化数值（多色变化画起来图会很臃肿），但换算成多色也是一样的。这里没看懂没关系，通过下图来看看双色数值变化就肯定能明白我的意思了：\n\n由上图可以看到，rgba 中的 r 值和 g 值 在内插的过程中不断地进行变化，而正是由于这样的一个过程，我们最终就可以绘制出来一个三色渐变的三角形。\n所以，内插的过程其实就是 WebGL 系统在图形光栅化后，根据顶点着色器中的 varying 变量计算出中间每个片元的颜色，再将计算好的 varying 值传递到片元着色器中。\n总结\n本文的最后，跟大家一起回顾本文的主要内容：\n\n图形绘制期间，顶点着色器到片元着色器之间还有图形装配、光栅化两个重要的步骤\n在光栅化后，我们可以通过 gl_FragCoord 人为的干预每个片元的颜色值，可为片元指定不同的颜色\nvarying 变量传递到片元着色器之前还有个内插过程，每个片元的颜色将被一一计算出来再传递到片元着色器中\n"},"front-end/webgl/2.3.-实战消除锯齿":{"title":"2.3. 实战消除锯齿","links":[],"tags":[],"content":"3. 实战消除锯齿\n经过上一小节的学习，我们了解到了片元着色器中的一个新的内置变量——gl_FragCoord，通过它我们可以拿到每一个片元（像素点）的 x、y 值，因而我们可以干预每一个像素点的颜色值！在上一节中，我们通过它实现了一个以 x 为轴从左到右从绿到黄的一个渐变色正方形。\n那这一小节，我们继续深入，再次借助 gl_FragCoord 的能力来实战一下消除锯齿，顺便巩固我们对图形绘制流程的熟悉，深入理解顶点着色器、片元着色器的工作内容。\n在正文开始前，先声明，本文是加深我们对颜色、着色器、图像绘制过程理解的实战 demo，真实场景消除锯齿请参考业界方案和类库。\n什么是锯齿\n什么是锯齿？相信大家通过字面意思就大概能明白，那就是一种凹凸不平的像锯齿一样的东西。我们直接看看前一小节彩色三角示例的放大截图：\n\n如截图所示，我们肉眼就能看出三角形的两条腰明显要比底边的显示效果更加的”不平滑”，那这种”不平滑”其实就是图像锯齿。（本文不会特别深入，感兴趣的同学可以自己找点资料来深入学习）\n锯齿是怎么产生的呢？其实就是图像边缘（不同颜色）之间的颜色生硬过渡（采样不足造成）产生的，特别是圆弧、斜边这种场景锯齿感会特别明显，而水平、垂直方向上基本看不出什么锯齿感。\n就以上述的截图为例，我们画布的颜色是黑色，然后三角形的三个边是其他的颜色（反正不是黑色），如果颜色之间生硬过度就会出现锯齿的情况。我们通过图片来大概分析一下锯齿的产生：\n\n光栅化步骤后的每个片元的情况如上图所示，深色背景和橙色三角形被分割成一个一个格子，这些格子组成了屏幕像素。以上图为例，我们想象每个网格正中心为取色点，当三角形的范围盖过了取色点那就为橙色，否则为黑色。我以斜边的一个分块为例画了下图：\n\n如图所示，取色点在斜边范围内的像素被绘制成了橙色，而没在范围内的被绘制成黑色。就这个图而言，我们已经可以看见锯齿了，这也就是锯齿产生的基本原因。\n那我们要如何消除锯齿呢？其实原理很简单，我们只需要让像素之间产生一定的渐变效果，就能从肉眼上去除锯齿了！对于这一点，我们不需要想得太复杂，我们可以想象成将边缘的像素点的颜色设置成 原色 和 背景色 的混合颜色，以产生一种渐变色的效果，就能使得边缘的颜色过度平滑，锯齿也就不明显了。\n关说不直观，我们直接看下图进行理解：\n\n上图中，我把靠近边缘的像素点绘制成了透明度低一点的橙色，以形成三角形边和背景色之间的平滑过度效果，为的就是避免颜色之间”非黑即白”的生硬过度，如此一来就能从肉眼层面将锯齿消除了。\n实战准备阶段\n经过了半篇文章的铺垫，我们终于进入到实战环节了。我们现在知道了消除锯齿就是要实现一个边缘之间的平滑过渡效果，也就是渐变过渡。那我们回顾上一小节刚学习片元着色器的内置变量——gl_FragCoord，我说过我们可以用它来干预片元着色器对每个片元的颜色绘制，并且在上一节中我们已经通过它来实现正方形的颜色渐变了！那这一节，我们接着来使用它实现边缘的渐变效果！\n首先我们先绘制出一个三角形，为了方便三角形边缘的坐标计算，我打算把三角形绘制在 canvas 的左下角，也就是 gl_FragCoord 坐标 (0, 0) 的位置。我按照下图的尺寸进行三角形绘制：\n\n如图，这个是个钝角三角形，底边长 180px * 2，高度为 120px，然后我把画布的 宽度设置成 600px, 高度设置成 150px。图中蓝色字体的坐标对应 WebGL 系统中的坐标。我把三角形的颜色设置为黄色，最终可以画出如下的三角形：\n&lt;template&gt;\n  &lt;canvas id=&quot;ice-3_1&quot; width=&quot;600&quot; height=&quot;150&quot;&gt;&lt;/canvas&gt;\n&lt;/template&gt;\n \n&lt;script setup lang=&quot;ts&quot;&gt;\nimport { onMounted } from &#039;vue&#039;\nimport {\n  createGl,\n  createShader,\n  createProgram,\n  createBuffer\n} from &#039;@ice-webgl/utils&#039;\n \nconst vertexCode = `\n  attribute vec4 a_Position;\n  attribute vec4 a_Color;\n  varying vec4 v_Color;\n \n  void main () {\n    gl_Position = a_Position;\n    v_Color = a_Color;\n  }\n`\n \nconst fragmentCode = `\n  precision mediump float;\n  varying vec4 v_Color;\n \n  void main () {\n    gl_FragColor = v_Color;\n  }\n`\n \nlet gl, a_Position, canvas, a_Color\n \nconst initGl = () =&gt; {\n  gl = createGl(&#039;#ice-3_1&#039;)\n \n  const vertexShader = createShader(gl, gl.VERTEX_SHADER, vertexCode)\n  const fragmentShader = createShader(gl, gl.FRAGMENT_SHADER, fragmentCode)\n \n  draw(gl, vertexShader, fragmentShader)\n}\n \nconst draw = (gl, vertexShader, fragmentShader) =&gt; {\n  const program = createProgram(gl, vertexShader, fragmentShader)\n \n  a_Position = gl.getAttribLocation(program, &#039;a_Position&#039;)\n  a_Color = gl.getAttribLocation(program, &#039;a_Color&#039;)\n \n  const verticesColors = new Float32Array([\n    -1., -1., 1., 1., 0., 1.,\n    -.4, .6, 1., 1., 0., 1.,\n    .2, -1., 1., 1., 0., 1.,\n  ])\n \n  const FSIZE = verticesColors.BYTES_PER_ELEMENT\n \n  const buffer = gl.createBuffer()\n  gl.bindBuffer(gl.ARRAY_BUFFER, buffer)\n  gl.bufferData(gl.ARRAY_BUFFER, verticesColors, gl.STATIC_DRAW)\n  gl.vertexAttribPointer(a_Position, 2, gl.FLOAT, false, FSIZE * 6, 0)\n  gl.enableVertexAttribArray(a_Position)\n \n  gl.vertexAttribPointer(a_Color, 4, gl.FLOAT, false, FSIZE * 6, FSIZE * 2)\n  gl.enableVertexAttribArray(a_Color)\n \n  gl.clearColor(0., 0., 0., .9)\n  gl.clear(gl.COLOR_BUFFER_BIT)\n  gl.drawArrays(gl.TRIANGLES, 0, 3)\n}\n \nonMounted(() =&gt; {\n  initGl()\n})\n&lt;/script&gt;\n \n&lt;script lang=&quot;ts&quot;&gt;\nimport { defineComponent } from &#039;vue&#039;\n \nexport default defineComponent({\n  name: &#039;Third3_1&#039;\n})\n&lt;/script&gt;\n如示例程序中的黄色三角形，我们发现锯齿感更加严重了（特别是左腰的边）！这是个好事情，毕竟我们实现锯齿消除后，可以更清晰地看到前后的效果差异。那接下来，我们进行实战消除锯齿前的最后准备阶段，了解一些 GLSL 中的内置函数。\nGLSL——mix\n首先来看看函数用法，详细可以参考 mix-OpenGL：\nmix(vec4 x, vex4 y, float a)\n函数的会返回 x 、 y 的线性混合值，可以看成是 x*(1 - a) + y*a 的结果。（注意，x 、 y 是 vec4 类型，本案例代表的是 rgba 的颜色值）\n我们可以简单理解为它可以帮我们根据 a 值取两个颜色之间的插值，就跟上一节提到的 varying 变量 的插值一样的。反正我们记住一点，当 a 为 0 时，就是只取前面的颜色，当 a 为 1 时就是只取后面的颜色，处于中间时取中间颜色！\n所以，在消除锯齿的艰巨任务中，它就是帮我们处理颜色渐变的关键函数。\nGLSL——atan\n再来看看我们熟悉又陌生的反正切函数，详细可以参考 atan-OpenGL。这个函数我不算太细致的讲，因为正切、正弦这种都涉及数学知识了，大家也都学过，自己按照自己的方式去回顾一下就好了。（我也是翻了好些资料重学这些中学时期都能倒背如流的三角函数知识了～）\n这里提到这个函数，我们只需要知道我们用它来计算三角形斜边上的 y 值坐标即可（知 x 求 y）。\n这里是函数的用法：\nfloat tanARadian = atan(120., 180.);\nemm，然后顺便提一下，GLSL 中内置了很多数学相关的函数，如 sin、cos、sqrt 等等，并且我们都可以直接进行调用，不需要像 JavaScript 一样通过 Math.xxx 的形式去调用的。\nGLSL——smoothstep\n详细了解可看 smoothstep-OpenGL，它是用来求两个值之间的插值的。我们可以关注文档对他的详情描述：\n\nsmoothstep performs smooth Hermite interpolation between 0 and 1 when edge0 &lt; x &lt; edge1. This is useful in cases where a threshold function with a smooth transition is desired.\n\n百度翻译一下就是：当 edge0 ＜ x ＜ edge1 时，smoothstep 在0和1之间执行平滑埃尔米特插值。这在需要具有平滑过渡的阈值函数的情况下是有用的。所以它很适合我们的这个需求！\n那么，它的用法是：\n// edge0 下边缘的值；edge1 上边缘的值\nsmoothstep(genType edge0, genType edge1, genType x);\nedge0 代表下边缘的值，edge1 代表上边缘的值，也就是一个是 min，一个是 max。 我们分三种情况看它的返回结果：\n\n第三个参数 x 小于 edge0（min） 时，会返回 0.0\n第三个参数 x 大于 edge1（max） 时，返回 1.0\n第三个参数 x 位于 edge0（min） 和 edge1（max） 之间时，会返回 x 在这个区间内与 edge0（min） 距离的占比\n\n实战 gl_FragCoord 消除锯齿\n\n注意！本次实战仅消除三角形左腰的锯齿。\n\n简单实现的方案：我通过 gl_FragCoord.xy 获得每一个点的坐标，判断这个坐标是否接近三角形的左腰边线的位置（通过三角函数计算），如果接近的话就设置一定的渐变颜色，以产生平滑的过渡效果。\n\n如上图所示，黄色点代表其中一个像素点，我们可以通过 gl_FragCoord.xy 获取到它的坐标。红色点代表左腰线上的点，我们通过当前的 gl_FragCoord.x 坐标和正切公式计算出它的 y 值，直接判断黄色点的 y 值和红色点的 y 值的差是否处于一定范围，是的话则设置渐变。\n核心的片元着色器代码如下：\nconst fragmentGradientCode = `\n  precision mediump float;\n  varying vec4 v_Color;\n \n  void main () {\n    // 求角度 A 的弧度值，对应图中的左下角的锐角\n    float tanARadian = atan(120., 180.);\n    // 计算 当前坐标点 和 左腰坐标点 y 值的 差\n    float vertexY = gl_FragCoord.x * tan(tanARadian) - gl_FragCoord.y;\n    // 混合背景色(黑色) 和 v_Color(黄色)\n    gl_FragColor = mix(vec4(0., 0., 0., .9), v_Color, smoothstep(.1, 2.4, vertexY));\n  }\n`\n如下示例程序，我们通过将两个三角形放在一起做对比，看看消除锯齿后的效果差异吧！（仅对第二个三角形的左腰边线进行锯齿消除处理）\n&lt;template&gt;\n  &lt;canvas id=&quot;ice-3_2_a&quot; width=&quot;600&quot; height=&quot;150&quot;&gt;&lt;/canvas&gt;\n  &lt;canvas id=&quot;ice-3_2_b&quot; width=&quot;600&quot; height=&quot;150&quot;&gt;&lt;/canvas&gt;\n&lt;/template&gt;\n \n&lt;script setup lang=&quot;ts&quot;&gt;\nimport { onMounted } from &#039;vue&#039;\nimport {\n  createGl,\n  createShader,\n  createProgram,\n  createBuffer\n} from &#039;@ice-webgl/utils&#039;\n \nconst vertexCode = `\n  attribute vec4 a_Position;\n  attribute vec4 a_Color;\n  varying vec4 v_Color;\n \n  void main () {\n    gl_Position = a_Position;\n    v_Color = a_Color;\n  }\n`\n \nconst fragmentCode = `\n  precision mediump float;\n  varying vec4 v_Color;\n \n  void main () {\n    gl_FragColor = v_Color;\n  }\n`\n \nconst fragmentGradientCode = `\n  precision mediump float;\n  varying vec4 v_Color;\n \n  void main () {\n    float tanARadian = atan(120., 180.);\n    float vertexY = gl_FragCoord.x * tan(tanARadian) - gl_FragCoord.y;\n    gl_FragColor = mix(\n    vec4(0., 0., 0., .9),\n    v_Color, smoothstep(.1, 2.4, vertexY)\n    );\n  }\n`\n \nconst initGl = () =&gt; {\n  const glA = createGl(&#039;#ice-3_2_a&#039;)\n  const glB = createGl(&#039;#ice-3_2_b&#039;)\n \n  const vertexShader = createShader(glA, glA.VERTEX_SHADER, vertexCode)\n  const fragmentShader = createShader(glA, glA.FRAGMENT_SHADER, fragmentCode)\n \n  const vertexBShader = createShader(glB, glB.VERTEX_SHADER, vertexCode)\n  const fragmentGradientShader = createShader(\n      glB,\n      glB.FRAGMENT_SHADER,\n      fragmentGradientCode\n  )\n \n  draw(glA, vertexShader, fragmentShader)\n  draw(glB, vertexBShader, fragmentGradientShader)\n}\n \nconst draw = (gl, vertexShader, fragmentShader) =&gt; {\n  const program = createProgram(gl, vertexShader, fragmentShader)\n \n  const a_Position = gl.getAttribLocation(program, &#039;a_Position&#039;)\n  const a_Color = gl.getAttribLocation(program, &#039;a_Color&#039;)\n \n  const verticesColors = new Float32Array([\n    -1., -1., 1., 1., 0., 1.,\n    -.4, .6, 1., 1., 0., 1.,\n    .2, -1., 1., 1., 0., 1.,\n  ])\n \n  const FSIZE = verticesColors.BYTES_PER_ELEMENT\n \n  const buffer = gl.createBuffer()\n  gl.bindBuffer(gl.ARRAY_BUFFER, buffer)\n  gl.bufferData(gl.ARRAY_BUFFER, verticesColors, gl.STATIC_DRAW)\n  gl.vertexAttribPointer(a_Position, 2, gl.FLOAT, false, FSIZE * 6, 0)\n  gl.enableVertexAttribArray(a_Position)\n \n  gl.vertexAttribPointer(a_Color, 4, gl.FLOAT, false, FSIZE * 6, FSIZE * 2)\n  gl.enableVertexAttribArray(a_Color)\n \n  gl.clearColor(0., 0., 0., .9)\n  gl.clear(gl.COLOR_BUFFER_BIT)\n  gl.drawArrays(gl.TRIANGLES, 0, 3)\n}\n \nonMounted(() =&gt; {\n  initGl()\n})\n&lt;/script&gt;\n \n&lt;script lang=&quot;ts&quot;&gt;\nimport { defineComponent } from &#039;vue&#039;\n \nexport default defineComponent({\n  name: &#039;Third3_2&#039;\n})\n&lt;/script&gt;\n为了让大家更清楚的看到差异，我把示例程序放大后的效果截图放出来：\n\n总结\n本文的最后，跟大家一起回顾本文的主要内容：\n\n锯齿产生的根本原因：边缘、背景颜色的生硬过渡产生肉眼可见的凹凸不平的像素锯齿\n消除锯齿的关键，通过渐变颜色产生平滑的过渡效果，使得肉眼看起来图像的边缘比较平整\n了解 GLSL 内置函数并实战使用，稍微深入片元着色器的代码编写。相关函数如 tan、atan、smoothstep\n用 gl_FragCoord 实战干预像素点的颜色，加深对 WebGL 中图像绘制，片元着色器工作原理的理解\n"},"front-end/webgl/2.4.-初探纹理图像":{"title":"2.4. 初探纹理图像","links":["front-end/webgl/1.6.-WebGL-绘制基本图形"],"tags":[],"content":"4. 初探纹理图像\n经过之前章节的学习，相信大家已经掌握了基本的二维几何图形绘制和着色器的基本工作原理，对 WebGL 已经有点熟悉了。那么这一节开始，我们开始学习 WegGL 中的纹理映射，let’s go！\n可能大家跟我一样，在还没学习到这一节的时候心里可能都会有个疑问，那就是虽然我们学 WebGL 的各种基础图形绘制、各种颜色控制，但如果我们要显示真实场景的图片，那我们应该怎样做呢？难道要自己把模型绘制出来，再上个色？比如说下面这张猫猫：\n\n其实真的有心去画，慢慢绘制各种基本图形加线段，控制好每个像素点的颜色…emmm…好像也不是不行，只是工作量巨大，并且可能没有什么意义。那遇到这样的问题，我们应该如何解决呢？这个时候，纹理图像就登场了！\n什么是纹理图像\n纹理图像是通过纹理映射的技术，将一张图贴到我们绘制的几何图形的表面上，这样我们就能在 WebGL 中使用真实的图片了，而这样的图形就是纹理图像。\n其实纹理映射就是将图像的每一个像素点的颜色映射到我们绘制好的图形上。回顾前两小节的内容，在顶点着色器执行完后，还有图形装配和光栅化的步骤，而光栅化后我们得到的是一个充满片元的图形，最后片元着色器再进行逐片元操作对每个像素点涂上颜色。而这里，无非就是给光栅化后的每个片元涂上对应照片中的颜色。\n\n如上图所示，纹理映射的基本工作方式就是这样，根据图片将光栅化后的对应位置的每个片元涂上对应的颜色。 所以，组成纹理图像的基本单位就是一个个像素，这里称之为——纹素，纹素的颜色值使用 RGB 或者 RGBA 的格式。\n纹理坐标\n上文提到了纹理映射要将像素点的颜色涂到对应位置的纹素上，那我们就需要对”位置”有个明确的认识，这就需要用到——纹理坐标。没错，又双叒叕是坐标～我们想一下，我们既然要贴图，那是贴半张、还是一张呢？贴到目标载体的左上角还是右下角呢？\n纹理坐标就是图像上的坐标，我们通过它可以拿到纹素的颜色，它的坐标系统如图所示：\n\n这一看，还是我们比较熟悉的坐标系呢，左下角为原点。大家可能注意到了，笔者在图片的顶点都标了坐标（尽管图片是个长方形的），不管长宽，范围都是 0 到 1。所以，这一点上我们的纹理坐标跟 WebGL 的坐标系统类似，范围就在 0-1 之间，并不依赖图片自身尺寸。（为了跟 x 、 y 坐标系统区分开，纹理坐标命名采用 s 和 t 来命名）\n那有了纹理坐标后，我们就只需要将对应的纹理坐标贴到我们的 WebGL 系统的顶点坐标中就可以实现纹理图像了。我们可以通过下图来加深理解：\n\n看到这里，相信你也知道了纹理映射的基本原理了，那接下来我们就进入实战，把文章开头的”猫猫”图贴到我们的 WebGL 图形的表面去！\n第一张纹理图片\n额，我觉得实战纹理图片这个部分跟之前学习 WebGL 缓冲区对象的时候有点像，也可以将整体实现拆分成几个步骤，然后也会用到一些新的 api。所以这里，我们跟之前一样，先以实战一张纹理图片为主，本文不用过度关注每个 api 的用法、参数，主要掌握好主流程才是关键。\n然后我们在下一节的文章中再详细了解相关的 api 一些具体的用法，还有不同参数带来的不同效果。那我们本文就专注于如何实现第一张纹理图像吧！\n1. 着色器代码实现\n首先看看顶点着色器的代码实现。通过上文的了解我们知道目前我们需要两种类型的坐标，其中一个是顶点坐标，另外一个就是纹理坐标，所以我们顶点着色器的代码实现如下：\nconst vertexCode = `\n  // 顶点坐标\n  attribute vec4 a_Position;\n  // 接收纹理坐标\n  attribute vec2 a_TexCoord;\n  // 向片元着色器传递纹理坐标\n  varying vec2 v_TexCoord;\n \n  void main () {\n    gl_Position = a_Position;\n    v_TexCoord = a_TexCoord;\n  }\n`\n上述代码其实我们都相对比较熟悉了，通过两个 attribute 变量分别接收 顶点、纹理 坐标，再通过 varying 变量 将纹理坐标传递给片元着色器（经过上一小节的学习，我们知道这里的纹理坐标其实是经过 WebGL 系统内插后的坐标值，它并不完全等于传入顶点着色器时候的纹理坐标）。\n那么接下来，就该轮到片元着色器了。这里，它需要根据每个片元的的纹理坐标，到图像对应的纹素上提取颜色值，再绘制到当前片元中。\nconst fragmentCode = `\n  precision mediump float;\n  // 接收纹理坐标\n  varying vec2 v_TexCoord;\n  // 取样器，这里可将其理解为纹理对象\n  uniform sampler2D u_Sampler;\n \n  void main () {\n    // texture2D 用于抽取纹理图片中纹素的颜色\n    gl_FragColor = texture2D(u_Sampler, v_TexCoord);\n  }\n`\n在片元着色器的代码实现中，我们看到了两个相对比较陌生的东西，一个是 sampler2D 的变量类型，一个 texture2D 的内置函数。那么在这里，我们简单了解一下他们的作用：\n\nsampler2D。sampler 就是取样器（提取纹理图像的颜色），我们简单理解它就是纹素的颜色值\ntexture2D。内置函数，可抽取纹素颜色。传入单元编号（纹理对象）、纹理坐标两个参数使用。\n\n2. WebGL 基础代码\n这里，我们快速带过一下基础的 WebGL 长方形的绘制代码实现。（基本都是之前章节提过的，不会所有都深入）\n因为我们的纹理图像是需要”贴”到一个长方形的模型上，所以我们还是需要跟之前章节一样绘制一个模型。回顾 WebGL 绘制基本图形 中，我们可以通过两个三角形来实现一个长方形，坐标如下：\n\n这里不再详细演示了，我们注意一下 buffer 数据即可，它跟之前的有一点不一样，我们这次存放的是顶点坐标和纹理坐标：\n// 前两个是顶点坐标，后两个是纹理坐标（图像取的是整张图，所以是0-1）\nconst verticesTexCoords = new Float32Array([\n  -.5, .5,   0., 1., \n  -.5, -.5,   0., 0.,\n  .5, .5,   1., 1.,\n  .5,-.5,   1., 0.\n])\n然后我们再注意下步进参数和偏移参数的设置即可：\n// 设置顶点坐标\nconst a_Position = gl.getAttribLocation(program, &#039;a_Position&#039;)\n// 注意步进参数设置\ngl.vertexAttribPointer(a_Position, 2, gl.FLOAT, false, FSIZE * 4, 0)\ngl.enableVertexAttribArray(a_Position)\n \n// 设置纹理坐标\nconst a_TexCoord = gl.getAttribLocation(program, &#039;a_TexCoord&#039;)\n// 注意步进参数、偏移参数设置\ngl.vertexAttribPointer(a_TexCoord, 2, gl.FLOAT, false, FSIZE * 4, FSIZE * 2)\ngl.enableVertexAttribArray(a_TexCoord)\n我们先来看一下模型的效果（这里我暂时给图形涂上蓝色方便大家看）：\n&lt;template&gt;\n  &lt;canvas id=&quot;ice-4_1&quot; width=&quot;640&quot; height=&quot;400&quot;&gt;&lt;/canvas&gt;\n&lt;/template&gt;\n \n&lt;script setup lang=&quot;ts&quot;&gt;\nimport { onMounted } from &#039;vue&#039;\nimport {\n  createGl,\n  createShader,\n  createProgram,\n} from &#039;@ice-webgl/utils&#039;\n \nconst vertexCode = `\n  attribute vec4 a_Position;\n  attribute vec2 a_TexCoord;\n  varying vec2 v_TexCoord;\n \n  void main () {\n    gl_Position = a_Position;\n    v_TexCoord = a_TexCoord;\n  }\n`\n \nconst fragmentCode = `\n  precision mediump float;\n  varying vec2 v_TexCoord;\n  uniform sampler2D u_Sampler;\n \n  void main () {\n    gl_FragColor = vec4(0., 0., 1., .9);\n  }\n`\n \nlet gl, program, a_Position, canvas, img\n \nconst initGl = () =&gt; {\n  gl = createGl(&#039;#ice-4_1&#039;)\n \n  const vertexShader = createShader(gl, gl.VERTEX_SHADER, vertexCode)\n  const fragmentShader = createShader(gl, gl.FRAGMENT_SHADER, fragmentCode)\n  program = createProgram(gl, vertexShader, fragmentShader)\n \n  const verticesTexCoords = new Float32Array([\n      -.5, .5, 0., 1.,\n      -.5, -.5, 0., 0.,\n      .5, .5, 1., 1.,\n      .5,-.5, 1., 0.\n  ])\n  const FSIZE = verticesTexCoords.BYTES_PER_ELEMENT\n \n  const buffer = gl.createBuffer()\n  gl.bindBuffer(gl.ARRAY_BUFFER, buffer)\n  gl.bufferData(gl.ARRAY_BUFFER, verticesTexCoords, gl.STATIC_DRAW)\n \n  const a_Position = gl.getAttribLocation(program, &#039;a_Position&#039;)\n  gl.vertexAttribPointer(a_Position, 2, gl.FLOAT, false, FSIZE * 4, 0)\n  gl.enableVertexAttribArray(a_Position)\n  const a_TexCoord = gl.getAttribLocation(program, &#039;a_TexCoord&#039;)\n  gl.vertexAttribPointer(a_TexCoord, 2, gl.FLOAT, false, FSIZE * 4, FSIZE * 2)\n  gl.enableVertexAttribArray(a_TexCoord)\n \n  gl.clearColor(0., 0., 0., .9)\n  gl.clear(gl.COLOR_BUFFER_BIT)\n \n  gl.drawArrays(gl.TRIANGLE_STRIP, 0, 4)\n}\n \nonMounted(() =&gt; {\n  initGl()\n})\n&lt;/script&gt;\n \n&lt;script lang=&quot;ts&quot;&gt;\nimport { defineComponent } from &#039;vue&#039;\n \nexport default defineComponent({\n  name: &#039;Third4_1&#039;\n})\n&lt;/script&gt;\n我们要贴图的模型（长方形）已经造出来了，那接下来就让我们将图片贴到这个蓝色的长方形上面吧。\n3. 实战纹理映射\n首先第一步的准备工作，我们当然是要搞个图片了！这里我们直接通过 Image 对象来创建一个图片实例，并进行加载：\nconst img = new Image()\n// 图片地址（注意不允许跨域）\nimg.src = &#039;/public/images/third/4.1.jpeg&#039;\nimg.onload = function () {\n  // 一系列实现纹理映射的相关代码\n}\n这里我们要注意一个小点就是 WebGL 中不可以使用跨域的图片，这一点跟我们平时对 &lt;img /&gt; 标签、或者 Image 对象的理解会有些差异～如果我们在 WebGL 中使用了跨域的图片资源，浏览器将会出现如下的报错信息：\n\n\n                  \n                  Uncaught DOMException \n                  \n                \nFailed to execute ‘texImage2D’ on ‘WebGLRenderingContext’: The image element contains cross-origin data, and may not be loaded.\n\n当然，我们也是可以通过设置 crossOrigin 属性来使用跨域的图片资源，具体操作可以参考 WebGL 跨域图像，因为不是本文的主要内容，我就不在这里进行展开了。\n\n接下来，我们就分步骤具体看看图片加载完成后（onload回调）我们具体需要怎么做：\n\n注意！如果有对某个 api 想详细了解的，大家可以点击外链到 MDN 中详细查看，本文以实现功能为主，不会详细展开！\n\n1. 创建纹理对象\n回顾缓冲区对象的使用，第一步其实跟这里是一样的，都是先要创建对象！这里我们通过 gl.createTexture 这个 api 来创建纹理对象：\nconst texture = gl.createTexture()\n上述代码中，我们创建了一个纹理对象，用它来管理 WebGL 中的纹理图像。\n2. 激活纹理单元\n所谓纹理单元就是用来”管理”纹理图像的。我们每用一张图片，都要给他指定一个纹理单元。一般情况下，WebGL 中默认有 8 个纹理单元，从 gl.TEXTURE0 - gl.TEXTURE7。\n我们在使用纹理单元之前，首先要激活它，就是通过 gl.activeTexture 这个 api ：\n// 参数就是待激活的纹理单元\ngl.activeTexture(gl.TEXTURE0)\n3. 绑定纹理对象\n绑定…纹理对象？好像学缓冲区的时候也有绑定缓冲区对象这玩意…没错，就是这么相似，在使用纹理对象之前，我们也需要对其进行绑定。这一步我们依然可以跟缓冲区对象一样地理解：需要绑定纹理对象才能对其进行操作。\n这一步，我们通过 gl.bindTexture 这个 api 来绑定纹理对象：\n// 绑定纹理对象\ngl.bindTexture(gl.TEXTURE_2D, texture)\ngl.bindTexture 的第一个参数 target ，它可以传递好些值如：gl.TEXTURE_2D 、gl.TEXTURE_CUBE_MAP、 gl.TEXTURE_3D 等等，这里我们只需要 gl.TEXTURE_2D 即可，因为我们的图像也是一张 2D 的猫猫照片而已。\n到这一步，WebGL 系统中关于纹理对象的状态可以理解成如下图片：\n\n4. 配置纹理对象\n这一步比较关键，因为我们需要设置纹理图像以什么样的方式映射到我们的模型中，是放大还是缩小、是否要重复等等\n这里我们通过 gl.texParameteri 这个 api 通过设置不同的参数来进行配置。当我们点开这个 MDN 文档的时候我们可以发现，这个 api 所用到的参数有很多种配合使用的场景，但我们这里并不需要所有都一下子掌握，我们主要关注本文示例程序实现所需要的即可。\n首先我们配置 gl.TEXTURE_MIN_FILTER 纹理缩小时的填充方法：\n// 纹理缩小，使用 gl.LINEAR 计算距离中心像素最近的四个像素的平均值\ngl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.LINEAR);\n接着再配置 gl.TEXTURE_WRAP_* 纹理水平、垂直 填充 ：\n// 填充方式都是 gl.CLAMP_TO_EDGE 边缘切割取值\ngl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);\ngl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);\n这里对于 gl.LINEAR、gl.CLAMP_TO_EDGE 这些参数不太理解的也没关系，我们会在后面的学习中继续深入了解。这里我们仅需要知道我们通过配置这些参数就能实现我们的第一张纹理图像即可。\n5. 分配纹理图像\n配置好纹理对象的参数后，我们是不是该想到一件事！图片 onload 后我们好像从来都没有用到它呀！所以这一步，我们就需要将纹理图像给到我们的纹理对象去使用！\n我们使用 gl.texImage2D 这个 api 来实现，然而…还是一如既往地一堆参数…\n这里我们简单地过一下每个参数的简介，留个印象就好：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n参数描述target这个应该不用我介绍了，直接就 gl.TEXTURE_2D 它吧level0 级是基本图像等级。这里我们传 0internalformat图像的内部格式。如 RGBformat纹理数据的格式。需要和 internalformat 的值一致type纹理数据的类型。gl.UNSIGNED_BYTE：每个颜色分量占 1 字节pixels纹理的像素源，本文是 Image 对象\n参数是真的有点多…不过大家不用有太多心智负担，还是那句话，本文只是初探，我们大概知道有这回事就行了。直接看看示例中的用法：\n// 本文用的图片是 jpeg 格式，所以格式参数均为 gl.RGB\ngl.texImage2D(gl.TEXTURE_2D, 0, gl.RGB, gl.RGB, gl.UNSIGNED_BYTE, img)\n那么到这一步，我们在 JavaScript 创建的 Image 图片对象就已经传入到 WebGL 系统的纹理对象中了。\n6. 纹理单元传递给片元着色器\n经过上一步的处理，现在我们的纹理图像已经存在 WebGL 的纹理对象中了。那还记得前文提到的片元着色器代码中的取样器变量 u_Sampler 吗？这里，我们就将纹理对象（纹理单元）传递给 u_Sampler 变量。（注意这里为什么是用 uniform 变量，首先是因为其需要在片元着色器中使用，其次它只是被分配一个纹理对象而已，不需要像 varying 一样有内插的过程）\n这一步，我们通过 gl.uniform1i 这个 api 来实现：\n// 获取 uniform 变量地址\nconst u_Sampler = gl.getUniformLocation(program, &#039;u_Sampler&#039;)\n// 将 gl.TEXTURE0（0号纹理单元） 分配给 u_Sampler 变量\ngl.uniform1i(u_Sampler, 0)\n这个 api 的使用相对简单一点，我们只需要注意第二个参数，它是一个数字，传入 0 代表将 gl.TEXTURE0 绑定的纹理对象分配到 u_Sampler 上。\n7. 片元着色器抽取纹素颜色\n这一步，就是我们片元着色器中用到的内置函数 texture2D，它会根据片元的坐标 (x, y) 从纹理图像中抽取出对应位置的像素颜色，然后将颜色绘制到当前的片元中（该内置函数的返回值是一个颜色值）。\n对应到本文的着色器代码中，第一个参数 u_Sampler 为取样器，其实就是我们的纹理对象（我们将绑定好的纹理对象传入到 u_Sampler 变量中）；第二个参数 v_TexCoord 就是从顶点着色器中传进来的（内插后的）坐标 (x, y)（我们从缓冲区数据中读到纹素坐标，经过 varying 内插后传入到片元着色器）。\ngl_FragColor = texture2D(u_Sampler, v_TexCoord);\n以上所有步骤，我们相关配置基本上就完成了，最后我们正常通过 gl.drawArrays 绘制我们的长方形，我们就能在 canvas 中看到我们的纹理图像了！直接看如下示例程序：\n&lt;template&gt;\n  &lt;el-switch v-model=&quot;isY&quot; active-text=&quot;开启Y轴反转&quot; /&gt;\n \n  &lt;canvas id=&quot;ice-4_2&quot; width=&quot;640&quot; height=&quot;400&quot;&gt;&lt;/canvas&gt;\n&lt;/template&gt;\n \n&lt;script setup lang=&quot;ts&quot;&gt;\nimport { onMounted, ref, watch } from &#039;vue&#039;\nimport {\n  createGl,\n  createShader,\n  createProgram,\n} from &#039;@ice-webgl/utils&#039;\nimport imageUrl from &#039;/public/images/third/4.1.jpeg&#039;\n \nconst isY = ref(false)\n \nconst vertexCode = `\n  attribute vec4 a_Position;\n  attribute vec2 a_TexCoord;\n  varying vec2 v_TexCoord;\n \n  void main () {\n    gl_Position = a_Position;\n    v_TexCoord = a_TexCoord;\n  }\n`\n \nconst fragmentCode = `\n  precision mediump float;\n  varying vec2 v_TexCoord;\n  uniform sampler2D u_Sampler;\n \n  void main () {\n    gl_FragColor = texture2D(u_Sampler, v_TexCoord);\n  }\n`\n \nlet gl, program, a_Position, canvas, img\n \nconst initGl = () =&gt; {\n  gl = createGl(&#039;#ice-4_2&#039;)\n \n  const vertexShader = createShader(gl, gl.VERTEX_SHADER, vertexCode)\n  const fragmentShader = createShader(gl, gl.FRAGMENT_SHADER, fragmentCode)\n  program = createProgram(gl, vertexShader, fragmentShader)\n \n  const verticesTexCoords = new Float32Array([\n      -.5, .5, 0., 1.,\n      -.5, -.5, 0., 0.,\n      .5, .5, 1., 1.,\n      .5,-.5, 1., 0.\n  ])\n  const FSIZE = verticesTexCoords.BYTES_PER_ELEMENT\n \n  const buffer = gl.createBuffer()\n  gl.bindBuffer(gl.ARRAY_BUFFER, buffer)\n  gl.bufferData(gl.ARRAY_BUFFER, verticesTexCoords, gl.STATIC_DRAW)\n \n  const a_Position = gl.getAttribLocation(program, &#039;a_Position&#039;)\n  gl.vertexAttribPointer(a_Position, 2, gl.FLOAT, false, FSIZE * 4, 0)\n  gl.enableVertexAttribArray(a_Position)\n  const a_TexCoord = gl.getAttribLocation(program, &#039;a_TexCoord&#039;)\n  gl.vertexAttribPointer(a_TexCoord, 2, gl.FLOAT, false, FSIZE * 4, FSIZE * 2)\n  gl.enableVertexAttribArray(a_TexCoord)\n \n  gl.clearColor(0., 0., 0., .9)\n \n  drawPicture()\n}\n \nconst drawPicture = () =&gt; {\n  const texture = gl.createTexture()\n \n  gl.pixelStorei(gl.UNPACK_FLIP_Y_WEBGL, isY.value)\n \n  gl.activeTexture(gl.TEXTURE0)\n  gl.bindTexture(gl.TEXTURE_2D, texture)\n \n  gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.LINEAR)\n  gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE)\n  gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE)\n \n  gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGB, gl.RGB, gl.UNSIGNED_BYTE, img)\n \n  const u_Sampler = gl.getUniformLocation(program, &#039;u_Sampler&#039;)\n  gl.uniform1i(u_Sampler, 0)\n \n  gl.clear(gl.COLOR_BUFFER_BIT)\n  gl.drawArrays(gl.TRIANGLE_STRIP, 0, 4)\n}\n \nconst initImage = () =&gt; {\n  img = new Image()\n  img.src = imageUrl\n  img.onload = function () {\n    initGl()\n  }\n}\n \nwatch(isY, () =&gt; {\n  drawPicture()\n})\n \nonMounted(() =&gt; {\n  initImage()\n})\n&lt;/script&gt;\n \n&lt;script lang=&quot;ts&quot;&gt;\nimport { defineComponent } from &#039;vue&#039;\n \nexport default defineComponent({\n  name: &#039;Third4_2&#039;\n})\n&lt;/script&gt;\n \n&lt;style lang=&quot;scss&quot; scoped&gt;\n#ice-4_2 {\n  margin-top: 16px;\n}\n&lt;/style&gt;\n哈哈哈，图像居然是反的！这里我是故意的，上述介绍了纹理映射中的步骤中，其实我还隐藏了一步没有讲，那就是 Y 轴反转。当然，这一点放在最后讲也是为了加深大家的印象和理解。\n首先来了解一下为什么我们需要 Y 轴反转这个操作，我们直接看下图即可：\n\n由图可知，纹理坐标的原点是图片的左下角，而图片自身的坐标原点是左上角，所以我们不加入 Y 轴反转的时候，纹理坐标所取的纹素点其实跟原图在 Y 轴上是相反的！详情我们可以看看 百度百科-图像坐标系 的讲解～\n所以！！我在上述示例程序中留了个交互功能，大家可以通过自行切换 Y 轴反转的状态来自行体验一下最终的纹理图像效果！\n总结\n本文的最后，跟大家一起回顾本文的主要内容。这里我们直接回顾本文的核心——纹理图像的实现过程：\n\n创建纹理对象 gl.createTexture\n设置 Y 轴反转 gl.pixelStorei\n激活纹理单元 gl.activeTexture\n绑定纹理对象 gl.bindTexture（绑定后才能操作纹理对象）\n配置纹理对象 gl.texParameteri\n将纹理图像分配给纹理对象进行填充 gl.texImage2D（纹理图像 → 纹理对象）\n将纹理单元传递给片元着色器 gl.uniform1i（纹理对象传递给 u_Sampler 变量）\n片元着色器抽取纹素颜色 内置函数 texture2D（通过取样器和片元坐标）\n\n本文一下子提到了很多新的 api，然后整个纹理图像的实现过程步骤也比较多，所以我还是建议大家也自行操作一番，按照步骤自己敲敲代码～"},"front-end/webgl/_resource/3.-WebGL绘制动态点":{"title":"3. WebGL绘制动态点","links":[],"tags":[],"content":""},"front-end/webpack/README":{"title":"README","links":[],"tags":[],"content":"\n\njuejin.cn/post/6844904032587382797\n\n\ngithub.com/biaochenxuying/blog/issues/47\n\n\nWebpack | TreeShaking 工作原理 - 知乎 (zhihu.com)\n\n"},"front-end/webpack/demo/src/markdown/doc":{"title":"doc","links":[],"tags":[],"content":"About\nHello markdown !"},"front-end/webpack/index":{"title":"index","links":[],"tags":[],"content":"Webpack 解决了什么问题？\n如何在前端项目中更高效地管理和维护项目的每一个资源。\n想要搞明白 Webpack，就必须先对它想要解决的问题或者目标有一个充分的认识。\n模块化的演进过程\nStage 1 - 文件划分方式\n以一个 js 脚本文件为模块划分，通过 script 标签引入：\n// module-a.js\nfunction foo(){\n    console.log(&quot;ModuleA#foo&quot;)\n}\n \n// module-b.js\nfunction bar(){\n    console.log(&quot;ModuleB#bar&quot;)\n}\n&lt;!-- index.html --&gt;\n&lt;html&gt;\n    &lt;script src=&quot;module-a.js&quot; &gt;&lt;/script&gt;\n    &lt;script src=&quot;module-b.js&quot; &gt;&lt;/script&gt;\n&lt;/html&gt;\n\n模块直接在全局工作，大量模块成员污染全局作用域；\n没有私有空间，所有模块内的成员都可以在模块外部被访问或者修改；\n一旦模块增多，容易产生命名冲突；\n无法管理模块与模块之间的依赖关系；\n在维护的过程中也很难分辨每个成员所属的模块；\n\nStage 2 - 命名空间方式\n在每一个 js 文件中，通过在 window 上挂载全局唯一的模块标识变量进行模块导出：\n// module-a.js\nwindow.moduleA = {\n    foo: function (){\n        console.log(&quot;ModuleA#foo&quot;)\n    }\n}\n\n解决了命名冲突的问题，但是其他问题依旧存在；\n\nStage 3 - IIFE\n通过 IIFE 立即执行函数，为模块提供了私有空间，将模块成员声明在 IIFE 的作用域中，需要暴露给外部的成员，即可挂载到 window 全局对象中；这种方式为模块带来了私有成员的概念，私有成员通过闭包的方式进行访问。\n;(function (){\n    var name = &quot;module-a&quot;\n    function foo(){\n        console.log(&quot;ModuleA#foo&quot;)\n    }\n    window.moduleA = {\n        foo: foo\n    }\n})()\n\n实现了模块私有空间；\n避免了污染全局作用域即成员命名冲突；\n\nStage 4 - IIFE 依赖参数\n在 IIFE 的基础之上，进一步通过传入参数，去声明该模块依赖的模块：\n;(function ($){\n    var name = &quot;module-a&quot;\n    function foo(){\n        console.log(&quot;ModuleA#foo&quot;)\n        $(&#039;body&#039;).animate({margin: &quot;20px&quot;})\n    }\n    window.moduleA = {\n        foo: foo\n    }\n})(jQuery)\n\n强调了模块间的依赖关系；\n\n模块的加载问题\n上述的方式都是直接通过 script 标签引入模块，当模块较多，模块依赖复杂时，会变得很难处理以及带来许多不必要的麻烦。\n更为理想的方式是在页面中引入一个 js 入口文件，其余所有用到的模块都可以通过代码去控制，按需加载。\n模块化规范的出现\n上述的阶段都是通过约定实现模块化，不同的开发者在实施过程中会出现细微的差别。\n为了统一不同开发者、不同项目之间的差异，就需要制定一个行业标准去规范模块化的实现方式\n两点需求：\n\n一个统一的模块化标准规范\n一个可以自动加载模块的基础库\n\n\nCommonJS 规范\nNode.js 中所遵循的模块规范，该规范约定一个文件就是一个模块，每个模块都有单独的作用域；通过 module.exports 导出成员，再通过 require 函数载入模块。\n\n早期制定前端模块化标准时，并没有直接选择 CommonJS 规范，而是专门为浏览器端重新设计了一个规范——AMD (Asynchronous Module Definition)，即异步模块定义规范。\n同期推出 Require.js，除了实现了 AMD 模块化规范，本身也是一个非常强大的模块加载器。\n// AMD 规范定义一个模块\ndefine([&#039;jquery&#039;, &#039;./module2.js&#039;], function($, module2) { \n    return {\n        start: function(){\n            $(&#039;body&#039;).animate({margin: &#039;20px&#039; }) \n            module2()\n        }\n    }\n})\n \n// AMD 规范载入一个模块\nrequire([&#039;./modules/module1.js&#039;], function (module1) { \n    module1.start()\n})\n模块化的标准规范\nJavaScript 的标准逐渐走向完善，模块化规范的最佳实践方式也基本实现了统一：\n\n\n在 Node.js 环境中，遵循 CommonJS 规范来组织模块；\n\n\n在浏览器环境中，遵循 ES Modules 规范；\n\n\nES Modules 规范是 ECMAScript 2015 （ES6）中才定义的模块系统，是近几年才制定的标准，存在环境兼容的问题。随着Webpack等一系列打包工具的流行，这一规范才开始逐渐被普及，经过多年的迭代， ES Modules 已发展成为现今最主流的前端模块化标准。\n模块打包工具的出现\n\n我们所使用的 ES Modules 模块系统本身就存在环境兼容问题，尽管现如今主流浏览器的最新版本都支持这一特性，但是目前还无法保证用户的浏览器使用情况，所以还需要解决兼容问题；\n模块化的方式划分出来的模块文件过多，而前端应用又运行在浏览器中，每一个文件都需要单独从服务器请求回来零散的模块文件，必然会导致浏览器的频繁发送网络请求，影响应用的工作效率；\n随着应用日益复杂，在前端应用开发过程中不仅仅只有JavaScript代码需要模块化，HTML 和 CSS 这些资源文件也会面临需要被模块化的问题；从宏观角度来看，这些文件也都应该看作前端应用中的一个模块，只不过这些模块的种类和用途跟 JavaScript 不同；\n\n基于以上需求，我们对打包工具做出了对应的设想：\n\n具备代码的编译能力，能将开发时编写的包含新特性或者存在浏览器差异的代码，转化为兼容大多数环境的代码；\n能够将众多分散的模块重新打包到一起，解决浏览器频繁请求模块文件的问题；\n能够将开发过程中的一系列资源文件都视作模块，打包在一起。\n\n如何使用 Webpack 实现模块化打包？\nWebpack 4 以后的版本支持零配置的方式直接启动打包，整个过程会按照约定将 src/index.js 作为打包入口，最终打包的结果会存放到 dist/main.js 中。\nWebpack 的工作模式\nWebpack 针对不同环境的三组预设配置：\n\nproduction：启动内置优化插件，自动优化打包结果，打包速度偏慢；\ndevelopment：自动优化打包速度，添加一些调试过程中的辅助插件以便于更好的调试错误；\nnone：运行最原始的打包，不做任何额外处理，这种模式一般需要分析我们模块的打包结果时会用到。\n\n想要修改 Webpack 工作模式的方式有两种：\n\n通过 CLI --mode 参数传入；\n通过配置文件设置 mode 属性；\n\n打包结果运行原理\n通过设置 mode=none，可查看详细的 webpack 打包产物：\n整体生成的代码是一个 IIFE，函数参数为源代码中对于的模块：\n(function(modules) {})\n([\n    (function(module, __webpack_exports__, __webpack_require__) {}),\n    (function(module, __webpack_exports__, __webpack_require__) {}),\n])\n在 IIFE 内部，即 Webpack 的入口：\n// The module cache\nvar installedModules = {};\n// The require function\nfunction __webpack_require__(moduleId) {}\n// expose the modules object (__webpack_modules__)\n__webpack_require__.m = modules;\n// expose the module cache\n__webpack_require__.c = installedModules;\n// define getter function for harmony exports\n__webpack_require__.d = function(exports, name, getter) {};\n// define __esModule on exports\n__webpack_require__.r = function(exports) {};\n \n// create a fake namespace object\n// mode &amp; 1: value is a module id, require it\n// mode &amp; 2: merge all properties of value into the ns\n// mode &amp; 4: return value when already ns object\n// mode &amp; 8|1: behave like require\n__webpack_require__.t = function(value, mode) {};\n// getDefaultExport function for compatibility with non-harmony modules\n__webpack_require__.n = function(module) {};\n// Object.prototype.hasOwnProperty.call\n__webpack_require__.o = function(object, property) {};\n// __webpack_public_path__\n__webpack_require__.p = &quot;&quot;;\n \n// Load entry module and return exports\nreturn __webpack_require__(__webpack_require__.s = 0);\n\n声明了一个对象 installedModules，用于管理已经加载过的模块；\n声明了加载模块函数 __webpack_require__；\n之后在 __webpack_require__上挂载了一些数据和一些工具方法；\n最后调用  __webpack_require__(0)，加载第一个模块，即入口点模块；\n\n__webpack_require__\nfunction __webpack_require__(moduleId) {\n    // Check if module is in cache\n    if(installedModules[moduleId]) {\n        return installedModules[moduleId].exports;\n    }\n    // Create a new module (and put it into the cache)\n    var module = installedModules[moduleId] = {\n        i: moduleId,\n        l: false,\n        exports: {}\n    };\n    // Execute the module function\n    modules[moduleId].call(module.exports, module, module.exports, __webpack_require__);\n \n    // Flag the module as loaded\n    module.l = true;\n \n    // Return the exports of the module\n    return module.exports;\n}\n上述代码清晰地展示了模块是如何被加载的，模块本身是一个函数，使用 call 并将 module.exports 作为 this ，同时传入一个模块必要的参数进行调用。调用后，标记该模块已加载，并返回模块的导出内容；\n__webpack_require__.r\n__webpack_require__.r = function(exports) {\n    if(typeof Symbol !== &#039;undefined&#039; &amp;&amp; Symbol.toStringTag) {\n        Object.defineProperty(exports, Symbol.toStringTag, { value: &#039;Module&#039; });\n    }\n    Object.defineProperty(exports, &#039;__esModule&#039;, { value: true });\n};\nr 函数很简单，只是在模块导出内容对象上做了一个标记，指明这是个 ESModule。\n如何通过 Loader 加载特殊资源？\nWebpack 支持管理前端项目中任意类型的资源文件，只需要添加合适 Loader 进行处理即可。\n如何加载资源模块？\n我们以一个例子来进行了解，修改 Webpack 配置，新建一个 main.css 文件，将其作为入口模块，此时进行打包会报错，因为默认的 Loader 只能处理 js 文件，而对于 CSS 样式会报错不能进行语法解析。\n而处理 CSS 文件，可使用 css-loader ，修改配置文件：\nmodule.exports = {\n  entry: &quot;./src/main.css&quot;,\n  module: {\n    rules: [\n      {\n        test: /\\.css$/,\n        use: &quot;css-loader&quot;\n      }\n    ]\n  }\n}\n此时则可以进行正常打包了，虽然只有一个 main.css 文件，但是打包后的模块却有两个：\n[\n  (function (module, __webpack_exports__, __webpack_require__) {\n    &quot;use strict&quot;;\n    __webpack_require__.r(__webpack_exports__);\n    var _css_loader_ = __webpack_require__(1);\n    var _css_loader__default = __webpack_require__.n(_css_loader_);\n    // Imports\n    var ___CSS_LOADER_EXPORT___ = _css_loader__default()(function (i) { return i[1] });\n    // Module\n    ___CSS_LOADER_EXPORT___.push([module.i, &quot;body {\\n  margin: 0;\\n  padding: 0;\\n}&quot;, &quot;&quot;]);\n    // Exports\n    __webpack_exports__[&quot;default&quot;] = (___CSS_LOADER_EXPORT___);\n \n  }),\n  (function (module, exports, __webpack_require__) {\n    &quot;use strict&quot;;\n \n    /**\n     * MIT License www.opensource.org/licenses/mit-license.php\n     * Author Tobias Koppers @sokra\n     */\n    // css base code, injected by the css-loader\n    // eslint-disable-next-line func-names\n    module.exports = function (cssWithMappingToString) {\n      var list = []; // return the list of modules as css string\n \n      list.toString = function toString() {\n        return this.map(function (item) {\n          var content = cssWithMappingToString(item);\n \n          if (item[2]) {\n            return &quot;@media &quot;.concat(item[2], &quot; {&quot;).concat(content, &quot;}&quot;);\n          }\n \n          return content;\n        }).join(&quot;&quot;);\n      }; \n      // import a list of modules into the list\n      list.i = function (modules, mediaQuery, dedupe) {\n        if (typeof modules === &quot;string&quot;) {\n          modules = [[null, modules, &quot;&quot;]];\n        }\n \n        var alreadyImportedModules = {};\n \n        if (dedupe) {\n          for (var i = 0; i &lt; this.length; i++) {\n            var id = this[i][0];\n \n            if (id != null) {\n              alreadyImportedModules[id] = true;\n            }\n          }\n        }\n \n        for (var _i = 0; _i &lt; modules.length; _i++) {\n          var item = [].concat(modules[_i]);\n \n          if (dedupe &amp;&amp; alreadyImportedModules[item[0]]) {\n            continue;\n          }\n \n          if (mediaQuery) {\n            if (!item[2]) {\n              item[2] = mediaQuery;\n            } else {\n              item[2] = &quot;&quot;.concat(mediaQuery, &quot; and &quot;).concat(item[2]);\n            }\n          }\n          list.push(item);\n        }\n      };\n      return list;\n    };\n  })\n]\n通过注释，可以了解到，第二个模块是 css_loader 注入的一个模块，先不管其作用，首先main.css 是并没有生效的：\n___CSS_LOADER_EXPORT___.push([module.i, &quot;body {\\n  margin: 0;\\n  padding: 0;\\n}&quot;, &quot;&quot;]);\n__webpack_exports__[&quot;default&quot;] = (___CSS_LOADER_EXPORT___);\n因为代码中，入口模块仅是把 CSS 字符串化，然后放到一个数组中，默认导出了，这也就是 css-loader 的主要做的。\n也就是说，只是把 CSS 加载到了 js 代码中，并没有进行使用，使其生效的做法是添加 style-loader：\n{\n    test: /\\.css$/,\n    use: [\n        &quot;style-loader&quot;,\n        &quot;css-loader&quot;\n    ]\n}\n\n注意，对同一个模块使用多个 Loader 时，需要注意 Loader 的顺序，因为 Webpack 会从 loader 数组尾部开始对模块进行处理。\n\n为什么在 js 加载资源文件？\n假设在开发页面上的某个局部功能时，需要用到一个样式模块和一个图片文件；如果你还是将这些资源文件单独引入到 HTML 中，然后再到 JS 中添加对应的逻辑代码。\n试想如果后期这个局部功能不用了，你就需要同时删除 JS 中的代码和 HTML 中的资源文件引入，也就是需要同时维护两条线。而如果你遵照 Webpack 的这种设计，所有资源的加载都是由 JS 代码控制，后期只需要维护 JS 代码这一条线即可。\n如果建立这种依赖关系：\n\n逻辑上比较合理，因为 JS 确实需要这些资源文件配合才能实现整体功能；\n配合 Webpack 这类工具的打包能确保在上线时，资源不会缺失，而且都是必要的；\n\n学习新事物不是说学会它的所有用法，你就能提高，能搞明白新事物为什么这样设计，基本上你就算出道了。\n开发一个 Loader\n开发一个处理 markdown 的 Loader，进一步了解 Loader 的处理机制：\nmodule.exports = (source) =&gt; {\n  console.log(source)\n  return &quot;hello loader!&quot;\n}\n{\n    test: /\\.md$/,\n    // 使用相对路径导入\n    use: &#039;./loader/markdown-loader&#039;\n}\n通过这样配置后，直接打包输出，会提示 You may need an additional loader to handle the result of these loaders.，这是因为资源文件经过一连串的流水线式的 Loader 处理后，必须返回标准的 JS 代码：\ngraph LR\nS[Any Source] --&gt; Loader1 \nLoader1 --&gt; Loader2\nLoader2 --&gt; Loader3\nLoader3 --&gt; E[JavaScript Code]\n\n解决办法：\n\n直接在这个 Loader 的最后返回一段 JS 代码字符串\n再找一个合适的加载器，在后面接着处理我们这里得到的结果\n\n我们尝试着，将 loader 中的返回内容，替换为 js 代码字符串：\nmodule.exports = (source) =&gt; {\n  console.log(source)\n  return &quot;console.log(&#039;hello loader!&#039;)&quot;\n}\n此时进行打包则不会报错了，而生成的模块中也包含了 loader 返回的内容：\n(function(module, exports) {\n    console.log(&#039;hello loader!&#039;)\n})\n实现 Loader 的逻辑\n需要安装一个能够将 Markdown 解析为 HTML 的模块 —— marked，在 markdown-loader.js 中导入这个模块然后使用这个模块去解析 source。\nconst { marked } = require(&#039;marked&#039;)\n \nmodule.exports = source =&gt; {\n  //1. 将 markdown 转换为 html 字符串\n  const html = marked(source)\n  //2. 将 html 字符串拼接为一段导出字符串的 JS 代码\n  const code = `module.exports = ${JSON.stringify(html)}`\n  return code\n}\n再次打包模块内容如下：\n(function(module, exports) {\n    module.exports = &quot;&lt;h1&gt;About&lt;/h1&gt;\\n&lt;p&gt;Hello markdown !&lt;/p&gt;\\n&quot;\n})\n多个 Loader 的配合\n另外，我们可以直接让 markdown-loader 返回 html 字符串，将其交给其他 Loader 进行处理。\n安装一个处理 HTML 的 Loader html-loader，安装完成过后，回到配置文件同样把 use 属性修改为一个数组以便依次使用多个 Loader：\n{\n    test: /\\.md$/,\n    use: [&quot;html-loader&quot;, &#039;./loader/markdown.loader&#039;]\n}\nhtml-loader 所作的操作等价于我们上面手动处理的操作：\n(function(module, exports) {\n    // Module\n    var code = &quot;&lt;h1&gt;About&lt;/h1&gt;\\n&lt;p&gt;Hello markdown !&lt;/p&gt;\\n&quot;;\n    // Exports\n    module.exports = code;\n})\n如何利用插件机制横向扩展 Webpack 的构建能力？\nWebpack 插件机制的目的，是为了增强Webpack在项目自动化构建方面的能力。\n常见的插件使用场景：\n\n实现自动在打包之前清除 dist目录(上次的打包结果）\n自动生成应用所需要的 HTML 文件\n根据不同环境为代码注入类似 API 地址这种可能变化的部分\n拷贝不需要参与打包的资源文件到输出目录压缩\nWebpack 打包完成后输出的文件自动发布打包结果到服务器，实现自动部署\n\n体验插件机制\n清除打包产物插件\nWebpack 每次打包的结果都是直接覆盖到 dist 目录打包前，dist 目录中就可能已经存入了一些在上一次打包操作时遗留的文件，再次打包时，只能覆盖掉同名文件；已经移除的资源文件就会一直累积在里面，最终导致部署上线时出现多余文件。\n更合理的做法是，在每次完整打包之前，自动清理 dist 目录每次打包过后，dist 目录中就只会存在那些必要的文件。\nclean-webpack-plugin 是一个第三方的 npm 包，安装后回到 Webpack 的配置文件中导入该插件模块导出 CleanWebpackPlugin：\n$ npm install clean-webpack-plugin --save-dev\nconst { CleanWebpackPlugin } = require(&#039;clean-webpack-plugin&#039;)\n生成 html 插件\nHTML 文件一般都是通过硬编码的方式，单独存放在项目根目录下这种方式有两个问题：\n\n项目发布时，我们需要同时发布根目录下的 HTML 文件和 dist 目录中所有的打包结果，非常麻烦，而且上线过后还要确保 HTML 代码中的资源文件路径是正确的。\n如果打包结果输出的目录或者文件名称发生变化，那 HTML 代码中所对应的 script 标签也需要我们手动修改路径。\n\n相比于之前写死 HTML 文件的方式，自动生成 HTML 的优势在于：\n\nHTML 也输出到 dist目录中了，上线时只需要把 dist 目录发布出去；\nHTML 中的 script 标签是自动引入的，所以可以确保资源文件的路径是正常的；\n\n$ npm install html-webpack-plugin --save-dev\nconst HtmlWebpackPlugin = require(&#039;html-webpack-plugin&#039;)\n对于生成的 HTML 文件，页面 title 必须要，改很多时候还需要我们自定义页面的一些 meta 标签和一些基础的 DOM 结构，可以在该插件配置中进行指定：\nnew HtmlWebpackPlugin({\n    title: &#039;Webpack Plugin Sample&#039;, \n    meta: {viewport: &#039;width=device-width&#039;}\n})\n而当需要更复杂的修改时，可以通过提供一个模板 html 文件，在模板中进行变量替换：\nnew HtmlWebpackPlugin({\n    title: &#039;Webpack Plugin Sample&#039;, \n    template: &#039;./src/index.html&#039;\n})\nhtml-webpack-plugin 插件除了自定义输出文件的内容，同时输出多个 HTML 文件也是一个非常常见的需求。\n通过 HtmlWebpackPlugin 创建的对象就是用于生成 index.html 文件的，可通过再创建一个新的实例对象用于创建额外的 HTML 文件。\n用于复制文件的插件\n项目中一般还有一些不需要参与构建的静态文件，最终也需要发布到线上，例如网站的 favicon, robots.txt 等。一般建议把这类文件统一放在项目根目录下的 public 或者 static 目录中，希望 Webpack 在打包时一并将这个目录下所有的文件复制到输出目录，这种需求可以使用copy-webpack-plugin插件实现：\n$ npm install copy-webpack-plugin --save-dev\nconst CopyWebpackPlugin = require(&#039;copy-webpack-plugin&#039;)\n \nnew CopyWebpackPlugin([&#039;public&#039;,&#039;static&#039;])\n开发一个插件\n开发一个用于移除打包产物中的多行注释的插件：\nclass RemoveCommentsPlugin {\n    apply(compiler) {\n        compiler.hooks.emit.tap(&#039;RemoveCommentsPlugin&#039;, compilation =&gt; {\n            // compilation =&gt; 可以理解为此次打包的上下文\n            for (const name in compilation.assets) {\n                if (name.endsWith(&#039;.js&#039;)) {\n                    const contents = compilation.assets[name].source()\n                    const noComments = contents.replace(/\\/\\*{2,}\\/\\s?/g, &quot;&quot;)\n                    compilation.assets[name] = {\n                        source: () =&gt; noComments,\n                        size: () =&gt; noComments.length\n                    }\n                }\n            }\n        })\n    }\n}\nWebpack 为每一个工作环节都预留了合适的钩子，扩展时只需要找到合适的时机去做合适的事情。\n探索 Webpack 运行机制与核心工作原理\n如果想了解 Webpack 整个工作过程的细节，那就需要更深入地了解刚刚说到的每一个环节，它们落实到代码层面到底做了些什么，或者说是如何实现的，必须有针对性的去“查阅” Webpack的源代码。\n工作原理剖析\n\nWebpack CLI 启动打包流程；\n递归依赖树，将每个模块交给对应的 Loader 处理；\n载入 Webpack 核心模块，创建 Compiler 对象；\n使用 Compiler 对象开始编译整个项目；\n从入口文件开始，解析模块依赖，形成依赖关系树；\n合并 Loader 处理完的结果，将打包结果输出到 dist 目录。\n\nWebpack CLI 作用\n就是将 CLI 参数和 Webpack 配置文件中的配置整合，得到一个完整的配置对象：\n\n通过 yargs 模块解析 CLI 参数（运行 webpack 命令时通过命令行传入的参数）；\n\n"},"functional-paradigm/ch1":{"title":"我们在做什么","links":["functional-paradigm/ch2"],"tags":[],"content":"第 1 章：我们在做什么？\n介绍\n你好，我是 Franklin Risby 教授，很高兴认识你。接下来我们将共度一段时光了，因为我要教你一些函数式编程的知识。好了，关于我就介绍到这里，你怎么样？我希望你已经熟悉 JavaScript 语言了，关于面向对象也有一点点的经验了，而且自认为是一个合格的程序员。希望你没有昆虫学博士学位也能找到并杀死一些臭虫（bug）。\n我并不假设你之前有任何函数式编程相关的知识——我们都知道假设的后果是什么（译者注：此处原文是“we both know what happens when you assume”，源自一句名言“When you assume you make an ASS of U and ME”，意思是“让两人都难堪”）。但我猜想你在使用可变状态（mutable state）、无限制副作用（unrestricted side effects）和无原则设计（unprincipled design）的过程中已经遇到过一些麻烦。好了，介绍到此为止，我们进入正题。\n本章的目的是让你对函数式编程的目的有一个初步认识，对一个程序之所以是函数式程序的原因有一定了解，要不然就会像无头苍蝇一样，不问青红皂白地避免使用对象——这等于是在做无用功。写代码需要遵循一定的原则，就像水流湍急的时候你需要天文罗盘来指引一样。\n现在已经有一些通用的编程原则了，各种缩写词带领我们在编程的黑暗隧道里前行：DRY（不要重复自己，don’t repeat yourself），高内聚低耦合（loose coupling high cohesion），YAGNI （你不会用到它的，ya ain’t gonna need it），最小意外原则（Principle of least surprise），单一责任（single responsibility）等等。\n我当然不会啰里八嗦地把这些年我听到的原则都列举出来，你知道重点就行。重点是这些原则同样适用于函数式编程，只不过它们与本书的主题不十分相关。在我们深入主题之前，我想先通过本章给你这样一种感觉，即你在敲键盘的时候内心就能强烈感受到的那种函数式的氛围。\n\n一个简单例子\n我们从一个愚蠢的例子开始。下面是一个海鸥程序，鸟群合并则变成了一个更大的鸟群，繁殖则增加了鸟群的数量，增加的数量就是它们繁殖出来的海鸥的数量。注意这个程序并不是面向对象的良好实践，它只是强调当前这种变量赋值方式的一些弊端。\nvar Flock = function(n) {\n  this.seagulls = n;\n};\n \nFlock.prototype.conjoin = function(other) {\n  this.seagulls += other.seagulls;\n  return this;\n};\n \nFlock.prototype.breed = function(other) {\n  this.seagulls = this.seagulls * other.seagulls;\n  return this;\n};\n \nvar flock_a = new Flock(4);\nvar flock_b = new Flock(2);\nvar flock_c = new Flock(0);\n \nvar result = flock_a.conjoin(flock_c).breed(flock_b).conjoin(flock_a.breed(flock_b)).seagulls;\n//=&gt; 32\n我相信没人会写这样糟糕透顶的程序。代码的内部可变状态非常难以追踪，而且，最终的答案还是错的！正确答案是 16，但是因为 flock_a 在运算过程中永久地改变了，所以得出了错误的结果。这是 IT 部门混乱的表现，非常粗暴的计算方式。\n如果你看不懂这个程序，没关系，我也看不懂。重点是状态和可变值非常难以追踪，即便是在这么小的一个程序中也不例外。\n我们试试另一种更函数式的写法：\nvar conjoin = function(flock_x, flock_y) { return flock_x + flock_y };\nvar breed = function(flock_x, flock_y) { return flock_x * flock_y };\n \nvar flock_a = 4;\nvar flock_b = 2;\nvar flock_c = 0;\n \nvar result = conjoin(breed(flock_b, conjoin(flock_a, flock_c)), breed(flock_a, flock_b));\n//=&gt;16\n很好，这次我们得到了正确的答案，而且少写了很多代码。不过函数嵌套有点让人费解…（我们会在第 5 章解决这个问题）。这种写法也更优雅，不过代码肯定是越直白越好，所以如果我们再深入挖掘，看看这段代码究竟做了什么事，我们会发现，它不过是在进行简单的加（conjoin） 和乘（breed）运算而已。\n代码中的两个函数除了函数名有些特殊，其他没有任何难以理解的地方。我们把它们重命名一下，看看它们的真面目。\nvar add = function(x, y) { return x + y };\nvar multiply = function(x, y) { return x * y };\n \nvar flock_a = 4;\nvar flock_b = 2;\nvar flock_c = 0;\n \nvar result = add(multiply(flock_b, add(flock_a, flock_c)), multiply(flock_a, flock_b));\n//=&gt;16\n这么一来，你会发现我们不过是在运用古人早已获得的知识：\n// 结合律（assosiative）\nadd(add(x, y), z) == add(x, add(y, z));\n \n// 交换律（commutative）\nadd(x, y) == add(y, x);\n \n// 同一律（identity）\nadd(x, 0) == x;\n \n// 分配律（distributive）\nmultiply(x, add(y,z)) == add(multiply(x, y), multiply(x, z));\n是的，这些经典的数学定律迟早会派上用场。不过如果你一时想不起来也没关系，多数人已经很久没复习过这些数学知识了。我们来看看能否运用这些定律简化这个海鸥小程序。\n// 原有代码\nadd(multiply(flock_b, add(flock_a, flock_c)), multiply(flock_a, flock_b));\n \n// 应用同一律，去掉多余的加法操作（add(flock_a, flock_c) == flock_a）\nadd(multiply(flock_b, flock_a), multiply(flock_a, flock_b));\n \n// 再应用分配律\nmultiply(flock_b, add(flock_a, flock_a));\n漂亮！除了调用的函数，一点多余的代码都不需要写。当然这里我们定义 add 和 multiply 是为了代码完整性，实际上并不必要——在调用之前它们肯定已经在某个类库里定义好了。\n你可能在想“你也太偷换概念了吧，居然举一个这么数学的例子”，或者“真实世界的应用程序比这复杂太多，不能这么简单地推理”。我之所以选择这样一个例子，是因为大多数人都知道加法和乘法，所以很容易就能理解数学可以如何为我们所用。\n不要感到绝望，本书后面还会穿插一些范畴学（category theory）、集合论（set theory）以及 lambda 运算的知识，教你写更加复杂的代码，而且一点也不输本章这个海鸥程序的简洁性和准确性。你也不需要成为一个数学家，本书要教给你的编程范式实践起来就像是使用一个普通的框架或者 api 一样。\n你也许会惊讶，我们可以像上例那样遵循函数式的范式去书写完整的、日常的应用程序，有着优异性能的程序，简洁且易推理的程序，以及不用每次都重新造轮子的程序。如果你是罪犯，那违法对你来说是好事；但在本书中，我们希望能够承认并遵守数学之法。\n我们希望去践行每一部分都能完美接合的理论，希望能以一种通用的、可组合的组件来表示我们的特定问题，然后利用这些组件的特性来解决这些问题。相比命令式（稍后本书将会介绍命令式的精确定义，暂时我们还是先把重点放在函数式上）编程的那种“某某去做某事”的方式，函数式编程将会有更多的约束，不过你会震惊于这种强约束、数学性的“框架”所带来的回报。\n我们已经看到函数式的点点星光了，但在真正开始我们的旅程之前，我们要先掌握一些具体的概念。\n第 2 章：一等公民的函数"},"functional-paradigm/ch2":{"title":"一等公民的函数","links":["functional-paradigm/ch3"],"tags":[],"content":"第 2 章: 一等公民的函数\n快速概览\n当我们说函数是“一等公民”的时候，我们实际上说的是它们和其他对象都一样…所以就是普通公民（坐经济舱的人？）。函数真没什么特殊的，你可以像对待任何其他数据类型一样对待它们——把它们存在数组里，当作参数传递，赋值给变量…等等。\n这是 JavaScript 语言的基础概念，不过还是值得提一提的，因为在 Github 上随便一搜就能看到对这个概念的集体无视，或者也可能是无知。我们来看一个杜撰的例子：\nconst hi = name =&gt; `Hi ${name}`;\nconst greeting = name =&gt; hi(name);\n这里 greeting 指向的那个把 hi 包了一层的包裹函数完全是多余的。为什么？因为 JavaScript 的函数是可调用的，当 hi 后面紧跟 () 的时候就会运行并返回一个值；如果没有 ()，hi 就简单地返回存到这个变量里的函数。我们来确认一下：\nhi; // name =&gt; `Hi ${name}`\nhi(&quot;jonas&quot;); // &quot;Hi jonas&quot;\ngreeting 只不过是转了个身然后以相同的参数调用了 hi 函数而已，因此我们可以这么写：\nconst greeting = hi;\ngreeting(&quot;times&quot;); // &quot;Hi times&quot;\n换句话说，hi 已经是个接受一个参数的函数了，为何要再定义一个额外的包裹函数，而它仅仅是用这个相同的参数调用 hi？完全没有道理。这就像在大夏天里穿上你最厚的大衣，只是为了跟热空气过不去，然后吃上个冰棍。真是脱裤子放屁多此一举。\n用一个函数把另一个函数包起来，目的仅仅是延迟执行，真的是非常糟糕的编程习惯。（稍后我将告诉你原因，跟可维护性密切相关。）\n充分理解这个问题对读懂本书后面的内容至关重要，所以我们再来看几个例子。以下代码都来自 npm 上的模块包：\n// 太傻了\nconst getServerStuff = callback =&gt; ajaxCall(json =&gt; callback(json));\n \n// 这才像样\nconst getServerStuff = ajaxCall;\n世界上到处都充斥着这样的垃圾 ajax 代码。以下是上述两种写法等价的原因：\n// 这行\najaxCall(json =&gt; callback(json));\n \n// 等价于这行\najaxCall(callback);\n \n// 那么，重构下 getServerStuff\nconst getServerStuff = callback =&gt; ajaxCall(callback);\n \n// ...就等于\nconst getServerStuff = ajaxCall // &lt;-- 看，没有括号哦\n各位，以上才是写函数的正确方式。一会儿再告诉你为何我对此如此执着。\nconst BlogController = {\n  index(posts) { return Views.index(posts); },\n  show(post) { return Views.show(post); },\n  create(attrs) { return Db.create(attrs); },\n  update(post, attrs) { return Db.update(post, attrs); },\n  destroy(post) { return Db.destroy(post); },\n};\n这个可笑的控制器（controller）99% 的代码都是垃圾。我们可以把它重写成这样：\nconst BlogController = {\n  index: Views.index,\n  show: Views.show,\n  create: Db.create,\n  update: Db.update,\n  destroy: Db.destroy,\n};\n…或者直接全部删掉，因为它的作用仅仅就是把视图（Views）和数据库（Db）打包在一起而已。\n为何钟爱一等公民？\n好了，现在我们来看看钟爱一等公民的原因是什么。前面 getServerStuff 和 BlogController 两个例子你也都看到了，虽说添加一些没有实际用处的间接层实现起来很容易，但这样做除了徒增代码量，提高维护和检索代码的成本外，没有任何用处。\n另外，如果一个函数被不必要地包裹起来了，而且发生了改动，那么包裹它的那个函数也要做相应的变更。\nhttpGet(&#039;/post/2&#039;, json =&gt; renderPost(json));\n如果 httpGet 要改成可以抛出一个可能出现的 err 异常，那我们还要回过头去把“胶水”函数也改了。\n// 把整个应用里的所有 httpGet 调用都改成这样，可以传递 err 参数。\nhttpGet(&#039;/post/2&#039;, (json, err) =&gt; renderPost(json, err));\n写成一等公民函数的形式，要做的改动将会少得多：\nhttpGet(&#039;/post/2&#039;, renderPost);  // renderPost 将会在 httpGet 中调用，想要多少参数都行\n除了删除不必要的函数，正确地为参数命名也必不可少。当然命名不是什么大问题，但还是有可能存在一些不当的命名，尤其随着代码量的增长以及需求的变更，这种可能性也会增加。\n项目中常见的一种造成混淆的原因是，针对同一个概念使用不同的命名。还有通用代码的问题。比如，下面这两个函数做的事情一模一样，但后一个就显得更加通用，可重用性也更高：\n// 只针对当前的博客\nconst validArticles = articles =&gt;\n  articles.filter(article =&gt; article !== null &amp;&amp; article !== undefined),\n \n// 对未来的项目更友好\nconst compact = xs =&gt; xs.filter(x =&gt; x !== null &amp;&amp; x !== undefined);\n在命名的时候，我们特别容易把自己限定在特定的数据上（本例中是 articles）。这种现象很常见，也是重复造轮子的一大原因。\n有一点我必须得指出，你一定要非常小心 this 值，别让它反咬你一口，这一点与面向对象代码类似。如果一个底层函数使用了 this，而且是以一等公民的方式被调用的，那你就等着 JS 这个蹩脚的抽象概念发怒吧。\nvar fs = require(&#039;fs&#039;);\n \n// 太可怕了\nfs.readFile(&#039;freaky_friday.txt&#039;, Db.save);\n \n// 好一点点\nfs.readFile(&#039;freaky_friday.txt&#039;, Db.save.bind(Db));\n \n把 Db 绑定（bind）到它自己身上以后，你就可以随心所欲地调用它的原型链式垃圾代码了。this 就像一块脏尿布，我尽可能地避免使用它，因为在函数式编程中根本用不到它。然而，在使用其他的类库时，你却不得不向这个疯狂的世界低头。\n也有人反驳说 this 能提高执行速度。如果你是这种对速度吹毛求疵的人，那你还是合上这本书吧。要是没法退货退款，也许你可以去换一本更入门的书来读。\n至此，我们才准备好继续后面的章节。\n第 3 章: 纯函数的好处"},"functional-paradigm/ch3":{"title":"纯函数的好处","links":["functional-paradigm/ch4"],"tags":[],"content":"第 3 章：纯函数的好处\n再次强调“纯”\n首先，我们要厘清纯函数的概念。\n\n纯函数是这样一种函数，即相同的输入，永远会得到相同的输出，而且没有任何可观察的副作用。\n\n比如 slice 和 splice，这两个函数的作用并无二致——但是注意，它们各自的方式却大不同，但不管怎么说作用还是一样的。我们说 slice 符合纯函数的定义是因为对相同的输入它保证能返回相同的输出。而 splice 却会嚼烂调用它的那个数组，然后再吐出来；这就会产生可观察到的副作用，即这个数组永久地改变了。\nvar xs = [1,2,3,4,5];\n \n// 纯的\nxs.slice(0,3);\n//=&gt; [1,2,3]\n \nxs.slice(0,3);\n//=&gt; [1,2,3]\n \nxs.slice(0,3);\n//=&gt; [1,2,3]\n \n \n// 不纯的\nxs.splice(0,3);\n//=&gt; [1,2,3]\n \nxs.splice(0,3);\n//=&gt; [4,5]\n \nxs.splice(0,3);\n//=&gt; []\n在函数式编程中，我们讨厌这种会改变数据的笨函数。我们追求的是那种可靠的，每次都能返回同样结果的函数，而不是像 splice 这样每次调用后都把数据弄得一团糟的函数，这不是我们想要的。\n来看看另一个例子。\n// 不纯的\nvar minimum = 21;\n \nvar checkAge = function(age) {\n  return age &gt;= minimum;\n};\n \n \n// 纯的\nvar checkAge = function(age) {\n  var minimum = 21;\n  return age &gt;= minimum;\n};\n在不纯的版本中，checkAge 的结果将取决于 minimum 这个可变变量的值。换句话说，它取决于系统状态（system state）；这一点令人沮丧，因为它引入了外部的环境，从而增加了认知负荷（cognitive load）。\n这个例子可能还不是那么明显，但这种依赖状态是影响系统复杂度的罪魁祸首（www.curtclifton.net/storage/papers/MoseleyMarks06a.pdf ）。输入值之外的因素能够左右 checkAge 的返回值，不仅让它变得不纯，而且导致每次我们思考整个软件的时候都痛苦不堪。\n另一方面，使用纯函数的形式，函数就能做到自给自足。我们也可以让 minimum 成为一个不可变（immutable）对象，这样就能保留纯粹性，因为状态不会有变化。要实现这个效果，必须得创建一个对象，然后调用 Object.freeze 方法：\nvar immutableState = Object.freeze({\n  minimum: 21\n});\n副作用可能包括…\n让我们来仔细研究一下“副作用”以便加深理解。那么，我们在纯函数定义中提到的万分邪恶的副作用到底是什么？“作用”我们可以理解为一切除结果计算之外发生的事情。\n“作用”本身并没什么坏处，而且在本书后面的章节你随处可见它的身影。“ 副作用”的关键部分在于“副”。就像一潭死水中的“水”本身并不是幼虫的培养器，“死”才是生成虫群的原因。同理，副作用中的“副”是滋生 bug 的温床。\n\n副作用是在计算结果的过程中，系统状态的一种变化，或者与外部世界进行的可观察的交互。\n\n副作用可能包含，但不限于：\n\n更改文件系统\n往数据库插入记录\n发送一个 http 请求\n可变数据\n打印/log\n获取用户输入\nDOM 查询\n访问系统状态\n\n这个列表还可以继续写下去。概括来讲，只要是跟函数外部环境发生的交互就都是副作用——这一点可能会让你怀疑无副作用编程的可行性。函数式编程的哲学就是假定副作用是造成不正当行为的主要原因。\n这并不是说，要禁止使用一切副作用，而是说，要让它们在可控的范围内发生。后面讲到 functor 和 monad 的时候我们会学习如何控制它们，目前还是尽量远离这些阴险的函数为好。\n副作用让一个函数变得不纯是有道理的：从定义上来说，纯函数必须要能够根据相同的输入返回相同的输出；如果函数需要跟外部事物打交道，那么就无法保证这一点了。\n我们来仔细了解下为何要坚持这种「相同输入得到相同输出」原则。注意，我们要复习一些八年级数学知识了。\n八年级数学\n根据 mathisfun.com：\n\n函数是不同数值之间的特殊关系：每一个输入值返回且只返回一个输出值。\n\n换句话说，函数只是两种数值之间的关系：输入和输出。尽管每个输入都只会有一个输出，但不同的输入却可以有相同的输出。下图展示了一个合法的从 x 到 y 的函数关系；\n（www.mathsisfun.com/sets/function.html）\n相反，下面这张图表展示的就不是一种函数关系， 因为输入值 5 指向了多个输出：\n（www.mathsisfun.com/sets/function.html）\n函数可以描述为一个集合，这个集合里的内容是 (输入, 输出) 对：[(1,2), (3,6), (5,10)]（看起来这个函数是把输入值加倍）。\n或者一张表：\n  输入 输出   1 2   2 4   3 6  \n甚至一个以 x 为输入 y 为输出的函数曲线图：\n\n如果输入直接指明了输出，那么就没有必要再实现具体的细节了。因为函数仅仅只是输入到输出的映射而已，所以简单地写一个对象就能“运行”它，使用 [] 代替 () 即可。\nvar toLowerCase = {&quot;A&quot;:&quot;a&quot;, &quot;B&quot;: &quot;b&quot;, &quot;C&quot;: &quot;c&quot;, &quot;D&quot;: &quot;d&quot;, &quot;E&quot;: &quot;e&quot;, &quot;D&quot;: &quot;d&quot;};\n \ntoLowerCase[&quot;C&quot;];\n//=&gt; &quot;c&quot;\n \nvar isPrime = {1: false, 2: true, 3: true, 4: false, 5: true, 6: false};\n \nisPrime[3];\n//=&gt; true\n当然了，实际情况中你可能需要进行一些计算而不是手动指定各项值；不过上例倒是表明了另外一种思考函数的方式。（你可能会想“要是函数有多个参数呢？”。的确，这种情况表明了以数学方式思考问题的一点点不便。暂时我们可以把它们打包放到数组里，或者把 arguments 对象看成是输入。等学习 curry 的概念之后，你就知道如何直接为函数在数学上的定义建模了。）\n戏剧性的是：纯函数就是数学上的函数，而且是函数式编程的全部。使用这些纯函数编程能够带来大量的好处，让我们来看一下为何要不遗余力地保留函数的纯粹性的原因。\n追求“纯”的理由\n可缓存性（Cacheable）\n首先，纯函数总能够根据输入来做缓存。实现缓存的一种典型方式是 memoize 技术：\nvar squareNumber  = memoize(function(x){ return x*x; });\n \nsquareNumber(4);\n//=&gt; 16\n \nsquareNumber(4); // 从缓存中读取输入值为 4 的结果\n//=&gt; 16\n \nsquareNumber(5);\n//=&gt; 25\n \nsquareNumber(5); // 从缓存中读取输入值为 5 的结果\n//=&gt; 25\n下面的代码是一个简单的实现，尽管它不太健壮。\nvar memoize = function(f) {\n  var cache = {};\n \n  return function() {\n    var arg_str = JSON.stringify(arguments);\n    cache[arg_str] = cache[arg_str] || f.apply(f, arguments);\n    return cache[arg_str];\n  };\n};\n值得注意的一点是，可以通过延迟执行的方式把不纯的函数转换为纯函数：\nvar pureHttpCall = memoize(function(url, params){\n  return function() { return $.getJSON(url, params); }\n});\n这里有趣的地方在于我们并没有真正发送 http 请求——只是返回了一个函数，当调用它的时候才会发请求。这个函数之所以有资格成为纯函数，是因为它总是会根据相同的输入返回相同的输出：给定了 url 和 params 之后，它就只会返回同一个发送 http 请求的函数。\n我们的 memoize 函数工作起来没有任何问题，虽然它缓存的并不是 http 请求所返回的结果，而是生成的函数。\n现在来看这种方式意义不大，不过很快我们就会学习一些技巧来发掘它的用处。重点是我们可以缓存任意一个函数，不管它们看起来多么具有破坏性。\n可移植性／自文档化（Portable / Self-Documenting）\n纯函数是完全自给自足的，它需要的所有东西都能轻易获得。仔细思考思考这一点…这种自给自足的好处是什么呢？首先，纯函数的依赖很明确，因此更易于观察和理解——没有偷偷摸摸的小动作。\n// 不纯的\nvar signUp = function(attrs) {\n  var user = saveUser(attrs);\n  welcomeUser(user);\n};\n \nvar saveUser = function(attrs) {\n    var user = Db.save(attrs);\n    ...\n};\n \nvar welcomeUser = function(user) {\n    Email(user, ...);\n    ...\n};\n \n// 纯的\nvar signUp = function(Db, Email, attrs) {\n  return function() {\n    var user = saveUser(Db, attrs);\n    welcomeUser(Email, user);\n  };\n};\n \nvar saveUser = function(Db, attrs) {\n    ...\n};\n \nvar welcomeUser = function(Email, user) {\n    ...\n};\n这个例子表明，纯函数对于其依赖必须要诚实，这样我们就能知道它的目的。仅从纯函数版本的 signUp 的签名就可以看出，它将要用到 Db、Email 和 attrs，这在最小程度上给了我们足够多的信息。\n后面我们会学习如何不通过这种仅仅是延迟执行的方式来让一个函数变纯，不过这里的重点应该很清楚，那就是相比不纯的函数，纯函数能够提供多得多的信息；前者天知道它们暗地里都干了些什么。\n其次，通过强迫“注入”依赖，或者把它们当作参数传递，我们的应用也更加灵活；因为数据库或者邮件客户端等等都参数化了（别担心，我们有办法让这种方式不那么单调乏味）。如果要使用另一个 Db，只需把它传给函数就行了。如果想在一个新应用中使用这个可靠的函数，尽管把新的 Db 和 Email 传递过去就好了，非常简单。\n在 JavaScript 的设定中，可移植性可以意味着把函数序列化（serializing）并通过 socket 发送。也可以意味着代码能够在 web workers 中运行。总之，可移植性是一个非常强大的特性。\n命令式编程中“典型”的方法和过程都深深地根植于它们所在的环境中，通过状态、依赖和有效作用（available effects）达成；纯函数与此相反，它与环境无关，只要我们愿意，可以在任何地方运行它。\n你上一次把某个类方法拷贝到新的应用中是什么时候？我最喜欢的名言之一是 Erlang 语言的作者 Joe Armstrong 说的这句话：“面向对象语言的问题是，它们永远都要随身携带那些隐式的环境。你只需要一个香蕉，但却得到一个拿着香蕉的大猩猩…以及整个丛林”。\n可测试性（Testable）\n第三点，纯函数让测试更加容易。我们不需要伪造一个“真实的”支付网关，或者每一次测试之前都要配置、之后都要断言状态（assert the state）。只需简单地给函数一个输入，然后断言输出就好了。\n事实上，我们发现函数式编程的社区正在开创一些新的测试工具，能够帮助我们自动生成输入并断言输出。这超出了本书范围，但是我强烈推荐你去试试 Quickcheck——一个为函数式环境量身定制的测试工具。\n合理性（Reasonable）\n很多人相信使用纯函数最大的好处是引用透明性（referential transparency）。如果一段代码可以替换成它执行所得的结果，而且是在不改变整个程序行为的前提下替换的，那么我们就说这段代码是引用透明的。\n由于纯函数总是能够根据相同的输入返回相同的输出，所以它们就能够保证总是返回同一个结果，这也就保证了引用透明性。我们来看一个例子。\nvar Immutable = require(&#039;immutable&#039;);\n \nvar decrementHP = function(player) {\n  return player.set(&quot;hp&quot;, player.hp-1);\n};\n \nvar isSameTeam = function(player1, player2) {\n  return player1.team === player2.team;\n};\n \nvar punch = function(player, target) {\n  if(isSameTeam(player, target)) {\n    return target;\n  } else {\n    return decrementHP(target);\n  }\n};\n \nvar jobe = Immutable.Map({name:&quot;Jobe&quot;, hp:20, team: &quot;red&quot;});\nvar michael = Immutable.Map({name:&quot;Michael&quot;, hp:20, team: &quot;green&quot;});\n \npunch(jobe, michael);\n//=&gt; Immutable.Map({name:&quot;Michael&quot;, hp:19, team: &quot;green&quot;})\ndecrementHP、isSameTeam 和 punch 都是纯函数，所以是引用透明的。我们可以使用一种叫做“等式推导”（equational reasoning）的技术来分析代码。所谓“等式推导”就是“一对一”替换，有点像在不考虑程序性执行的怪异行为（quirks of programmatic evaluation）的情况下，手动执行相关代码。我们借助引用透明性来剖析一下这段代码。\n首先内联 isSameTeam 函数：\nvar punch = function(player, target) {\n  if(player.team === target.team) {\n    return target;\n  } else {\n    return decrementHP(target);\n  }\n};\n因为是不可变数据，我们可以直接把 team 替换为实际值：\nvar punch = function(player, target) {\n  if(&quot;red&quot; === &quot;green&quot;) {\n    return target;\n  } else {\n    return decrementHP(target);\n  }\n};\nif 语句执行结果为 false，所以可以把整个 if 语句都删掉：\nvar punch = function(player, target) {\n  return decrementHP(target);\n};\n如果再内联 decrementHP，我们会发现这种情况下，punch 变成了一个让 hp 的值减 1 的调用：\nvar punch = function(player, target) {\n  return target.set(&quot;hp&quot;, target.hp-1);\n};\n总之，等式推导带来的分析代码的能力对重构和理解代码非常重要。事实上，我们重构海鸥程序使用的正是这项技术：利用加和乘的特性。对这些技术的使用将会贯穿本书，真的。\n并行代码\n最后一点，也是决定性的一点：我们可以并行运行任意纯函数。因为纯函数根本不需要访问共享的内存，而且根据其定义，纯函数也不会因副作用而进入竞争态（race condition）。\n并行代码在服务端 js 环境以及使用了 web worker 的浏览器那里是非常容易实现的，因为它们使用了线程（thread）。不过出于对非纯函数复杂度的考虑，当前主流观点还是避免使用这种并行。\n总结\n我们已经了解什么是纯函数了，也看到作为函数式程序员的我们，为何深信纯函数是不同凡响的。从这开始，我们将尽力以纯函数式的方式书写所有的函数。为此我们将需要一些额外的工具来达成目标，同时也尽量把非纯函数从纯函数代码中分离。\n如果手头没有一些工具，那么纯函数程序写起来就有点费力。我们不得不玩杂耍似的通过到处传递参数来操作数据，而且还被禁止使用状态，更别说“作用”了。没有人愿意这样自虐。所以让我们来学习一个叫 curry 的新工具。\n第 4 章: 柯里化（curry）"},"functional-paradigm/ch4":{"title":"柯里化（curry）","links":["functional-paradigm/ch5"],"tags":[],"content":"第 4 章: 柯里化（curry）\n不可或缺的 curry\n（译者注：原标题是“Can’t live if livin’ is without you”，为英国乐队 Badfinger 歌曲 Without You 中歌词。）\n我父亲以前跟我说过，有些事物在你得到之前是无足轻重的，得到之后就不可或缺了。微波炉是这样，智能手机是这样，互联网也是这样——老人们在没有互联网的时候过得也很充实。对我来说，函数的柯里化（curry）也是这样。\ncurry 的概念很简单：只传递给函数一部分参数来调用它，让它返回一个函数去处理剩下的参数。\n你可以一次性地调用 curry 函数，也可以每次只传一个参数分多次调用。\nvar add = function(x) {\n  return function(y) {\n    return x + y;\n  };\n};\n \nvar increment = add(1);\nvar addTen = add(10);\n \nincrement(2);\n// 3\n \naddTen(2);\n// 12\n这里我们定义了一个 add 函数，它接受一个参数并返回一个新的函数。调用 add 之后，返回的函数就通过闭包的方式记住了 add 的第一个参数。一次性地调用它实在是有点繁琐，好在我们可以使用一个特殊的 curry 帮助函数（helper function）使这类函数的定义和调用更加容易。\n我们来创建一些 curry 函数享受下（译者注：此处原文是“for our enjoyment”，语出自圣经）。\nvar curry = require(&#039;lodash&#039;).curry;\n \nvar match = curry(function(what, str) {\n  return str.match(what);\n});\n \nvar replace = curry(function(what, replacement, str) {\n  return str.replace(what, replacement);\n});\n \nvar filter = curry(function(f, ary) {\n  return ary.filter(f);\n});\n \nvar map = curry(function(f, ary) {\n  return ary.map(f);\n});\n我在上面的代码中遵循的是一种简单，同时也非常重要的模式。即策略性地把要操作的数据（String， Array）放到最后一个参数里。到使用它们的时候你就明白这样做的原因是什么了。\nmatch(/\\s+/g, &quot;hello world&quot;);\n// [ &#039; &#039; ]\n \nmatch(/\\s+/g)(&quot;hello world&quot;);\n// [ &#039; &#039; ]\n \nvar hasSpaces = match(/\\s+/g);\n// function(x) { return x.match(/\\s+/g) }\n \nhasSpaces(&quot;hello world&quot;);\n// [ &#039; &#039; ]\n \nhasSpaces(&quot;spaceless&quot;);\n// null\n \nfilter(hasSpaces, [&quot;tori_spelling&quot;, &quot;tori amos&quot;]);\n// [&quot;tori amos&quot;]\n \nvar findSpaces = filter(hasSpaces);\n// function(xs) { return xs.filter(function(x) { return x.match(/\\s+/g) }) }\n \nfindSpaces([&quot;tori_spelling&quot;, &quot;tori amos&quot;]);\n// [&quot;tori amos&quot;]\n \nvar noVowels = replace(/[aeiou]/ig);\n// function(replacement, x) { return x.replace(/[aeiou]/ig, replacement) }\n \nvar censored = noVowels(&quot;*&quot;);\n// function(x) { return x.replace(/[aeiou]/ig, &quot;*&quot;) }\n \ncensored(&quot;Chocolate Rain&quot;);\n// &#039;Ch*c*l*t* R**n&#039;\n这里表明的是一种“预加载”函数的能力，通过传递一到两个参数调用函数，就能得到一个记住了这些参数的新函数。\n我鼓励你使用 npm install lodash 安装 lodash，复制上面的代码放到 REPL 里跑一跑。当然你也可以在能够使用 lodash 或 ramda 的网页中运行它们。\n不仅仅是双关语／咖喱\ncurry 的用处非常广泛，就像在 hasSpaces、findSpaces 和 censored 看到的那样，只需传给函数一些参数，就能得到一个新函数。\n用 map 简单地把参数是单个元素的函数包裹一下，就能把它转换成参数为数组的函数。\nvar getChildren = function(x) {\n  return x.childNodes;\n};\n \nvar allTheChildren = map(getChildren);\n只传给函数一部分参数通常也叫做局部调用（partial application），能够大量减少样板文件代码（boilerplate code）。考虑上面的 allTheChildren 函数，如果用 lodash 的普通 map 来写会是什么样的（注意参数的顺序也变了）：\nvar allTheChildren = function(elements) {\n  return _.map(elements, getChildren);\n};\n通常我们不定义直接操作数组的函数，因为只需内联调用 map(getChildren) 就能达到目的。这一点同样适用于 sort、filter 以及其他的高阶函数（higher order function）（高阶函数：参数或返回值为函数的函数）。\n当我们谈论纯函数的时候，我们说它们接受一个输入返回一个输出。curry 函数所做的正是这样：每传递一个参数调用函数，就返回一个新函数处理剩余的参数。这就是一个输入对应一个输出啊。\n哪怕输出是另一个函数，它也是纯函数。当然 curry 函数也允许一次传递多个参数，但这只是出于减少 () 的方便。\n总结\ncurry 函数用起来非常得心应手，每天使用它对我来说简直就是一种享受。它堪称手头必备工具，能够让函数式编程不那么繁琐和沉闷。\n通过简单地传递几个参数，就能动态创建实用的新函数；而且还能带来一个额外好处，那就是保留了数学的函数定义，尽管参数不止一个。\n下一章我们将学习另一个重要的工具：组合（compose）。\n第 5 章: 代码组合（compose）\n练习\n开始练习之前先说明一下，我们将默认使用 ramda 这个库来把函数转为 curry 函数。或者你也可以选择由 lodash 的作者编写和维护的 lodash-fp。这两个库都很好用，选择哪一个就看你自己的喜好了。\n你还可以对自己的练习代码做单元测试，或者把代码拷贝到一个 REPL 里运行看看。\n这些练习的答案可以在本书仓库中找到。\nvar _ = require(&#039;ramda&#039;);\n \n \n// 练习 1\n//==============\n// 通过局部调用（partial apply）移除所有参数\n \nvar words = function(str) {\n  return split(&#039; &#039;, str);\n};\n \n// 练习 1a\n//==============\n// 使用 `map` 创建一个新的 `words` 函数，使之能够操作字符串数组\n \nvar sentences = undefined;\n \n \n// 练习 2\n//==============\n// 通过局部调用（partial apply）移除所有参数\n \nvar filterQs = function(xs) {\n  return filter(function(x){ return match(/q/i, x);  }, xs);\n};\n \n \n// 练习 3\n//==============\n// 使用帮助函数 `_keepHighest` 重构 `max` 使之成为 curry 函数\n \n// 无须改动:\nvar _keepHighest = function(x,y){ return x &gt;= y ? x : y; };\n \n// 重构这段代码:\nvar max = function(xs) {\n  return reduce(function(acc, x){\n    return _keepHighest(acc, x);\n  }, -Infinity, xs);\n};\n \n \n// 彩蛋 1:\n// ============\n// 包裹数组的 `slice` 函数使之成为 curry 函数\n// //[1,2,3].slice(0, 2)\nvar slice = undefined;\n \n \n// 彩蛋 2:\n// ============\n// 借助 `slice` 定义一个 `take` curry 函数，该函数调用后可以取出字符串的前 n 个字符。\nvar take = undefined;"},"functional-paradigm/ch5":{"title":"代码组合（compose）","links":["ch6"],"tags":[],"content":"第 5 章: 代码组合（compose）\n函数饲养\n这就是 组合（compose，以下将称之为组合）：\nvar compose = function(f,g) {\n  return function(x) {\n    return f(g(x));\n  };\n};\nf 和 g 都是函数，x 是在它们之间通过“管道”传输的值。\n组合看起来像是在饲养函数。你就是饲养员，选择两个有特点又遭你喜欢的函数，让它们结合，产下一个崭新的函数。组合的用法如下：\nvar toUpperCase = function(x) { return x.toUpperCase(); };\nvar exclaim = function(x) { return x + &#039;!&#039;; };\nvar shout = compose(exclaim, toUpperCase);\n \nshout(&quot;send in the clowns&quot;);\n//=&gt; &quot;SEND IN THE CLOWNS!&quot;\n两个函数组合之后返回了一个新函数是完全讲得通的：组合某种类型（本例中是函数）的两个元素本就该生成一个该类型的新元素。把两个乐高积木组合起来绝不可能得到一个林肯积木。所以这是有道理的，我们将在适当的时候探讨这方面的一些底层理论。\n在 compose 的定义中，g 将先于 f 执行，因此就创建了一个从右到左的数据流。这样做的可读性远远高于嵌套一大堆的函数调用，如果不用组合，shout 函数将会是这样的：\nvar shout = function(x){\n  return exclaim(toUpperCase(x));\n};\n让代码从右向左运行，而不是由内而外运行，我觉得可以称之为“左倾”（吁——）。我们来看一个顺序很重要的例子：\nvar head = function(x) { return x[0]; };\nvar reverse = reduce(function(acc, x){ return [x].concat(acc); }, []);\nvar last = compose(head, reverse);\n \nlast([&#039;jumpkick&#039;, &#039;roundhouse&#039;, &#039;uppercut&#039;]);\n//=&gt; &#039;uppercut&#039;\nreverse 反转列表，head 取列表中的第一个元素；所以结果就是得到了一个 last 函数（译者注：即取列表的最后一个元素），虽然它性能不高。这个组合中函数的执行顺序应该是显而易见的。尽管我们可以定义一个从左向右的版本，但是从右向左执行更加能够反映数学上的含义——是的，组合的概念直接来自于数学课本。实际上，现在是时候去看看所有的组合都有的一个特性了。\n// 结合律（associativity）\nvar associative = compose(f, compose(g, h)) == compose(compose(f, g), h);\n// true\n这个特性就是结合律，符合结合律意味着不管你是把 g 和 h 分到一组，还是把 f 和 g 分到一组都不重要。所以，如果我们想把字符串变为大写，可以这么写：\ncompose(toUpperCase, compose(head, reverse));\n \n// 或者\ncompose(compose(toUpperCase, head), reverse);\n因为如何为 compose 的调用分组不重要，所以结果都是一样的。这也让我们有能力写一个可变的组合（variadic compose），用法如下：\n// 前面的例子中我们必须要写两个组合才行，但既然组合是符合结合律的，我们就可以只写一个，\n// 而且想传给它多少个函数就传给它多少个，然后让它自己决定如何分组。\n \nvar lastUpper = compose(toUpperCase, head, reverse);\n \nlastUpper([&#039;jumpkick&#039;, &#039;roundhouse&#039;, &#039;uppercut&#039;]);\n//=&gt; &#039;UPPERCUT&#039;\n \n \nvar loudLastUpper = compose(exclaim, toUpperCase, head, reverse)\n \nloudLastUpper([&#039;jumpkick&#039;, &#039;roundhouse&#039;, &#039;uppercut&#039;]);\n//=&gt; &#039;UPPERCUT!&#039;\n运用结合律能为我们带来强大的灵活性，还有对执行结果不会出现意外的那种平和心态。至于稍微复杂些的可变组合，也都包含在本书的 support 库里了，而且你也可以在类似 lodash、underscore 以及 ramda 这样的类库中找到它们的常规定义。\n结合律的一大好处是任何一个函数分组都可以被拆开来，然后再以它们自己的组合方式打包在一起。让我们来重构重构前面的例子：\nvar loudLastUpper = compose(exclaim, toUpperCase, head, reverse);\n \n// 或\nvar last = compose(head, reverse);\nvar loudLastUpper = compose(exclaim, toUpperCase, last);\n \n// 或\nvar last = compose(head, reverse);\nvar angry = compose(exclaim, toUpperCase);\nvar loudLastUpper = compose(angry, last);\n \n// 更多变种...\n关于如何组合，并没有标准的答案——我们只是以自己喜欢的方式搭乐高积木罢了。通常来说，最佳实践是让组合可重用，就像 last 和 angry 那样。如果熟悉 Fowler 的《重构》一书的话，你可能会认识到这个过程叫做 “extract method”——只不过不需要关心对象的状态。\npointfree\npointfree 模式指的是，永远不必说出你的数据。咳咳对不起（译者注：此处原文是“Pointfree style means never having to say your data”，源自 1970 年的电影 Love Story 里的一句著名台词“Love means never having to say you’re sorry”。紧接着作者又说了一句“Excuse me”，大概是一种幽默）。它的意思是说，函数无须提及将要操作的数据是什么样的。一等公民的函数、柯里化（curry）以及组合协作起来非常有助于实现这种模式。\n// 非 pointfree，因为提到了数据：word\nvar snakeCase = function (word) {\n  return word.toLowerCase().replace(/\\s+/ig, &#039;_&#039;);\n};\n \n// pointfree\nvar snakeCase = compose(replace(/\\s+/ig, &#039;_&#039;), toLowerCase);\n看到 replace 是如何被局部调用的了么？这里所做的事情就是通过管道把数据在接受单个参数的函数间传递。利用 curry，我们能够做到让每个函数都先接收数据，然后操作数据，最后再把数据传递到下一个函数那里去。另外注意在 pointfree 版本中，不需要 word 参数就能构造函数；而在非 pointfree 的版本中，必须要有 word 才能进行一切操作。\n我们再来看一个例子。\n// 非 pointfree，因为提到了数据：name\nvar initials = function (name) {\n  return name.split(&#039; &#039;).map(compose(toUpperCase, head)).join(&#039;. &#039;);\n};\n \n// pointfree\nvar initials = compose(join(&#039;. &#039;), map(compose(toUpperCase, head)), split(&#039; &#039;));\n \ninitials(&quot;hunter stockton thompson&quot;);\n// &#039;H. S. T&#039;\n另外，pointfree 模式能够帮助我们减少不必要的命名，让代码保持简洁和通用。对函数式代码来说，pointfree 是非常好的石蕊试验，因为它能告诉我们一个函数是否是接受输入返回输出的小函数。比如，while 循环是不能组合的。不过你也要警惕，pointfree 就像是一把双刃剑，有时候也能混淆视听。并非所有的函数式代码都是 pointfree 的，不过这没关系。可以使用它的时候就使用，不能使用的时候就用普通函数。\ndebug\n组合的一个常见错误是，在没有局部调用之前，就组合类似 map 这样接受两个参数的函数。\n// 错误做法：我们传给了 `angry` 一个数组，根本不知道最后传给 `map` 的是什么东西。\nvar latin = compose(map, angry, reverse);\n \nlatin([&quot;frog&quot;, &quot;eyes&quot;]);\n// error\n \n \n// 正确做法：每个函数都接受一个实际参数。\nvar latin = compose(map(angry), reverse);\n \nlatin([&quot;frog&quot;, &quot;eyes&quot;]);\n// [&quot;EYES!&quot;, &quot;FROG!&quot;])\n如果在 debug 组合的时候遇到了困难，那么可以使用下面这个实用的，但是不纯的 trace 函数来追踪代码的执行情况。\nvar trace = curry(function(tag, x){\n  console.log(tag, x);\n  return x;\n});\n \nvar dasherize = compose(join(&#039;-&#039;), toLower, split(&#039; &#039;), replace(/\\s{2,}/ig, &#039; &#039;));\n \ndasherize(&#039;The world is a vampire&#039;);\n// TypeError: Cannot read property &#039;apply&#039; of undefined\n这里报错了，来 trace 下：\nvar dasherize = compose(join(&#039;-&#039;), toLower, trace(&quot;after split&quot;), split(&#039; &#039;), replace(/\\s{2,}/ig, &#039; &#039;));\n// after split [ &#039;The&#039;, &#039;world&#039;, &#039;is&#039;, &#039;a&#039;, &#039;vampire&#039; ]\n啊！toLower 的参数是一个数组，所以需要先用 map 调用一下它。\nvar dasherize = compose(join(&#039;-&#039;), map(toLower), split(&#039; &#039;), replace(/\\s{2,}/ig, &#039; &#039;));\n \ndasherize(&#039;The world is a vampire&#039;);\n \n// &#039;the-world-is-a-vampire&#039;\ntrace 函数允许我们在某个特定的点观察数据以便 debug。像 haskell 和 purescript 之类的语言出于开发的方便，也都提供了类似的函数。\n组合将成为我们构造程序的工具，而且幸运的是，它背后是有一个强大的理论做支撑的。让我们来研究研究这个理论。\n范畴学\n范畴学（category theory）是数学中的一个抽象分支，能够形式化诸如集合论（set theory）、类型论（type theory）、群论（group theory）以及逻辑学（logic）等数学分支中的一些概念。范畴学主要处理对象（object）、态射（morphism）和变化式（transformation），而这些概念跟编程的联系非常紧密。下图是一些相同的概念分别在不同理论下的形式：\n\n抱歉，我没有任何要吓唬你的意思。我并不假设你对这些概念都了如指掌，我只是想让你明白这里面有多少重复的内容，让你知道为何范畴学要统一这些概念。\n在范畴学中，有一个概念叫做…范畴。有着以下这些组件（component）的搜集（collection）就构成了一个范畴：\n\n对象的搜集\n态射的搜集\n态射的组合\nidentity 这个独特的态射\n\n范畴学抽象到足以模拟任何事物，不过目前我们最关心的还是类型和函数，所以让我们把范畴学运用到它们身上看看。\n对象的搜集\n对象就是数据类型，例如 String、Boolean、Number 和 Object 等等。通常我们把数据类型视作所有可能的值的一个集合（set）。像 Boolean 就可以看作是 [true, false] 的集合，Number 可以是所有实数的一个集合。把类型当作集合对待是有好处的，因为我们可以利用集合论（set theory）处理类型。\n态射的搜集\n态射是标准的、普通的纯函数。\n态射的组合\n你可能猜到了，这就是本章介绍的新玩意儿——组合。我们已经讨论过 compose 函数是符合结合律的，这并非巧合，结合律是在范畴学中对任何组合都适用的一个特性。\n这张图展示了什么是组合：\n\n\n这里有一个具体的例子：\nvar g = function(x){ return x.length; };\nvar f = function(x){ return x === 4; };\nvar isFourLetterWord = compose(f, g);\nidentity 这个独特的态射\n让我们介绍一个名为 id 的实用函数。这个函数接受随便什么输入然后原封不动地返回它：\nvar id = function(x){ return x; };\n你可能会问“这到底哪里有用了？”。别急，我们会在随后的章节中拓展这个函数的，暂时先把它当作一个可以替代给定值的函数——一个假装自己是普通数据的函数。\nid 函数跟组合一起使用简直完美。下面这个特性对所有的一元函数（unary function）（一元函数：只接受一个参数的函数） f 都成立：\n// identity\ncompose(id, f) == compose(f, id) == f;\n// true\n嘿，**这就是实数的单位元（identity property）**嘛！如果这还不够清楚直白，别着急，慢慢理解它的无用性。很快我们就会到处使用 id 了，不过暂时我们还是把它当作一个替代给定值的函数。这对写 pointfree 的代码非常有用。\n好了，以上就是类型和函数的范畴。不过如果你是第一次听说这些概念，我估计你还是有些迷糊，不知道范畴到底是什么，为什么有用。没关系，本书全书都在借助这些知识编写示例代码。至于现在，就在本章，本行文字中，你至少可以认为它向我们提供了有关组合的知识——比如结合律和单位律。\n除了类型和函数，还有什么范畴呢？还有很多，比如我们可以定义一个有向图（directed graph），以节点为对象，以边为态射，以路径连接为组合。还可以定义一个实数类型（Number），以所有的实数为对象，以 &gt;= 为态射（实际上任何偏序（partial order）或全序（total order）都可以成为一个范畴）。范畴的总数是无限的，但是要达到本书的目的，我们只需要关心上面定义的范畴就好了。至此我们已经大致浏览了一些表面的东西，必须要继续后面的内容了。\n总结\n组合像一系列管道那样把不同的函数联系在一起，数据就可以也必须在其中流动——毕竟纯函数就是输入对输出，所以打破这个链条就是不尊重输出，就会让我们的应用一无是处。\n我们认为组合是高于其他所有原则的设计原则，这是因为组合让我们的代码简单而富有可读性。另外范畴学将在应用架构、模拟副作用和保证正确性方面扮演重要角色。\n现在我们已经有足够的知识去进行一些实际的练习了，让我们来编写一个示例应用。\n第 6 章: 示例应用\n练习\nrequire(&#039;../../support&#039;);\nvar _ = require(&#039;ramda&#039;);\nvar accounting = require(&#039;accounting&#039;);\n \n// 示例数据\nvar CARS = [\n    {name: &quot;Ferrari FF&quot;, horsepower: 660, dollar_value: 700000, in_stock: true},\n    {name: &quot;Spyker C12 Zagato&quot;, horsepower: 650, dollar_value: 648000, in_stock: false},\n    {name: &quot;Jaguar XKR-S&quot;, horsepower: 550, dollar_value: 132000, in_stock: false},\n    {name: &quot;Audi R8&quot;, horsepower: 525, dollar_value: 114200, in_stock: false},\n    {name: &quot;Aston Martin One-77&quot;, horsepower: 750, dollar_value: 1850000, in_stock: true},\n    {name: &quot;Pagani Huayra&quot;, horsepower: 700, dollar_value: 1300000, in_stock: false}\n  ];\n \n// 练习 1:\n// ============\n// 使用 _.compose() 重写下面这个函数。提示：_.prop() 是 curry 函数\nvar isLastInStock = function(cars) {\n  var last_car = _.last(cars);\n  return _.prop(&#039;in_stock&#039;, last_car);\n};\n \n// 练习 2:\n// ============\n// 使用 _.compose()、_.prop() 和 _.head() 获取第一个 car 的 name\nvar nameOfFirstCar = undefined;\n \n \n// 练习 3:\n// ============\n// 使用帮助函数 _average 重构 averageDollarValue 使之成为一个组合\nvar _average = function(xs) { return reduce(add, 0, xs) / xs.length; }; // &lt;- 无须改动\n \nvar averageDollarValue = function(cars) {\n  var dollar_values = map(function(c) { return c.dollar_value; }, cars);\n  return _average(dollar_values);\n};\n \n \n// 练习 4:\n// ============\n// 使用 compose 写一个 sanitizeNames() 函数，返回一个下划线连接的小写字符串：例如：sanitizeNames([&quot;Hello World&quot;]) //=&gt; [&quot;hello_world&quot;]。\n \nvar _underscore = replace(/\\W+/g, &#039;_&#039;); //&lt;-- 无须改动，并在 sanitizeNames 中使用它\n \nvar sanitizeNames = undefined;\n \n \n// 彩蛋 1:\n// ============\n// 使用 compose 重构 availablePrices\n \nvar availablePrices = function(cars) {\n  var available_cars = _.filter(_.prop(&#039;in_stock&#039;), cars);\n  return available_cars.map(function(x){\n    return accounting.formatMoney(x.dollar_value);\n  }).join(&#039;, &#039;);\n};\n \n \n// 彩蛋 2:\n// ============\n// 重构使之成为 pointfree 函数。提示：可以使用 _.flip()\n \nvar fastestCar = function(cars) {\n  var sorted = _.sortBy(function(car){ return car.horsepower }, cars);\n  var fastest = _.last(sorted);\n  return fastest.name + &#039; is the fastest&#039;;\n};"},"golang/command":{"title":"command","links":[],"tags":[],"content":"go mod init\n该命令在当前路径下初始化一个 go.mod 文件，接受一个参数，即模块路径；\n\n这里说的模块路径（module path）并不是文件系统中的索引路径，它只是一个逻辑概念，用于标识该模块的一个唯一字符串，通常会以域名作为模块路径的前缀，因为域名是全球范围内是唯一的，这可以确保模块的唯一性；\n\ngo install\n该命令拉取指定的包源码并编译构建，可执行文件则会被安装至 GOBIN环境变量下的路径，默认是 $GOPATH/bin，如果 $GOPATH 不存在，则取$HOME/go/bin；如果是在 $GOROOT 路径下执行 install 命令，那么可执行文件则会被安装至 $GOROOT/bin 或 $GOTOOLDIR ；\n在 Go 1.16 后，install 命令可以携带包版本后缀（如 @latest or @v1.0.0），继而忽略任意路径下的 go.mod的影响，也不会改变其中的内容；"},"golang/context":{"title":"context","links":[],"tags":[],"content":"简介\ncontext包是在go1.7版本中引入到标准库中的，\n为什么需要context\n在并发程序中，由于超时、取消操作或者一些异常情况，往往需要进行抢占操作或者中断后续操作。\ncontext可以用来在goroutine之间传递上下文信息，相同的context可以传递给运行在不同goroutine中的函数，上下文对于多个goroutine同时使用是安全的，context包定义了上下文类型，可以使用background、TODO创建一个上下文，在函数调用链之间传播context，也可以使用WithDeadline、WithTimeout、WithCancel 或 WithValue 创建的修改副本替换它。\nContext 结构体\n// A Context carries a deadline, cancelation signal, and request-scoped values\n// across API boundaries. Its methods are safe for simultaneous use by multiple\n// goroutines.\ntype Context interface {\n    // Done returns a channel that is closed when this Context is canceled\n    // or times out.\n    Done() &lt;-chan struct{}\n \n    // Err indicates why this context was canceled, after the Done channel\n    // is closed.\n    Err() error\n \n    // Deadline returns the time when this Context will be canceled, if any.\n    Deadline() (deadline time.Time, ok bool)\n \n    // Value returns the value associated with key or nil if none.\n    Value(key interface{}) interface{}\n}\n\nDone()，返回一个 channel / nil。当 times out 或者调用 cancel 方法时，将会 close 掉；\nErr()，如果Done返回的channel没有关闭，将返回nil;如果Done返回的channel已经关闭，将返回非空的值表示任务结束的原因。如果是context被取消，Err将返回Canceled；如果是context超时，Err将返回DeadlineExceeded。\nDeadline()，返回绑定当前context的任务被取消的截止时间；如果没有设定期限，将返回ok == false。\nValue()，返回context存储的键值对中当前key对应的值，如果没有对应的key,则返回nil。\n\n所有方法\nfunc Background() Context\nfunc TODO() Context\n \nfunc WithCancel(parent Context) (ctx Context, cancel CancelFunc)\nfunc WithDeadline(parent Context, deadline time.Time) (Context, CancelFunc)\nfunc WithTimeout(parent Context, timeout time.Duration) (Context, CancelFunc)\nfunc WithValue(parent Context, key, val interface{}) Context\n上面可以看到 Context 是一个接口，想要使用就得实现其方法。在 context 包内部已经为我们实现好了两个空的 Context，可以通过调用 Background() 和TODO() 方法获取。一般的将它们作为 Context 的根，往下派生。\n使用\n创建 context\n使用之前提到的两个方法创建context:\n\ncontext.Backgroud()\ncontext.TODO()\n\n这两个函数其实只是互为别名，没有差别，官方给的定义是：\n\ncontext.Background 是上下文的默认值，所有其他的上下文都应该从它衍生（Derived）出来。\ncontext.TODO 应该只在不确定应该使用哪种上下文时使用；\n\n所以在大多数情况下，我们都使用context.Background作为起始的上下文向下传递；传递前通常需要使用另外四个函数进行衍生，而且可以继续在原本基础上派生。\nWithCancel  取消控制\n在完成一个复杂的需求会开多个gouroutine去处理逻辑，将导致无法准确控制他们，这时则可以使用withCancel来衍生一个context传递到不同的goroutine中，当想让这些goroutine停止运行，就可以调用cancel来进行取消：\nfunc WithCancel() {\n    ctx, cancel := context.WithCancel(context.Background())\n    go Speak(ctx)\n    time.Sleep(10 * time.Second)\n    cancel()\n    time.Sleep(1 * time.Second)\n}\n \nfunc Speak(ctx context.Context) {\n    for range time.Tick(time.Second) {\n        select {\n            case &lt;-ctx.Done():\n            fmt.Println(&quot;我要闭嘴了&quot;)\n            return\n            default:\n            fmt.Println(&quot;balabalabalabala&quot;)\n        }\n    }\n}\n延时 10s 内，不断打印 balabalabalabala，执行 cancel()之后，ctx.Done() 发出信号，返回；\n注意，因为 time.Tick(time.Second)是不断产生时刻 channel，如果这里不调用 return，会一直处于 ctx.Done() 状态，也就是一直打印 我要闭嘴了；\nWithValue 携带数据\n\n小白也能看懂的context包详解：从入门到精通 (qq.com)\n快速掌握 Golang context 包，简单示例 | Deepzz’s Blog\n深入理解Golang之context - 知乎 (zhihu.com)\n"},"golang/embed":{"title":"embed","links":[],"tags":[],"content":"embed 包及其使用详解\nembed是在Go 1.16中新加包。它通过***//go:embed***指令，可以在编译阶段将静态资源文件打包进编译好的程序中，并提供访问这些文件的能力。\n为什么需要 embed 包\n\n**部署过程更简单。**传统部署要么需要将静态资源与已编译程序打包在一起上传，或者使用docker和dockerfile自动化前者，这在精神上是很麻烦的。\n**确保程序的完整性。**在运行过程中损坏或丢失静态资源通常会影响程序的正常运行。\n您可以独立控制程序所需的静态资源。\n\n常用场景\n\nGo模板\n静态web服务\n数据库迁移\n\n基本使用\n三种数据类型\n在embed中，可以将静态资源文件嵌入到三种类型的变量，分别为：字符串、字节数组、embed.FS 文件类型。\npackage main\n \nimport (\n    _ &quot;embed&quot;\n    &quot;fmt&quot;\n)\n \n//go:embed version.txt\nvar version string\n \n//go:embed version.txt\nvar versionByte []byte\n \nfunc main() {\n    fmt.Printf(&quot;version %q\\n&quot;, version)\n}\n前两种文件类型比较简单，直接使用指令//go:embed 文件名 将对应的文件内容导入到变量中。\n第三种 embed.FS 文件类型，需要了解其3个对外方法：\n// Open 打开要读取的文件，并返回文件的fs.File结构.\nfunc (f FS) Open(name string) (fs.File, error)\n \n// ReadDir 读取并返回整个命名目录\nfunc (f FS) ReadDir(name string) ([]fs.DirEntry, error)\n \n// ReadFile 读取并返回文件的内容.\nfunc (f FS) ReadFile(name string) ([]byte, error)\n例如，在项目根目录下有如下静态资源目录结构：\n|-static\n|---js\n|------util.js\n|---img\n|------logo.jpg\n|---index.html\n\n以下代码中，通过 live 参数控制访问的文件系统，通过指令//go:embed static 将路径下的 static 绑定为 embededFiles，\npackage main\n \nimport (\n    &quot;embed&quot;\n    &quot;io/fs&quot;\n    &quot;log&quot;\n    &quot;net/http&quot;\n    &quot;os&quot;\n)\n \n \nfunc main() {\n    useOS := len(os.Args) &gt; 1 &amp;&amp; os.Args[1] == &quot;live&quot;\n    http.Handle(&quot;/&quot;, http.FileServer(getFileSystem(useOS)))\n    http.ListenAndServe(&quot;:8888&quot;, nil)\n}\n \n//go:embed static\nvar embededFiles embed.FS\n \nfunc getFileSystem(useOS bool) http.FileSystem {\n    if useOS {\n        log.Print(&quot;using live mode&quot;)\n        return http.FS(os.DirFS(&quot;static&quot;))\n    }\n \n    log.Print(&quot;using embed mode&quot;)\n \n    fsys, err := fs.Sub(embededFiles, &quot;static&quot;)\n    if err != nil {\n        panic(err)\n    }\n    return http.FS(fsys)\n}\n注意点\n\n\n在使用//go:embed指令的文件都需要导入 embed 包；\n\n\n//go:embed 指令只能用在包一级的变量；\n\n\n当包含目录时，它不会包含以“.”或“*“开头的文件。但是如果使用通配符，比如dir/\\*，它将包含所有匹配的文件，即使它们以“.”或”*”开头。\n\n"},"golang/function":{"title":"function","links":[],"tags":[],"content":"append\n用于在切片（slice）中追加元素，返回该切片；容量不足，底层会自动创建一个新的数组。"},"golang/goroutine":{"title":"goroutine","links":[],"tags":[],"content":"sync\n多个并发协程之间不需要通信，那么就可以使用 sync.WaitGroup完成并发任务：\nimport (\n\t&quot;fmt&quot;\n\t&quot;sync&quot;\n\t&quot;time&quot;\n)\n \nvar wg sync.WaitGroup\n \nfunc download(url string) {\n\tfmt.Println(&quot;start to download&quot;, url)\n\ttime.Sleep(time.Second) // 模拟耗时操作\n\twg.Done()\n}\n \nfunc main() {\n\tfor i := 0; i &lt; 3; i++ {\n\t\twg.Add(1)\n\t\tgo download(&quot;a.com/&quot; + string(i+&#039;0&#039;))\n\t}\n\twg.Wait()\n\tfmt.Println(&quot;Done!&quot;)\n}\n\nwg.Add(1)：为该 WaitGroup 添加一个计数，wg.Done()，减去一个计数；\ngo download()：启动新的协程并发执行 download 函数；\nwg.Wait()：等待所有的协程执行结束；\n\nchannel\n“"},"golang/interface":{"title":"interface","links":[],"tags":[],"content":"接口（interface）定义了一个对象的行为规范，只定义规范不实现，由具体的对象来实现规范的细节。\ninterface（接口）是一种较为常见的特性，很多语言都有接口特性。 Go语言的 interface 是非侵入式的，不像 Java 的 interface 实现需要显示的声明。\nGo语言提倡面向接口编程。\n接口类型\n在Go语言中接口（interface）是一种类型，一种抽象的类型。\ninterface是一组method的集合，接口做的事情就像是定义一个协议（规则），不关心对方是什么类型，只关心对方能做什么。这是duck-type programming的一种体现，只要一个物体能像鸭子一样叫那我们就可以称它为鸭子；只要一个软件能存储和查询数据我们就可以称它为数据库；只要一台机器有洗衣服和甩干的功能我们就可以称它为洗衣机。\n接口的定义\nGo语言中每个接口由数个方法（零个或多个）组成，接口的定义格式如下：\ntype 接口类型名 interface{\n    方法名1( 参数列表1 ) 返回值列表1\n    方法名2( 参数列表2 ) 返回值列表2\n    …\n}\n其中：\n\n接口名：使用type将接口定义为自定义的类型名。Go语言的接口在命名时，一般会在单词后面添加er，如有写操作的接口叫Writer，有字符串功能的接口叫Stringer等。接口名最好要能突出该接口的类型含义。\n方法名：当方法名首字母是大写且这个接口类型名首字母也是大写时，这个方法可以被接口所在的包（package）之外的代码访问。\n参数列表、返回值列表：参数列表和返回值列表中的参数变量名可以省略。\n\n实现接口的条件\n一个对象只要全部实现了接口中的方法，那么就实现了这个接口。换句话说，接口就是一个需要实现的方法列表。\n接口类型变量\n那实现了接口有什么用呢？\n声明一个接口类型的变量，其能够存储所有实现了该接口的实例。\n值接收者和指针接收者实现接口的区别\n使用值接收者实现接口和使用指针接收者实现接口有什么区别呢？接下来我们通过一个例子看一下其中的区别。\n我们有一个Mover接口和一个dog结构体。\ntype Mover interface {\n\tmove()\n}\n \ntype dog struct {}\n值接收者实现接口\nfunc (d dog) move() {\n\tfmt.Println(&quot;狗会动&quot;)\n}\n此时实现接口的是dog类型：\nfunc main() {\n\tvar x Mover\n\tvar wangcai = dog{} // 旺财是dog类型\n\tx = wangcai         // x可以接收dog类型\n\tvar fugui = &amp;dog{}  // 富贵是*dog类型\n\tx = fugui           // x可以接收*dog类型\n\tx.move()\n}\n从上面的代码中我们可以发现，使用值接收者（func (d dog)）实现接口之后，不管是 dog 结构体还是其结构体指针 *dog 类型的变量都可以赋值给该接口变量。\n因为Go语言中有对指针类型变量求值的语法糖，dog 指针fugui内部会自动求值*fugui。\n指针接收者实现接口\n同样的代码我们再来测试一下使用指针接收者有什么区别：\nfunc (d *dog) move() {\n\tfmt.Println(&quot;狗会动&quot;)\n}\nfunc main() {\n\tvar x Mover\n\tvar wangcai = dog{} // 旺财是dog类型\n\tx = wangcai         // x不可以接收dog类型\n\tvar fugui = &amp;dog{}  // 富贵是*dog类型\n\tx = fugui           // x可以接收*dog类型\n}\n此时实现Mover接口的是*dog类型，所以不能给x传入dog类型的 wangcai，此时 x 只能存储*dog类型的值。\n类型与接口的关系\n一个类型实现多个接口\n一个类型可以同时实现多个接口，而接口间彼此独立，不知道对方的实现。 例如，狗可以叫，也可以动。我们就分别定义Sayer 接口和 Mover 接口：\n// Sayer 接口\ntype Sayer interface {\n\tsay()\n}\n \n// Mover 接口\ntype Mover interface {\n\tmove()\n}\ndog 既可以实现 Sayer 接口，也可以实现 Mover 接口。\n多个类型实现同一接口\nGo语言中不同的类型还可以实现同一接口 首先我们定义一个Mover接口，它要求必须有一个move方法。并且一个接口的方法，不一定需要由一个类型完全实现，接口的方法可以通过在类型中嵌入其他类型或者结构体来实现。\n接口嵌套\n接口与接口间可以通过嵌套创造出新的接口。\n// Sayer 接口\ntype Sayer interface {\n\tsay()\n}\n \n// Mover 接口\ntype Mover interface {\n\tmove()\n}\n \n// 接口嵌套\ntype animal interface {\n\tSayer\n\tMover\n}\n空接口\nGo语言中接口分为两种类型，分别是包含一组的方法的接口和空接口。在src/runtime/runtime2.go文件中分别使用iface和eface两个结构体来描述。\n空接口的定义\n空接口是指没有定义任何方法的接口。因此任何类型都实现了空接口。类似 Java 中的 Object 类。\n空接口类型的变量可以存储任意类型的变量。\n空接口的应用\n空接口作为函数的参数\n使用空接口实现可以接收任意类型的函数参数。\n// 空接口作为函数参数\nfunc show(a interface{}) {\n\tfmt.Printf(&quot;type:%T value:%v\\n&quot;, a, a)\n}\n空接口作为map的值\n使用空接口实现可以保存任意值的字典。\n// 空接口作为map值\nvar studentInfo = make(map[string]interface{})\nstudentInfo[&quot;name&quot;] = &quot;娃哈哈&quot;\nstudentInfo[&quot;age&quot;] = 18\nstudentInfo[&quot;married&quot;] = false\nfmt.Println(studentInfo)\n类型断言\n空接口可以存储任意类型的值，那我们如何获取其存储的具体数据呢？\n接口值\n一个接口的值（简称接口值）是由一个具体类型和具体类型的值两部分组成的。这两部分分别称为接口的动态类型和动态值。\n我们来看一个具体的例子：\nvar w io.Writer\nw = os.Stdout\nw = new(bytes.Buffer)\nw = nil\n想要判断空接口中的值这个时候就可以使用类型断言，其语法格式：\nx.(T)\n其中：\n\nx：表示类型为interface{}的变量\nT：表示断言x可能是的类型。\n\n该语法返回两个值，第一个是x转化为T类型后的变量，第二个值是一个布尔值，若为true则表示断言成功，为false则表示断言失败。\nfunc main() {\n\tvar x interface{}\n\tx = &quot;Hello&quot;\n\tv, ok := x.(string)\n\tif ok {\n\t\tfmt.Println(v)\n\t} else {\n\t\tfmt.Println(&quot;类型断言失败&quot;)\n\t}\n}\n接口的底层原理\ntype iface struct {\n\ttab  *itab\n\tdata unsafe.Pointer\n}\n \ntype itab struct {\n\tinter *interfacetype // 接口定义的类型信息\n\t_type *_type \t\t// 接口实际指向值得类型信息\n\thash  uint32 \t\t// copy of _type.hash. Used for type switches.\n\t_     [4]byte\n\tfun   [1]uintptr \t// 接口方法实现列表，即函数地址列表，按字典序排序\n}\n \ntype eface struct {\n\t_type *_type \t\t// 类型\n\tdata  unsafe.Pointer // 底层数据的指针\n}\n \ntype _type struct {\n\tsize       uintptr  // 存储了类型需要占用的内存空间，主要在初始化时内存分配使用\n\tptrdata    uintptr \t// size of memory prefix holding all pointers\n\thash       uint32 \t// 用于判断类型相等\n\ttflag      tflag \t// 类型的 Tags\n\talign      uint8 \t// 结构体内对齐\n\tfieldAlign uint8 \t// 结构体作为 field 时的对齐\n\tkind       uint8 \t// 类型编号，定义域 runtime/typekind.go\n\t// function for comparing objects of this type\n\t// (ptr to object A, ptr to object B) -&gt; ==?\n\tequal func(unsafe.Pointer, unsafe.Pointer) bool\n\t// gcdata stores the GC type data for the garbage collector.\n\t// If the KindGCProg bit is set in kind, gcdata is a GC program.\n\t// Otherwise it is a ptrmask bitmap. See mbitmap.go for details.\n\tgcdata    *byte\n\tstr       nameOff\n\tptrToThis typeOff\n    \n    // nameOff 和 typeOff 类型是 int32 ，这两个值是链接器负责嵌入的，相对于可执行文件的元信息的偏移量。\n    // 元信息会在运行期，加载到 runtime.moduledata 结构体中 (src/runtime/symtab.go)。\n    // runtime 提供了一些 helper 函数，这些函数能够帮你找到相对于 moduledata 的偏移量，比如 resolveNameOff \n    // (src/runtime/type.go) and resolveTypeOff (src/runtime/type.go)\n}\niface 和 eface 都是用 interface 声明。但是由于空接口在Go语言中非常常见，所以使用特殊类型实现。\n_type 结构体相对较为简单，并没有太多可说之处；itab除了 _type 字段外多了 interfacetype。\n_interfacetype 从字面上来说可以轻易得知它代表的是当前的接口类型，那么 _type 对应的则必然是接口所指向值的类型信息，\nhash 则是 _type.hash 的拷贝，fun 数组持有组成该 interface 虚函数表的函数的指针，所以 fun 数组保存的元素数量和具体类型相关联而无法设置成固定大小。\ntype interfacetype struct {\n\ttyp     _type\n\tpkgpath name\n\tmhdr    []imethod\n}\n \ntype imethod struct {\n\tname nameOff\n\tityp typeOff\n}\ninterfacetype 定义于src/runtime/type.go文件中，由三个字段组成，除了 typ 这个Go语言类型的 runtime 表示，还有pkgpath 和 mhdr 两个字段，其主要作用就是 interface 的公共描述，类似的还有 maptype、arraytype、chantype 等，这些都在 type.go 文件中由定义，可以理解成 Go语言类型的 runtime 外在的表现信息。\n变量是如何转变成 interface 的\n在上一部分内容中我们已经了解了interface的数据结构，接下来让我们通过下面的代码来了解它们时如何被初始化的\nfunc main(){\n\tvar temp myinterface = MyStruct{ID:1}\n\ttemp.Func1()\n \n}\ntype myinterface interface {\n\tFunc1() string\n\tFunc2() string\n}\n \ntype MyStruct struct {\n\tID int64\n\tptr *int64\n}\n//go:noinline\nfunc (m MyStruct) Func1() string {\n\treturn fmt.Sprintf(&quot;Func1 implement&quot;)\n}\n//go:noinline\nfunc (m MyStruct) Func2() string {\n\treturn fmt.Sprintf(&quot;Func2 implement&quot;)\n}\n使用 go tool compile -N -S -l test.go 查看生成的汇编代码。在此我们只需要关心 var temp myinterface = MyStruct{ID:1} 这一行代码的细节，其他暂时忽略。生成的汇编代码如下\n0x0024 00036 (test.go:8)        PCDATA  $0, $0\n        0x0024 00036 (test.go:8)        PCDATA  $1, $1\n        0x0024 00036 (test.go:8)        XORPS   X0, X0\n        0x0027 00039 (test.go:8)        MOVUPS  X0, &quot;&quot;..autotmp_1+48(SP)\n        0x002c 00044 (test.go:8)        MOVQ    $1, &quot;&quot;..autotmp_1+48(SP)\n        0x0035 00053 (test.go:8)        PCDATA  $0, $1\n        0x0035 00053 (test.go:8)        LEAQ    go.itab.&quot;&quot;.MyStruct,&quot;&quot;.myinterface(SB), AX\n        0x003c 00060 (test.go:8)        PCDATA  $0, $0\n        0x003c 00060 (test.go:8)        MOVQ    AX, (SP)\n        0x0040 00064 (test.go:8)        PCDATA  $0, $1\n        0x0040 00064 (test.go:8)        PCDATA  $1, $0\n        0x0040 00064 (test.go:8)        LEAQ    &quot;&quot;..autotmp_1+48(SP), AX\n        0x0045 00069 (test.go:8)        PCDATA  $0, $0\n        0x0045 00069 (test.go:8)        MOVQ    AX, 8(SP)\n        0x004a 00074 (test.go:8)        CALL    runtime.convT2I(SB)\n        0x004f 00079 (test.go:8)        PCDATA  $0, $1\n        0x004f 00079 (test.go:8)        MOVQ    24(SP), AX\n        0x0054 00084 (test.go:8)        MOVQ    16(SP), CX\n        0x0059 00089 (test.go:8)        PCDATA  $1, $2\n        0x0059 00089 (test.go:8)        MOVQ    CX, &quot;&quot;.temp+32(SP)\n        0x005e 00094 (test.go:8)        PCDATA  $0, $0\n        0x005e 00094 (test.go:8)        MOVQ    AX, &quot;&quot;.temp+40(SP)\n \n将上述过程分成三个部分\n1. 分配空间\nMOVQ    $1, &quot;&quot;..autotmp_1+48(SP)\n...\nLEAQ    &quot;&quot;..autotmp_1+48(SP), AX\nMOVQ    AX, 8(SP)\n$1 对应的是 MyStruct 的 ID，被存储在当前栈帧的自底向上+48偏移量的位置,。后续编译器可以根据它的存储位置来用地址对其进行引用。\n2. 创建 itab\nLEAQ    go.itab.&quot;&quot;.MyStruct,&quot;&quot;.myinterface(SB), AX\nMOVQ    AX, (SP)\n看上去编译器已经为提前创建了必需的 itab 来表示 iface，并且通过全局符号提供给我们使用。编译器这么做的原因不言而喻，毕竟不管在运行时创建了多少 iface&lt;myinterface,MyStruct&gt;，只需要一个 itab，从 itab 内的定义也可以看出其并不会和运行时所初始化的变量由任何关系。 在本文中并不会继续深入了解 go.itab.&quot;&quot;.MyStruct,&quot;&quot;.myinterface符号 ，感兴趣的同学看这篇文章 ，非常的深入细致\n3. 分配数据\nCALL    runtime.convT2I(SB)\nMOVQ    24(SP), AX\nMOVQ    16(SP), CX\n在1、2中我们看到了解到目前栈顶（SP）保存着 go.itab.&quot;&quot;.MyStruct,&quot;&quot;.myinterface 的地址，8(sp) 则保存着变量的地址。上面两个指针会作为参数传给 convT2I 函数，此函数会创建并返回 interface。 src/runtime/iface.go\nfunc convT2I(tab *itab, elem unsafe.Pointer) (i iface) {\n\tt := tab._type\n\tif raceenabled {\n\t\traceReadObjectPC(t, elem, getcallerpc(), funcPC(convT2I))\n\t}\n\tif msanenabled {\n\t\tmsanread(elem, t.size)\n\t}\n\tx := mallocgc(t.size, t, true)\n\ttypedmemmove(t, x, elem)\n\ti.tab = tab\n\ti.data = x\n\treturn\n}\n上述代码做了4件事情：\n\n它创建了一个 iface 的结构体 i。\n它将我们刚给 i.tab 赋的值赋予了 itab 指针。\n它在堆上分配了一个 i.tab._type 的新对象 i.tab._type，然后将第二个参数 elem 指向的值拷贝到这个新对象上。\n将最后的 interface 返回。 现在我们终于得到了完整的 interface\n\n动态派发实现\n下面是第一行实例化的汇编代码\nMOVQ    $1, &quot;&quot;..autotmp_1+48(SP)\nLEAQ    go.itab.&quot;&quot;.MyStruct,&quot;&quot;.myinterface(SB), AX\nMOVQ    AX, (SP)\nLEAQ    &quot;&quot;..autotmp_1+48(SP), AX\nMOVQ    AX, 8(SP)\nCALL    runtime.convT2I(SB)\nMOVQ    24(SP), AX\nMOVQ    16(SP), CX\nMOVQ    CX, &quot;&quot;.temp+32(SP)\nMOVQ    AX, &quot;&quot;.temp+40(SP)\n接着是对方法间接调用的汇编代码\nMOVQ    &quot;&quot;.temp+32(SP), AX\nMOVQ    24(AX), AX\nMOVQ    &quot;&quot;.temp+40(SP), CX\nMOVQ    CX, (SP)\nCALL    AX\nAX中保存的是itab的指针,实际上是指向go.itab.&quot;&quot;.MyStruct,&quot;&quot;.myinterface的指针.对其解饮用并offset 24个字节,上面itab的结构体定义我们可以得知此时指向的itab.fun . 并且我们已经知道了fun[0]实际上指向的是main.(MyStruct).Func1的指针. 因为方法本身没有参数,所以在入参的时候只需要传入receiver,并通过CALL指令即可完成函数调用.\n如果我们修改代码为如下形式\ntemp.Func2()\n这是再查看汇编代码,则和最初的有所不同\nMOVQ    &quot;&quot;.temp+32(SP), AX\nMOVQ    32(AX), AX\nMOVQ    &quot;&quot;.temp+40(SP), CX\nMOVQ    CX, (SP)\nCALL    AX\n轻易可以得知其获取到的函数指针相对第一次的增加了8字节的偏移,这个很容易理解,因为上面提到过fun字段是接口方法实现列表是按照字典序排序的.\n\n《Go语言原来这么简单》 — 接口 - 掘金 (juejin.cn)\n深入理解golang中的接口 - 掘金 (juejin.cn)\n"},"golang/interface/interface":{"title":"interface","links":[],"tags":[],"content":"接口（interface）定义了一个对象的行为规范，只定义规范不实现，由具体的对象来实现规范的细节。\ninterface（接口）是一种较为常见的特性，很多语言都有接口特性。 Go语言的 interface 是非侵入式的，不像 Java 的 interface 实现需要显示的声明。\nGo语言提倡面向接口编程。\n接口类型\n在Go语言中接口（interface）是一种类型，一种抽象的类型。\ninterface是一组method的集合，接口做的事情就像是定义一个协议（规则），不关心对方是什么类型，只关心对方能做什么。这是duck-type programming的一种体现，只要一个物体能像鸭子一样叫那我们就可以称它为鸭子；只要一个软件能存储和查询数据我们就可以称它为数据库；只要一台机器有洗衣服和甩干的功能我们就可以称它为洗衣机。\n接口的定义\nGo语言中每个接口由数个方法（零个或多个）组成，接口的定义格式如下：\ntype 接口类型名 interface{\n    方法名1( 参数列表1 ) 返回值列表1\n    方法名2( 参数列表2 ) 返回值列表2\n    …\n}\n其中：\n\n接口名：使用type将接口定义为自定义的类型名。Go语言的接口在命名时，一般会在单词后面添加er，如有写操作的接口叫Writer，有字符串功能的接口叫Stringer等。接口名最好要能突出该接口的类型含义。\n方法名：当方法名首字母是大写且这个接口类型名首字母也是大写时，这个方法可以被接口所在的包（package）之外的代码访问。\n参数列表、返回值列表：参数列表和返回值列表中的参数变量名可以省略。\n\n实现接口的条件\n一个对象只要全部实现了接口中的方法，那么就实现了这个接口。换句话说，接口就是一个需要实现的方法列表。\n接口类型变量\n那实现了接口有什么用呢？\n声明一个接口类型的变量，其能够存储所有实现了该接口的实例。\n值接收者和指针接收者实现接口的区别\n使用值接收者实现接口和使用指针接收者实现接口有什么区别呢？接下来我们通过一个例子看一下其中的区别。\n我们有一个Mover接口和一个dog结构体。\ntype Mover interface {\n\tmove()\n}\n \ntype dog struct {}\n值接收者实现接口\nfunc (d dog) move() {\n\tfmt.Println(&quot;狗会动&quot;)\n}\n此时实现接口的是dog类型：\nfunc main() {\n\tvar x Mover\n\tvar wangcai = dog{} // 旺财是dog类型\n\tx = wangcai         // x可以接收dog类型\n\tvar fugui = &amp;dog{}  // 富贵是*dog类型\n\tx = fugui           // x可以接收*dog类型\n\tx.move()\n}\n从上面的代码中我们可以发现，使用值接收者（func (d dog)）实现接口之后，不管是 dog 结构体还是其结构体指针 *dog 类型的变量都可以赋值给该接口变量。\n因为Go语言中有对指针类型变量求值的语法糖，dog 指针fugui内部会自动求值*fugui。\n指针接收者实现接口\n同样的代码我们再来测试一下使用指针接收者有什么区别：\nfunc (d *dog) move() {\n\tfmt.Println(&quot;狗会动&quot;)\n}\nfunc main() {\n\tvar x Mover\n\tvar wangcai = dog{} // 旺财是dog类型\n\tx = wangcai         // x不可以接收dog类型\n\tvar fugui = &amp;dog{}  // 富贵是*dog类型\n\tx = fugui           // x可以接收*dog类型\n}\n此时实现Mover接口的是*dog类型，所以不能给x传入dog类型的 wangcai，此时 x 只能存储*dog类型的值。\n类型与接口的关系\n一个类型实现多个接口\n一个类型可以同时实现多个接口，而接口间彼此独立，不知道对方的实现。 例如，狗可以叫，也可以动。我们就分别定义Sayer 接口和 Mover 接口：\n// Sayer 接口\ntype Sayer interface {\n\tsay()\n}\n \n// Mover 接口\ntype Mover interface {\n\tmove()\n}\ndog 既可以实现 Sayer 接口，也可以实现 Mover 接口。\n多个类型实现同一接口\nGo语言中不同的类型还可以实现同一接口 首先我们定义一个Mover接口，它要求必须有一个move方法。并且一个接口的方法，不一定需要由一个类型完全实现，接口的方法可以通过在类型中嵌入其他类型或者结构体来实现。\n接口嵌套\n接口与接口间可以通过嵌套创造出新的接口。\n// Sayer 接口\ntype Sayer interface {\n\tsay()\n}\n \n// Mover 接口\ntype Mover interface {\n\tmove()\n}\n \n// 接口嵌套\ntype animal interface {\n\tSayer\n\tMover\n}\n空接口\nGo语言中接口分为两种类型，分别是包含一组的方法的接口和空接口。在src/runtime/runtime2.go文件中分别使用iface和eface两个结构体来描述。\n空接口的定义\n空接口是指没有定义任何方法的接口。因此任何类型都实现了空接口。类似 Java 中的 Object 类。\n空接口类型的变量可以存储任意类型的变量。\n空接口的应用\n空接口作为函数的参数\n使用空接口实现可以接收任意类型的函数参数。\n// 空接口作为函数参数\nfunc show(a interface{}) {\n\tfmt.Printf(&quot;type:%T value:%v\\n&quot;, a, a)\n}\n空接口作为map的值\n使用空接口实现可以保存任意值的字典。\n// 空接口作为map值\nvar studentInfo = make(map[string]interface{})\nstudentInfo[&quot;name&quot;] = &quot;娃哈哈&quot;\nstudentInfo[&quot;age&quot;] = 18\nstudentInfo[&quot;married&quot;] = false\nfmt.Println(studentInfo)\n类型断言\n空接口可以存储任意类型的值，那我们如何获取其存储的具体数据呢？\n接口值\n一个接口的值（简称接口值）是由一个具体类型和具体类型的值两部分组成的。这两部分分别称为接口的动态类型和动态值。\n我们来看一个具体的例子：\nvar w io.Writer\nw = os.Stdout\nw = new(bytes.Buffer)\nw = nil\n想要判断空接口中的值这个时候就可以使用类型断言，其语法格式：\nx.(T)\n其中：\n\nx：表示类型为interface{}的变量\nT：表示断言x可能是的类型。\n\n该语法返回两个值，第一个是x转化为T类型后的变量，第二个值是一个布尔值，若为true则表示断言成功，为false则表示断言失败。\nfunc main() {\n\tvar x interface{}\n\tx = &quot;Hello&quot;\n\tv, ok := x.(string)\n\tif ok {\n\t\tfmt.Println(v)\n\t} else {\n\t\tfmt.Println(&quot;类型断言失败&quot;)\n\t}\n}\n接口的底层原理\ntype iface struct {\n\ttab  *itab\n\tdata unsafe.Pointer\n}\n \ntype itab struct {\n\tinter *interfacetype // 接口定义的类型信息\n\t_type *_type \t\t// 接口实际指向值得类型信息\n\thash  uint32 \t\t// copy of _type.hash. Used for type switches.\n\t_     [4]byte\n\tfun   [1]uintptr \t// 接口方法实现列表，即函数地址列表，按字典序排序\n}\n \ntype eface struct {\n\t_type *_type \t\t// 类型\n\tdata  unsafe.Pointer // 底层数据的指针\n}\n \ntype _type struct {\n\tsize       uintptr  // 存储了类型需要占用的内存空间，主要在初始化时内存分配使用\n\tptrdata    uintptr \t// size of memory prefix holding all pointers\n\thash       uint32 \t// 用于判断类型相等\n\ttflag      tflag \t// 类型的 Tags\n\talign      uint8 \t// 结构体内对齐\n\tfieldAlign uint8 \t// 结构体作为 field 时的对齐\n\tkind       uint8 \t// 类型编号，定义域 runtime/typekind.go\n\t// function for comparing objects of this type\n\t// (ptr to object A, ptr to object B) -&gt; ==?\n\tequal func(unsafe.Pointer, unsafe.Pointer) bool\n\t// gcdata stores the GC type data for the garbage collector.\n\t// If the KindGCProg bit is set in kind, gcdata is a GC program.\n\t// Otherwise it is a ptrmask bitmap. See mbitmap.go for details.\n\tgcdata    *byte\n\tstr       nameOff\n\tptrToThis typeOff\n    \n    // nameOff 和 typeOff 类型是 int32 ，这两个值是链接器负责嵌入的，相对于可执行文件的元信息的偏移量。\n    // 元信息会在运行期，加载到 runtime.moduledata 结构体中 (src/runtime/symtab.go)。\n    // runtime 提供了一些 helper 函数，这些函数能够帮你找到相对于 moduledata 的偏移量，比如 resolveNameOff \n    // (src/runtime/type.go) and resolveTypeOff (src/runtime/type.go)\n}\niface 和 eface 都是用 interface 声明。但是由于空接口在Go语言中非常常见，所以使用特殊类型实现。\n_type 结构体相对较为简单，并没有太多可说之处；itab除了 _type 字段外多了 interfacetype。\n_interfacetype 从字面上来说可以轻易得知它代表的是当前的接口类型，那么 _type 对应的则必然是接口所指向值的类型信息，\nhash 则是 _type.hash 的拷贝，fun 数组持有组成该 interface 虚函数表的函数的指针，所以 fun 数组保存的元素数量和具体类型相关联而无法设置成固定大小。\ntype interfacetype struct {\n\ttyp     _type\n\tpkgpath name\n\tmhdr    []imethod\n}\n \ntype imethod struct {\n\tname nameOff\n\tityp typeOff\n}\ninterfacetype 定义于src/runtime/type.go文件中，由三个字段组成，除了 typ 这个Go语言类型的 runtime 表示，还有pkgpath 和 mhdr 两个字段，其主要作用就是 interface 的公共描述，类似的还有 maptype、arraytype、chantype 等，这些都在 type.go 文件中由定义，可以理解成 Go语言类型的 runtime 外在的表现信息。\n变量是如何转变成 interface 的\n在上一部分内容中我们已经了解了interface的数据结构，接下来让我们通过下面的代码来了解它们时如何被初始化的\nfunc main(){\n\tvar temp myinterface = MyStruct{ID:1}\n\ttemp.Func1()\n \n}\ntype myinterface interface {\n\tFunc1() string\n\tFunc2() string\n}\n \ntype MyStruct struct {\n\tID int64\n\tptr *int64\n}\n//go:noinline\nfunc (m MyStruct) Func1() string {\n\treturn fmt.Sprintf(&quot;Func1 implement&quot;)\n}\n//go:noinline\nfunc (m MyStruct) Func2() string {\n\treturn fmt.Sprintf(&quot;Func2 implement&quot;)\n}\n使用 go tool compile -N -S -l test.go 查看生成的汇编代码。在此我们只需要关心 var temp myinterface = MyStruct{ID:1} 这一行代码的细节，其他暂时忽略。生成的汇编代码如下\n0x0024 00036 (test.go:8)        PCDATA  $0, $0\n        0x0024 00036 (test.go:8)        PCDATA  $1, $1\n        0x0024 00036 (test.go:8)        XORPS   X0, X0\n        0x0027 00039 (test.go:8)        MOVUPS  X0, &quot;&quot;..autotmp_1+48(SP)\n        0x002c 00044 (test.go:8)        MOVQ    $1, &quot;&quot;..autotmp_1+48(SP)\n        0x0035 00053 (test.go:8)        PCDATA  $0, $1\n        0x0035 00053 (test.go:8)        LEAQ    go.itab.&quot;&quot;.MyStruct,&quot;&quot;.myinterface(SB), AX\n        0x003c 00060 (test.go:8)        PCDATA  $0, $0\n        0x003c 00060 (test.go:8)        MOVQ    AX, (SP)\n        0x0040 00064 (test.go:8)        PCDATA  $0, $1\n        0x0040 00064 (test.go:8)        PCDATA  $1, $0\n        0x0040 00064 (test.go:8)        LEAQ    &quot;&quot;..autotmp_1+48(SP), AX\n        0x0045 00069 (test.go:8)        PCDATA  $0, $0\n        0x0045 00069 (test.go:8)        MOVQ    AX, 8(SP)\n        0x004a 00074 (test.go:8)        CALL    runtime.convT2I(SB)\n        0x004f 00079 (test.go:8)        PCDATA  $0, $1\n        0x004f 00079 (test.go:8)        MOVQ    24(SP), AX\n        0x0054 00084 (test.go:8)        MOVQ    16(SP), CX\n        0x0059 00089 (test.go:8)        PCDATA  $1, $2\n        0x0059 00089 (test.go:8)        MOVQ    CX, &quot;&quot;.temp+32(SP)\n        0x005e 00094 (test.go:8)        PCDATA  $0, $0\n        0x005e 00094 (test.go:8)        MOVQ    AX, &quot;&quot;.temp+40(SP)\n \n将上述过程分成三个部分\n1. 分配空间\nMOVQ    $1, &quot;&quot;..autotmp_1+48(SP)\n...\nLEAQ    &quot;&quot;..autotmp_1+48(SP), AX\nMOVQ    AX, 8(SP)\n$1 对应的是 MyStruct 的 ID，被存储在当前栈帧的自底向上+48偏移量的位置,。后续编译器可以根据它的存储位置来用地址对其进行引用。\n2. 创建 itab\nLEAQ    go.itab.&quot;&quot;.MyStruct,&quot;&quot;.myinterface(SB), AX\nMOVQ    AX, (SP)\n看上去编译器已经为提前创建了必需的 itab 来表示 iface，并且通过全局符号提供给我们使用。编译器这么做的原因不言而喻，毕竟不管在运行时创建了多少 iface&lt;myinterface,MyStruct&gt;，只需要一个 itab，从 itab 内的定义也可以看出其并不会和运行时所初始化的变量由任何关系。 在本文中并不会继续深入了解 go.itab.&quot;&quot;.MyStruct,&quot;&quot;.myinterface符号 ，感兴趣的同学看这篇文章 ，非常的深入细致\n3. 分配数据\nCALL    runtime.convT2I(SB)\nMOVQ    24(SP), AX\nMOVQ    16(SP), CX\n在1、2中我们看到了解到目前栈顶（SP）保存着 go.itab.&quot;&quot;.MyStruct,&quot;&quot;.myinterface 的地址，8(sp) 则保存着变量的地址。上面两个指针会作为参数传给 convT2I 函数，此函数会创建并返回 interface。 src/runtime/iface.go\nfunc convT2I(tab *itab, elem unsafe.Pointer) (i iface) {\n\tt := tab._type\n\tif raceenabled {\n\t\traceReadObjectPC(t, elem, getcallerpc(), funcPC(convT2I))\n\t}\n\tif msanenabled {\n\t\tmsanread(elem, t.size)\n\t}\n\tx := mallocgc(t.size, t, true)\n\ttypedmemmove(t, x, elem)\n\ti.tab = tab\n\ti.data = x\n\treturn\n}\n上述代码做了4件事情：\n\n它创建了一个 iface 的结构体 i。\n它将我们刚给 i.tab 赋的值赋予了 itab 指针。\n它在堆上分配了一个 i.tab._type 的新对象 i.tab._type，然后将第二个参数 elem 指向的值拷贝到这个新对象上。\n将最后的 interface 返回。 现在我们终于得到了完整的 interface\n\n动态派发实现\n下面是第一行实例化的汇编代码\nMOVQ    $1, &quot;&quot;..autotmp_1+48(SP)\nLEAQ    go.itab.&quot;&quot;.MyStruct,&quot;&quot;.myinterface(SB), AX\nMOVQ    AX, (SP)\nLEAQ    &quot;&quot;..autotmp_1+48(SP), AX\nMOVQ    AX, 8(SP)\nCALL    runtime.convT2I(SB)\nMOVQ    24(SP), AX\nMOVQ    16(SP), CX\nMOVQ    CX, &quot;&quot;.temp+32(SP)\nMOVQ    AX, &quot;&quot;.temp+40(SP)\n接着是对方法间接调用的汇编代码\nMOVQ    &quot;&quot;.temp+32(SP), AX\nMOVQ    24(AX), AX\nMOVQ    &quot;&quot;.temp+40(SP), CX\nMOVQ    CX, (SP)\nCALL    AX\nAX中保存的是itab的指针,实际上是指向go.itab.&quot;&quot;.MyStruct,&quot;&quot;.myinterface的指针.对其解饮用并offset 24个字节,上面itab的结构体定义我们可以得知此时指向的itab.fun . 并且我们已经知道了fun[0]实际上指向的是main.(MyStruct).Func1的指针. 因为方法本身没有参数,所以在入参的时候只需要传入receiver,并通过CALL指令即可完成函数调用.\n如果我们修改代码为如下形式\ntemp.Func2()\n这是再查看汇编代码,则和最初的有所不同\nMOVQ    &quot;&quot;.temp+32(SP), AX\nMOVQ    32(AX), AX\nMOVQ    &quot;&quot;.temp+40(SP), CX\nMOVQ    CX, (SP)\nCALL    AX\n轻易可以得知其获取到的函数指针相对第一次的增加了8字节的偏移,这个很容易理解,因为上面提到过fun字段是接口方法实现列表是按照字典序排序的.\n\n《Go语言原来这么简单》 — 接口 - 掘金 (juejin.cn)\n深入理解golang中的接口 - 掘金 (juejin.cn)\n"},"golang/logger":{"title":"logger","links":[],"tags":[],"content":"在日常开发中，日志是必不可少的功能。虽然有时可以用fmt库输出一些信息，但是灵活性不够。Go 标准库提供了一个日志库log。\n使用\nlog 包定义了 Logger 类型，该类型提供了一些格式化输出的方法。也提供了一个预定义的 “标准” logger，名为std，即标准日志；可以通过调用函数Print系列(Print|Printf|Println）、Fatal系列（Fatal|Fatalf|Fatalln）、和Panic系列（Panic|Panicf|Panicln）来使用，比自行创建一个 logger 对象更容易使用。\n\nPrint/Printf/Println：正常输出日志；\n\n\nPanic/Panicf/Panicln：输出日志后，以拼装好的字符串为参数调用panic；\nFatal/Fatalf/Fatalln：输出日志后，调用os.Exit(1)退出程序。\n\n配置\n默认情况下的logger只会提供日志的时间信息，但是很多情况下我们希望得到更多信息，比如记录该日志的文件名和行号等。log标准库中为我们提供了定制这些设置的方法。\n\n\nlog.SetPrefix为每条日志文本前增加一个前缀，调用log.Prefix可以获取当前设置的前缀；\n\n\nlog.SetFlags函数用来设置标准 logger 的输出配置，Flags函数返回当前配置；\nconst (\n    Ldate         = 1 &lt;&lt; iota     // 日期：2009/01/23\n    Ltime                         // 时间：01:23:23\n    Lmicroseconds                 // 微秒级别的时间：01:23:23.123123（用于增强Ltime位）\n    Llongfile                     // 文件全路径名+行号： /a/b/c/d.go:23\n    Lshortfile                    // 文件名+行号：d.go:23（会覆盖掉Llongfile）\n    LUTC                          // 使用UTC时间\n    LstdFlags     = Ldate | Ltime // 标准logger的初始值\n)\n\n\nlog.SetOutput 用来设置标准 logger 的输出，默认输出到标准错误（stderr）。\n\n\n使用标准的 logger 时，我们通常会把上面的配置操作写到init函数中；\n自定义\nlog标准库中还提供了一个创建新logger对象的构造函数–New，用于自定义 logger 对象：\nfunc New(out io.Writer, prefix string, flag int) *Logger\nlog.New接受三个参数：\n\nio.Writer：日志都会写到这个Writer中；\nprefix：前缀，也可以之后调用logger.SetPrefix设置；\nflag：选项，也可以之后调用logger.SetFlag设置。\n\n注意到，第一个参数为io.Writer，我们可以使用io.MultiWriter实现多目的地输出：\nwriter1 := &amp;bytes.Buffer{}\nwriter2 := os.Stdout\nwriter3, err := os.OpenFile(&quot;log.txt&quot;, os.O_WRONLY|os.O_CREATE, 0755)\n \nlogger := log.New(io.MultiWriter(writer1, writer2, writer3), &quot;&quot;, log.Lshortfile|log.LstdFlags)\n实现\n实现\nlog库的核心是Output方法，我们简单看一下：\n// src/log/log.go \nfunc (l *Logger) Output(calldepth int, s string) error {  \n    now := time.Now() // get this early.  \n    var file string  \n    var line int\n    // 加锁，保证多goroutine下的安全\n    l.mu.Lock()  \n    defer l.mu.Unlock()\n    // 如果配置了获取文件和行号的话\n    if l.flag&amp;(Lshortfile|Llongfile) != 0 {    \n        // Release lock while getting caller info - it&#039;s expensive.    \n        l.mu.Unlock()   \n        var ok bool    \n        _, file, line, ok = runtime.Caller(calldepth)    \n        if !ok {     \n            file = &quot;???&quot;      \n            line = 0    \n        } \n        // 获取到行号等信息后，再加锁，保证安全\n        l.mu.Lock()  \n    }  \n    // 把日志信息和设置的日志抬头进行拼接\n    l.buf = l.buf[:0]  \n    l.formatHeader(&amp;l.buf, now, file, line)  \n    l.buf = append(l.buf, s...)  \n    if len(s) == 0 || s[len(s)-1] != &#039;\\n&#039; {    \n        l.buf = append(l.buf, &#039;\\n&#039;)  \n    }  \n    _, err := l.out.Write(l.buf)  \n    return err \n} \n如果设置了Lshortfile或Llongfile，Ouput方法中会调用runtime.Caller获取文件名和行号。runtime.Caller的参数calldepth表示获取调用栈向上多少层的信息，当前层为 0。\n一般的调用路径是：\n\n程序中使用log.Printf之类的函数；\n在log.Printf内调用std.Output。\n\n我们在Output方法中需要获取调用log.Printf的文件和行号。 calldepth传入 0 表示Output方法内调用runtime.Caller的那一行信息，传入 1 表示log.Printf内调用std.Output那一行的信息， 传入 2 表示程序中调用log.Printf的那一行信息。显然这里要用 2。\n然后调用formatHeader处理前缀和选项。\n最后将生成的字节流写入到Writer中。\n这里有两个优化技巧：\n\n由于runtime.Caller调用比较耗时，先释放锁，避免等待时间过长；\n为了避免频繁的内存分配，logger中保存了一个类型为[]byte的buf，可重复使用。前缀和日志内容先写到这个buf中，然后统一写入Writer，减少 io 操作。\n\n\nGo 每日一库之 log - 大俊的博客 (darjun.github.io)\nGo语言标准库之log - 二十三岁的有德 - 博客园 (cnblogs.com)\nGo语言实战笔记（十八）| Go log 日志\n"},"golang/module":{"title":"module","links":[],"tags":[],"content":"GOPATH\n在 Go 1.5 版本之前，go get 安装的所有依赖都是按照模块路径，存放在 $GOPATH/src 下，没有版本控制。\ngo vendor\nGo 1.5 版本推出了 vendor 机制，即在项目根目录创建 vendor 目录，用于放置该项目依赖；\n该命令只是将当前项目在$GOPATH下引用的依赖，复制到  vendor 目录，并使用vendor/vendor.json 进行管理；\n通常是应用工程（包含main.go）会使用 govendor，也就是离线保存第三方依赖，需要将  vendor 目录也包含进版本管理；\ngo build 的时候会先去 vendor 目录查找依赖，如果没有找到会再去 GOPATH 目录下查找。\n要想开启 vendor 机制， Go 项目必须位于 $GOPATH 环境变量配置的某个路径的 src 目录下面。\ngo mod\nGo 1.11 版本推出 modules 机制，简称 mod，从Go 1.13 开始，go module 将是 Go 默认的依赖管理工具。\n包不再保存在 $GOPATH 中，而是被下载到了 $GOPATH/pkg/mod 路径下。"},"golang/os":{"title":"os","links":[],"tags":[],"content":"Signal\n信号(Signal) 是 Linux, 类 Unix 和其它 POSIX 兼容的操作系统中用来进程间通讯的一种方式。\n对于 Linux 系统来说，信号就是软中断，用来通知进程发生了异步事件。\n当信号发送到某个进程中时，操作系统会中断该进程的正常流程，并进入相应的信号处理函数执行操作，完成后再回到中断的地方继续执行。\n有时候我们想在 Go 程序中处理 Signal 信号，比如收到SIGTERM信号后优雅的关闭程序，以及 goroutine 结束通知等。\nGo 语言提供了对信号处理的包（os/signal）。\nGo 中对信号的处理主要使用 os/signal 包中的两个方法：一个是notify方法用来监听收到的信号；一个是 stop 方法用来取消监听。\nGo 信号通知机制可以通过往一个 channel 中发送os.Signal实现。\nimport (\n\t&quot;fmt&quot;\n\t&quot;os&quot;\n\t&quot;os/signal&quot;\n\t&quot;syscall&quot;\n)\n \nfunc signal01() {\n\t// 创建一个os.Signal channel\n\tsigs := make(chan os.Signal, 1)\n\t// 创建一个bool channel\n\tdone := make(chan bool, 1)\n\t// 注册要接收的信号，syscall.SIGINT: 接收 ctrl+c, syscall.SIGTERM: 程序退出\n\t// 信号没有信号参数表示接收所有的信号\n\tsignal.Notify(sigs, syscall.SIGINT, syscall.SIGTERM)\n\t// 此goroutine为执行阻塞接收信号。一旦有了它，它就会打印出来\n\t// 然后通知程序可以完成\n\tgo func() {\n\t\tsig := &lt;-sigs\n\t\tfmt.Println(sig.String())\n\t\tdone &lt;- true\n\t}()\n\t\n\tfmt.Println(&quot;awaiting signal&quot;)\n\t&lt;-done\t// 程序将在此处等待，直到它预期信号；在“done”上发送一个值，然后退出\n\tfmt.Println(&quot;exiting&quot;)\n}\n取消监听信号，使用 signal.Stop()，当程序再次被中断是，直接中断，不会输出 exiting；\n{\n    // ...\n    go func() {\n        sig := &lt;-sigs\n        fmt.Println(sig)\n        done &lt;- true\n    }()\n    // 不允许继续往sigs中存入内容\n    signal.Stop(sigs)\n    fmt.Println(&quot;awaiting signal&quot;)\n    &lt;-done\n     fmt.Println(&quot;exiting&quot;)\n}\n优雅的重启方式： Graceful restart in Golang - Gregory Trubetskoy (grisha.org)\n常见方法\nos.Stat\n用于获取文件或目录的相关信息，例如文件大小、修改时间等\nos.IsNotExist\n用于判断一个错误是否表示文件或目录不存在，它接受一个错误作为参数，并返回一个布尔值，表示该错误是否表示文件或目录不存在。即通常与 os.Stat 一起使用，判断某个文件或目录是否存在。"},"golang/package":{"title":"package","links":[],"tags":[],"content":"包和文件\n一个包的源代码保存在一个或多个以.go为文件后缀名的源文件中，通常一个包所在目录路径的后缀是包的导入路径。\n\n例如包gopl.io/ch1/helloworld对应的目录路径是$GOPATH/src/gopl.io/ch1/helloworld。\n\n每个包都对应一个独立的名字空间。例如，在 image 包中的 Decode 函数和在 unicode/utf16 包中的 Decode 函数是不同的。\n在 Go 语言中，一个简单的规则是：如果一个名字是大写字母开头的，那么该名字对于包来说是导出的。\n包的导入\nGo语言的规范并没有指明包的导入路径字符串的具体含义，导入路径的具体含义是由构建工具来解释的。\n每个导入声明语句都明确指定了当前包和被导入包之间的依赖关系。如果遇到包循环导入的情况，Go语言的构建工具将报告错误。\n包的初始化\n包的初始化首先是解决包级变量的依赖顺序，然后按照包级变量声明出现的顺序依次初始化：\n如果包中含有多个.go源文件，它们将按照发给编译器的顺序进行初始化，Go语言的构建工具首先会将.go文件根据文件名排序，然后依次调用编译器编译。\n每个文件都可以包含多个init初始化函数，其除了不能被调用或引用外，其他行为和普通函数类似。\n\n每个包在解决依赖的前提下，以导入声明的顺序初始化，每个包只会被初始化一次；\n初始化工作是自下而上进行的，main 包最后被初始化；\n\n总结一个 go 程序代码的执行顺序：\n\n初始化所有被导入的包\n初始化被导入的包所有全局变量\n被导入的包init函数调用：\n\n同一个 go 文件的 init() 调用顺序是从上到下的;\n同一个 package 中不同文件是按文件名字符串比较“从小到大”顺序调用各文件中的 init() 函数;\n不同的 package，按照 main 包中”先import的先调用”的顺序调用其包中的 init();\n\n\nMain 函数执行\n\nGo 工具\nGo 语言的工具箱集合了一系列功能的命令集。它可以看作是一个包管理器（类似于Linux中的 apt 和 rpm 工具），用于包的查询、计算包的依赖关系、从远程版本控制系统下载它们等任务。\n\ngo get命令支持当前流行的托管网站 GitHub、Bitbucket 和 Launchpad，可以直接向它们的版本控制系统请求代码。\ngo get命令获取的代码是真实的本地存储仓库，而不仅仅只是复制源文件，因此你依然可以使用版本管理工具比较本地代码的变更或者切换到其它的版本。\n\n例如golang.org/x/net包目录对应一个Git仓库：\n$ cd $GOPATH/src/golang.org/x/net\n$ git remote -v\norigin  go.googlesource.com/net (fetch)\norigin  go.googlesource.com/net (push)\n需要注意的是导入路径含有的网站域名和本地 Git 仓库对应远程服务地址并不相同，真实的 Git 地址是 go.googlesource.com。这其实是 Go 语言工具的一个特性，可以让包用一个自定义的导入路径，但是真实的代码却是由更通用的服务提供，例如 googlesource.com 或 github.com。因为页面 golang.org/x/net/html 包含了如下的元数据，它告诉 Go 语言的工具当前包真实的 Git 仓库托管地址：\n$ go build gopl.io/ch1/fetch\n$ ./fetch golang.org/x/net/html\n&lt;!DOCTYPE html&gt;\n&lt;html lang=&quot;en&quot;&gt;\n&lt;title&gt;The Go Programming Language&lt;/title&gt;\n&lt;meta http-equiv=&quot;Content-Type&quot; content=&quot;text/html; charset=utf-8&quot;/&gt;\n&lt;meta name=&quot;go-import&quot; content=&quot;golang.org/x/net git go.googlesource.com/net&quot;&gt;\n&lt;meta http-equiv=&quot;refresh&quot; content=&quot;0; url=pkg.go.dev/golang.org/x/net/html&quot;&gt;\n&lt;/head&gt;\n&lt;body&gt;\n&lt;a href=&quot;pkg.go.dev/golang.org/x/net/html&quot;&gt;Redirecting to documentation...&lt;/a&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n\n\ngo build命令编译命令行参数指定的每个包。如果包是一个库，则忽略输出结果；这可以用于检测包是可以正确编译的。\n\n\n如果包的名字是 main，go build 将调用链接器在当前目录创建一个可执行程序；以导入路径的最后一段作为可执行程序的名字。\n\n\n默认情况下，go build命令构建指定的包和它依赖的包，然后丢弃除了最后的可执行文件之外所有的中间编译结果。\n\n\ngo install命令和go build命令很相似，但是它会保存每个包的编译成果，而不是将它们都丢弃。\n\n\n被编译的包会被保存到GOPATH/pkg目录下，目录路径和 src目录路径对应，可执行程序被保存到GOPATH/bin目录。\n\n\nGo 语言的构建工具对包含internal名字的路径段的包导入路径做了特殊处理。这种包叫internal包，一个 internal 包只能被和 internal 目录有同一个父目录的包所导入。\n例如，net/http/internal/chunked 内部包只能被 net/http/httputil 或 net/http 包导入，但是不能被 net/url 包导入。不过 net/url 包却可以导入net/http/httputil包。\nnet/http\nnet/http/internal/chunked\nnet/http/httputil\nnet/url\n"},"golang/path":{"title":"path","links":[],"tags":[],"content":"filepath\nJoin\nJoin函数可以将任意数量的路径元素放入一个单一路径里，会根据需要添加斜杠。结果是经过简化的，所有的空字符串元素会被忽略。\n例如：\nfmt.Println(path.Join(&quot;c:&quot;, &quot;aa&quot;, &quot;bb&quot;, &quot;cc.txt&quot;))\n// c:/aa/bb/cc.txt\n源码：\nfunc join(elem []string) string {\n\tfor i, e := range elem {\n\t\tif e != &quot;&quot; {\n\t\t\treturn joinNonEmpty(elem[i:])\n\t\t}\n\t}\n\treturn &quot;&quot;\n}\n \n// joinNonEmpty is like join, but it assumes that the first element is non-empty.\nfunc joinNonEmpty(elem []string) string {\n\tif len(elem[0]) == 2 &amp;&amp; elem[0][1] == &#039;:&#039; {\n\t\t// First element is drive letter without terminating slash.\n\t\t// Keep path relative to current directory on that drive.\n\t\t// Skip empty elements.\n\t\ti := 1\n\t\tfor ; i &lt; len(elem); i++ {\n\t\t\tif elem[i] != &quot;&quot; {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\treturn Clean(elem[0] + strings.Join(elem[i:], string(Separator)))\n\t}\n\t// The following logic prevents Join from inadvertently creating a\n\t// UNC path on Windows. Unless the first element is a UNC path, Join\n\t// shouldn&#039;t create a UNC path. See golang.org/issue/9167.\n\tp := Clean(strings.Join(elem, string(Separator)))\n\tif !isUNC(p) {\n\t\treturn p\n\t}\n\t// p == UNC only allowed when the first element is a UNC path.\n\thead := Clean(elem[0])\n\tif isUNC(head) {\n\t\treturn p\n\t}\n\t// head + tail == UNC, but joining two non-UNC paths should not result\n\t// in a UNC path. Undo creation of UNC path.\n\ttail := Clean(strings.Join(elem[1:], string(Separator)))\n\tif head[len(head)-1] == Separator {\n\t\treturn head + tail\n\t}\n\treturn head + string(Separator) + tail\n}\n \n// isUNC reports whether path is a UNC path.\nfunc isUNC(path string) bool {\n\treturn volumeNameLen(path) &gt; 2\n}\nIsAbs"},"golang/reflect/reflect":{"title":"reflect","links":[],"tags":[],"content":"为何需要反射?\n需要编写一个函数能够处理一类并不满足普通公共接口的类型的值：\n\n可能是因为它们并没有确定的表示方式；\n或在我们设计该函数的时候这些类型可能还不存在；\n\n总之，就是没有办法来检查未知类型的表示方式。这就是我们需要反射的原因。\n\n反射机制允许我们在程序运行时检查变量的类型结构、值、方法等，同时还能动态修改变量值、调用方法等。\n\nreflect.Type 和 reflect.Value\n反射是由 reflect 包提供的，其中定义了两个重要的类型，Type 和 Value。\n\n一个 reflect.Type 表示一个 Go 类型，它是一个接口，且满足 fmt.Stringer 接口；\n一个 reflect.Value 可以装载任意类型的值，也满足 fmt.Stringer 接口。\n\n函数 reflect.TypeOf 接受任意的 interface{} 类型，并以 reflect.Type 形式返回其动态类型；\n\n\n返回的是一个动态类型的接口值，总是返回具体的类型；\nvar w io.Writer = os.Stdout\nfmt.Println(reflect.TypeOf(w)) // &quot;*os.File&quot;\n\n\n函数 reflect.ValueOf 接受任意的 interface{} 类型，并返回一个装载着其动态值的 reflect.Value；\n\n\n返回的结果也是具体的类型，但是 reflect.Value 也可以持有一个接口值；\nv := reflect.ValueOf(3) // a reflect.Value\nfmt.Println(v)          // &quot;3&quot;\nfmt.Printf(&quot;%v\\n&quot;, v)   // &quot;3&quot;\n \n// 除非 Value 持有的是字符串，否则 String 方法只返回其类型\nfmt.Println(v.String()) // NOTE: &quot;&lt;int Value&gt;&quot;\n\n\n逆操作是 reflect.Value.Interface 方法。它返回一个 interface{} 类型，装载着与 reflect.Value 相同的具体值：\nv := reflect.ValueOf(3) // a reflect.Value\nx := v.Interface()      // an interface{}\ni := x.(int)            // an int\nfmt.Printf(&quot;%d\\n&quot;, i)   // &quot;3&quot;\n\n\n\nreflect.Value 和 interface{} 都能装载任意的值。\n所不同的是，一个空的接口隐藏了值内部的表示方式和所有方法，因此只有我们知道具体的动态类型才能使用类型断言来访问内部的值，内部值我们没法访问。\n\nreflect.Value和reflect.Type都有一个Kind()方法，返回一个reflect.Kind类型的变量。与reflect.Type的区别是：Kind指代的底层类型，而Type是静态声明的类型。\n通过 reflect.Value 修改值\n一个变量就是一个可寻址的内存空间，里面存储了一个值，并且存储的值可以通过内存地址来更新。\n对于以下的声明语句：\nx := 2                   // value   type    variable?\na := reflect.ValueOf(2)  // 2       int     no\nb := reflect.ValueOf(x)  // 2       int     no\nc := reflect.ValueOf(&amp;x) // &amp;x      *int    no\nd := c.Elem()            // 2       int     yes (x)\n其中 a 对应的变量不可取地址。因为 a 中的值仅仅是整数 2 的拷贝副本。b 中的值也同样不可取地址。c 中的值还是不可取地址，它只是一个指针&amp;x的拷贝。\n实际上，所有通过reflect.ValueOf(x)返回的reflect.Value都是不可取地址的。\n但是对于 d，它是 c 的解引用方式生成的，指向另一个变量，因此是可取地址的。我们可以通过调用reflect.ValueOf(&amp;x).Elem()，来获取任意变量 x 对应的可取地址的 Value。\n我们可以通过调用reflect.Value的CanAddr方法来判断其是否可以被取地址：\nfmt.Println(a.CanAddr()) // &quot;false&quot;\nfmt.Println(b.CanAddr()) // &quot;false&quot;\nfmt.Println(c.CanAddr()) // &quot;false&quot;\nfmt.Println(d.CanAddr()) // &quot;true&quot;\n要从变量对应的可取地址的reflect.Value来访问变量需要三个步骤。第一步是调用Addr()方法，它返回一个 Value，里面保存了指向变量的指针。\n然后是在 Value 上调用Interface()方法，也就是返回一个interface{}，里面包含指向变量的指针。最后，如果我们知道变量的类型，我们可以使用类型的断言机制将得到的interface{}类型的接口强制转为普通的类型指针。这样我们就可以通过这个普通指针来更新变量了：\nx := 2\nd := reflect.ValueOf(&amp;x).Elem()   // d refers to the variable x\npx := d.Addr().Interface().(*int) // px := &amp;x\n*px = 3                           // x = 3\nfmt.Println(x)                    // &quot;3&quot;\n或者，不使用指针，而是通过调用可取地址的reflect.Value的reflect.Value.Set方法来更新对应的值：\nd.Set(reflect.ValueOf(4))\nfmt.Println(x) // &quot;4&quot;\nSet 方法将在运行时执行和编译时进行类似的可赋值性约束的检查，对一个不可取地址的reflect.Value调用 Set 方法也会导致 panic 异常。\n很多用于基本数据类型的Set方法：SetInt、SetUint、SetString和SetFloat等\n获取结构体字段标签\n使用结构体成员标签用于设置对应 JSON 对应的名字。其中 json 成员标签让我们可以选择成员的名字和抑制零值成员的输出。\n显示一个类型的方法集\n可使用reflect.Type来打印任意值的类型和枚举它的方法：\nfunc Print(x interface{}) {\n    v := reflect.ValueOf(x)\n    t := v.Type()\n    fmt.Printf(&quot;type %s\\n&quot;, t)\n \n    for i := 0; i &lt; v.NumMethod(); i++ {\n        methType := v.Method(i).Type()\n        fmt.Printf(&quot;func (%s) %s%s\\n&quot;, t, t.Method(i).Name,\n            strings.TrimPrefix(methType.String(), &quot;func&quot;))\n    }\n}\n一些忠告\n反射是一个强大并富有表达力的工具，但是它应该被小心地使用，原因有三：\n\n基于反射的代码是比较脆弱的。对于每一个会导致编译器报告类型错误的问题，在反射中都有与之相对应的误用问题，不同的是编译器会在构建时马上报告错误，而反射则是在真正运行到的时候才会抛出panic异常，可能是写完代码很久之后了，而且程序也可能运行了很长的时间。\n即使对应类型提供了相同文档，但是反射的操作不能做静态类型检查，而且大量反射的代码通常难以理解。总是需要小心翼翼地为每个导出的类型和其它接受interface{}或reflect.Value类型参数的函数维护说明文档。\n基于反射的代码通常比正常的代码运行速度慢一到两个数量级。对于一个典型的项目，大部分函数的性能和程序的整体性能关系不大，所以当反射能使程序更加清晰的时候可以考虑使用。\n"},"golang/sql":{"title":"sql","links":[],"tags":[],"content":"Go使用SQL与类SQL数据库的惯例是通过标准库 database/sql。这是一个对关系型数据库的通用抽象，它提供了标准的、轻量的、面向行的接口。\n概述\n在Go中访问数据库需要用到sql.DB接口：它可以创建语句(statement)和事务(transaction)，执行查询，获取结果。\n对于sql.DB，首先要了解到它并不是数据库连接，也并未在概念上映射到特定的数据库(Database)或模式(schema)。它只是一个接口和数据库实体的抽象，这个数据库可能是各种各样的，例如一个本地文件、通过网络连接访问的远程数据库，或者是一个内存中的数据库。\nsql.DB 在后台为你执行以下重要的事情：\n\n操作具体的驱动打开/关闭实际底层数据库的连接；\n按需管理连接池，可能有之前提到的多种情形；\n\nsql.DB 抽象的设计目的是让您不必担心如何管理对底层数据存储的并发访问。当您使用连接执行任务时，连接将被标记为正在使用，当不再使用时，连接将返回到可用池。这样做的一个后果是，如果您未能将连接释放回池，则可能导致sql.DB打开大量连接，可能会耗尽资源(太多连接、太多打开的文件句柄、缺乏可用的网络端口等)。稍后我们将对此进行更多讨论。\n在创建sql.DB之后，您可以使用它来查询它所表示的数据库，以及创建语句和事务。\n引入数据库驱动\n使用数据库时，除了database/sql包本身，还需要引入想使用的特定数据库驱动。\n你通常不应该直接使用数据库驱动，尽管有些驱动鼓励你那样做（在我看来，这是个错误的想法）。相反，如果可能的话，你的代码应该只引用定义在包 database/sql 的类型。这有助于避免你的代码依赖于这个驱动，以至于你可以以很小的代码修改就可更换底层的数据库驱动（也就是你要访问的数据库）。这也强制你使用 go 的惯用语法，而不是特定驱动的作者提供的惯用语法。\n在本文档中，我们使用出自 @julienschmidt 和 @arnehormann 优秀的 MySQL drivers 为例。\n首先，我们将相关依赖导入到 go 源文件中：\nimport (\n\t&quot;database/sql&quot;\n\t_ &quot;github.com/go-sql-driver/mysql&quot;\n)\n注意到，我们是匿名加载数据库驱动的，即将它的包名的别名设置为 _，所以它导出的名称对我们是不可见的。在底层，该驱动会将其自身注册到 database/sql包中，通常情况下，除了 init 函数运行，其他任何事情都不会发生。\n现在可以准备访问一个数据库了。\n访问数据库\n现在我们载入了数据库驱动，正准备创建一个数据库对象，即一个 sql.DB。为此，你可以使用 sql.Open。它会返回一个 *sql.DB。\nfunc main() {\n\tdb, err := sql.Open(&quot;mysql&quot;,\n\t\t&quot;user:password@tcp(127.0.0.1:3306)/hello&quot;)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\tdefer db.Close()\n}\n在上面的例子中，我们说明几件事情：\n\nsql.OPEN 的第一个参数是驱动名，这是一个驱动被用于将其自身注册到 database/sql中的字符串，按照惯例，它会与包名保持一直以避免歧义。例如， mysql 对应着 github.com/go-sql-driver/mysql。某些驱动不会遵循该惯例使用数据库名称，例如 sqlite3包名为 github.com/mattn/go-sqlite3 以及postgres是 github.com/lib/pq。\n第二个参数是驱动特定的语法，将向驱动表明如何访问底层数据库。在例子中，我们将连接到本地 Mysql 数据库实例中的 hello 数据库。\n你应该（几乎）总是对所有 database/sql 操作返回结果，做检测和处理错误。只有很少一些特殊情况，这样做是没有意义的， 我们将在后面讨论。\n如果 sql.DB 没有一个生命周期超出当前函数作用域，那么通常会使用defer db.Close()。\n\n可能与直觉相反，sql.OPEN 不会建立任何与数据库的连接，也不会验证驱动连接的参数。它只是简单地为后续将使用的数据库做了抽象。底层数据库第一个实际的连接将会被懒加载式地建立，即当它首次被需要的时候。如果你想要立即检测数据库的可用性和可访问性（例如可以建立网络连接以及登录），可使用 db.Ping，不过要记住检测错误：\nerr = db.Ping()\nif err != nil {\n\t// do something here\n}\n当操作完数据库时，虽然习惯上使用 Close()关闭，但是 sql.DB 对象是为了长连接而设计的，不要频繁Open()和Close()数据库。应该为每个不同的待访问数据库创建一个 sql.DB实例，并在用完前一直保留它。需要时可将其作为参数传递，或注册为全局对象，但是要让其保持开启状态。且不要在短链接函数中 Open() 或Close()，也应该将 sql.DB作为参数传入其中。\n如果你不把sql.DB当成长期对象来用而频繁开关启停，就可能遭遇各式各样的错误：无法复用和共享连接，耗尽网络资源，由于TCP连接保持在TIME_WAIT状态而间断性的失败等……这些问题就是没有按照database/sql设计的意图使用的标志。\n现在是时候使用你的 sql.DB 对象了。\n检索结果集合\n有许多种惯用的从数据库检索数据结果的操作：\n\n执行查询返回多行；\n准备一个语句重复使用，执行多次并销毁它；\n以一次性的方式执行语句，而不准备重复使用；\n执行查询返回单行，这是特殊情况的快捷方式。\n\nGo 的 database/sql 函数名称是重要的。如果一个函数名称包含 Query，那么它是被设计为向数据库查询的，会返回多行，即使它是空的。不返回多行的语言不应该使用 Query 函数，而应该使用 Exec()。\n获取数据\n让我们看一个如何查询数据库的例子，我们从 users 表中查询一个 id 为 1 的 user，然后输出它的 id 和 name。我们将使用 rows.Scan()把结果一次一行分配到变量中。\nvar (\n\tid int\n\tname string\n)\nrows, err := db.Query(&quot;select id, name from users where id = ?&quot;, 1)\nif err != nil {\n\tlog.Fatal(err)\n}\ndefer rows.Close()\nfor rows.Next() {\n\terr := rows.Scan(&amp;id, &amp;name)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\tlog.Println(id, name)\n}\nerr = rows.Err()\nif err != nil {\n\tlog.Fatal(err)\n}\n以下是上述代码所作的事情：\n\n我们使用 db.Query() 发送查询请求到数据库，通常要检查错误；\n延迟执行 db.Close()，这非常重要；\n使用 rows.Next() 遍历这些行；\n通过rows.Scan()读取这些行中的列，到变量中；\n遍历完列后，检查错误；\n\n这几乎是在Go中实现它的唯一方法。例如，你不能将列当作一个 map。这是因为所有东西都是强类型的。你需要创建正确的类型的变量并向他们传递指针，如上所示。\n其中有几个部分很容易出错，可能会产生不好的后果。\n\n在 for rows.Next() 循环中，需要每次检查错误。如果有错误发生，你需要知晓。不要仅仅假设循环会迭代直到处理完所有行。\n其次，只要有一个 open 的结果集（rows 表示的），底层的连接则是 busy 的，不能用于其他查询。意味着它在连接池中是不可用的。如果你使用 rows.Next() 迭代所有的列数据，最终你读到最后一行，接着  rows.Next() 将遇到 一个内部的 EOF 错误，会为你调用 rows.Close()函数。但是某些原因下，你退出了循环，即更早返回等，然后 rows 不会关闭，所以连接仍然保持 open 状态。（如果 rows.Next()由于错误返回 false，它会自动关闭）。这是一个轻易耗尽资源的方式。\n如果 rows已经关闭，那么 rows.Close() 将是无害的空操作，所以你可以调用它多次。注意，我们首先检查错误，并仅在没有错误时调用 rows.Close()，以避免运行时 panic。\n应该总是使用 defer rows.Close()，即使你也在循环最后显性地调用了 rows.Close()，这也不是个坏主意；\n不要在循环中 defer。一个 deferred 的语句不会执行直到这个函数退出时，所以一个长时间运行的函数不应该使用它。如果你这样做，你将缓慢地积累内存。如果你重复地在循环中查询和消费结果集，应该在处理完成每一个结果时，显式地调用 rows.Close() ，而不是使用 defer。\n\nScan() 原理\n当你遍历每一行且将其 scan 到目标变量时，Go 在幕后为你执行数据类型转为工作。这基于目标变量的类型。意识到这一点能简化你的代码并帮助你避免重复性的工作。\n例如，假设你从表中选择了一些行，表中定义了字符串类型的列，例如VARCHAR(45)之类的。然而，你可能知道，表中总是包含数字。如果你传一个指针给字符串，Go 将复制这个字节转化为字符串。现在，你能使用 strconv.ParseInt() 或类似的将转化值转化为数字的方式。你将不得不检测 SQL 操作的错误，以及转化为整型的错误。这是麻烦又枯燥的。\n或者，你能向 Scan() 传一个指向整型的指针。Go 将会检测到然后调用 strconv.ParseInt()。如果转化中报错了，Scan() 也会返回。你的代码现在更间接也更少了。这也即是推荐使用 database/sql的方式。\n查询前的准备\n通常情况下，你应该总是做好查询被多次使用的准备。准备查询的结果即是一个预处理语句，当你需要执行语句时，它能有占位符（placeholders，也叫值绑定 bind values）作为你需要的参数。出于通常的理由（例如，避免 SQL 注入攻击），这比拼接字符串更好。\n在 MySQL 中，参数占位符是 ?，在 PostgreSQL 中是 $N，这里的 N 是数字。SQLite 接受其中任何一种。在 Oracle 占位符以冒号:为首而且是命名的，如：:params1。我们将使用 ? 因为我们是以 MySQL 为例的。\nstmt, err := db.Prepare(&quot;select id, name from users where id = ?&quot;)\nif err != nil {\n\tlog.Fatal(err)\n}\ndefer stmt.Close()\nrows, err := stmt.Query(1)\nif err != nil {\n\tlog.Fatal(err)\n}\ndefer rows.Close()\nfor rows.Next() {\n\t// ...\n}\nif err = rows.Err(); err != nil {\n\tlog.Fatal(err)\n}\n在底层， 实际上是db.Query()在准备，执行并关闭一个准备好的语句。这是到数据库的三次往返。如果你不够仔细，你能将应用程序与数据库的交互增加三倍！一些驱动在特定情况下能够避免，但不是所有驱动都能做到的。更多可参考预处理语句。\n单行查询\n如果一个查询最多返回一行，你能在冗长的模板代码中使用一个快捷方式：\nvar name string\nerr = db.QueryRow(&quot;select name from users where id = ?&quot;, 1).Scan(&amp;name)\nif err != nil {\n\tlog.Fatal(err)\n}\nfmt.Println(name)\n查询中的错误会被延迟直到 Scan() 被调用，然后从中返回。你也能在预处理语句上调用 QueryRow()：\nstmt, err := db.Prepare(&quot;select name from users where id = ?&quot;)\nif err != nil {\n\tlog.Fatal(err)\n}\ndefer stmt.Close()\nvar name string\nerr = stmt.QueryRow(1).Scan(&amp;name)\nif err != nil {\n\tlog.Fatal(err)\n}\nfmt.Println(name)\n使用事务修改数据\n现在我们已经准备好了解如何使用事务修改数据了。如果你习惯了使用 “statement” 对象获取行数据及更新数据的编程语言，那么这种区别看起来可能是不太自然的，但是在 Go 中，这种区别的存在，有一个很重要的原因。\n修改数据的语句\n使用 Exec()，与预处理语句是最佳的，对于实现INSERT, UPDATE, DELETE, 或者其他不会返回任何行数据的语句。以下的例子将展示如果插入一行数据并检验操作的元数据：\nstmt, err := db.Prepare(&quot;INSERT INTO users(name) VALUES(?)&quot;)\nif err != nil {\n\tlog.Fatal(err)\n}\nres, err := stmt.Exec(&quot;Dolly&quot;)\nif err != nil {\n\tlog.Fatal(err)\n}\nlastId, err := res.LastInsertId()\nif err != nil {\n\tlog.Fatal(err)\n}\nrowCnt, err := res.RowsAffected()\nif err != nil {\n\tlog.Fatal(err)\n}\nlog.Printf(&quot;ID = %d, affected = %d\\n&quot;, lastId, rowCnt)\n执行语句将产生一个 sql.Result，它能够返回语句的元数据：最后插入行的 ID，以及影响的行的数量。\n假如你并不关心结果呢？假如你仅是想要执行一条语句然后检查是否有任何错误，但忽略结果呢？下面两条语句不是在做相同的事情吗？\n_, err := db.Exec(&quot;DELETE FROM users&quot;)  // OK\n_, err := db.Query(&quot;DELETE FROM users&quot;) // BAD\n答案是不。它们没有做相同的事情，而且你从不应该使用向那样使用 Query()。Query() 返回一个 sql.Rows，它会保留数据库连接直到它被关闭掉。因为这可能有未读取的数据（例如更多的数据行），所以连接不能被使用。上面的例子中，连接将一直不会被释放。垃圾收集器最终将为你关闭底层的net.Conn，但是这可能需要很长时间。此外 database/sql 包会一直追踪在连接池中的连接，希望你在某时刻释放它，以至于连接能够再次使用。因此，这个反模式是一个耗尽资源（例如，太多的连接）的好的方式。\n使用事务\n在 Go 中，一个事务本质上是一个保留连接到数据存储的对象。它让你完成我们目前为止见过的所有操作，但是保证他们在相同的连接中被执行。\n调用db.Begin() 开始一个事务，使用返回的结果的Tx 变量上的 Commit() 或者 Rollback()方法来关闭事务。在底层，Tx 从连接池获取一个连接，然后将其保留且只在本次事务中使用。Tx 上的方法都一对一地映射到可以在数据库本身上调用的方法，例如 Query 等。\n在事务中创建的预处理语句被单独地绑定在该事务中。查看预处理了解更多。\n你不应该在你的 SQL 代码中，将事务相关函数如Begin() 和Commit() 与 SQL 语句如 BEGIN 和 COMMIT 混用。可能会导致糟糕地结果：\n\nTx 对象将保持 open，即会保留一个连接池中的连接不会返回；\n数据库的状态可能会与 Go 变量代表的状态不同步；\n你能相信你是在一个事务内，单一的连接中执行查询，而实际上 Go 已隐性地为你已经创建了多个连接，并且一些语句不是事务的一部分。\n\n当你在事务内进行操作时，你应该注意，不要调用 db 变量。在使用 db.Begin() 创建的 Tx 变量上完成你的所有调用。db 并不在事务中，只是 Tx 变量在事务中。如果你进一步调用 db.Exec() 或者类似的函数，这些调用将会发生在你的事务作用域之外的其他连接上。\n如果你需要修改连接状态的多个语句，即使你不想要事务本身，你也需要一个Tx。例如：\n\n创建多个临时的表，且只对一个连接可见；\n设置变量，例如 MysSQL 的 SET @var := somevalue 语法；\n改变连接选项，例如设置字符集或超时；\n\n如果你需要做任何与此相关的事情，你需要将你的活动绑定到一个单独的连接中，在 Go 中唯一的方式就是使用 Tx。\n使用预处理语句\n预处理语句拥有 Go 的所有常见的好处：安全，高效，方便。但是他们可能与你可能用过的预处理语句的实现有一些不同，尤其是关于他们与 database/sql 内部构件的一些交互。\n预处理语句和连接\n在数据库层级，连接是没有直接暴露的给 database/sql 的用户的。你不能在连接上预处理语句，而是在 DB 或 Tx 上预处理语句。并且 database/sql 具有一些便捷行为，如自动重试。由于这些原因，预处理语句和连接之间的底层关联存在于驱动程序级别，会对您的代码隐藏。\n这是它的工作原理：\n\n当你预处理一个语句时，它是在连接池中的一个连接中预处理的；\nStmt 对象会记住哪一个连接使用过；\n当你执行 Stmt 时，它会尝试该连接。如果它不可用，可能是关闭了或者是忙于其他别的什么事，它会从连接池中获取另一个连接并基于该连接重新预处理语句；\n\n当原始的连接是忙碌时，语句将会根据所需重新预处理，数据库的高并发使用，可能会导致大量连接繁忙，从而创建大量的预处理语句。这可能导致显性的语句泄漏，语句被预处理和重新预处理会远超你认为的频繁，甚至达到服务端对语句的数量限制。\n避免预处理语句\nGo 在底层为你创建预处理语句。例如一个简单的 db.Query(sql, param1, param2)，用于预处理 SQL，然后带着参数执行，最后关闭语句。\n然而有时候，一个预处理语句并不是你想要的，这可能有以下几个原因：\n\n数据库不支持预处理语句。例如，当使用 MySQL 驱动时，你能连接 MemSQL 和 Sphinx，因为它们支持 MySQL 连接协议。但是它们不支持二进制协议这包括预处理语句，所以它们会以奇怪的方式失败。\n语句的重用程度不够，不值得使用，而且安全问题用其他方式处理，因此不需要性能开销。可以在 VividCortex 博客上看一个例子。\n\n如果你不想要使用预处理语句，你需要使用 fmt.Sprint() ，或者，类似的，组装 SQL，然后将其作为db.Query() 或 db.QueryRow() 唯一的参数传入。并且你的驱动需要支持明文查询执行，这已经在 Go 1.1 中被加入了，通过Execer 和 Queryer 接口，文档在这。\n事务中的预处理语句\n在一个 Tx 中创建的预处理语句会单独绑定到其中，所以之前的关于重新预处理的警告并不适用。当你在一个 Tx 对象上操作时，你的操作会直接映射到底层有且只有一个的连接。\n这也意味着在 Tx 内创建的预处理语句不能从其中分离使用。同样的，在 DB中创建的预处理语句也不能在事务中使用，因为它们将绑定到一个不同的连接。\n要在 Tx 中使用在事务外创建的预处理语句，你能使用 Tx.Stmt，它将从事务外部的预处理语句中创建一个新的特定于事务的语句。它通过获取一个现有的预处理语句，设置到事务的连接，并在每次执行所有语句时重新预处理所有语句来实现这一点。这种行为及其实现是不可取的，甚至在database/sql 源代码中有一个 TODO 来改进它;我们不建议使用这种方法。\n在事务中使用预处理语句时必须谨慎。考虑下面的例子:\ntx, err := db.Begin()\nif err != nil {\n\tlog.Fatal(err)\n}\ndefer tx.Rollback()\nstmt, err := tx.Prepare(&quot;INSERT INTO foo VALUES (?)&quot;)\nif err != nil {\n\tlog.Fatal(err)\n}\ndefer stmt.Close() // danger!\nfor i := 0; i &lt; 10; i++ {\n\t_, err = stmt.Exec(i)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n}\nerr = tx.Commit()\nif err != nil {\n\tlog.Fatal(err)\n}\n// stmt.Close() runs here!\n在 Go 1.4 之前，关闭一个 *sql.Tx 将与其关联的连接释放回池中，但是在此之后执行了对预处理语句的 Close 的延迟调用，这可能导致对底层连接的并发访问，从而导致连接状态不一致。如果您使用的是 Go 1.4 或更高版本，则应该确保在事务提交或回滚之前始终关闭语句。. 这个问题在 Go 1.4 中由CR 131650043修复。\n参数占位符语法\n预处理语句中占位符参数的语法是特定于数据库的。例如，比较 MySQL、PostgreSQL 和Oracle：\nMySQL               PostgreSQL            Oracle\n=====               ==========            ======\nWHERE col = ?       WHERE col = $1        WHERE col = :col\nVALUES(?, ?, ?)     VALUES($1, $2, $3)    VALUES(:val1, :val2, :val3)\n处理错误\n几乎所有的包含 database/sql 类型的操作都会在最后一个值返回错误。你应该总是检查这些错误，从不忽略。\n这有一些特殊情况的错误行为，或者说你可能需要这些额外的东西。\n迭代结果集的错误\n思考以下代码：\nfor rows.Next() {\n\t// ...\n}\nif err = rows.Err(); err != nil {\n\t// handle the error here\n}\n来自 rows.Err() 的错误可能是在 rows.Next() 循环中的各种错误的结果。循环可能由于多种原因退出，而不是正常退出，所以总是需要检查循环是否正常终止。一个不正常的终止会自动调用 rows.Close()，尽管多次调用它是无害的。\n关闭结果集的错误\n如果你过早的退出循环，应该总是显式地关闭一个 sql.Rows，如前面提到的。如果循环正常退出或发生错误，它将自动关闭，但是你可能错误地这样做：\nfor rows.Next() {\n\t// ...\n\tbreak; // whoops, rows is not closed! memory leak...\n}\n// do the usual &quot;if err = rows.Err()&quot; [omitted here]...\n// it&#039;s always safe to [re?]close here:\nif err = rows.Close(); err != nil {\n\t// but what should we do if there&#039;s an error?\n\tlog.Println(err)\n}\nrows.Close() 返回的错误是通用规则的唯一例外，是所有数据库中错误，最好捕获和检测的。如果 rows.Close() 返回一个错误，这不太清楚你应该做什么。记录错误信息或者异常可能是唯一清晰的东西，如果它也不清晰，可能你应该忽略这个错误。\nQueryRow() 的错误\n思考以下的获取单行的代码：\nvar name string\nerr = db.QueryRow(&quot;select name from users where id = ?&quot;, 1).Scan(&amp;name)\nif err != nil {\n\tlog.Fatal(err)\n}\nfmt.Println(name)\n假如没有 id = 1 的用户会怎样？然后结果中将无行数据，.Scan() 将不会将值 scan 进 name。那么会发生什么呢？\nGo 定义了一个特殊的错误常量，被叫做 sql.ErrNoRows ，当结果是空时，会从 QueryRow() 被返回。这在大多数情况下需要被当作特殊情况来处理。一个空的结果通常在应用程序代码中不会被当作为错误，如果你不检测一个错误是否是这个错误常量，将导致意想不到的应用程序代码错误。\n来自查询的错误将被延迟直到 Scan() 被调用，然后从其中返回。上面的代码这样写更好：\nvar name string\nerr = db.QueryRow(&quot;select name from users where id = ?&quot;, 1).Scan(&amp;name)\nif err != nil {\n\tif err == sql.ErrNoRows {\n\t\t// there were no rows, but otherwise no error occurred\n\t} else {\n\t\tlog.Fatal(err)\n\t}\n}\nfmt.Println(name)\n有人可能会问为什么一个空结果集会认为是一个错误。一个空集没有任何错误。理由是 QueryRow() 方法需要这样的特殊情况让调用者区分是否 QueryRow() 实际上查找到了一行数据；没有它的，Scan() 将不会做任何事情，最后你可能不会意识到变量没有从数据库获得任何值。\n当你使用 QueryRow() 时，你应该只会遇到这个错误。如果你在别处遇到这个错误，你可能做错了什么。\n识别特定数据库错误\n编写如下代码是很有诱惑力的：\nrows, err := db.Query(&quot;SELECT someval FROM sometable&quot;)\n// err contains:\n// ERROR 1045 (28000): Access denied for user &#039;foo&#039;@&#039;::1&#039; (using password: NO)\nif strings.Contains(err.Error(), &quot;Access denied&quot;) {\n\t// Handle the permission-denied error\n}\n尽管这不是实现的最佳方式。例如，字符串值可能根据服务器用于发送错误消息的语言而变化。更好的方式是对比错误的数据来识别是个什么特定的错误。\n然而，这个机制要做的因驱动而异，因为这不是 database/sql 它本身的一部分。在 本教程专注 MySQL 驱动中， 你可以编写如下代码：\nif driverErr, ok := err.(*mysql.MySQLError); ok { \n    // Now the error number is accessible directly\n\tif driverErr.Number == 1045 {\n\t\t// Handle the permission-denied error\n\t}\n}\n不过，这儿的 MySQLError 类型有特定的驱动提供，.Number 字段可能因驱动而不同。然而，该数字的值来自 MySQL 的错误消息，因此是特定于数据库的，而不是特定于驱动程序的。\n这样的代码依然很丑，相比于 1045，一个神奇的数据，是一种代码的气味。一些驱动（虽然不是 MySQL，出于跑题的缘故）提供了一个错误识别码的列表。例如，Postgres pq 驱动程序在error.go 中。还有一个外部的 MySQL 错误数字，由 VividCortex 维护。使用这样的列表，上面的代码最好这样写：\nif driverErr, ok := err.(*mysql.MySQLError); ok {\n    if driverErr.Number == mysqlerr.ER_ACCESS_DENIED_ERROR {\n        // Handle the permission-denied error\n    }\n}\n处理连接错误\n如果到数据库的连接断开、终止或出现错误，该怎么办?\n当发生这种情况时，您不需要实现任何逻辑来重试失败的语句。作为 database/sql 中的连接池的一部分，处理失败连接是内置的。如果您执行一个查询或其他语句，而底层连接失败了，Go 将重新打开一个新连接（或只是从连接池中获取另一个连接）并重试，最多 10 次。\n然而，可能会有一些意想不到的后果。当发生其他错误条件时，可能会重试某些类型的错误。这也可能是驱动程序特有的。MySQL 驱动程序的一个例子是，使用 KILL 取消不需要的语句（例如长时间运行的查询）会导致该语句被重试多达10次。\n操作 Nulls\n可为空的列是令人恼怒的，并且会导致很多丑陋的代码。如果能避免可尽量避免。如果不能，然后你将需要使用 database/sql中的特殊类型处理它们，或者你自己定义。\n有可为空的布尔类型，字符串类型，整型以及浮点型。你可以这样使用它们：\nfor rows.Next() {\n\tvar s sql.NullString\n\terr := rows.Scan(&amp;s)\n\t// check err\n\tif s.Valid {\n\t   // use s.String\n\t} else {\n\t   // NULL value\n\t}\n}\n可空类型的限制，以及避免可空列的原因，以防你需要更多具有说服力的：\n\n没有 sql.NullUint64  或  sql.NullYourFavoriteType，你需要自己定义它们；\n可空性可能很棘手，而且不适合于未来。如果你认为某些东西可能将不会为空，但是你的想法错了，那么你的程序将崩溃，也许很少，在你推出它们之前，你将不会捕获错误。\n最棒的事情是，Go 有一个很有用的默认零值，对于每个变量。可空的东西不是这样工作的。\n\n如果你需要定义你自己的类型处理空值，你可以拷贝 sql.NullString 的设计来实现它。\n如果你在数据库中不能避免存在空值，另一个大多数数据库都是可行的方法，叫做 COALESCE()。您可以使用类似下面这样的代码，而不需要引入大量的 sql.Null* 类型。\nrows, err := db.Query(`\n\tSELECT\n\t\tname,\n\t\tCOALESCE(other_field, &#039;&#039;) as otherField\n\tWHERE id = ?\n`, 42)\n \nfor rows.Next() {\n\terr := rows.Scan(&amp;name, &amp;otherField)\n\t// ..\n\t// If `other_field` was NULL, `otherField` is now an empty string. This works with other data types as well.\n}\n操作未知的列\nScan() 函数需要你准确传入目标变量的正确数量。假如你不知道查询将返回什么呢？\n如果你不知道查询将返回多少列，可以使用 Columns() 找到一个列的列表的名字。你能检测该列表的数量来判断其中有多少列，并且你能在 Scan() 中传入一个有正确数量的值的切片 slice 。例如一些 MySQL 的复刻在 SHOW PROCEESLIST 命令时，返回不同的列，所以你不得不准备在其中会遇到错误。\n这有一种方法；还有其他的：\ncols, err := rows.Columns()\nif err != nil {\n\t// handle the error\n} else {\n\tdest := []interface{}{ // Standard MySQL columns\n\t\tnew(uint64), // id\n\t\tnew(string), // host\n\t\tnew(string), // user\n\t\tnew(string), // db\n\t\tnew(string), // command\n\t\tnew(uint32), // time\n\t\tnew(string), // state\n\t\tnew(string), // info\n\t}\n\tif len(cols) == 11 {\n\t\t// Percona Server\n\t} else if len(cols) &gt; 8 {\n\t\t// Handle this case\n\t}\n\terr = rows.Scan(dest...)\n\t// Work with the values in dest\n}\n如果你不知道列的或者他们的类型，你应该使用 sql.RawBytes。\ncols, err := rows.Columns() // Remember to check err afterwards\nvals := make([]interface{}, len(cols))\nfor i, _ := range cols {\n\tvals[i] = new(sql.RawBytes)\n}\nfor rows.Next() {\n\terr = rows.Scan(vals...)\n\t// Now you can check each element of vals for nil-ness,\n\t// and you can use type introspection and type assertions\n\t// to fetch the column into a typed variable.\n}\n连接池\n这是在 database/sql 中基础的连接池。没有很多的能力去控制和检测它，但是这有一些你知道后会发现很有用的事情：\n\n连接池意味着执行两个连续的语句在一个单独的数据库中，可能开启两个连接并分离执行它们。对于程序员来说这很常见，即感到疑惑为什么他们的代码有反常行为。例如，LOCK TABLES 跟在 INSERT 后会堵塞，因为 INSERT 在一个不持有表锁的连接上。\n连接会在需要且池中没有空闲的连接时被创建。\n默认情况下，连接的数量没有上限。如果你尝试一次性做很多事情，你能创建一个任意数量的连接。这将导致数据库返回错误例如 “too many connections.”。\n在 Go 1.1 或以后，你能使用 db.SetMaxIdConns(N) 来限制连接池中空闲状态下的连接的数量。然而，这并不会限制连接池的连接的数量。\n在 Go 1.2.1 或以后，你能使用 db.SetMaxOpenConns 来限制数据库开启的连接的最大数量。遗憾的是，在 1.2 中，一个 deadlock bug (fix) 阻止 db.SetMaxOpenConns(N) 安全使用。\n连接回收相当地快，使用 db.SetMaxIdleConns(N) 设置一个较大的等待连接数量，能减少滚动，并且帮助保持连接重用。\n保持连接长时间空闲将导致问题（像在 issue MySQL 在 Microsoft Azure）。尝试 db.SetConnMaxLifetime(duration) 因为重用长期保活的连接可能导致网络问题。这懒关闭不使用的连接，例如关闭失效的连接可能会被延迟。\n\n惊奇，反模式和限制\n虽然你一旦习惯了 database/sql，它将变得很简单，但是可能会感到惊讶，对于它支持的使用情况的细节之处。这在 Go 的核心库中很常见。\n资源耗尽\n如本文内容所述，如果你没有如预期一般使用  database/sql，你必然造成麻烦，通常通过消耗资源或阻止它们被高效重用：\n\n开启或关闭数据库能导致资源耗尽；\n读取行数据失败或使用 rows.Close()保留连接池中的连接；\n对不会返回行数据的语句使用 Query() 将保留池中的连接；\n如果不了解预处理语句的工作方式，可能会导致大量额外的数据库活动。\n\n大 uint64 值\n有一些奇怪的错误， 你不能将大的无符号整数作为参数传递给语句，如果它们的高位被设置了：\n_, err := db.Exec(&quot;INSERT INTO users(id) VALUES&quot;, math.MaxUint64) // Error\n这将会抛出一个错误，注意，如果你使用 uint64 的值，因为它们可能一开始很小，没有错误，但随着时间的推移而增加，并开始抛出错误。\n连接状态不匹配\n有些东西能改变连接的状态，并且能造成错误由于以下两个原因：\n\n一些连接状态，例如你是否在事务中，应该通过 Go 的类型被处理；\n你可能假设你的查询运行在一个单独的连接中，当它们并不是时。\n\n例如，使用USE语句设置当前数据库，是许多人都会做的一件典型的事情。但是在 Go 中，它只会影响你运行它的连接。除非您处于事务中，否则您认为在该连接上执行的其他语句实际上可能运行在从池中获得的不同连接上，因此它们不会看到此类更改的影响。\n此外，在您更改连接之后，它将返回池，并可能污染其他一些代码的状态。这就是为什么永远不应该像 SQL 那样发出 BEGIN 或 COMMIT 语句的原因之一。\n特定数据库的语法\ndatabase/sql API 提供了面向行的数据库的抽象，但是特定的数据库和驱动程序在行为和/或语法上可能有所不同，例如预处理语句的占位符。\n多结果集\nGo 驱动程序不以任何方式支持来自单个查询的多个结果集，而且似乎也没有这样做的计划，尽管有支持批量操作(如批量复制)的特性请求。\n这意味着，除其他外，返回多个结果集的存储过程将无法正常工作。"},"golang/third/echo":{"title":"echo","links":[],"tags":[],"content":"开始\n// 创建 echo 实例\ne := echo.New()\n// 路由\ne.GET(&quot;/&quot;, func(c echo.Context) error {\n    return c.String(http.StatusOK, &quot;Hello, World!&quot;)\n})\nURL路径参数\n// e.GET(&quot;/users/:id&quot;, getUser)\nfunc getUser(c echo.Context) error {\n    id := c.Param(&quot;id&quot;)\n    return c.String(http.StatusOK, id)\n}\n请求参数\n// e.GET(&quot;/show&quot;, show) /show?team=x-men&amp;member=wolverine\nfunc show(c echo.Context) error {\n    team := c.QueryParam(&quot;team&quot;)\n    member := c.QueryParam(&quot;member&quot;)\n    return c.String(http.StatusOK, &quot;team:&quot; + team + &quot;, member:&quot; + member)\n}\n表单\napplication/x-www-form-urlencoded\nfunc save(c echo.Context) error {\n    // 获取 name 和 email 的值\n    name := c.FormValue(&quot;name&quot;)\n    email := c.FormValue(&quot;email&quot;)\n    return c.String(http.StatusOK, &quot;name:&quot; + name + &quot;, email:&quot; + email)\n}\ncurl -d &quot;name=Joe Smith&quot; -d &quot;email=joe@labstack.com&quot; http://localhost:1323/save\n\n-d 选项用于发送以application/x-www-form-urlencoded格式编码的数据，该格式常用于普通表单数据的提交；\n-d 选项后面的参数应该是一个字符串，多个参数可以使用&amp;连接发送，也可以分开发送；\n但表单数据终被编码为一个字符串，其中每个表单字段的名称和值都以=符号连接，不同的表单字段之间以&amp;符号进行连接。\n\nmultipart/form-data\nfunc save(c echo.Context) error {\n    // Get name\n    name := c.FormValue(&quot;name&quot;)\n    // Get avatar\n    avatar, err := c.FormFile(&quot;avatar&quot;)\n    if err != nil {\n        return err\n    }\n \n    // Source\n    src, err := avatar.Open()\n    if err != nil {\n        return err\n    }\n    defer src.Close()\n \n    // Destination\n    dst, err := os.Create(avatar.Filename)\n    if err != nil {\n        return err\n    }\n    defer dst.Close()\n \n    // Copy\n    if _, err = io.Copy(dst, src); err != nil {\n        return err\n    }\n \n    return c.HTML(http.StatusOK, &quot;&lt;b&gt;Thank you! &quot; + name + &quot;&lt;/b&gt;&quot;)\n}\n$ curl -F &quot;name=Joe Smith&quot; -F &quot;avatar=@/path/to/your/avatar.png&quot; http://localhost:1323/save\n//output =&gt; &lt;b&gt;Thank you! Joe Smith&lt;/b&gt;\n\n-F 选项用于发送 multipart/form-data 格式的数据，该格式通常用于上传文件或二进制数据等场景。\n如果要上传文件，则值可以是一个以@符号开头的文件路径；\n在 multipart/form-data 格式中，每个键值对都会被编码为一条消息，消息中包含了该键值对的元数据和值的数据，与 -d传送的格式还是区别的；\n\n处理请求\n\n根据 Content-Type 请求标头将 json，xml，form 或 query 负载绑定到 Go 结构中。\n通过状态码将响应渲染为 json 或者 xml 格式。\n\ntype User struct {\n    Name  string `json:&quot;name&quot; xml:&quot;name&quot; form:&quot;name&quot; query:&quot;name&quot;`\n    Email string `json:&quot;email&quot; xml:&quot;email&quot; form:&quot;email&quot; query:&quot;email&quot;`\n}\n \ne.POST(&quot;/users&quot;, func(c echo.Context) error {\n    u := new(User)\n    if err := c.Bind(u); err != nil {\n        return err\n    }\n    return c.JSON(http.StatusCreated, u)\n    // 或者\n    // return c.XML(http.StatusCreated, u)\n})\n静态资源\n下面的代码定义/static/*目录为静态资源文件目录\ne.Static(&quot;/static&quot;, &quot;static&quot;)\n路由\n基于基数树（Radix Tire），Echo 的路由查询速度非常快。路由使用 sync pool 来重用内存，实现无 GC 开销下的零动态内存分配。\n匹配所有\n匹配零个或多个字符的路径。例如， /users/* 将会匹配：\n\n/users/\n/users/1\n/users/1/files/1\n/users/anything...\n\n路径匹配顺序\n\nStatic (固定路径)\nParam (参数路径)\nMatch any (匹配所有)\n\ne.GET(&quot;/users/:id&quot;, func(c echo.Context) error {\n    return c.String(http.StatusOK, &quot;/users/:id&quot;)\n})\n \ne.GET(&quot;/users/new&quot;, func(c echo.Context) error {\n    return c.String(http.StatusOK, &quot;/users/new&quot;)\n})\n \ne.GET(&quot;/users/1/files/*&quot;, func(c echo.Context) error {\n    return c.String(http.StatusOK, &quot;/users/1/files/*&quot;)\n})\n上面定义的路由将按下面的优先级顺序匹配:\n\n/users/new\n/users/:id\n/users/1/files/*\n\n组路由\nEcho#Group(prefix string, m ...Middleware) *Group\n\n可以将具有相同前缀的路由归为一组从而定义具有可选中间件的新子路由。除了一些特殊的中间件外，组路由也会继承父中间件。若要在组路由中添加中间件，则需使用 Group.Use(m ...Middleware) 。最后，组路由也可以嵌套。\n下面的代码，我们创建了一个 admin 组，它需要对 /admin/* 路由进行基本的 HTTP 身份认证。\ng := e.Group(&quot;/admin&quot;)\ng.Use(middleware.BasicAuth(func(username, password string) bool {\n    if username == &quot;joe&quot; &amp;&amp; password == &quot;secret&quot; {\n        return true\n    }\n    return false\n}))\ng.GET(&quot;/users/:id&quot;, userHander)\ng.POST(&quot;/login&quot;, authHander)\n路由命名\n每个路由都会返回一个 Route 对象，这个对象可以用来给路由命名。比如：\nrouteInfo := e.GET(&quot;/users/:id&quot;, func(c echo.Context) error {\n    return c.String(http.StatusOK, &quot;/users/:id&quot;)\n})\nrouteInfo.Name = &quot;user&quot;\n \n// 或者这样写\ne.GET(&quot;/users/new&quot;, func(c echo.Context) error {\n    return c.String(http.StatusOK, &quot;/users/new&quot;)\n}).Name = &quot;newuser&quot;\n当你需要在模版生成 uri 但是又无法获取路由的引用，或者多个路由使用相同的处理器(handler)的时候，路由命名就会显得更方便。\n构造URI\nEcho#URI(handler HandlerFunc, params ...interface{}) 可以用来在任何业务处理代码里生成带有特殊参数的URI。这样在你重构自己的应用程序的时候，可以很方便的集中处理所有的 URI 。\n// 业务处理\nh := func(c echo.Context) error {\n    return c.String(http.StatusOK, &quot;OK&quot;)\n}\n// 路由\ne.GET(&quot;/users/:id&quot;, h)\n \nurl := e.URI(h, 1)\nfmt.Println(url)\t// &#039;/users/1&#039;\n除了 Echo#URI，还可以使用 Echo#Reverse(name string, params ...interface{}) 方法根据路由名生成 uri。比如，当 foobar 进行如下设置时，使用 Echo#Reverse(&quot;foobar&quot;, 1234) 就会生成 /users/1234 ：\n// Handler\nh := func(c echo.Context) error {\n    return c.String(http.StatusOK, &quot;OK&quot;)\n}\n// Route\ne.GET(&quot;/users/:id&quot;, h).Name = &quot;foobar&quot;\n \nurl := e.Reverse(&quot;foobar&quot;, 1)\nfmt.Println(url)\t// &#039;/users/1&#039;\n中间件\n中间件是一个函数，嵌入在HTTP 的请求和响应之间。它可以获得 Echo#Context 对象用来进行一些特殊的操作， 比如记录每个请求或者统计请求数。\nAction 的处理在所有的中间件运行完成之后。\n中间件分为根级，组级，和路由级中间件\nRoot Level (Before router)\nEcho#Pre() 用于注册一个在路由执行之前运行的中间件，可以用来修改请求的一些属性。比如在请求路径结尾添加或者删除一个’/‘来使之能与路由匹配。\n下面的这几个内建中间件应该被注册在这一级别：\n\nAddTrailingSlash\nRemoveTrailingSlash\nMethodOverride\n\n注意: 由于在这个级别路由还没有执行，所以这个级别的中间件不能调用任何 echo.Context 的 API。\nRoot Level (After router)\n大部分时间你将用到 Echo#Use() 在这个级别注册中间件。 这个级别的中间件运行在路由处理完请求之后，可以调用所有的 echo.Context API。\n下面的这几个内建中间件应该被注册在这一级别：\n\nBodyLimit\nLogger\nGzip\nRecover\nBasicAuth\nJWTAuth\nSecure\nCORS\nStatic\n\nGroup Level\n当在路由中创建一个组的时候，可以为这个组注册一个中间件。例如，给 admin 这个组注册一个 BasicAuth 中间件。\ne := echo.New()\nadmin := e.Group(&quot;/admin&quot;, middleware.BasicAuth())\n也可以在创建组之后用 admin.Use()注册该中间件。\nRoute Level\n当你创建了一个新的路由，可以选择性的给这个路由注册一个中间件。\ne := echo.New()\ne.GET(&quot;/&quot;, &lt;Handler&gt;, &lt;Middleware...&gt;)"},"golang/wheel/orm/REDAME":{"title":"REDAME","links":[],"tags":[],"content":"Binary was compiled with ‘CGO_ENABLED=0’, go-sqlite3 requires cgo to work. This is a stub\n编译二进制文件时，未开启 CGO，也就是这个环境变量，因为 go-sqlite3 依赖 cgo，需要 C 环境才行，Windows上面默认是没有 gcc 的，安装即可：sourceforge.net/projects/mingw-w64/files/；\n然后修改环境变量：$ go env -w CGO_ENABLED=1"},"index":{"title":"index","links":[],"tags":[],"content":"Today-I-Learned\n📝 Today I Learned - A list of all things I learn on daily basis."},"linux/Kernel-工程结构":{"title":"Kernel 工程结构","links":[],"tags":[],"content":"Kernel 工程结构\n内核源码目录如下：\narch         COPYING        drivers   init     kernel       make_deb.sh  README    sound\nblock        CREDITS        firmware  ipc      lib          Makefile     samples   tools\nbuild_image  crypto         fs        Kbuild   LICENSES     mm           scripts   usr\ncerts        Documentation  include   Kconfig  MAINTAINERS  net          security  virt\n\narch ：主要包含和硬件体系结构相关的代码，如arm、x86、MIPS，PPC，每种CPU平台占一个相应的目录。arch中的目录下存放的是各个平台以及各个平台的芯片对Linux内核进程调度、内存管理、 中断等的支持，以及每个具体的SoC和电路板的板级支持代码。\nblock ：在Linux中block表示块设备（以块（多个字节组成的整体，类似于扇区）为单位来整体访问），譬如说SD卡、Nand、硬盘等都是块设备，block目录下放的是一些Linux存储体系中关于块设备管理的代码。\ncrypto ：这个目录下存放的是常用加密和散列算法（如md5、AES、 SHA等），还有一些压缩和CRC校验算法。\nDocumentation：内核各部分的文档描述。\ndrivers ：设备驱动程序，里面列出了linux内核支持的所有硬件设备的驱动源代码，每个不同的驱动占用一个子目录，如char、block、 net、 mtd、 i2c等。\nfs ：fs就是file system，里面包含Linux所支持的各种文件系统，如EXT、FAT、 NTFS、 JFFS2等。\ninclude ：包括编译核心所需要的大部分头文件，例如与平台无关的头文件在 include/linux 子目录下，与 cpu 架构相关的头文件在include目录下对应的子目录中。\ninit ：内核初始化代码，这个目录下的代码就是linux内核启动时初始化内核的代码。\nipc ：即 inter process commuication ，进程间通信，该目录下都是linux进程间通信的代码。\nkernel ：kernel 就是Linux内核，是Linux中最核心的部分，包括进程调度、定时器等，而和平台相关的一部分代码放在arch/*/kernel目录下。\nlib ：存放的都是一些公用的有用的库函数，注意这里的库函数和C语言的库函数不一样的，因为在内核编程中是不能用C语言标准库函数的，所以需要使用lib中的库函数，除此之外与处理器结构相关的库函数代码被放在 arch/*/lib/ 目录下。\nmm ： 包含了所有独立于 cpu 体系结构的内存管理代码，如页式存储管理内存的分配和释放等，而与具体硬件体系结构相关的内存管理代码位于 arch/*/mm 目录下，例如 arch/arm/mm/fault.c 。\nnet ： 网络协议栈相关代码，net 目录下实现各种常见的网络协议。\nscripts ：这个目录下全部是脚本文件，这些脚本文件不是linux内核工作时使用的，而是用了配置编译linux内核的。\nsecurity ：内核安全模型相关的代码，例如最有名的 SELINUX。\nsound ： ALSA、 OSS音频设备的驱动核心代码和常用设备驱动。\nusr ： 实现用于打包和压缩的 cpio 等。\n"},"linux/Linux-系统构成":{"title":"Linux 系统构成","links":[],"tags":[],"content":"Linux 系统构成\n一个完整的 linux 系统，通常包含了 Uboot、kernel、设备树以及根文件系统。\nUboot\nU-Boot 是一个主要用于嵌入式系统的引导加载程序，可以支持多种不同的计算机系统结构，包括PPC、ARM、AVR32、MIPS、x86、68k、Nios 与 MicroBlaze。\nUboot 的全称 Universal Boot Loader，是遵循 GPL 条款的开源项目， U-Boot 的主要作用是用来启动操作系统内核，它分为两个阶段，即 boot + loader：\n\nboot 阶段启动系统，初始化硬件设备，建立内存空间映射图，将系统的软硬件带到一个合适的状态；\nloader 阶段将操作系统内核文件加载至内存，之后跳转到内核所在地址运行。\n\nBootloader\nPC 机上引导程序一般由 BIOS 开始执行，然后读取硬盘中位于 MBR(Main Boot Record，主引导记录)中的 Bootloader (例如 LILO 或 GRUB)，并进一步引导操作系统的启动。\nPC 机的 BootLoader 的主要运行任务就是将内核映象从硬盘上读到 RAM 中，然后跳转到内核的入口点去运行，即开始启动操作系统。\n嵌入式系统中通常没有像 BIOS 那样的固件程序，因此整个系统的加载启动就完全由 Bootloader 来完成，它主要的功能是加载与引导内核映像。\n一般来说，BootLoader 是一段小程序，在系统上电时执行，是基于特定硬件平台来实现的，因此几乎不可能为所有的嵌入式系统建立一个通用的Bootloader，不同的处理器架构都有不同的 Bootloader，其不但依赖于cpu的体系结构，还依赖于嵌入式系统板级设备的配置。\nLinux Kernel\nLinux 是一种开源电脑操作系统内核，是一个用 C 语言写成，符合POSIX标准的类 Unix 操作系统。\nLinux 内核的主要模块（或组件）分以下几个部分：进程管理子系统、内存管理子系统、文件子系统、网络子系统、设备子系统等。\n\nDevice Tree\nDevice Tree 设备树是一种用于描述硬件的数据结构和语言。更确切地说，它是一种操作系统可读的硬件描述，这样操作系统就不需要对机器的细节进行硬编码。\n它以可读性强的文本方式，将硬件的层次结构、设备的属性和资源配置等信息整合到一个统一的文档中，促使不同硬件平台之间可以共享相同的内核代码。\n设备树包括设备树源码（Device Tree Source，DTS）文件、 设备树编译工具（Device Tree Compiler，DTC）与二进制格式设备树（Device Tree Blob，DTB）， DTS包含的头文件格式为DTSI。\nnode1 {\n   a-string-property = &quot;A string&quot;;\n   a-string-list-property = &quot;first string&quot;, &quot;second string&quot;;\n   a-byte-data-property = [0x01 0x23 0x34 0x56];\n \n   child-node1 {\n      first-child-property;\n      second-child-property = &lt;1&gt;;\n      a-string-property = &quot;Hello, world&quot;;\n   };\n};\nUboot和Linux不能直接识别DTS文件，而DTB可以被内核与BootLoader识别解析， 通常在制作NAND Flash、SD Card启动镜像时，通常会为DTB文件留下一部分存储区域以存储DTB， 在BootLoader启动内核时，会先读取DTB到内存，再提供给内核使用。\n\nrootfs\nrootfs 根文件系统是linux在初始化时加载的第一个文件系统， 根文件系统包括根目录和真实文件系统，它包含系统引导和使其他文件系统得以挂载（mount）所必要的文件。\n根文件系统包函Linux启动时所必须的目录和关键性的文件，例如Linux启动时必要的初始化文件， 它在init目录下。此外根文件系统中还包括了许多的应用程序bin目录等， 任何包括这些Linux 系统启动所必须的文件都可以成为根文件系统。\n在Linux内核启动的初始阶段，首先内核会初始化一个基于内存的文件系统，如initramfs，initrd等，然后以只读的方式去加载根文件系统（load rootfs）， 读取并且运行/sbin/init初始化文件，根据/etc/inittab配置文件完成系统的初始化工作 （/sbin/init是一个二进制可执行文件，为系统的初始化程序，而/etc/inittab是它的配置文件）， 在初始化的过程中，还会以读写的方式重新挂载根文件系统，在系统启动后， 根文件系统就可用于存储数据了，存在根文件系统是Linux启动时的必要条件。\n常见的根文件系统制作工具有 buildroot、Ubuntu、Debian、yocto、busybox。"},"linux/设备树":{"title":"设备树","links":[],"tags":[],"content":"常见的几个DT\n\nDTS 是指.dts格式的文件，是一种 ASII 文本格式的设备树描述，也是我们要编写的设备树源码，一般一个.dts文件对应一个硬件平台。在Linux源码的“arch/arm64/boot/dts/”目录下又根据芯片厂商进行分类。\nDTSI 是指由芯片厂商提供，是同一芯片平台“共用”的设备树文件。\nDTC 是指编译设备树源码的工具，一般情况下我们需要手动安装这个编译工具。\nDTB 是设备树源码编译生成的文件，类似于我们C语言中“.C”文件编译生成“.bin”文件。\nDTBO 是设备树叠加层编译生成的文件，可以对DTB进行叠加补充。\n"},"nodejs/EventLoop/event-loop-1":{"title":"event-loop-1","links":[],"tags":[],"content":"原文地址：Event Loop and the Big Picture — NodeJS Event Loop Part 1, Deepal Jayasekara, Apr 23, 2017\n处理 I/O 的不同方式使得 Node.js 区别于其他的编程平台。\n我们常常听到别人在介绍 Node.js 时说 “一个基于 google v8 JavaScript 引擎的非阻塞，事件驱动的平台”。这句话究竟意味着什么？\n“非阻塞” 和 “事件驱动” 是什么意思？所有这些问题的答案涉及到 NodeJs 的核心，事件循环。\n在这个系列中，我会阐释什么是事件循环，它是如何工作的，它如何影响我们的应用，如何有效使用等等。在这篇文章中，我将讲解 NodeJs 如何工作，如何访问 I/O，如何跨平台工作等等。\n反应器模式 （Reactor Pattern）\nNodeJS 在一个事件驱动的模型中工作，其中涉及到一个事件多路分用器（Event Demultiplexer） 和一个事件队列（Event Queue）。所有的 I/O 请求最终会生成一个或成功或失败或其他触发器的事件（Event）。事件通过下面的算法进行处理：\n\n事件多路分用器接受 I/O 请求并将这些请求委托给对应的硬件。\n当 I/O 请求被处理时（例如：一个文件里的数据可以被读取，一个 socket 的数据可以被读取等），事件多路分用器将该特定动作的回调处理器添加到一个待处理的队列中。这些回调被称为事件，事件添加的队列被称为事件队列。\n当事件队列中存在待处理的事件时，它们会按入队的顺序依次执行，直到队列为空。\n如果事件队列中没有待处理的事件或者事件多路分用器没有挂起的请求，程序会结束。否则，又会从第一步重新开始。\n\n协调整个机制的程序被称为事件循环（Event Loop）。\n\n事件循环是单线程和半无限的循环。因为它在没有更多的工作要做时会在一些时间点退出，这就是为什么称为半无限循环的原因。在开发者的视角，这就是程序退出的地方。\n\n注意：不要将事件循环和 NodeJs 的 EventEmitter 混淆。EventEmitter 跟事件循环相比完全是另一个不同的概念。\n\n上面的图解是 NodeJs 如何工作的一个高层次概述，展示了一种被称作反应器模式的设计模式的主要组件。但是实际情况比这个要复杂的多，到底有多复杂呢？\n\n事件多路分发器不是在所有系统平台上处理所有 I/O 的单一组件。\n事件队列并不像图中展示的那样是一个所有事件都入队和出队的单独队列。并且 I/O 不是唯一入队的事件类型。\n\n因此，让我们更深入些。\n事件多路分发器 (Event Demultiplexer)\n事件多路分发器不是一个在真实世界中存在的组件，而是反应器模式中的一个抽象概念。\n现实世界中，事件多路分发器在不同的系统中有不同的实现。比如在 Linux 中的 epoll ，BSD（MacOS）系统中的 kqueue ，Solaris 中的 event ports ，windows 中的 **IOCP（Input Output Completion Port）**等等。NodeJS 利用这些实现提供的底层非阻塞，异步的硬件 I/O 能力。\n文件 I/O 的复杂性\n但令人烦心的是，并不是所有类型的 I/O 都可以使用这些实现执行。即使在同一操作系统平台，对不同类型的 I/O 的支持也十分复杂。\n典型的例子，网络 I/O 使用 epoll，kqueue，events ports 和 IOCP 可以以非阻塞的方式执行。但是文件 I/O 则不一定。特定的系统，如 Linux 不支持完全的异步访问文件系统。并且在 MacOS 系统上 kqueue 的文件系统事件通知/信号有很多限制 (更多相关介绍)。情况复杂到以至于几乎不可能同时处理所有文件系统的复杂度来提供完整的异步功能。\nDNS 的复杂性\n与文件 I/O 相似，Node API 提供的 DNS 函数也有一定的复杂性。因为 NodeJS DNS 函数如 dns.lookup，会访问系统配置文件如 nsswitch.conf，resolve.conf 和 /etc/hosts，之前提到的文件系统的复杂性也适用于 dns.lookup 函数。\n因此，引入了一个线程池来提供不能被硬件异步 I/O 工具（epoll/kqueue/event ports/IOCP）直接支持的 I/O 功能。现在我们知道并不是所有的 I/O 功能发生在线程池。NodeJS 尽最大的努力使用非阻塞和异步硬件 I/O 来处理大部分的 I/O 工作，但是对于那些阻塞或者处理起来很复杂的 I/O，则使用线程池。\n\n但是 I/O 不是线程池唯一处理的任务。Node.js 的部分 crypto 功能如 crypto.pbkdf2，异步版本的 crypto.randomBytes，crypto.randomFill，异步版本的 zlib 也运行在 libuv 的线程池。因为它们属于 CPU 密集型工作，在线程池工作能够避免阻塞事件循环。\n\n把他们拼在一起\n正如我们看到的，实际世界中，在所有不同操作系统平台支持所有不同类型的 I/O（文件 I/O，网络 I/O，DNS 等）非常困难。一部分 I/O 可以使用原生硬件实现执行，同时保留完整的异步，另外一部分类型的 I/O 则需要在线程池中执行以保证异步特性。\n\nNode 开发者中，一个普遍的误解是 Node 在线程池中处理所有的 I/O。\n\n为了管理整个过程同时支持跨平台的 I/O，应该有一个抽象层封装了平台间和平台内的复杂度，并且为 Node 提供上层通用 API。\n那么是谁呢？女士们，先生们，有请 libuv!\n\nlibuv is cross-platform support library which was originally written for NodeJS. It’s designed around the event-driven asynchronous I/O model.\n\n\nThe library provides much more than a simple abstraction over different I/O polling mechanisms: ‘handles’ and ‘streams’ provide a high level abstraction for sockets and other entities; cross-platform file I/O and threading functionality is also provided, amongst other things.\n\n让我们看下 libuv 的组成。下面的图表来自于官方文档，描述了暴露出的通用 API 处理了哪些不同类型的 I/O。\n\n现在我们知道事件多路分发器，不是一个原子（不可分割）的实体，而是一个被 Libuv 抽象出的处理 I/O 过程的 APIs 集合，暴露给 NodeJS 的上层使用。libuv 除了提供事件多路分发器给 Node，它还为 NodeJS 提供了完整的事件循环功能，包含事件队列机制。\n现在让我们看下事件队列。\n事件队列\n事件队列按理说是一个所有的事件入队，然后事件循环按顺序处理，直到队列为空的数据结构。但是在 Node 中实际发生的和反应器模式描述的完全不同。所以差异在哪？\n\nNodeJS 中不止一个队列，不同类型的事件会在它们自己的队列中入队。\n在处理完一个阶段后，移向下一个阶段之前，事件循环将会处理两个中间队列，直到两个中间队列为空。\n\n那么总共有多少个队列呢？中间队列又是什么？\n有 4 个主要类型的队列，被原生的 libuv 事件循环处理。\n\nExpired timers and intervals Queue - 使用 setTimeout 添加的过期计时器的回调或者使用 setInterval 添加的间隔函数。\nIO Events Queue -  完成的 I/O 事件\nImmediate queue- 使用 setImmediate 函数添加的回调\nClose Handlers Queue- 任何一个 close 事件处理器。\n\n\n注意，尽管我在这里为方便说 “队列”，但它们中的一些实际上有不同类型的数据结构（timers 被存储在最小堆里）\n\n除了四个主要的队列，这里另外有两个我之前提到的 “中间队列”，它们被 Node 处理。这些队列不是 libuv 的一部分，而是 NodeJS 的一部分。它们分别是：\n\nNext Ticks Queue - 使用 process.nextTick() 函数添加的回调\nother Microtasks Queue - 包含其他微任务如成功( resolved )的 Promise 回调\n\n它是如何工作的？\n正如你在下面图表中所见，Node 开始事件循环先检查 timers 队列中是否有任何过期的 timers，然后在每个步骤中处理每个队列，同时保持对所有待处理对象的引用计数器。处理完 close handlers 队列，如果在所有的队列中没有要处理的项，而且也没有挂起的操作，那么循环将会退出。\n在事件循环中每个队列的处理过程可以看做事件循环的一个阶段。\n\n有趣的是被描绘成红色的中间队列，只要一个阶段结束，事件循环将会检查这两个中间阶段是否有要处理的项。如果有，事件循环会立马开始处理它们直到两个队列为空。一旦为空，事件循环就移到下一个阶段。\n\n例如，事件循环当前处理有着 5 个事件处理器的 immediate queue。同时，两个处理器回调被添加到 next tick queue。一旦事件处理器完成 immediate queue 中的 5 个事件处理器，事件循环将会在移到 close handlers 队列之前，检测到 next tick queue 里面有两个要处理的项。然后事件处理器会处理完 next tick queue 里面的处理器。然后移到 close handlers 队列。\n\nNext tick queue vs Other Microtasks\nnext tick queue 比 other micotasks 有着更高的优先级。当在一个阶段的结尾时 libuv 传递控制权给 Node 的高层，此时这两个队列都在事件循环的两个阶段之间被处理。你应该注意到我用暗红色来表示 next tick queue，这意味着在开始处理 promise 的微队列之前，next tick queue 是空的。\n\nnext tick queue 的优先级比 promise 的高仅仅适合于 V8 提供的原生 JS 提供的 promise。如果你使用 q 库或者 bluebird，你将会观察到一个不同的结果，因为它们早于原生的 promise，有不同的语义。q 和 bluebird 处理 promise 也有不同的方式，后面的文章我会解释。\n\n这些所谓的中间队列的协定引入了一个新的问题，IO starvation (IO 饥饿)。广泛的使用 process.nextTick 填充 next tick queue 将会强迫事件循环处理 next tick queue 而不前进。这将会导致 IO 饥饿，因为 next tick queue 未被清空前事件循环不能继续。\n\n为了防止这种清空，这里有一个 next tick queue 的最大限制，可以使用 procsess.maxTickDepth 参数设置，但是因为某些原因，已经从 NodeJS v0.12 移除了。。\n\n最后，你知道了什么是事件循环，如何实现的和 Node 处理异步 I/O。让我们看下 Libuv 在 NodeJS 架构中的位置；\n"},"nodejs/EventLoop/event-loop-2":{"title":"event-loop-2","links":[],"tags":[],"content":"原文地址：Timers, Immediates and Process.nextTick— NodeJS Event Loop Part 2, Deepal Jayasekara, May 11, 2017\n在上篇文章中，我讲述了 NodeJS 事件循环的总体图景。这篇文章中，我将详细讨论三个重要的队列：timers, immediates and process.nextTick 回调。\nNext Tick Queue\n\nNext tick 队列与其他 4 个主要队列分隔开，是因为它不是 libuv 原生提供的，而是 Node 自己实现的。\n事件循环中要移动到一个阶段前（timers queue, IO events queue, immediates queue, close handlers queue 是 4 个主要的阶段），Node 会检查 nextTick 队列是否为空。如果不为空，Node 会一直处理该队列直到不为空。\n\nNode v11 引入了一些变化，导致巨大的行为差异。详细介绍见: medium.com/@dpjayasekara/new-changes-to-timers-and-microtasks-from-node-v11-0-0-and-above-68d112743eb3\n\n这引入了一个问题：通过 process.nextTick 递归或重复添加事件到 nextTick 队列会导致 I/O 和其他队列一直无法被处理。以下代码为例：\nconst fs = require(&#039;fs&#039;);\n \nfunction addNextTickRecurs(count) {\n    let self = this;\n    if (self.id === undefined) {\n        self.id = 0;\n    }\n \n    if (self.id === count) return;\n \n    process.nextTick(() =&gt; {\n        console.log(`process.nextTick call ${++self.id}`);\n        addNextTickRecurs.call(self, count);\n    });\n}\n \naddNextTickRecurs(Infinity);\nsetTimeout(console.log.bind(console, &#039;omg! setTimeout was called&#039;), 10);\nsetImmediate(console.log.bind(console, &#039;omg! setImmediate also was called&#039;));\nfs.readFile(__filename, () =&gt; {\n    console.log(&#039;omg! file read complete callback was called!&#039;);\n});\n \nconsole.log(&#039;started&#039;);\n你将看到输出中没有 ‘omg!…’， 全是 nextTick 回调的无限循环，而 setTimeout, setImmediate 和 fs.readFile 回调永远不会被调用；\n\nNode v0.12 之前，有一个属性 process.maxTickDepth 用于限制 process.nextTick 队列的长度。当它被手动设置后，Node 一次只会处理 next tick queue 中不多于 maxTickDepth 的回调。但这个属性在 Node v0.12 中被移除。因此，在更新版本的 Node 中，应避免重复添加事件到 next tick queue。\n\nTimers queue\n当你使用 setTimeout 或 setInterval 时，Node 将会添加计时器到 libuv 的计时器堆。事件循环中轮到计时器阶段时，Node 将会检查计时器堆中过期的计时器，并按它们设置的先后顺序依次调用它们的回调。\n计时器并不能精确保证回调会在过期时间到时被执行。计时器回调的执行时机取决于操作系统（Node 必须在执行回调前检查计时器的过期时间，而这一过程会消耗一定的 CPU 时间）和事件循环中当前进程的表现。更准确地说，计时器保证的是回调不会在过期时间未到前被执行。我们可以用以下代码来模拟这种情况\nconst start = process.hrtime();\n \nsetTimeout(() =&gt; {\n    const end = process.hrtime(start);\n    console.log(`timeout callback executed after ${end[0]}s and ${end[1]/Math.pow(10,9)}ms`);\n}, 1000);\n上述代码在程序开始时设置一个过期时间为 1 秒的计时器，并打印到实际执行回调用了多长时间。如果你多次运行这段代码，你将注意到它每次都会打印不同的结果，并且永远不会打印 timeout callback executed after 1s and 0ms。你将看到类似下面的结果。\ntimeout callback executed after 1s and 0.006058353ms\ntimeout callback executed after 1s and 0.004489878ms\ntimeout callback executed after 1s and 0.004307132ms\n...\n\n这种超时的本质导致当 setTimeout 与 setImmediate 一起使用时会有意想不到的结果。我将在后面章节详细讲述。\nImmediates Queue\n虽然 immediates 队列和计时器过期的行为非常相似，但它有自己的特点。不像计时器我们无法保证它的回调什么时候被执行（即使把过期时间设为 0），immediates 队列保证了它会在事件循环的 **I/O 阶段后立即被处理。**通过 setImmediate 可以向 immediates 队列添加事件。\nsetImmediate(() =&gt; {\n   console.log(&#039;Hi, this is an immediate&#039;);\n});\nsetTimeout vs setImmediate ?\n让我们看看文章开头的事件循环图，你会看到当程序开始时 Node 从处理计时器队列开始，处理完 I/O 后再轮到 immediates 队列。根据图上的逻辑，我们可以推测以下代码的输出。\nsetTimeout(function() {\n    console.log(&#039;setTimeout&#039;)\n}, 0);\nsetImmediate(function() {\n    console.log(&#039;setImmediate&#039;)\n});\n你会推测上面的代码总是会先打印 setTimeout 再打印 setImmediate，因为过期计时器队列比 immediates 先处理。但实际这段代码无法保证这样的输出结果。你多次运行这段代码，会得到不同的输出结果。\n这是因为 NodeJS 为了对齐 Chrome’s timers cap，把最小过期时间定为 1ms。所以即使你把过期时间设为 0ms，会被覆盖为 1ms。\n\n如果你想知道更多这一点上 Node 和不同浏览器的行为差异，请看 javascript-event-loop-vs-node-js-event-loop\n\n每次新的事件循环开始时，NodeJS 通过系统调用获得当前时钟。根据 CPU 的繁忙情况，获取当前时钟的操作耗时可能不超过也可能超过 1ms。如果少于 1ms，NodeJS 将认为这个计时器还没过期，因为过期时间是 1ms，这时事件循环会移动到 I/O 阶段再到 immediates 队列，然后发现队列中有一个事件并进行处理，也就意味着 setImmediate 比 setTimeout 先执行。但如果耗时超过 1ms，计时器就会被认为已过期，执行顺序结果相反。\n下面中代码保证了 immediate 一定会比计时器的先执行。\nconst fs = require(&#039;fs&#039;);\n \nfs.readFile(__filename, () =&gt; {\n    setTimeout(() =&gt; {\n        console.log(&#039;timeout&#039;)\n    }, 0);\n    setImmediate(() =&gt; {\n        console.log(&#039;immediate&#039;)\n    })\n});\n让我们看看上述代码的执行流程\n\n开始，程序异步读取文件，并提供一个处理文件读取完毕的回调。\n事件循环开始\n当文件读取完毕，执行回调作为一个事件添加到 I/O 队列\n因为没有其他事件，Node 会一直等待 I/O 事件，然后发现 I/O 队列有一个事件，开始执行回调\n执行回调过程中，一个计时器添加到计时器堆，一个 immediate 添加到 immediate 队列\n现在事件循环正处在 I/O 阶段，因为没有要处理的 I/O 事件，事件循环会移动到 immediate 阶段，发现有一个 immediate 回调，然后 immediate 回调被执行\n下一轮事件循环发现有一个过期的计时器，然后执行计时器回调\n\n结论\n看看事件循环中不同阶段 / 队列如何一起工作，以下面的代码为例\nsetImmediate(() =&gt; console.log(&#039;this is set immediate 1&#039;));\nsetImmediate(() =&gt; console.log(&#039;this is set immediate 2&#039;));\nsetImmediate(() =&gt; console.log(&#039;this is set immediate 3&#039;));\n \nsetTimeout(() =&gt; console.log(&#039;this is set timeout 1&#039;), 0);\nsetTimeout(() =&gt; {\n    console.log(&#039;this is set timeout 2&#039;);\n    process.nextTick(() =&gt; console.log(&#039;this is process.nextTick added inside setTimeout&#039;));\n}, 0);\nsetTimeout(() =&gt; console.log(&#039;this is set timeout 3&#039;), 0);\nsetTimeout(() =&gt; console.log(&#039;this is set timeout 4&#039;), 0);\nsetTimeout(() =&gt; console.log(&#039;this is set timeout 5&#039;), 0);\n \nprocess.nextTick(() =&gt; console.log(&#039;this is process.nextTick 1&#039;));\nprocess.nextTick(() =&gt; {\n    process.nextTick(console.log.bind(console, &#039;this is the inner next tick inside next tick&#039;));\n});\nprocess.nextTick(() =&gt; console.log(&#039;this is process.nextTick 2&#039;));\nprocess.nextTick(() =&gt; console.log(&#039;this is process.nextTick 3&#039;));\nprocess.nextTick(() =&gt; console.log(&#039;this is process.nextTick 4&#039;));\n执行上面的代码后，以下事件被添加到对应的事件循环队列\n\n3 immediates\n5 timer callbacks\n5 next tick callbacks\n\n执行流程是这样：\n\n事件循环开始，发现 next tick 队列不为空，开始处理 next tick callbacks。执行第二个 next tick callback 时一个新的 next tick callback 添加到队列末尾，并在最后被执行。\n执行计时器队列中过期的计时器。执行第二个计时器回调时，一个新的 next tick callback 添加到 next tick 队列。\n当所有过期计时器执行完，事件循环检查 next tick 队列有一个事件并执行。\n因为没有 I/O 事件，事件循环移动到 immediates 阶段开始处理 immediates 队列。\n\n代码运行结果如下\nthis is process.nextTick 1\nthis is process.nextTick 2\nthis is process.nextTick 3\nthis is process.nextTick 4\nthis is the inner next tick inside next tick\nthis is set timeout 1\nthis is set timeout 2\nthis is set timeout 3\nthis is set timeout 4\nthis is set timeout 5\nthis is process.nextTick added inside setTimeout\nthis is set immediate 1\nthis is set immediate 2\nthis is set immediate 3\n"},"nodejs/EventLoop/event-loop-3":{"title":"event-loop-3","links":[],"tags":[],"content":"原文地址：Promises, Next-Ticks, and Immediates— NodeJS Event Loop Part 3, Deepal Jayasekara, Jul 22, 2017\n上篇文章讲述了事件循环中的计时器，immediates 和每个队列如何按顺序执行。\n这篇文章将关注事件循环如何处理 resolved/rejected promises (包括原生的 JS promises, Q promises, 和 Bluebird promises) 和 next tick 回调。如果你对 Promises 不熟悉，建议你先对 Promises 进行初步了解。\n原生 Promises\n\nNode v11 引入了一些变化，对 nextTick，Promise，setImmediate 和 setTimeout 回调的执行顺序有巨大影响。详细介绍见 medium.com/@dpjayasekara/new-changes-to-timers-and-microtasks-from-node-v11-0-0-and-above-68d112743eb3\n\n原生 promise 的回调被认为是一种微任务，并被添加到 microtask 队列，并紧接着 next tick 队列被处理。\n\nPromise.resolve().then(() =&gt; console.log(&#039;promise1 resolved&#039;));\nPromise.resolve().then(() =&gt; console.log(&#039;promise2 resolved&#039;));\nPromise.resolve().then(() =&gt; {\n    console.log(&#039;promise3 resolved&#039;);\n    process.nextTick(() =&gt; console.log(&#039;next tick inside promise resolve handler&#039;));\n});\nPromise.resolve().then(() =&gt; console.log(&#039;promise4 resolved&#039;));\nPromise.resolve().then(() =&gt; console.log(&#039;promise5 resolved&#039;));\nsetImmediate(() =&gt; console.log(&#039;set immediate1&#039;));\nsetImmediate(() =&gt; console.log(&#039;set immediate2&#039;));\n \nprocess.nextTick(() =&gt; console.log(&#039;next tick1&#039;));\nprocess.nextTick(() =&gt; console.log(&#039;next tick2&#039;));\nprocess.nextTick(() =&gt; console.log(&#039;next tick3&#039;));\n \nsetTimeout(() =&gt; console.log(&#039;set timeout&#039;), 0);\nsetImmediate(() =&gt; console.log(&#039;set immediate3&#039;));\nsetImmediate(() =&gt; console.log(&#039;set immediate4&#039;));\n以上代码的执行流程：\n\n5 个处理器添加到 resolved promises 微任务队列\n2 个处理器添加到 setImmediate 队列\n3 个 处理器添加到 process.nextTick 队列\n1 个 计时器添加到计时器队列\n2 个处理器添加到 setImmediate 队列\n\n事件循环开始：\n\n发现和处理 process.nextTick 队列中 3 个待处理项\n发现和处理 promises 微任务队列中 5 个待处理项\n处理 promises 微任务队列过程中一个新的待处理项添加到 process.nextTick 队列\npromises 微任务队列处理完后发现 process.nextTick 队列有一个待处理项，开始处理\nprocess.nextTick 队列和 promises 微任务队列都为空后，移动到计时器队列，有 1 个过期计时器待处理，进行处理\n无过期计时器待处理后，移动到 I/O 阶段，因为没有挂起的 I/O，继续移动到 setImmediate 队列处理 4 个待处理项\n最后循环处理完所有事情，程序退出\n\n\n为什么是 “promises microtask” 而不是 “microtask”？resolved/rejected promises 和 process.nextTick 都是微任务 microtask。\n\n代码输出如下：\nnext tick1\nnext tick2\nnext tick3\npromise1 resolved\npromise2 resolved\npromise3 resolved\npromise4 resolved\npromise5 resolved\nnext tick inside promise resolve handler\nset timeout\nset immediate1\nset immediate2\nset immediate3\nset immediate4\n\nQ 和 Bluebird\n我们现在知道 JS 原生 promises 的 resolve/reject 回调会被当作微任务进行调度，并在每个阶段前被处理。Q 和 Bluebird 又是怎样？\nNodeJS 实现原生 promises 前，人们使用 Q 和 Bluebird。因为 Q 和 Bluebird 先于原生 promises，它们有与原生 promises 不同的语义。\n写这篇文件时， Q (v1.5.0) 使用 process.nextTick 队列来调度resolved/rejected promises 的回调。根据 Q 的文档：\n\nNote that resolution of a promise is always asynchronous: that is, the fulfillment or rejection handler will always be called in the next turn of the event loop (i.e. process.nextTick in Node). This gives you a nice guarantee when mentally tracing the flow of your code, namely that then will always return before either handler is executed.\n\n另一方面，Bluebird (v3.5.0) 默认使用 setImmediate 来调度 resolved/rejected promises 的回调，代码见 这里。\n为了更清楚地认识，我们以下面的代码为例：\nconst Q = require(&#039;q&#039;);\nconst BlueBird = require(&#039;bluebird&#039;);\n \nPromise.resolve().then(() =&gt; console.log(&#039;native promise resolved&#039;));\nBlueBird.resolve().then(() =&gt; console.log(&#039;bluebird promise resolved&#039;));\nsetImmediate(() =&gt; console.log(&#039;set immediate&#039;));\nQ.resolve().then(() =&gt; console.log(&#039;q promise resolved&#039;));\nprocess.nextTick(() =&gt; console.log(&#039;next tick&#039;));\nsetTimeout(() =&gt; console.log(&#039;set timeout&#039;), 0);\n上面的例子中，BlueBird.resolve().then 回调与 setImmediate 有相同的语义，因此 bluebird 的回调在 immediates 队列中，并在 setImmediate 回调之前。而 Q 使用 process.nextTick 来调度回调，Q.resolve().then 在 process.nextTick 队列并在 process.nextTick 回调之前。我们可以用如下输出来验证我们的推测：\nq promise resolved\nnext tick\nnative promise resolved\nset timeout\nbluebird promise resolved\nset immediate\n\n\n虽然上面的例子只使用了 resolve promise，但 reject promise 的行为时一样的。文章最后，我会给一个同时有 resolve reject 的例子。\n\nBluebird 给我们提供了一个选项，让我们可以选择调度机制。这意味着我们可以在 bluebird 用 process.nextTick 而不是 setImmediate 来实现 promise。Bluebird 提供 setScheduler 这个 API，它接收一个用于替换默认 setImmediate 调度方法的函数。\n为了在 bluebird 中使用 process.nextTick 作为调度器，我们可以这样：\nconst BlueBird = require(&#039;bluebird&#039;);\nBlueBird.setScheduler(process.nextTick);\n想使用 setTimeout 则可以：\nconst BlueBird = require(&#039;bluebird&#039;);\nBlueBird.setScheduler((fn) =&gt; {\n    setTimeout(fn, 0);\n});\n为了防止文章过长，我这里不再赘述各种使用样例。你可以尽情尝试不同的调度器，查看输出结果。\n在新版本 node 中使用 setImmediate 替代 process.nextTick 有它的好处、因为从 NodeJS v0.12 开始，不再有 process.maxTickDepth，过多添加事件到 nextTick 队列会导致 I/O 饿死。而 immediates 队列在 I/O 队列之后，因此用 setImmediate 替代 process.nextTick 能够避免这种情况。\n最后的例子\n以下代码会产生有点复杂难懂的输出：\nconst Q = require(&#039;q&#039;);\nconst BlueBird = require(&#039;bluebird&#039;);\n \nPromise.resolve().then(() =&gt; console.log(&#039;native promise resolved&#039;));\nBlueBird.resolve().then(() =&gt; console.log(&#039;bluebird promise resolved&#039;));\nsetImmediate(() =&gt; console.log(&#039;set immediate&#039;));\nQ.resolve().then(() =&gt; console.log(&#039;q promise resolved&#039;));\nprocess.nextTick(() =&gt; console.log(&#039;next tick&#039;));\nsetTimeout(() =&gt; console.log(&#039;set timeout&#039;), 0);\nQ.reject().catch(() =&gt; console.log(&#039;q promise rejected&#039;));\nBlueBird.reject().catch(() =&gt; console.log(&#039;bluebird promise rejected&#039;));\nPromise.reject().catch(() =&gt; console.log(&#039;native promise rejected&#039;));\nq promise resolved\nq promise rejected\nnext tick\nnative promise resolved\nnative promise rejected\nset timeout\nbluebird promise resolved\nbluebird promise rejected\nset immediate\n你应该会有两个问题：\n\n如果 Q 使用 process.nextTick，为什么 q promise rejected 在 next tick 之前？\n如果 Bluebird 使用 setImmediate，为什么 bluebird promise rejected 在 set immediate 之前？\n\n这是因为两个库都有一个内部的队列来存放所有 resolved/rejected promise 回调，然后把这个内部队列添加到事件循环对应的队列中，这样事件循环就会一次性处理内部队列中所有的回调。更详细解释见 这里\n让我们以 bluebird 为例。当使用 bluebird resolve 或 rejecte 承诺时，会启动一个队列，并将 resolve/reject 回调添加到已启动队列中。然后计划使用 setImmediation 回调处理该队列。如果有更多的 promise 被 resolve 或 rejecte，它们将被添加到同一个队列中，这个队列已经计划在事件循环启动时立即执行。现在让我们再回顾一下代码；\n在这种情况下，bluebird 在 setImmediation 之前调用 resolve。也就是说，一个队列已经启动时，第一个蓝鸟的resolve 已经在队列中，并且计划使用 setimmediation 处理它。此时，setimmediation 队列将如下所示。\n\nProcess this queue — [ (Log “bluebird promise resolved”) ]\nLog “set immediate”\n\n一旦执行了所有语句，setimmediation队列将如下所示：\n\nProcess this queue — [ (Log “bluebird promise resolved”), (Log “bluebird promise rejected”) ]\nLog “set immediate”\n\nbluebird 没有将新的 promise 回调添加为新的 setImmediation 回调，而是将它插入到上面启动的同一个队列中。\n在执行上述所有语句之后，事件循环将启动。在 setImmediation状态时，它将首先处理 promise 回调队列，然后执行我们提供的实际 setImmediation 回调，结果则如上所示。"},"nodejs/EventLoop/event-loop-4":{"title":"event-loop-4","links":[],"tags":[],"content":"原文地址：Handling IO — NodeJS Event Loop Part 4, Deepal Jayasekara, Nov 26, 2017\n本篇文章中，我将详细讨论 NodeJS 如何处理 I/O，深入探讨事件循环的实现以及 I/O 如何与其他异步操作组合在一起。\n异步 I/O\nNodeJS 中我们反复谈到异步 I/O。正如本系列第一篇文章提到的，I/O 并不注定是同步的。\n所有操作系统实现中，它们都提供异步 I/O 的事件通知接口（linux epoll, macOS kqueue，solaris event ports，windows IOCP 等）。NodeJS 利用这些系统级别的事件通知系统来提供非阻塞、异步 I/O。\n如下图所见，NodeJS 是一系列工具的集合，它们聚合成高性能的 NodeJS 运行时。这些工具包括：\n\nChrome v8 引擎 —— 高效执行 JavaScript\nLibuv —— 异步 I/O 事件循环\nc-ares —— DNS 操作\n其他插件如 http-parser，crypto 和 zlib\n\n\n这篇文章中我会讲解 Libuv 和它如何向 Node 提供异步 I/O。让我们再回顾事件循环图示。\n\n我们已经学到的事件循环知识有：\n\n事件循环从处理所有过时的定时器开始\n接着处理所有挂起的 I/O 操作，可能会等待挂起的 I/O 变为完成\n然后处理 setImmediate 回调\n最后处理 I/O close 的处理器\n\n上述每个阶段间，libuv 会把阶段的执行结果通知 Node 架构的更上层部分，也就是 JavaScript。每次通知发生时，process.nextTick 回调和其他微任务回调就会被执行。\n现在，让我们理解 NodeJS 在事件循环中如何处理 I/O。\n\n什么是 I/O？\n一般地，涉及到除 CPU 以外的外部设备的工作都可被称为 I/O。最常见的抽象 I/O 类型有文件操作和 TCP/UDP 网络操作。\n\nLibuv 和 NodeJS I/O\nJavaScript 本身没有能力实现异步 I/O 操作。NodeJS 开发过程中，libuv 最初是为了给 Node 提供异步 I/O。libuv 现在已经是一个独立的库，可独立被使用。Libuv 在 NodeJS 架构中的角色是抽象和屏蔽内部 I/O 复杂度，给上层的 Node 提供通用的接口，让 Node 具有跨平台的异步 I/O 能力。\n如 NodeJS 架构图所示，libuv 在架构中处于较底层的位置。现在，让我们看看 NodeJS 上层和 libuv 事件循环各阶段之间的关系。\n\n相比于事件循环中存在 4 个可区分的阶段，在 libuv 中其实存在 7 个可区分的阶段：\n\nTimers —— 执行过期的 setTimeout 和 setInterval 回调\nPending I/O callbacks —— 执行挂起的已完成或发生错误 I/O 回调\nIdle handlers —— libuv 内部事务处理\nPrepare Handlers —— poll I/O 前的准备工作\nI/O Poll —— 可能等待任意的 I/O 变为完成\nCheck handlers —— poll I/O 后的事后工作，一般是 setImmediate 回调\nClose handlers —— 所有关闭 I/O 的处理器\n\n如果你还记得第一篇文章，你可能会疑惑：\n\nCheck handlers 是什么？它在事件循环图中不存在。\nI/O Polling 是什么？为什么要在执行已完成 I/O 回调后阻塞 I/O？Node 难道不是非阻塞的吗？\n\n让我们来解释这两个问题。\nCheck Handlers\nNodeJS 初始化时，它会把所有 setImmediate 回调注册为 libuv 的 Check handlers。这意味着你使用 setImmediate 传入的回调会增加在 Libuv 的 Check handlers 队列中。它保证了这些回调会在事件循环中的 I/O 操作后被执行。\nI/O Polling\n现在你应该在猜测 I/O Polling 是什么。虽然我把 I/O 回调队列和 I/O Polling 合并为事件循环中的单一阶段，但实际上 I/O Polling 发生在处理完已完成 / 已错误的 I/O 回调。\n关于 I/O Polling 最重要的事实是它是可选的。I/O Polling 是否发生取决于当时的具体情况。为了彻底地了解它，我们看看 libuv 中的实现代码。\nr = uv__loop_alive(loop);\nif (!r)\n    uv__update_time(loop);\n \nwhile (r != 0 &amp;&amp; loop-&gt;stop_flag == 0) {\n    uv__update_time(loop);\n    uv__run_timers(loop);\n    ran_pending = uv__run_pending(loop);\n    uv__run_idle(loop);\n    uv__run_prepare(loop);\n \n    timeout = 0;\n    if ((mode == UV_RUN_ONCE &amp;&amp; !ran_pending) || mode == UV_RUN_DEFAULT)\n        timeout = uv_backend_timeout(loop);\n \n    uv__io_poll(loop, timeout);\n    uv__run_check(loop);\n    uv__run_closing_handles(loop);\n \n    if (mode == UV_RUN_ONCE) {\n        uv__update_time(loop);\n        uv__run_timers(loop);\n    }\n \n    r = uv__loop_alive(loop);\n    if (mode == UV_RUN_ONCE || mode == UV_RUN_NOWAIT)\n        break;\n}\n对不熟悉 C 的人这段代码可能会人头痛。让我们尝试找到它的精髓而不过分关注细节。它来自于 libuv 源码的 core.c 文件的 uv_run 方法。但最重要的是，它是 NodeJS 事件循环的核心。\n让我们再看看事件循环图，它与代码可以对应起来。让我们一行行来解释代码：\n\nuv__loop_alive —— 检查是否有待调用的被引用的处理器，或是否有活跃的挂起操作\nuv__update_time —— 发起系统调用获得当前时间，更新循环的时间（用于判断过期的计时器）\nuv__run_timers —— 运行所有过期的计时器\nuv__run_pending —— 运行所有已完成 / 已错误的 I/O 回调\nuv__io_poll —— Poll for I/O\nuv__run_check —— 运行所有 check handlers（setImmediate 回调在此）\nuv__run_closing_handles —— 运行所有关闭处理器\n\n首先，事件循环通过调用 uv__loop_alive 函数检查事件循环是否依然存活。\nstatic int uv__loop_alive(const uv_loop_t* loop) {\n  return uv__has_active_handles(loop) ||\n         uv__has_active_reqs(loop) ||\n         loop-&gt;closing_handles != NULL;\n}\nuv__loop_alive 函数返回 boolean 值。当满足以下条件时返回 true：\n\n存在待调用的活跃处理器\n存在挂起的活跃请求或操作\n存在待调用的关闭中的处理器\n\n只要 uv__loop_alive 返回 true，事件循环就会一直循环运行。\n运行完所有过期定时器的回调后，uv__run_pending 会被调用。它会处理 libuv 储存所有已完成 I/O 操作的 pending_queue。如果 pending_queue 为空，uv__run_pending 返回 0，否则执行队列中所有回调并返回 1。\nstatic int uv__run_pending(uv_loop_t* loop) {\n  QUEUE* q;\n  QUEUE pq;\n  uv__io_t* w;\n \n  if (QUEUE_EMPTY(&amp;loop-&gt;pending_queue))\n    return 0;\n \n  QUEUE_MOVE(&amp;loop-&gt;pending_queue, &amp;pq);\n \n  while (!QUEUE_EMPTY(&amp;pq)) {\n    q = QUEUE_HEAD(&amp;pq);\n    QUEUE_REMOVE(q);\n    QUEUE_INIT(q);\n    w = QUEUE_DATA(q, uv__io_t, pending_queue);\n    w-&gt;cb(loop, w, POLLOUT);\n  }\n \n  return 1;\n}\n现在让我们看看 libuv uv__io_poll 函数实现的 I/O Polling。\nuv__io_poll 第二个参数是 uv_backend_timeout 计算出的超时时间。uv__io_poll 利用这一参数决定应该阻塞 I/O 多长。如果超时时间为 0，I/O polling 会被跳过，事件循环移动到 check handlers（setImmediate）阶段。什么决定 timeout 的值是很有趣的部分。根据之前 uv_run 的代码，我们可以推导出以下流程：\n\n如果事件循环以 UV_RUN_DEFAULT 模式运行，timeout 根据 uv_backend_timeout 方法计算得出\n如果事件循环以 UV_RUN_ONCE 模式运行，并且 uv_run_pending 返回 0（例如 pending_queue 为空的情况），timeout 根据 uv_backend_timeout 方法计算得出\n以上两种都不是则 timeout 为 0\n\n\n不需要太过关注事件循环的不同模式比如 UV_RUN_DEFAULT 和 UV_RUN_ONCE，如果你真的有兴趣，看这里\n\n让我们看看 uv_backend_timeout 代码，理解 timeout 是如何计算得出的。\nint uv_backend_timeout(const uv_loop_t* loop) {\n  if (loop-&gt;stop_flag != 0)\n    return 0;\n \n  if (!uv__has_active_handles(loop) &amp;&amp; !uv__has_active_reqs(loop))\n    return 0;\n \n  if (!QUEUE_EMPTY(&amp;loop-&gt;idle_handles))\n    return 0;\n \n  if (!QUEUE_EMPTY(&amp;loop-&gt;pending_queue))\n    return 0;\n \n  if (loop-&gt;closing_handles)\n    return 0;\n \n  return uv__next_timeout(loop);\n}\n\n如果 stop_flag 被设置，意味着事件循环将要退出，超时时间为 0。\n如果没有活跃的 handles 和活跃的挂起状态的操作，不需要等待，因此超时时间为 0。\n如果有待执行的挂起状态的空闲 handles，不等待 I/0，因此超时时间为 0。\n如果 pending_queue 中有已完成的 I/O handlers，也不应该等待 I/O，因此超时时间为 0。\n如果存在挂起待执行的 close handlers，也不应该等待 I/O，因此超时时间为 0。\n\n如果以上条件都不满足，uv__next_timeout 被调用来决定 libuv 应该为 I/O 等待多长。\nint uv__next_timeout(const uv_loop_t* loop) {\n  const struct heap_node* heap_node;\n  const uv_timer_t* handle;\n  uint64_t diff;\n \n  heap_node = heap_min((const struct heap*) &amp;loop-&gt;timer_heap);\n  if (heap_node == NULL)\n    return -1; /* block indefinitely */\n \n  handle = container_of(heap_node, uv_timer_t, heap_node);\n  if (handle-&gt;timeout &lt;= loop-&gt;time)\n    return 0;\n \n  diff = handle-&gt;timeout - loop-&gt;time;\n  if (diff &gt; INT_MAX)\n    diff = INT_MAX;\n \n  return diff;\n}\nuv__next_timeout 负责返回离当前最近的定时器的值。如果没有，返回 -1，也就意味这无限。\n现在你应该对问题 “为什么要在执行已完成 I/O 回调后阻塞 I/O？Node 难道不是非阻塞的吗？” 有答案了。\n事件循环在存在待执行的挂起任务时不会阻塞，但如果不存在，循环就会一直阻塞直到有过期的定时器重新激活循环。\n现在我们知道循环会等待多久 I/O 变为已完成。timeout 被传入 uv__io_poll，uv__io_poll 一直等待进来的 I/O 操作，直到达到超时时间或系统设置的最大安全超时时间。超时后，循环会激活，移动到 check handlers 阶段。\nI/O Polling 在不同的操作系统有不同的实现。Linux 中使用系统内核调用方法 epoll_wait，macOS 使用 kqueue，Windows 使用 IOCP (Input Output Completion Port) 中的 GetQueuedCompletionStatus。我不会具体探讨 I/O Polling 如何工作，因为这个话题很复杂，至少要另外一个系列才能解释清楚（我不认为我会写）。\n关于线程池\n这篇文章还没有谈到线程池。正如我们在本系统第一篇文章中提到的，线程池主要用来处理所有的文件 I/O 操作，DNS 操作中的 getaddrinfo 和 getnameinfo 调用，因为不同操作系统文件 I/O 的复杂性（对这个问题复杂度的确切分析看这里）。因为线程池的大小是有限的（默认为 4），多个对文件系统的操作请求还是可能会被阻塞直到至少一个线程空闲可用。为了增加服务应用的性能，可通过环境变量 UV_THREADPOOL_SIZE 可将线程池的大小最大设为 128（截止这篇文章的时间）\n但是线程池固定大小的限制仍然是 NodeJS 应用的一大瓶颈，因为线程池不仅仅只负责文件 I/O，getaddrinfo 和 getnameinfo。一些特定 CPU 密集计算型的操作如加解密操作如 randomBytes, randomFill 和 pbkdf2 为了避免对应用的性能造成损害，也会在 libuv 线程池中运行。但这也可能导致线程成为 I/O 操作所需的稀缺资源。\n上一版 libuv 增强提案中有一点就是建议让线程池的大小可根据负载进行伸缩扩展。但是这项提案最终被撤回，取而代之的是未来会引入的一个关于线程的插件式 API；\n本篇文章的一些内容受 Saúl Ibarra Corretgé 2016 年在 NodeConfEU 的演讲启发。如果你想更多了解 libuv，我强烈建议你观看这一演讲视频。"},"nodejs/EventLoop/event-loop-5":{"title":"event-loop-5","links":[],"tags":[],"content":"For reference, here’s how HTML defines the event loop for renderer threads and worker threads: html.spec.whatwg.org/multipage/webappapis.html#event-loop-processing-model. Definition wise, a “task” in HTML parlance is a “macrotask” unless specified otherwise. A quick summary:\n\n\nDequeue a task from one of the task queues. This allows the browser to prioritize different types of tasks. For example, a requestAnimationFrame task put into their own task queue might be higher priority than a timer task when appropriate, while a requestIdleCallback task might be lower priority.\nRun that task.\nWhile the microtask queue is not empty, dequeue and run the earliest-queued microtask. (HTML calls this perform a microtask checkpoint.)\nIf this is a renderer thread, update the page rendering.\nIf this is a worker thread, and there are no more tasks left in any task queues, exit the worker.\n\n\nThe way setTimeout() works is roughly:\n\n\nIn another thread, run these steps:\n\nWait for some time, usually based on but could differ slightly from the provided timeout.\nQueue a task to run the provided callback.\n\n\nReturn a number that could be passed to clearTimeout().\n\n\nIn comparison, the way Node.js timers run is this:\n\n\nAdd the provided callback to the timer queue.\nIf the timer thread hasn’t been started, then run these steps in another thread:\n\nWait for some time, usually the shortest timeout of a registered callback in the timer queue.\nQueue a task to run these steps:\n\nRun all callbacks with this timeout, one by one..\nIf there are remaining callbacks in the timer, then redo step 2 “If the timer thread…” again.\nRun all microtasks. It’s actually run in the destructor of InternalCallbackScope here (when there are no process.nextTick() callbacks scheduled) or here (when there are).\nOtherwise, terminate this thread.\n\n\n\n\n\n\n(The “thread” here is idealized; libuv may or may not use threads to implement timers.)\nThis results in all timers of a specific timeout being run together rather than having microtasks run after each timer callback.\nBTW, I realize that people who have commented here already probably knows how everything works already, but in case a summary is needed by anyone for context.\nJavaScript Event Loop vs Node JS Event Loop\n原文地址：JavaScript Event Loop vs Node JS Event Loop | by Deepal Jayasekara | Deepal’s Blog\n事件循环对于新手来说是一个非常令人困惑的话题，并且通常不能完全理解。更让人困惑的是，有两个术语叫做“NodeJS事件循环”和“JavaScript事件循环”，后者指的是浏览器中的事件循环。这种区别导致了如下问题:\n\n\n这两者在行为上是相同的，相似的，还是完全不同的?\n\n\n如果不同，区别是什么?\n\n\n如果它们是相同的，为什么我们要消除“NodeJS事件循环”和“JavaScript事件循环”的歧义?\n\n\n简而言之，是的，它们在某些方面是相似的。是的，它们在某些实现方面也是不同的。\n因此，在本文中，我将通过几个例子来讨论这种消除歧义的方法，以澄清您可能对该主题存在的一些迫切的问题。\n什么是“事件循环”?\n术语“事件循环”是一种通用编程模式。它描述了一个简单的循环，迭代完成事件的结果，并处理它们。JavaScript/NodeJS 的事件循环也不例外。\n当JavaScript 应用程序运行时，它们会触发各种事件，这些事件将导致相应的事件处理程序进入队列进行处理。事件循环持续监视任何排队的事件处理程序，并相应地处理它们。\n“事件循环”——根据HTML5规范\nHTML5 Spec 描述了一套标准指南，供应商可以用来开发浏览器/JavaScript 运行时或其他相关库。它还描述了一组实现事件循环模型的准则，以及其他可能与事件循环相关的JavaScript特性，如计时器。\n大多数浏览器和JS运行时都倾向于遵循这些准则，以便更好地在万维网上兼容。然而，在某些情况下，它们会稍微偏离这一单一的真相来源，从而导致有趣的结果\n在本文中，我将讨论一些这样的情况，特别是 NodeJS 对比 Browser。我可能不会深入研究各个浏览器的实现细节，因为它们随时都可能发生变化。\n客户端 vs 服务器端 JavaScript\n多年来，JavaScript 一直局限于客户端应用程序，比如运行在浏览器上的交互式web应用程序。使用 NodeJS, JavaScript 也可以用于开发服务器端应用程序。虽然在两个用例中使用的是相同的编程语言，但客户端和服务器端有不同的需求。\n浏览器是一个沙箱环境，浏览器中的 JavaScript 没有执行服务器端 JavaScript 可以执行的某些任务的自由，如文件系统操作，某些网络操作等。这就需要服务器端JavaScript (NodeJS)中的事件循环来满足这些额外的需求。\n浏览器和 NodeJS 都用 JavaScript 实现了异步事件驱动模式。然而，“事件”，在浏览器的上下文中，是用户在网页上的交互(例如，点击，鼠标移动，键盘事件等)，但在 Node 的上下文中，事件是异步服务器端操作(例如，文件 I/O 访问，网络 I/O 等)。由于这种需求的差异，Chrome 和 Node 有不同的事件循环实现，尽管它们共享相同的 V8 JavaScript引擎来运行 JavaScript。\n由于“事件循环”只是一种编程模式，V8 允许插入一个外部事件循环实现来配合它的 JavaScript 运行时。利用这种灵活性，Chrome 浏览器使用 libevent 作为其事件循环实现，而NodeJS使用 libuv 实现事件循环。因此，chrome的事件循环和 NodeJS 的事件循环是基于两个不同的库，它们有不同之处，但它们也有共同的“事件循环”编程模式的相似之处。\n浏览器 vs Node-有什么不同?\n微观任务与宏观任务的区别\n\n什么是微观任务和宏观任务？\n简言之，宏任务和微任务是两种类型的异步任务。然而，微任务比宏任务具有更高的优先级。微任务的一个例子是 promise 回调。setTimeout 回调就是一个宏任务的例子。\n\n浏览器和Node之间的一个显著区别是它们如何优先处理微任务和宏任务。尽管 ≥ v11.0.0 的 NodeJS 版本在这方面与浏览器的行为一致，但 v11.0.0 之前的NodeJS版本有显著的差异，我在之前的文章中也讨论过。\n是时候尝试一下了！考虑下面的例子。\n在本例中，我们将调度一组承诺回调(微任务)和计时器回调(宏任务)，以了解每个 JavaScript 运行时是如何执行它的。\nPromise.resolve().then(() =&gt; console.log(&#039;promise1 resolved&#039;));\nPromise.resolve().then(() =&gt; console.log(&#039;promise2 resolved&#039;));\nsetTimeout(() =&gt; {\n    console.log(&#039;set timeout3&#039;)\n    Promise.resolve().then(() =&gt; console.log(&#039;inner promise3 resolved&#039;));\n}, 0);\nsetTimeout(() =&gt; console.log(&#039;set timeout1&#039;), 0);\nsetTimeout(() =&gt; console.log(&#039;set timeout2&#039;), 0);\nPromise.resolve().then(() =&gt; console.log(&#039;promise4 resolved&#039;));\nPromise.resolve().then(() =&gt; {\n    console.log(&#039;promise5 resolved&#039;)\n    Promise.resolve().then(() =&gt; console.log(&#039;inner promise6 resolved&#039;));\n});\nPromise.resolve().then(() =&gt; console.log(&#039;promise7 resolved&#039;));\n\n你也可以使用 queuemmicrotask 在浏览器和Node中调度微任务。但对于本例，我将使用 Promise 回调，因为 queuemmicrotask 仅在 Node v11.0.0 及以上版本可用。\n\n根据HTML5事件循环规范指南，事件循环在处理宏任务队列中的一个宏任务之后，应该完全处理微任务队列。在我们的例子中，当执行 setTimeout3 回调时，它调度了一个 promise 回调。根据 HTML5 规范，在移动到计时器回调队列中的任何其他回调之前，事件循环必须确保微任务队列为空。因此，它必须执行新添加的 promise 回调，该回调记录内部 promise3 的解析。处理完之后，微任务队列变为空，事件循环可以向前处理计时器回调队列中剩余的 setTimeout1 和 setTimeout2 回调函数。\n但是在 v11.0.0 之前的 NodeJS 版本中，微任务队列只在事件循环的两个阶段之间被清空。因此，内部的 promis3 回调直到执行了所有的 setTimeout3、setTimeout1 和 setTimeout2 回调，并且事件循环试图移动到下一个阶段(即I/O回调阶段)才有机会。\n嵌套计时器的行为\n不同的 NodeJS 和浏览器，以及不同的浏览器供应商/版本，计时器的行为是不同的。其中最有趣的两个事实是他延时为 0 的计时器的行为和嵌套计时器的行为。\n\n提示：可以通过显式地将超时设置为0或省略 timeout 参数来创建延时为0的计时器。\n\n作为理解这两种行为的实验，让我们在 Node v10.19.0、Node v11.0.0、Chrome、Firefox 和 Safari 中运行以下代码。这个代码片段将安排 8 个嵌套计时器：\nconst startHrTime = () =&gt; {\n  if (typeof window !== &#039;undefined&#039;) return performance.now();\n  return process.hrtime();\n}\n \nconst getHrTimeDiff = (start) =&gt; {\n  if (typeof window !== &#039;undefined&#039;) return performance.now() - start;\n  const [ts, tns] = (process.hrtime(start));\n  return ts * 1e3 + tns / 1e6;\n}\n \nconsole.log(&#039;start&#039;)\nconst start1 = startHrTime();\nconst outerTimer = setTimeout(() =&gt; {\n  const start2 = startHrTime();\n  console.log(`timer1: ${getHrTimeDiff(start1)}`)\n  setTimeout(() =&gt; {\n      const start3 = startHrTime();\n      console.log(`timer2: ${getHrTimeDiff(start2)}`)\n      setTimeout(() =&gt; {\n          const start4 = startHrTime();\n          console.log(`timer3: ${getHrTimeDiff(start3)}`)\n          setTimeout(() =&gt; {\n              const start5 = startHrTime();\n              console.log(`timer4: ${getHrTimeDiff(start4)}`)\n              setTimeout(() =&gt; {\n                  const start6 = startHrTime();\n                  console.log(`timer5: ${getHrTimeDiff(start5)}`)\n                  setTimeout(() =&gt; {\n                      const start7 = startHrTime();\n                      console.log(`timer6: ${getHrTimeDiff(start6)}`)\n                      setTimeout(() =&gt; {\n                          const start8 = startHrTime();\n                          console.log(`timer7: ${getHrTimeDiff(start7)}`)\n                          setTimeout(() =&gt; {\n                              console.log(`timer8: ${getHrTimeDiff(start8)}`)\n                          })\n                      })\n                  })\n              })\n          })\n      })\n  })\n})\n\n重要提示！为了精确地计算回调需要多长时间，我们在浏览器中使用了 performance.now()，在 NodeJS中使用了 process.hrtime()，使用了高分辨率计时器。为了便于分析，这些计算时间被四舍五入到两个小数中。此外，这些值不能 100% 保证在多次运行时是固定的，因为根据 CPU 的繁忙程度，触发 setTimeout 回调所需的时间将略高于提供的超时值。\n\n我们的实验结果有几个重要的观察结果:\n\n\n即使你将超时设置为 0，所有的 NodeJS 计时器似乎至少在 1ms 后触发。\n\n\nChrome 似乎将前4个嵌套计时器的最小超时时间限制为 1ms。但之后，上限似乎增加到4毫秒。\n\n\n不像Chrome，Firefox 似乎没有限制前 4 个计时器的超时时间。但类似的 Chrome，它的上限最小超时 4ms 从第五个嵌套计时器开始。\n\n\nSafari 似乎没有限制前 5 个定时器的超时时间。但它只从第 6 个嵌套计时器开始引入了 4ms 的上限。\n\n\n那么，浏览器中的4ms超时上限是从哪里来的呢?\n嵌套计时器的 4ms 上限实际上在HTML标准中有描述。根据标准：\n\n“Timers can be nested; after five such nested timers, however, the interval is forced to be at least four milliseconds.”\n\n根据这个规则，这个上限将从嵌套的第 5 个计时器开始应用，正如我们在实验中观察到的 Chrome 和 Firefox。然而，虽然原因不清楚，Safari 似乎并没有严格遵守规则，因为它应用了第 6 嵌套计时器的上限，而不是第 5。\n极客时间！在 Firefox 中，这个上限可以使用 about:config 中的 dom.min_timeout_value属性进行配置。默认情况下，根据HTML标准，这被设置为 4ms。喜欢调整和试验它！\n如果我们把浏览器放在一边，观察Node的结果，我们可以清楚地看到Node似乎并不关心基于嵌套级别的超时限制。相反，Node 和Chrome 都分享了另一个有趣的行为。\n最小超时在所有的 Node 和 Chrome 的计时器\nNodeJS 和 Chrome 都强制所有计时器的最小超时时间为 1ms，即使它们没有嵌套。但与 Chrome 不同的是，在NodeJS中，这 1ms 的延迟是固定的，与嵌套级别无关。\n下面是 NodeJS Timeout 类的相应代码片段，其中对所有计时器强制执行最小 1ms 超时(并附有解释原因的注释)：\n// Enforcing minimum expiry (‘after’ parameter) of 1ms in Node if the expiry is less than 1ms.\nfunction Timeout(callback, after, args, isRepeat, isRefed) {\n  after *= 1; // Coalesce to number or NaN\n  if (!(after &gt;= 1 &amp;&amp; after &lt;= TIMEOUT_MAX)) {\n    if (after &gt; TIMEOUT_MAX) {\n      process.emitWarning(`${after} does not fit into` +\n                          &#039; a 32-bit signed integer.&#039; +\n                          &#039;\\nTimeout duration was set to 1.&#039;,\n                          &#039;TimeoutOverflowWarning&#039;);\n    }\n    after = 1; // Schedule on next tick, follows browser behavior\n  }\n  \n  // ....redacted\n}\nChrome 在 DOMTimer 类中做了类似的工作。(您还可以看到当 maxTimerNestingLevel 达到时施加的 4ms 上限。)\nDOMTimer::DOMTimer(ExecutionContext* context, PassOwnPtrWillBeRawPtr&lt;ScheduledAction&gt; action, int interval, bool singleShot, int timeoutID)\n    : SuspendableTimer(context)\n    , m_timeoutID(timeoutID)\n    , m_nestingLevel(context-&gt;timers()-&gt;timerNestingLevel() + 1)\n    , m_action(action)\n{\n    // ... redacted ...\n    double intervalMilliseconds = std::max(oneMillisecond, interval * oneMillisecond);\n    if (intervalMilliseconds &lt; minimumInterval &amp;&amp; m_nestingLevel &gt;= maxTimerNestingLevel)\n        intervalMilliseconds = minimumInterval;\n    if (singleShot)\n        startOneShot(intervalMilliseconds, FROM_HERE);\n    else\n        startRepeating(intervalMilliseconds, FROM_HERE);\n}\n正如您所看到的，不同的 JavaScript 运行时都有自己独特的实现，包括嵌套计时器和 0 超时计时器。在开发JavaScript应用程序/库，并且不严格依赖于运行时特定的行为以获得更好的兼容性时，记住这一点很重要。\nprocess.nextTick 和 setImmediate\n浏览器和NodeJS之间的另一个主要区别是 process.nextTick 和 setImmediate。\nprocess.nextTick 严格来说只存在于 NodeJS 中，目前还没有对应的浏览器 API。虽然 nextTick 回调不一定是 NodeJS的 libuv 事件循环的一部分，但 nextTick 回调是 NodeJS 在事件循环期间跨越 C++ / JS 边界的结果。所以它可以被认为在某种程度上与事件循环有关。\nsetImmediation 也是一个特定于 nodejs 的 API。根据 MDN and caniuse.com ，setImmediation 在IE 10、IE 11 和 Edge 的一些早期版本中都可以使用，目前还不清楚其他浏览器供应商是否会在某一天实现这个端点。然而，在撰写本文时，它还不是所有浏览器的标准特性，不应该在所有浏览器中使用。\n相关链接\n\nHTML Standard — Timers spec\nEvent loop: microtasks and macrotasks\nWindowOrWorkerGlobalScope.setTimeout() — Web APIs | MDN\nlibevent vs libuv · GitHub\nlibevent\nEvent loop: microtasks and macrotasks\nHTML Standard — Event Loop\nECMAScript® 2021 Language Specification\nSource/core/frame/DOMTimer.cpp - chromium/blink - Git at Google\nNotes on setTimeout WindowOrWorkerGlobalScope.setTimeout() — Web APIs | MDN\nRemoval of libev from libuv github.com/joyent/libuv/issues/485\n\n\nhtml.spec.whatwg.org/multipage/webappapis.html#event-loop-processing-model\nhtml.spec.whatwg.org/multipage/timers-and-user-prompts.html#dom-settimeout\n"},"nodejs/Module/require":{"title":"require","links":[],"tags":[],"content":"node 模块化的实现\nnode中自带模块化机制，每个文件就是一个单独的模块，并且它遵循的是CommonJS规范，也就是使用require的方式导入模块，通过module.export的方式导出模块。\nnode模块的运行机制也很简单，其实就是在每一个模块外层包裹了一层函数，有了函数的包裹就可以实现代码间的作用域隔离。\n新建一个js文件，在第一行打印一个并不存在的变量，比如打印window，在node中是没有window的。\nconsole.log(window);\n通过node执行该文件，会发现报错信息如下。(请使用系统默认cmd执行命令)。\n(function (exports, require, module, __filename, __dirname) { console.log(window);\nReferenceError: window is not defined\n    at Object.&lt;anonymous&gt; (/Users/choice/Desktop/node/main.js:1:75)\n    at Module._compile (internal/modules/cjs/loader.js:689:30)\n    at Object.Module._extensions..js (internal/modules/cjs/loader.js:700:10)\n    at Module.load (internal/modules/cjs/loader.js:599:32)\n    at tryModuleLoad (internal/modules/cjs/loader.js:538:12)\n    at Function.Module._load (internal/modules/cjs/loader.js:530:3)\n    at Function.Module.runMain (internal/modules/cjs/loader.js:742:12)\n    at startup (internal/bootstrap/node.js:279:19)\n    at bootstrapNodeJSCore (internal/bootstrap/node.js:752:3)\n可以看到报错的顶层有一个自执行的函数，函数中包含exports, require, module, __filename, __dirname这些常用的全局变量。\n自执行函数也是前端模块化的实现方案之一，在早期前端没有模块化系统的时代，自执行函数可以很好的解决命名空间的问题，并且模块依赖的其他模块都可以通过参数传递进来。cmd和amd规范也都是依赖自执行函数实现的。\n在模块系统中，每个文件就是一个模块，每个模块外面会自动套一个函数，并且定义了导出方式 module.exports或者exports，同时也定义了导入方式require。\nlet moduleA = (function() {\n    module.exports = Promise;\n    return module.exports;\n})();\nrequire 加载模块\nrequire依赖node中的fs模块来加载模块文件，fs.readFile读取到的是一个字符串。\n在javascrpt中可以通过eval或者new Function的方式来将一个字符串转换成js代码来运行。\neval\nconst name = &#039;yd&#039;;\nconst str = &#039;const a = 123; console.log(name)&#039;;\neval(str); // yd;\n复制代码\nnew Function\nnew Function接收的是一个要执行的字符串，返回的是一个新的函数，调用这个新的函数字符串就会执行了。如果这个函数需要传递参数，可以在new Function的时候依次传入参数，最后传入的是要执行的字符串。比如这里传入参数b，要执行的字符串str。\nconst b = 3;\nconst str = &#039;let a = 1; return a + b&#039;;\nconst fun = new Function(&#039;b&#039;, str);\nconsole.log(fun(b, str)); // 4\n可以看到eval和Function实例化都可以用来执行javascript字符串，似乎他们都可以来实现require模块加载。不过在node中并没有选用他们来实现模块化，原因也很简单因为他们都有一个致命的问题，就是都容易被不属于他们的变量所影响。\n如下str字符串中并没有定义a，但是却可以使用上面定义的a变量，这显然是不对的，在模块化机制中，str字符串应该具有自身独立的运行空间，自身不存在的变量是不可以直接使用的。\nconst a = 1;\n \nconst str = &#039;console.log(a)&#039;;\n \neval(str);\n \nconst func = new Function(str);\nfunc();\nnode存在一个vm虚拟环境的概念，用来运行额外的js文件，他可以保证javascript执行的独立性，不会被外部所影响。\nvm 内置模块\n虽然外部定义了hello，但是str是一个独立的模块，并不在hello变量，所以会直接报错。\n// 引入vm模块， 不需要安装，node 自建模块\nconst vm = require(&#039;vm&#039;);\nconst hello = &#039;yd&#039;;\nconst str = &#039;console.log(hello)&#039;;\nwm.runInThisContext(str); // 报错\n所以node执行javascript模块时可以采用vm来实现。就可以保证模块的独立性了。\nrequire 代码实现\n介绍require代码实现之前先来回顾两个node模块的用法，因为下面会用得到。\npath 模块\n用于处理文件路径：\nbasename： 基础路径，有文件路径就不是基础路径，基础路径是1.js\nextname： 获取扩展名\ndirname： 父级路劲\njoin： 拼接路径\nresolve： 当前文件夹的绝对路径，注意使用的时候不要在结尾添加/\n__dirname： 当前文件所在文件夹的路径\n__filename： 当前文件的绝对路径\nfs 模块\n用于操作文件或者文件夹，比如文件的读写，新增，删除等。常用方法有readFile和readFileSync，分别是异步读取文件和同步读取文件。\nconst fs = require(&#039;fs&#039;);\nconst buffer = fs.readFileSync(&#039;./name.txt&#039;, &#039;utf8&#039;); // 如果不传入编码，出来的是二进制\nconsole.log(buffer);\nfs.access: 判断是否存在，node10提供的，exists方法已经被废弃，原因是不符合node规范，所以改为采用access来判断文件是否存在。\n实现 require 模块加载器\n首先导入依赖的模块path，fs，vm， 并且创建一个Require函数，这个函数接收一个modulePath参数，表示要导入的文件路径。\n// 导入依赖\nconst path = require(&#039;path&#039;); // 路径操作\nconst fs = require(&#039;fs&#039;); // 文件读取\nconst vm = require(&#039;vm&#039;); // 文件执行\n \n// 定义导入类，参数为模块路径\nfunction Require(modulePath) {\n    ...\n}\n在Require中获取到模块的绝对路径，方便使用fs加载模块，这里读取模块内容使用new Module来抽象，使用tryModuleLoad来加载模块内容，Module和tryModuleLoad稍后实现，Require的返回值应该是模块的内容，也就是module.exports。\n// 定义导入类，参数为模块路径\nfunction Require(modulePath) {\n    // 获取当前要加载的绝对路径\n    let absPathname = path.resolve(__dirname, modulePath);\n    // 创建模块，新建Module实例\n    const module = new Module(absPathname);\n    // 加载当前模块\n    tryModuleLoad(module);\n    // 返回exports对象\n    return module.exports;\n}\nModule的实现很简单，就是给模块创建一个exports对象，tryModuleLoad执行的时候将内容加入到exports中，id就是模块的绝对路径。\n// 定义模块, 添加文件id标识和exports属性\nfunction Module(id) {\n    this.id = id;\n    // 读取到的文件内容会放在exports中\n    this.exports = {};\n}\n之前说过node模块是运行在一个函数中，这里给Module挂载静态属性wrapper，里面定义一下这个函数的字符串，wrapper是一个数组，数组的第一个元素就是函数的参数部分，其中有exports，module，Require，__dirname，__filename, 都是模块中常用的全局变量。注意这里传入的Require参数是定义的Require。\n第二个参数就是函数的结束部分。两部分都是字符串，使用的时候将他们包裹在模块的字符串外部就可以了。\nModule.wrapper = [\n    &quot;(function(exports, module, Require, __dirname, __filename) {&quot;,\n    &quot;})&quot;\n]\n_extensions用于针对不同的模块扩展名使用不同的加载方式，比如JSON和javascript加载方式肯定是不同的。JSON使用JSON.parse来运行。\njavascript使用vm.runInThisContext来运行，可以看到fs.readFileSync传入的是module.id也就是Module定义时候id存储的是模块的绝对路径，读取到的content是一个字符串，使用Module.wrapper来包裹一下就相当于在这个模块外部又包裹了一个函数，也就实现了私有作用域。\n使用call来执行fn函数，第一个参数改变运行的this传入module.exports，后面的参数就是函数外面包裹参数exports，module， Require， __dirname， __filename。\nModule._extensions = {\n    &#039;.js&#039;(module) {\n        const content = fs.readFileSync(module.id, &#039;utf8&#039;);\n        const fnStr = Module.wrapper[0] + content + Module.wrapper[1];\n        const _filename = path.basename(module.id)\n    \tconst _dirname = module.id\n        const fn = vm.runInThisContext(fnStr);\n        fn.call(module.exports, module.exports, module, Require, _filename, _dirname);\n    },\n    &#039;.json&#039;(module) {\n        const json = fs.readFileSync(module.id, &#039;utf8&#039;);\n        module.exports = JSON.parse(json); // 把文件的结果放在exports属性上\n    }\n}\ntryModuleLoad函数接收的是模块对象，通过path.extname来获取模块的后缀名，然后使用Module._extensions来加载模块。\n// 定义模块加载方法\nfunction tryModuleLoad(module) {\n    // 获取扩展名\n    const extension = path.extname(module.id);\n    // 通过后缀加载当前模块\n    Module._extensions[extension](module);\n}\n至此Require加载机制基本就写完了。Require加载模块的时候传入模块名称，在Require方法中使用path.resolve(__dirname, modulePath)获取到文件的绝对路径。然后通过 new Module 实例化的方式创建module对象，将模块的绝对路径存储在module的id属性中，在module中创建exports属性为一个json对象。\n使用tryModuleLoad方法去加载模块，tryModuleLoad中使用path.extname获取到文件的扩展名，然后根据扩展名来执行对应的模块加载机制。\n最终将加载到的模块挂载module.exports中。tryModuleLoad执行完毕之后module.exports已经存在了，直接返回就可以了。\n// 导入依赖\nconst path = require(&#039;path&#039;); // 路径操作\nconst fs = require(&#039;fs&#039;); // 文件读取\nconst vm = require(&#039;vm&#039;); // 文件执行\n \n// 定义导入类，参数为模块路径\nfunction Require(modulePath) {\n    // 获取当前要加载的绝对路径\n    let absPathname = path.resolve(__dirname, modulePath);\n    // 创建模块，新建Module实例\n    const module = new Module(absPathname);\n    // 加载当前模块\n    tryModuleLoad(module);\n    // 返回exports对象\n    return module.exports;\n}\n// 定义模块, 添加文件id标识和exports属性\nfunction Module(id) {\n    this.id = id;\n    // 读取到的文件内容会放在exports中\n    this.exports = {};\n}\n// 定义包裹模块内容的函数\nModule.wrapper = [\n    &quot;(function(exports, module, Require, __dirname, __filename) {&quot;,\n    &quot;})&quot;\n]\n// 定义扩展名，不同的扩展名，加载方式不同，实现js和json\nModule._extensions = {\n    &#039;.js&#039;(module) {\n        const content = fs.readFileSync(module.id, &#039;utf8&#039;);\n        const fnStr = Module.wrapper[0] + content + Module.wrapper[1];\n        const fn = vm.runInThisContext(fnStr);\n        fn.call(module.exports, module.exports, module, Require,_filename,_dirname);\n    },\n    &#039;.json&#039;(module) {\n        const json = fs.readFileSync(module.id, &#039;utf8&#039;);\n        module.exports = JSON.parse(json); // 把文件的结果放在exports属性上\n    }\n}\n// 定义模块加载方法\nfunction tryModuleLoad(module) {\n    // 获取扩展名\n    const extension = path.extname(module.id);\n    // 通过后缀加载当前模块\n    Module._extensions[extension](module);\n}\n给模块添加缓存\n添加缓存也比较简单，就是文件加载的时候将文件放入缓存，再去加载模块时先看缓存中是否存在，如果存在直接使用，如果不存在再去重新加载，加载之后再放入缓存。\n// 定义导入类，参数为模块路径\nfunction Require(modulePath) {\n    // 获取当前要加载的绝对路径\n    let absPathname = path.resolve(__dirname, modulePath);\n    // 从缓存中读取，如果存在，直接返回结果\n    if (Module._cache[absPathname]) {\n        return Module._cache[absPathname].exports;\n    }\n    // 创建模块，新建Module实例\n    const module = new Module(absPathname);\n    // 添加缓存\n    Module._cache[absPathname] = module;\n    // 加载当前模块\n    tryModuleLoad(module);\n    // 返回exports对象\n    return module.exports;\n}\n省略模块后缀名\n自动给模块添加后缀名，实现省略后缀名加载模块，其实也就是如果文件没有后缀名的时候，遍历一下所有的后缀名看一下文件是否存在。\n// 定义导入类，参数为模块路径\nfunction Require(modulePath) {\n    // 获取当前要加载的绝对路径\n    let absPathname = path.resolve(__dirname, modulePath);\n    // 获取所有后缀名\n    const extNames = Object.keys(Module._extensions);\n    let index = 0;\n    // 存储原始文件路径\n    const oldPath = absPathname;\n    function findExt(absPathname) {\n        if (index === extNames.length) {\n           return throw new Error(&#039;文件不存在&#039;);\n        }\n        try {\n            fs.accessSync(absPathname);\n            return absPathname;\n        } catch(e) {\n            const ext = extNames[index++];\n            findExt(oldPath + ext);\n        }\n    }\n    // 递归追加后缀名，判断文件是否存在\n    absPathname = findExt(absPathname);\n    // 从缓存中读取，如果存在，直接返回结果\n    if (Module._cache[absPathname]) {\n        return Module._cache[absPathname].exports;\n    }\n    // 创建模块，新建Module实例\n    const module = new Module(absPathname);\n    // 添加缓存\n    Module._cache[absPathname] = module;\n    // 加载当前模块\n    tryModuleLoad(module);\n    // 返回exports对象\n    return module.exports;\n}\n\nrequire加载器实现原理 - 掘金 (juejin.cn)\n"},"rust/rust-bible/advanced/01-函数式编程-闭包":{"title":"01-函数式编程-闭包","links":[],"tags":[],"content":"闭包 Closure\n闭包是一种匿名函数，它可以赋值给变量也可以作为参数传递给其它函数，不同于函数的是，它允许捕获调用者作用域中的值，例如：\nfn main() {\n   let x = 1;\n   let sum = |y| x + y;\n \n   assert_eq!(3, sum(2));\n}\n闭包 sum，它拥有一个入参 y，同时捕获了作用域中的 x 的值，非常符合闭包的定义。\n闭包的形式定义：\n|param1, param2,...| {\n    语句1;\n    语句2;\n    返回表达式\n}\n只有一个返回表达式，简化为：\n|param1| 返回表达式\n注意：\n\n闭包中最后一行表达式返回的值，就是闭包执行后的返回值；\n闭包赋值给变量，闭包函数并没有执行；\n\n闭包类型推导\n\n\n闭包通常不需要显式地去声明类型，编译器会自动推导；\n\n\n当编译器推导出一种类型后，它就会一直使用该类型；\n\n\n结构体中的闭包\n// 定义结构体 Cacher，带一个泛型参数 T，where 关键字用于在泛型参数上添加额外的约束条件\nstruct Cacher&lt;T&gt; where T: Fn(u32) -&gt; u32,\n{\n    query: T,\n    value: Option&lt;u32&gt;,\n}\nFn特征表示 T 必须是一个函数类型，接受一个 u32 参数并返回一个 u32 值。这个约束条件被用来限制可以传递给 Cacher 结构体的函数类型，以确保它们符合预期的签名。\n为缓存实现方法：\nimpl&lt;T&gt; Cacher&lt;T&gt;\nwhere T: Fn(u32) -&gt; u32,\n{\n    fn new(query: T) -&gt; Cacher&lt;T&gt; {\n        Cacher {\n            query,\n            value: None,\n        }\n    }\n \n    // 先查询缓存值 `self.value`，若不存在，则调用 `query` 加载\n    fn value(&amp;mut self, arg: u32) -&gt; u32 {\n        match self.value {\n            Some(v) =&gt; v,\n            None =&gt; {\n                let v = (self.query)(arg);\n                self.value = Some(v);\n                v\n            }\n        }\n    }\n}\n捕获作用域中的值\n函数不能捕获作用域中的值，而闭包可以：\nfn main() {\n    let x = 4;\n \n    fn equal_to_x_fn(z: i32) -&gt; bool {\n        z == x\n    }\n    let equal_to_x_closure = |z| z == x;\n \n    let y = 4;\n \n    assert!(equal_to_x_fn(y));\n    assert!(equal_to_x_closure(y));\n}\n\n闭包对内存的影响\n当闭包从环境中捕获一个值时，会分配内存去存储这些值。对于有些场景来说，这种额外的内存分配会成为一种负担。与之相比，函数就不会去捕获这些环境值，因此定义和使用函数不会拥有这种内存负担。\n\n三种 Fn 特征\n闭包捕获变量有三种途径，恰好对应函数参数的三种传入方式：转移所有权、可变借用、不可变借用，因此相应的 Fn 特征也有三种：\n\n\nFnOnce，该类型的闭包会拿走被捕获变量的所有权，即该闭包只能运行一次；\nfn fn_once&lt;F&gt;(func: F)\nwhere\n    F: FnOnce(usize) -&gt; bool,\n{\n    println!(&quot;{}&quot;, func(3));\n    println!(&quot;{}&quot;, func(4));\n}\n \nfn main() {\n    let x = vec![1, 2, 3];\n    fn_once(|z|{z == x.len()})\n}\n仅实现 FnOnce 特征的闭包在调用时会转移所有权，显然不能对已失去所有权的闭包变量进行二次调用；\n叠加一个 Copy 特征可避免，此时调用闭包时，是使用其拷贝，FnOnce(usize) -&gt; bool + Copy，并没有发生所有权的转移。\n\n因为 Copy 类型的值在赋值给其他变量或传递给函数时，只会复制其内容，而不会移动或转移所有权；\n也就是实现了 Copy 特性的闭包实例会共享捕获的作用域变量，不会导致所有权问题；\n\n如果你想强制闭包取得捕获变量的所有权，可以在参数列表前添加 move 关键字，这种用法通常用于闭包的生命周期大于捕获变量的生命周期时，例如将闭包返回或移入其他线程。\nuse std::thread;\nlet v = vec![1, 2, 3];\nlet handle = thread::spawn(move || {\n    println!(&quot;Here&#039;s a vector: {:?}&quot;, v);\n});\nhandle.join().unwrap();\n\n\nFnMut，它以可变借用的方式捕获了环境中的值，因此可以修改该值：\nfn main() {\n    let mut s = String::new();\n \n    // let update_string =  |str| s.push_str(str);\n    // 写法有点反直觉，相比起来前面的 move 更符合使用和阅读习惯\n    let mut update_string =  |str| s.push_str(str);\n \n    update_string(&quot;hello&quot;);\n \n    println!(&quot;{:?}&quot;,s);\n}\n\n\nFn 特征，它以不可变借用的方式捕获环境中的值；\n\n\nmove 和 Fn\n实际上使用了 move 的闭包依然可能实现了 Fn 或 FnMut 特征，因为一个闭包实现了哪种 Fn 特征取决于该闭包如何使用被捕获的变量，而不是取决于闭包如何捕获它们。\n三种 Fn 的关系\n实际上，一个闭包并不仅仅实现某一种 Fn 特征，规则如下：\n\n所有的闭包都自动实现了 FnOnce 特征，因此任何一个闭包都至少可以被调用一次；\n没有移出所捕获变量的所有权的闭包自动实现了 FnMut 特征；\n不需要对捕获变量进行改变的闭包自动实现了 Fn 特征；\n\nfn main() {\n    let s = String::new();\n \n    // 闭包内部为不可变借用\n    let update_string =  || println!(&quot;{}&quot;,s);\n \n    exec(update_string);\n    exec1(update_string);\n    exec2(update_string);\n}\n \nfn exec&lt;F: FnOnce()&gt;(f: F)  {\n    f()\n}\n \nfn exec1&lt;F: FnMut()&gt;(mut f: F)  {\n    f()\n}\n \nfn exec2&lt;F: Fn()&gt;(f: F)  {\n    f()\n}\n虽然，闭包只是对 s 进行了不可变借用，实际上，它可以适用于任何一种 Fn 特征；\n关于第二条规则，有如下示例：\nfn main() {\n    let mut s = String::new();\n \n    let update_string = |str| -&gt; String {s.push_str(str); s };\n \n    exec(update_string);\n}\n \n// 编译出错\nfn exec&lt;&#039;a, F: FnMut(&amp;&#039;a str) -&gt; String&gt;(mut f: F) {\n    f(&quot;hello&quot;);\n}"},"rust/rust-bible/advanced/02-函数式编程-迭代器":{"title":"02-函数式编程-迭代器","links":[],"tags":[],"content":"For 循环与迭代器\n迭代器与 for 循环的区别在于 是否通过索引来访问集合；\n数组不是迭代器，但数组实现了 IntoIterator 特征，Rust 通过 for 语法糖，自动把实现了该特征的数组类型转换为迭代器；\nIntoIterator 特征拥有一个 into_iter 方法，因此我们还可以显式的把数组转换成迭代器：\nlet arr = [1, 2, 3];\nfor v in arr.into_iter() {\n    println!(&quot;{}&quot;, v);\n}\n惰性初始化\n在 Rust 中，迭代器是惰性的，意味着如果你不使用它，那么它将不会发生任何事：\nlet v1 = vec![1, 2, 3];\n \nlet v1_iter = v1.iter();\n \nfor val in v1_iter {\n    println!(&quot;{}&quot;, val);\n}\n创建了一个迭代器 v1_iter后，此时不会发生任何迭代行为，只有使用到该迭代器的时候，一切才开始。\nnext 方法\n先来看一个特征：\npub trait Iterator {\n    type Item;\n \n    fn next(&amp;mut self) -&gt; Option&lt;Self::Item&gt;;\n \n    // 省略其余有默认实现的方法\n}\n迭代器之所以成为迭代器，就是因为实现了 Iterator 特征，要实现该特征，最主要的就是实现其中的 next 方法，该方法控制如何从集合中取值，最终返回值的类型是关联类型Item。\n\n回顾：关联类型是在特征定义的语句块中，申明一个自定义类型，这样就可以在特征的方法签名中使用该类型；\n\n将 arr 转换成迭代器后，通过调用其上的 next 方法：\n\nnext 方法返回的是 Option 类型，当有值时返回 Some()，无值时返回 None；\n遍历是按照迭代器中元素的排列顺序依次进行的；\n手动迭代必须将迭代器声明为 mut 可变，因为调用 next 会改变迭代器其中的状态数据（当前遍历的位置等），而 for 循环去迭代则无需标注 mut，因为它会帮我们自动完成；\n\nlet values = vec![1, 2, 3];\n \n{\n    let result = match IntoIterator::into_iter(values) {\n        mut iter =&gt; loop {\n            match iter.next() {\n                Some(x) =&gt; { println!(&quot;{}&quot;, x); },\n                None =&gt; break,\n            }\n        },\n    };\n    result\n}\nIntoIterator::into_iter 是使用完全限定的方式去调用 into_iter 方法，这种调用方式跟 values.into_iter() 是等价的；\n使用了 loop 循环配合 next 方法来遍历迭代器中的元素，当迭代器返回 None 时，跳出循环。\nIntoIterator 特征\n迭代器自身也实现了 IntoIterator：\nimpl&lt;I: Iterator&gt; IntoIterator for I {\n    type Item = I::Item;\n    type IntoIter = I;\n \n    #[inline]\n    fn into_iter(self) -&gt; I {\n        self\n    }\n}\ninto_iter, iter, iter_mut\n\ninto_iter 会夺走所有权；\niter 是借用；\niter_mut 是可变借用；\n\n消费者与适配器\n消费者是迭代器上的方法，它会消费掉迭代器中的元素，然后返回其类型的值，这些消费者都有一个共同的特点：在它们的定义中，都依赖 next 方法来消费元素，因此这也是为什么迭代器要实现 Iterator 特征，而该特征必须要实现 next 方法的原因。\n消费者适配器\n只要迭代器上的某个方法 A 在其内部调用了 next 方法，那么 A 就被称为消费性适配器：因为 next 方法会消耗掉迭代器上的元素，所以方法 A 的调用也会消耗掉迭代器上的元素。\n一个例子是 sum 方法，它会拿走迭代器的所有权，然后通过不断调用 next 方法对里面的元素进行求和：\nfn main() {\n    let v1 = vec![1, 2, 3];\n \n    let v1_iter = v1.iter();\n \n    let total: i32 = v1_iter.sum();\n \n    assert_eq!(total, 6);\n \n    // v1_iter 是借用了 v1，因此 v1 可以照常使用\n    println!(&quot;{:?}&quot;, v1);\n \n    // 以下代码会报错，因为 `sum` 拿到了迭代器 `v1_iter` 的所有权\n    // println!(&quot;{:?}&quot;, v1_iter);\n}\n在使用 sum 方法后，我们将无法再使用 v1_iter，因为 sum 拿走了该迭代器的所有权：\nfn sum&lt;S&gt;(self) -&gt; S\n    where\n        Self: Sized,\n        S: Sum&lt;Self::Item&gt;,\n    {\n        Sum::sum(self)\n    }\n迭代器适配器\n既然消费者适配器是消费掉迭代器，然后返回一个值。那么迭代器适配器，顾名思义，会返回一个新的迭代器，这是实现链式方法调用的关键：v.iter().map().filter()...。\n与消费者适配器不同，迭代器适配器是惰性的，意味着你需要一个消费者适配器来收尾，最终将迭代器转换成一个具体的值：\nlet v1: Vec&lt;i32&gt; = vec![1, 2, 3];\n \nv1.iter().map(|x| x + 1);\n// iterators are lazy and do nothing unless consumed 迭代器 map 是惰性的，这里不产生任何效果\n// 还需要一个消费者适配器进行收尾：\nlet v2: Vec&lt;_&gt; = v1.iter().map(|x| x + 1).collect();\ncollect\ncollect 方法就是一个消费者适配器，使用它可以将一个迭代器中的元素收集到指定类型中，这里我们为 v2 标注了 Vec&lt;_&gt; 类型，就是为了告诉 collect：请把迭代器中的元素消费掉，然后把值收集成 Vec&lt;_&gt; 类型，至于为何使用 _，因为编译器会自动推导。\n为何 collect 在消费时要指定类型？是因为该方法其实很强大，可以收集成多种不同的集合类型；\nmap 会对迭代器中的每一个值进行一系列操作，然后把该值转换成另外一个新值，该操作是通过闭包 |x| x + 1 来完成；\n\nzip 是一个迭代器适配器，它的作用就是将两个迭代器的内容压缩到一起， 再通过 collect 将新迭代器中(K, V) 形式的值收集成 HashMap&lt;K, V&gt;：\nuse std::collections::HashMap;\nfn main() {\n    let names = [&quot;sunface&quot;, &quot;sunfei&quot;];\n    let ages = [18, 18];\n    let folks: HashMap&lt;_, _&gt; = names.into_iter().zip(ages.into_iter()).collect();\n \n    println!(&quot;{:?}&quot;,folks);\n}\n// {&quot;sunfei&quot;: 18, &quot;sunface&quot;: 18}\n闭包作为适配器参数\n实现 Iterator 特征\n其它集合类型一样可以创建迭代器，例如 HashMap。 你也可以创建自己的迭代器；\n首先，创建一个计数器：\nstruct Counter {\n    count: u32,\n}\n \nimpl Counter {\n    // 为计数器 Counter 实现了一个关联函数 new, 用于创建新的计数器实例\n    fn new() -&gt; Counter {\n        Counter { count: 0 }\n    }\n}\n// 为计数器实现 Iterator 特征\nimpl Iterator for Counter {\n    type Item = u32;\n \n    fn next(&amp;mut self) -&gt; Option&lt;Self::Item&gt; {\n        if self.count &lt; 5 {\n            self.count += 1;\n            Some(self.count)\n        } else {\n            None\n        }\n    }\n}\n \n迭代器的性能\nfor 循环和迭代器 iterator 完成同样的求和任务的性能对比，迭代器还要更快一点；\n迭代器是 Rust 的 零成本抽象（zero-cost abstractions）之一，意味着抽象并不会引入运行时开销，这与 Bjarne Stroustrup（C++ 的设计和实现者）在 Foundations of C++（2012） 中所定义的 零开销（zero-overhead）如出一辙：\n\nIn general, C++ implementations obey the zero-overhead principle: What you don’t use, you don’t pay for. And further: What you do use, you couldn’t hand code any better.\n一般来说，C++的实现遵循零开销原则：没有使用时，你不必为其买单。 更进一步说，需要使用时，你也无法写出更优的代码了。\n\n总之，迭代器是 Rust 受函数式语言启发而提供的高级语言特性，可以写出更加简洁、逻辑清晰的代码。编译器还可以通过循环展开（Unrolling）、向量化、消除边界检查等优化手段，使得迭代器和 for 循环都有极为高效的执行效率"},"rust/rust-bible/advanced/03-深入类型":{"title":"03-深入类型","links":[],"tags":[],"content":"类型转换\n常规的类型转换，即使用 as，一般是小类型向大类型做转换，因为反之转换会溢出报错：\nlet a = 3.1 as i8;\nlet b = 100_i8 as i32;\n \n// 内存地址转换为指针\nlet mut values: [i32; 2] = [1, 2];\nlet p1: *mut i32 = values.as_mut_ptr();\nlet first_address = p1 as usize; // 将p1内存地址转换为一个整数\nlet second_address = first_address + 4; // 4 == std::mem::size_of::&lt;i32&gt;()，i32类型占用4个字节，因此将内存地址 + 4\nlet p2 = second_address as *mut i32; // 访问该地址指向的下一个整数p2\nunsafe {\n    *p2 += 1;\n}\nassert_eq!(values[1], 3);\n对于转换错误，那么可以使用 TryInto：\n   let a: u8 = 10;\n   let b: u16 = 1500;\n \n   let b_: u8 = b.try_into().unwrap();\n   // try_into 会尝试进行一次转换，并返回一个 Result\n   if a &lt; b_ {\n     println!(&quot;Ten is less than one hundred.&quot;);\n   }\n以上转换方式主要用于数值类型；\n强制类型转换\n匹配特征时，不会做任何强制转换：\n// This declares an empty trait named `Trait`.\ntrait Trait {}\n \n// This is a function `foo` that takes a generic parameter `X` where `X` must implement the `Trait` trait.\n// The function itself does not have any implementation; it&#039;s just a placeholder.\nfn foo&lt;X: Trait&gt;(t: X) {}\n \n// This is an implementation of the `Trait` trait for references to `i32` (&amp;&#039;a i32).\n// It means that any reference to an `i32` type can be treated as implementing the `Trait` trait.\nimpl&lt;&#039;a&gt; Trait for &amp;&#039;a i32 {}\n \n// `&#039;a` is a lifetime parameter, it indicates that the implementation of the `Trait` trait is generic over lifetimes,\n// and it&#039;s saying that this implementation is valid for references (&amp;&#039;a i32) with any lifetime `&#039;a`.\n// The lifetime parameter &#039;a is a placeholder that will be replaced with an actual lifetime when the implementation is used.\n \n// `&amp;&#039;a i32` specifies that the trait is implemented for references to i32 with a certain lifetime &#039;a.\n// It means that any reference to an i32 with a specific lifetime can be treated as implementing the Trait trait.\n \n// In the main function, `t` is a mutable reference to an i32, and it doesn&#039;t directly implement the `Trait` trait.\n \nfn main() {\n    let t: &amp;mut i32 = &amp;mut 0;\n    foo(t);\n}\n点操作符\nnewtype\n在外部类型上实现外部特征必须使用 newtype 的方式，如果想使用 println!(”{}”, v) 的方式去格式化输出一个动态数组 Vec，以期给用户提供更加清晰可读的内容，那么就需要为 Vec 实现 Display 特征，二者都定义在标准库中：\nuse std::fmt;\n \nstruct Wrapper(Vec&lt;String&gt;);\n \nimpl fmt::Display for Wrapper {\n    fn fmt(&amp;self, f: &amp;mut fmt::Formatter) -&gt; fmt::Result {\n        write!(f, &quot;[{}]&quot;, self.0.join(&quot;, &quot;))\n    }\n}\n \nfn main() {\n    let w = Wrapper(vec![String::from(&quot;hello&quot;), String::from(&quot;world&quot;)]);\n    println!(&quot;w = {}&quot;, w);\n}\n\n类型异化：newtype 包装的同样的类型产生的新类型并不通用；\n隐藏内部类型：自定义类型不能直接调用内部类型方法；\n\n类型别名(Type Alias)\n类型别名并不是一个独立的全新的类型，而是某一个类型的别名。也就是不是一个新的类型，无法实现为其实现外部特征等。\n!永不返回类型\n! 用来说明一个函数永不返回任何值：\nfn main() {\n    let i = 2;\n    let v = match i {\n       0..=3 =&gt; i,\n      //  _ =&gt; println!(&quot;不合规定的值:{}&quot;, i)\n       _ =&gt; panic!(&quot;不合规定的值:{}&quot;, i)\n    };\n}\n上述代码中，使用 println 宏会编译报错类型不匹配，因为 println 返回元类型 ()， 而 panic 的返回值是 !，代表它决不会返回任何值，既然没有任何返回值，那自然不会存在分支类型不匹配的情况。\n不定长类型 DST\n从编译器何时能获知类型大小的角度出发，可以分成两类:\n\n定长类型( sized )，这些类型的大小在编译时是已知的；\n不定长类型( unsized )，与定长类型相反，它的大小只有到了程序运行时才能动态获知，这种类型又被称之为 DST (dynamically sized types)；\n\n正因为编译器无法在编译期获知类型大小，若你试图在代码中直接使用 DST 类型，将无法通过编译：\n\n动态大小的数组；\n切片；\nstr；\n特征对象\n\nfn my_function(n: usize) {\n    let array = [123; n];\n}\n \n \n// error\nlet s1: str = &quot;Hello there!&quot;;\nlet s2: str = &quot;How&#039;s it going?&quot;;\n \n// ok 字符串切片 &amp;str\nlet s3: &amp;str = &quot;on?&quot;\n \n// 只能通过引用或 Box 的方式来使用特征对象\nfn foobar_1(thing: &amp;dyn MyThing) {}     // OK\nfn foobar_2(thing: Box&lt;dyn MyThing&gt;) {} // OK\nfn foobar_3(thing: MyThing) {}          // ERROR!\n将动态数据固定化的秘诀就是使用引用指向这些动态数据，然后在引用中存储相关的内存位置、长度等信息;\n总结：只能间接使用的 DST。Rust 中常见的 DST 类型有: str、[T]、dyn Trait，它们都无法单独被使用，必须要通过引用或者 Box 来间接使用。\nSized 特征\n编译器在泛型类型中默认添加了 Sized 特征约束：\nfn generic&lt;T&gt;(t: T) {\n    // --snip--\n}\n \nfn generic&lt;T: Sized&gt;(t: T) {\n    // --snip--\n}\n而所有在编译时就能知道其大小的类型，都会自动实现 Sized 特征；\n每一个特征都是一个可以通过名称来引用的动态大小类型。\n因此如果想把特征作为具体的类型来传递给函数，你必须将其转换成一个特征对象：诸如 &amp;dyn Trait 或者 Box&lt;dyn Trait&gt; (还有 Rc&lt;dyn Trait&gt;)这些引用类型。\n在泛型函数中使用动态数据类型可以使用 ?Sized 特征；\nfn generic&lt;T: ?Sized&gt;(t: &amp;T) {\n    // --snip--\n}\n?Sized 特征用于表明类型 T 既有可能是固定大小的类型，也可能是动态大小的类型。还有一点要注意的是，函数参数类型从 T 变成了 &amp;T，因为 T 可能是动态大小的，因此需要用一个固定大小的指针(引用)来包裹它。\nBox\nBox 使用了一个引用来指向 str，但 Box 中没有该 str 的长度信息。所以不能使用 Box 将 str 类型包裹为固定大小类型。\n对于特征对象，编译器无需知道它具体是什么类型，只要知道它能调用哪几个方法即可，因此编译器帮我们实现了剩下的一切。\n// Error\nlet s1: Box&lt;str&gt; = Box::new(&quot;Hello there!&quot; as str);\nlet s2: Box&lt;str&gt; = &quot;Hello there!&quot;.into();"},"rust/rust-bible/advanced/04-智能指针":{"title":"智能指针","links":[],"tags":[],"content":"智能指针虽然也是指针，但是它是一个复杂的家伙：通过比引用更复杂的数据结构，包含比引用更多的信息，例如元数据，当前长度，最大可用长度等。\n引用计数智能指针：该智能指针允许你同时拥有同一个数据的多个所有权，它会跟踪每一个所有者并进行计数，当所有的所有者都归还后，该智能指针及指向的数据将自动被清理释放。\n智能指针，其实并不陌生，例如动态字符串 String 和动态数组 Vec，它们的数据结构中不仅仅包含了指向底层数据的指针，还包含了当前长度、最大长度等信息。\n智能指针往往是基于结构体实现，它与我们自定义的结构体最大的区别在于它实现了 Deref 和 Drop 特征：\n\nDeref 可以让智能指针像引用那样工作，这样你就可以写出同时支持智能指针和引用的代码，例如 *T；\nDrop 允许你指定智能指针超出作用域后自动执行的代码，例如做一些数据清除等收尾工作；\n\nBox&lt;T&gt; 堆对象分配\nBox&lt;T&gt; 是 Rust 中最常见的智能指针，其允许将一个值分配到堆上，然后在栈上保留一个智能指针指向堆上的数据。\n相比其它语言，Rust 堆上对象有一个特殊之处，它们都拥有一个所有者，因此受所有权规则的限制：当赋值时，发生的是所有权的转移。\nfn main() {\n    let b = foo(&quot;world&quot;);\n    println!(&quot;{}&quot;, b);\n}\n \nfn foo(x: &amp;str) -&gt; String {\n    let a = &quot;Hello, &quot;.to_string() + x;\n    a\n}\n在 foo 函数中，a 是 String 类型，它其实是一个智能指针结构体，该智能指针存储在函数栈中，指向堆上的字符串数据。当被从 foo 函数转移给 main 中的 b 变量时，栈上的智能指针被复制一份赋予给 b，而底层数据无需发生改变，这样就完成了所有权从 foo 函数内部到 b 的转移。\n堆栈的性能\n\n小型数据，在栈上的分配性能和读取性能都要比堆上高；\n中型数据，栈上分配性能高，但是读取性能和堆上并无区别，因为无法利用寄存器或 CPU 高速缓存，最终还是要经过一次内存寻址；\n大型数据，只建议在堆上分配和使用；\n\n总之，栈的分配速度肯定比堆上快，但是读取速度往往取决于你的数据能不能放入寄存器或 CPU 高速缓存。\n使用场景\nBox 是简单的封装，除了将值存储在堆上外，并没有其它性能上的损耗：\n\n特意的将数据分配在堆上；\n数据较大时，又不想在转移所有权时进行数据拷贝；\n类型的大小在编译期无法确定，但是我们又需要固定大小的类型时；\n特征对象，用于说明对象实现了一个特征，而不是某个特定的类型；\n\n使用 Box&lt;T&gt; 将数据存储在堆上\n如果一个变量拥有一个数值 let a = 3，那变量 a 必然是存储在栈上的，那如果我们想要 a 的值存储在堆上就需要使用 Box&lt;T&gt;：\nfn main() {\n    let a = Box::new(3);\n    println!(&quot;a = {}&quot;, a); // a = 3\n \n    // 下面一行代码将报错\n    // let b = a + 1; // cannot add `{integer}` to `Box&lt;{integer}&gt;`\n}\n这样就可以创建一个智能指针指向了存储在堆上的 3，并且 a 持有了该指针。\n\nprintln! 可以正常打印出 a 的值，是因为它隐式地调用了 Deref 对智能指针 a 进行了解引用；\n最后一行代码  let b = a + 1 报错，是因为在表达式中，我们无法自动隐式地执行 Deref 解引用操作，你需要使用 * 操作符 let b = *a + 1，来显式的进行解引用；\na 持有的智能指针将在作用域结束（main 函数结束）时，被释放掉，这是因为 Box&lt;T&gt; 实现了 Drop 特征；\n\n\n以上的例子在实际代码中其实很少会存在，因为将一个简单的值分配到堆上并没有太大的意义。将其分配在栈上，由于寄存器、CPU 缓存的原因，它的性能将更好，而且代码可读性也更好。\n\n避免栈上数据的拷贝\n当栈上数据转移所有权时，实际上是把数据拷贝了一份，最终新旧变量各自拥有不同的数据，因此所有权并未转移。\n\n在 Rust 中，当涉及到栈上数据的所有权转移时，实际上是将值从一个变量移动到另一个变量，而不是进行拷贝。这是 Rust 所推崇的“所有权模型”。\n但对于实现了 Copy 特征的类型，它们在进行值传递、赋值等操作时，并不会进行所有权转移，而是发生了值的拷贝。这是因为 Copy 特征的类型是在栈上分配内存的简单类型，比如整数、浮点数、字符等。这种情况下，原始变量仍然有效，而且新变量也拥有相同的值，没有发生所有权转移。\n\n而堆上则不然，底层数据并不会被拷贝，转移所有权仅仅是复制一份栈中的指针，再将新的指针赋予新的变量，然后让拥有旧指针的变量失效，最终完成了所有权的转移：\nfn main() {\n    // 在栈上创建一个长度为1000的数组\n    let arr = [0;1000];\n    // 将 arr 所有权转移 arr1，由于 `arr` 分配在栈上，因此这里实际上是直接重新深拷贝了一份数据\n    let arr1 = arr;\n \n    // arr 和 arr1 都拥有各自的栈上数组，因此不会报错\n    println!(&quot;{:?}&quot;, arr.len());\n    println!(&quot;{:?}&quot;, arr1.len());\n \n    // 在堆上创建一个长度为1000的数组，然后使用一个智能指针指向它\n    let arr = Box::new([0;1000]);\n    // 将堆上数组的所有权转移给 arr1，由于数据在堆上，因此仅仅拷贝了智能指针的结构体，底层数据并没有被拷贝\n    // 所有权顺利转移给 arr1，arr 不再拥有所有权\n    let arr1 = arr;\n    println!(&quot;{:?}&quot;, arr1.len());\n    // 由于 arr 不再拥有底层数组的所有权，因此下面代码将报错\n    // println!(&quot;{:?}&quot;, arr.len());\n}\n\n数组并没有实现 Copy 特征。数组在 Rust 中的赋值或传递时会发生所有权的转移（move），而不是发生值的拷贝。\n需要注意的是，数组的元素类型如果实现了 Copy 特征，那么数组本身可以实现 Copy 特征。如上，数组的元素是整数类型，而整数类型实现了 Copy，那么这个数组也可以实现 Copy。但这并不是数组本身的特性，而是元素类型的特性影响到了数组。\n\n将动态大小类型变为 Sized 固定大小类型\n\nRust 需要在编译时知道类型占用多少空间，如果一种类型在编译时无法知道具体的大小，那么被称为动态大小类型 DST。\n\n其中一种无法在编译时知道大小的类型是递归类型：在类型定义中又使用到了自身，或者说该类型的值的一部分可以是相同类型的其它值，这种值的嵌套理论上可以无限进行下去，所以 Rust 不知道递归类型需要多少空间：\nenum List {\n    Cons(i32, List),\n    Nil,\n}\n以上就是函数式语言中常见的 Cons List，它的每个节点包含一个 i32 值，还包含了一个新的 List，因此这种嵌套可以无限进行下去，Rust 认为该类型是一个 DST 类型，并给予报错。\n此时若想解决这个问题，就可以使用我们的 Box&lt;T&gt;：\nenum List {\n    Cons(i32, Box&lt;List&gt;),\n    Nil,\n}\n只需要将 List 存储到堆上，然后使用一个智能指针指向它，即可完成从 DST 到 Sized 类型 (固定大小类型) 的华丽转变。\n特征对象\n在 Rust 中，想实现不同类型组成的数组只有两个办法：枚举和特征对象，前者限制较多，因此后者往往是最常用的解决办法。\ntrait Draw {\n    fn draw(&amp;self);\n}\n \nstruct Button {\n    id: u32,\n}\nimpl Draw for Button {\n    fn draw(&amp;self) {\n        println!(&quot;这是屏幕上第{}号按钮&quot;, self.id)\n    }\n}\n \nstruct Select {\n    id: u32,\n}\n \nimpl Draw for Select {\n    fn draw(&amp;self) {\n        println!(&quot;这个选择框贼难用{}&quot;, self.id)\n    }\n}\n \nfn main() {\n    let elems: Vec&lt;Box&lt;dyn Draw&gt;&gt; = vec![Box::new(Button { id: 1 }), Box::new(Select { id: 2 })];\n \n    for e in elems {\n        e.draw()\n    }\n}\n以上代码将不同类型的 Button 和 Select 包装成 Draw 特征的特征对象，放入一个数组中，Box&lt;dyn Draw&gt; 就是特征对象。\n其实，特征也是 DST 类型，而特征对象在做的就是将 DST 类型转换为固定大小类型。\nBox 内存布局\n(stack)    (heap)\n┌──────┐   ┌───┐\n│ vec1 │──→│ 1 │\n└──────┘   ├───┤\n           │ 2 │\n           ├───┤\n           │ 3 │\n           ├───┤\n           │ 4 │\n           └───┘\n\n上述为Vec&lt;i32&gt; 的内存布局，可以看出，该智能指针存储在栈中，然后指向堆上的数组数据。那如果数组中每个元素都是一个 Box 对象呢？来看看 Vec&lt;Box&lt;i32&gt;&gt; 的内存布局：\n                    (heap)\n(stack)    (heap)   ┌───┐\n┌──────┐   ┌───┐ ┌─→│ 1 │\n│ vec2 │──→│B1 │─┘  └───┘\n└──────┘   ├───┤    ┌───┐\n           │B2 │───→│ 2 │\n           ├───┤    └───┘\n           │B3 │─┐  ┌───┐\n           ├───┤ └─→│ 3 │\n           │B4 │─┐  └───┘\n           └───┘ │  ┌───┐\n                 └─→│ 4 │\n                    └───┘\n\n因此当我们从中取出某个元素时，取到的是对应的智能指针 Box，需要对该智能指针进行解引用，才能取出最终的值：\nfn main() {\n    let arr = vec![Box::new(1), Box::new(2)];\n    let (first, second) = (&amp;arr[0], &amp;arr[1]);\n    let sum = **first + **second;\n}\n以上代码有几个值得注意的点：\n\n使用 &amp; 借用数组中的元素，否则会报所有权错误；\n表达式不能隐式的解引用，因此必须使用 ** 做两次解引用，第一次将 &amp;Box&lt;i32&gt; 类型转成 Box&lt;i32&gt;，第二次将 Box&lt;i32&gt; 转成 i32；\n\nBox::leak\nBox::leak，它可以消费掉 Box 并且强制目标值从内存中泄漏，这有啥用啊？\n例如，你可以把一个 String 类型，变成一个 &#039;static 生命周期的 &amp;str 类型：\nfn main() {\n   let s = gen_static_str();\n   println!(&quot;{}&quot;, s);\n}\n \nfn gen_static_str() -&gt; &amp;&#039;static str{\n    let mut s = String::new();\n    s.push_str(&quot;hello, world&quot;);\n \n    Box::leak(s.into_boxed_str())\n}\n通过 Box::leak 我们不仅返回了一个 &amp;str 字符串切片，它还是 &#039;static 生命周期的。\n\n真正具有 &#039;static 生命周期的往往都是编译期就创建的值，例如 let v = &quot;hello, world&quot;，这里 v 是直接打包到二进制可执行文件中的，因此该字符串具有 &#039;static 生命周期，再比如 const 常量。\n&#039;static 生命周期是 Rust 中表示静态生命周期的特殊标识符。它表示整个程序的运行时间，即程序的整个生命周期。值拥有 &#039;static 生命周期意味着这个值在程序的整个执行期间都有效，不会被销毁。\n在 Rust 中，有三种主要的生命周期标识符：\n\n&#039;static: 代表整个程序的生命周期，其内存空间在程序启动时分配，在程序结束时释放。对应于静态存储区域。\n&#039;a: 代表某个具体的生命周期，可以是函数的作用域、引用的生命周期等。\n&#039;_: 代表匿名生命周期，编译器会根据上下文自动推断。\n\n\n手动为变量标注 &#039;static 只是用来忽悠编译器的，但是超出作用域，一样被释放回收。而使用 Box::leak 就可以将一个运行期的值真正转为 &#039;static。\n总之，你需要一个在运行期初始化的值，但是可以全局有效，也就是和整个程序活得一样久，那么就可以使用 Box::leak，例如有一个存储配置的结构体实例，它是在运行期动态插入内容，那么就可以将其转为全局有效，虽然 Rc/Arc 也可以实现此功能，但是 Box::leak 是性能最高的。\n总结\nBox 背后是调用 jemalloc 来做内存管理，所以堆上的空间无需我们的手动管理。与此类似，带 GC 的语言中的对象也是借助于 Box 概念来实现的，一切皆对象 = 一切皆 Box， 只不过我们无需自己去 Box 罢了。\nDeref 解引用\n#[derive(Debug)]\nstruct Person {\n    name: String,\n    age: u8\n}\n \nimpl Person {\n    fn new(name: String, age: u8) -&gt; Self {\n        Person { name, age}\n    }\n \n    fn display(self: &amp;mut Person, age: u8) {\n        let Person{name, age} = &amp;self;\n    }\n}\n在 display 方法中，self 是 &amp;mut Person 的类型，对其取了一次引用 &amp;self，此时 &amp;self 的类型是 &amp;&amp;mut Person，然后又将其和 Person 类型进行匹配，取出其中的值。\n为何允许将 &amp;&amp;mut Person 跟 Person 进行匹配呢？\n\n何为智能指针？能不让你写出 ****s 形式的解引用，我认为就是智能: )，智能指针的名称来源，主要就在于它实现了 Deref 和 Drop 特征，这两个特征可以智能地帮助我们节省使用上的负担：\n\nDeref 可以让智能指针像引用那样工作，这样你就可以写出同时支持智能指针和引用的代码，例如 *T\nDrop 允许你指定智能指针超出作用域后自动执行的代码，例如做一些数据清除等收尾工作\n\n通过 * 获取引用背后的值\n常规引用是一个指针类型，包含了目标数据存储的内存地址。对常规引用使用 * 操作符，就可以通过解引用的方式获取到内存地址对应的数据值：\nfn main() {\n    let x = 5;\n    let y = &amp;x;\n \n    assert_eq!(5, x);\n    assert_eq!(5, *y);\n}\ny 就是一个常规引用，包含了值 5 所在的内存地址，然后通过解引用 *y，获取到了值 5。\n智能指针解引用\n智能指针，它是一个结构体类型，如果直接对其进行 *myStruct，显然编译器不知道该如何办，因此可以为智能指针结构体实现 Deref 特征。\n实现 Deref 后的智能指针结构体，就可以像普通引用一样，通过 * 进行解引用，例如 Box&lt;T&gt; 智能指针：\nfn main() {\n    // 智能指针 x 被 * 解引用为 i32 类型的值 1，然后再进行求和\n    let x = Box::new(1);\n    let sum = *x + 1;\n}\n定义自己的智能指针\nstruct MyBox&lt;T&gt;(T);\n \nimpl&lt;T&gt; MyBox&lt;T&gt; {\n    fn new(x: T) -&gt; MyBox&lt;T&gt; {\n        MyBox(x)\n    }\n}\n现在来为 MyBox 实现 Deref 特征，以支持 * 解引用操作符：\nuse std::ops::Deref;\n \nimpl&lt;T&gt; Deref for MyBox&lt;T&gt; {\n    type Target = T;\n \n    fn deref(&amp;self) -&gt; &amp;Self::Target {\n        &amp;self.0\n    }\n}\n当解引用 MyBox 智能指针时，返回元组结构体中的元素 &amp;self.0，有几点要注意的：\n\n在 Deref 特征中声明了关联类型 Target，关联类型主要是为了提升代码可读性；\nderef 返回的是一个常规引用，可以被 * 进行解引用；\n\n* 背后的原理\n当对智能指针 Box 进行解引用时，实际上 Rust 调用了以下方法：\n*(y.deref())\n首先调用 deref 方法返回值的常规引用，然后通过 * 对常规引用进行解引用，最终获取到目标值。\n至于 Rust 为何要使用这个有点啰嗦的方式实现，原因在于所有权系统的存在。如果 deref 方法直接返回一个值，而不是引用，那么该值的所有权将被转移给调用者，而我们不希望调用者仅仅只是 *T 一下，就拿走了智能指针中包含的值。\n\n需要注意的是，* 不会无限递归替换，从 *y 到 *(y.deref()) 只会发生一次，而不会继续进行替换然后产生形如 *((y.deref()).deref()) 的怪物。\n\n函数和方法中的隐式 Deref 转换\n对于函数和方法的传参，Rust 提供了一个极其有用的隐式转换：Deref 转换。若一个类型实现了 Deref 特征，那它的引用在传给函数或方法时，会根据参数签名来决定是否进行隐式的 Deref 转换，例如：\nfn main() {\n    let s = String::from(&quot;hello world&quot;);\n    display(&amp;s)\n}\n \nfn display(s: &amp;str) {\n    println!(&quot;{}&quot;,s);\n}\n以上代码有几点值得注意：\n\nString 实现了 Deref 特征，可以在需要时自动被转换为 &amp;str 类型\n&amp;s 是一个 &amp;String 类型，当它被传给 display 函数时，自动通过 Deref 转换成了 &amp;str\n必须使用 &amp;s 的方式来触发 Deref(仅引用类型的实参才会触发自动解引用)\n\n连续的隐式 Deref 转换\nDeref 可以支持连续的隐式转换，直到找到适合的形式为止：\nfn main() {\n    let s = MyBox::new(String::from(&quot;hello world&quot;));\n    display(&amp;s)\n}\n \nfn display(s: &amp;str) {\n    println!(&quot;{}&quot;,s);\n}\n首先 MyBox 被 Deref 成 String 类型，结果并不能满足 display 函数参数的要求，编译器发现 String 还可以继续 Deref 成 &amp;str，最终成功的匹配了函数参数。\n总之，当参与其中的类型定义了 Deref 特征时，Rust 会分析该类型并且连续使用 Deref 直到最终获得一个引用来匹配函数或者方法的参数类型，这种行为完全不会造成任何的性能损耗，因为完全是在编译期完成。\n缺点就是：如果你不知道某个类型是否实现了 Deref 特征，那么在看到某段代码时，并不能在第一时间反应过来该代码发生了隐式的 Deref 转换。\n看一下在方法、赋值中自动应用 Deref 的例子：\nfn main() {\n    let s = MyBox::new(String::from(&quot;hello, world&quot;));\n    let s1: &amp;str = &amp;s;\n    let s2: String = s.to_string();\n}\n对于 s1，我们通过两次 Deref 将 &amp;str 类型的值赋给了它（赋值操作需要手动解引用）；而对于 s2，我们在其上直接调用方法 to_string，实际上 MyBox 根本没有没有实现该方法，能调用 to_string，完全是因为编译器对 MyBox 应用了 Deref 的结果（方法调用会自动解引用）。\nDeref 规则总结\n一个类型为 T 的对象 foo，如果 T: Deref&lt;Target=U&gt;，那么，相关 foo 的引用 &amp;foo 在应用的时候会自动转换为 &amp;U。\n引用归一化\nRust 编译器实际上只能对 &amp;v 形式的引用进行解引用操作，那么问题来了，如果是一个智能指针或者 &amp;&amp;&amp;&amp;v 类型的呢？ 该如何对这两个进行解引用？\nRust 会在解引用时自动把智能指针和 &amp;&amp;&amp;&amp;v 做引用归一化操作，转换成 &amp;v 形式，最终再对 &amp;v 进行解引用：\n\n把智能指针（比如在库中定义的，Box、Rc、Arc、Cow 等）从结构体脱壳为内部的引用类型，也就是转成结构体内部的 &amp;v；\n把多重&amp;，例如 &amp;&amp;&amp;&amp;&amp;&amp;&amp;v，归一成 &amp;v；\n\n关于第二种情况，我们来看一段标准库源码：\nimpl&lt;T: ?Sized&gt; Deref for &amp;T {\n    type Target = T;\n \n    fn deref(&amp;self) -&gt; &amp;T {\n        *self\n    }\n}\n在这段源码中，&amp;T 被自动解引用为 T，也就是 &amp;T: Deref&lt;Target=T&gt; 。 按照这个代码，&amp;&amp;&amp;&amp;T 会被自动解引用为 &amp;&amp;&amp;T，然后再自动解引用为 &amp;&amp;T，以此类推， 直到最终变成 &amp;T。\n\n上述代码中的?Sized 是一个 trait bound 特征限制，用于指定类型参数 T 必须是一个具体的类型（sized type）或是一个动态大小类型（unsized type），即类型可以是具体大小也可以是动态大小。这样的 trait bound 主要用于处理引用（references）或 trait 对象（trait objects）。\nimpl&lt;T: ?Sized&gt; Deref for &amp;T 意味着对于任何类型 T，只要它是一个引用（reference），无论是具体大小还是动态大小，都实现了 Deref trait。这使得对 &amp;T 类型的引用可以被解引用（dereferenced），就像对原始类型 T 一样。\n\n几个例子\nfn foo(s: &amp;str) {}\n \n// 由于 String 实现了 Deref&lt;Target=str&gt;\nlet owned = &quot;Hello&quot;.to_string();\n \n// 因此下面的函数可以正常运行：\nfoo(&amp;owned);\nuse std::rc::Rc;\n \nfn foo(s: &amp;str) {}\n \n// String 实现了 Deref&lt;Target=str&gt;\nlet owned = &quot;Hello&quot;.to_string();\n// 且 Rc 智能指针可以被自动脱壳为内部的 `owned` 引用： &amp;String ，然后 &amp;String 再自动解引用为 &amp;str\nlet counted = Rc::new(owned);\n \n// 因此下面的函数可以正常运行:\nfoo(&amp;counted);\nstruct Foo;\n \nimpl Foo {\n    fn foo(&amp;self) { println!(&quot;Foo&quot;); }\n}\n \nlet f = &amp;&amp;Foo;\n \nf.foo();\n(&amp;f).foo();\n(&amp;&amp;f).foo();\n(&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;f).foo();\n三种 Deref 转换\n实际上 Rust 还支持将一个可变的引用转换成另一个可变的引用以及将一个可变引用转换成不可变的引用，规则如下：\n\n当 T: Deref&lt;Target=U&gt;，可以将 &amp;T 转换成 &amp;U，也就是之前看到的例子\n当 T: DerefMut&lt;Target=U&gt;，可以将 &amp;mut T 转换成 &amp;mut U\n当 T: Deref&lt;Target=U&gt;，可以将 &amp;mut T 转换成 &amp;U\n\nstruct MyBox&lt;T&gt; {\n    v: T,\n}\n \nimpl&lt;T&gt; MyBox&lt;T&gt; {\n    fn new(x: T) -&gt; MyBox&lt;T&gt; {\n        MyBox { v: x }\n    }\n}\n \nuse std::ops::Deref;\n \nimpl&lt;T&gt; Deref for MyBox&lt;T&gt; {\n    type Target = T;\n \n    fn deref(&amp;self) -&gt; &amp;Self::Target {\n        &amp;self.v\n    }\n}\n \nuse std::ops::DerefMut;\n \nimpl&lt;T&gt; DerefMut for MyBox&lt;T&gt; {\n    fn deref_mut(&amp;mut self) -&gt; &amp;mut Self::Target {\n        &amp;mut self.v\n    }\n}\n \nfn main() {\n    let mut s = MyBox::new(String::from(&quot;hello, &quot;));\n    display(&amp;mut s)\n}\n \nfn display(s: &amp;mut String) {\n    s.push_str(&quot;world&quot;);\n    println!(&quot;{}&quot;, s);\n}\n有几点值得注意:\n\n要实现 DerefMut 必须要先实现 Deref 特征：pub trait DerefMut: Deref；\nT: DerefMut&lt;Target=U&gt; ：将 &amp;mut T 类型通过 DerefMut 特征的方法转换为 &amp;mut U 类型，对应上例中，就是将 &amp;mut MyBox&lt;String&gt; 转换为 &amp;mut String；\nRust 可以把可变引用隐式的转换成不可变引用，但反之则不行；\n\nRc 与 Arc\nRust 所有权机制要求一个值只能有一个所有者，在大多数情况下，都没有问题，但是考虑以下情况：\n\n在图数据结构中，多个边可能会拥有同一个节点，该节点直到没有边指向它时，才应该被释放清理；\n在多线程中，多个线程可能会持有同一个数据，但是你受限于 Rust 的安全机制，无法同时获取该数据的可变引用；\n\n针对上述情况，Rust 在所有权机制之外又引入了额外的措施来简化相应的实现：通过引用计数的方式，允许一个数据资源在同一时刻拥有多个所有者。\n现机制就是 Rc 和 Arc，前者适用于单线程，后者适用于多线程。\nRc&lt;T&gt;\n引用计数(reference counting)，顾名思义，通过记录一个数据被引用的次数来确定该数据是否正在被使用。当引用次数归零时，就代表该数据不再被使用，因此可以被清理释放。\n当我们希望在堆上分配一个对象供程序的多个部分使用且无法确定哪个部分最后一个结束时，就可以使用 Rc 成为数据值的所有者，例如之前提到的多线程场景就非常适合。\n下面是经典的所有权被转移导致报错的例子：\nfn main() {\n    let s = String::from(&quot;hello, world&quot;);\n    // s在这里被转移给a\n    let a = Box::new(s);\n    // 报错！此处继续尝试将 s 转移给 b\n    let b = Box::new(s);\n}\n使用 Rc 就可以轻易解决：\nuse std::rc::Rc;\n \nfn main() {\n    let a = Rc::new(String::from(&quot;hello, world&quot;));\n    let b = Rc::clone(&amp;a);\n \n    assert_eq!(2, Rc::strong_count(&amp;a));\n    assert_eq!(Rc::strong_count(&amp;a), Rc::strong_count(&amp;b))\n}\n以上代码我们使用 Rc::new 创建了一个新的 Rc&lt;String&gt; 智能指针并赋给变量 a，该指针指向底层的字符串数据。\n智能指针 Rc&lt;T&gt; 在创建时，还会将引用计数加 1，此时获取引用计数的关联函数 Rc::strong_count 返回的值将是 1。\nRc::clone\n接着，我们又使用 Rc::clone 克隆了一份智能指针 Rc&lt;String&gt;，并将该智能指针的引用计数增加到 2。\n由于 a 和 b 是同一个智能指针的两个副本，因此通过它们两个获取引用计数的结果都是 2。\n不要被 clone 字样所迷惑，以为所有的 clone 都是深拷贝。这里的 clone 仅仅复制了智能指针并增加了引用计数，并没有克隆底层数据，因此 a 和 b 是共享了底层的字符串 s，这种复制效率是非常高的。\n当然你也可以使用 a.clone() 的方式来克隆，但是从可读性角度，我们更加推荐 Rc::clone 的方式。\n实际上在 Rust 中，还有不少 clone 都是浅拷贝，例如迭代器的克隆。\n观察引用计数的变化\n使用关联函数 Rc::strong_count 可以获取当前引用计数的值，我们来观察下引用计数如何随着变量声明、释放而变化：\nuse std::rc::Rc;\n \nfn main() {\n        let a = Rc::new(String::from(&quot;test ref counting&quot;));\n        println!(&quot;count after creating a = {}&quot;, Rc::strong_count(&amp;a)); // 1\n        let b =  Rc::clone(&amp;a);\n        println!(&quot;count after creating b = {}&quot;, Rc::strong_count(&amp;a)); // 2\n        {\n            let c =  Rc::clone(&amp;a);\n            println!(&quot;count after creating c = {}&quot;, Rc::strong_count(&amp;c)); // 3\n        }\n        println!(&quot;count after c goes out of scope = {}&quot;, Rc::strong_count(&amp;a)); // 2\n}\n有几点值得注意：\n\n由于变量 c 在语句块内部声明，当离开语句块时它会因为超出作用域而被释放，所以引用计数会减少 1，事实上这个得益于 Rc&lt;T&gt; 实现了 Drop 特征；\na、b、c 三个智能指针引用计数都是同样的，并且共享底层的数据，因此打印计数时用哪个都行；\n无法看到的是：当 a、b 超出作用域后，引用计数会变成 0，最终智能指针和它指向的底层字符串都会被清理释放；\n\n不可变引用\n事实上，Rc&lt;T&gt; 是指向底层数据的不可变的引用，因此你无法通过它来修改数据，这也符合 Rust 的借用规则：要么存在多个不可变借用，要么只能存在一个可变借用。\n但是实际开发中我们往往需要对数据进行修改，这时单独使用 Rc&lt;T&gt; 无法满足我们的需求，需要配合其它数据类型来一起使用，例如内部可变性的 RefCell&lt;T&gt; 类型以及互斥锁 Mutex&lt;T&gt;。事实上，在多线程编程中，Arc 跟 Mutex 锁的组合使用非常常见，它们既可以让我们在不同的线程中共享数据，又允许在各个线程中对其进行修改。\n一个综合例子\n考虑一个场景，有很多小工具，每个工具都有自己的主人，但是存在多个工具属于同一个主人的情况，此时使用 Rc&lt;T&gt; 就非常适合：\nuse std::rc::Rc;\n \nstruct Owner {\n    name: String,\n    // ...其它字段\n}\n \nstruct Gadget {\n    id: i32,\n    owner: Rc&lt;Owner&gt;,\n    // ...其它字段\n}\n \nfn main() {\n    // 创建一个基于引用计数的 `Owner`.\n    let gadget_owner: Rc&lt;Owner&gt; = Rc::new(Owner {\n        name: &quot;Gadget Man&quot;.to_string(),\n    });\n \n    // 创建两个不同的工具，它们属于同一个主人\n    let gadget1 = Gadget {\n        id: 1,\n        owner: Rc::clone(&amp;gadget_owner),\n    };\n    let gadget2 = Gadget {\n        id: 2,\n        owner: Rc::clone(&amp;gadget_owner),\n    };\n \n    // 释放掉第一个 `Rc&lt;Owner&gt;`\n    drop(gadget_owner);\n \n    // 尽管在上面我们释放了 gadget_owner，但是依然可以在这里使用 owner 的信息\n    // 原因是在 drop 之前，存在三个指向 Gadget Man 的智能指针引用，上面仅仅\n    // drop 掉其中一个智能指针引用，而不是 drop 掉 owner 数据，外面还有两个\n    // 引用指向底层的 owner 数据，引用计数尚未清零\n    // 因此 owner 数据依然可以被使用\n    println!(&quot;Gadget {} owned by {}&quot;, gadget1.id, gadget1.owner.name);\n    println!(&quot;Gadget {} owned by {}&quot;, gadget2.id, gadget2.owner.name);\n \n    // 在函数最后，`gadget1` 和 `gadget2` 也被释放，最终引用计数归零，随后底层\n    // 数据也被清理释放\n}\nRc 简单总结\n\nRc/Arc 是不可变引用，你无法修改它指向的值，只能进行读取，如果要修改，需要配合后面章节的内部可变性 RefCell 或互斥锁 Mutex；\n一旦最后一个拥有者消失，则资源会自动被回收，这个生命周期是在编译期就确定下来的；\nRc 只能用于同一线程内部，想要用于线程之间的对象共享，你需要使用 Arc；\nRc&lt;T&gt; 是一个智能指针，实现了 Deref 特征，因此你无需先解开 Rc 指针再使用里面的 T，而是可以直接使用 T，例如上例中的 gadget1.owner.name\n\n多线程无力的 Rc&lt;T&gt;\n来看看在多线程场景使用 Rc&lt;T&gt; 会如何：\nuse std::rc::Rc;\nuse std::thread;\n \nfn main() {\n    let s = Rc::new(String::from(&quot;多线程漫游者&quot;));\n    for _ in 0..10 {\n        let s = Rc::clone(&amp;s);\n        let handle = thread::spawn(move || {\n           println!(&quot;{}&quot;, s)\n        });\n    }\n}\n由于我们还没有学习多线程的章节，上面的例子就特地简化了相关的实现。首先通过 thread::spawn 创建一个线程，然后使用 move 关键字把克隆出的 s 的所有权转移到线程中。\n能够实现这一点，完全得益于 Rc 带来的多所有权机制，但是以上代码会报错：\nerror[E0277]: `Rc&lt;String&gt;` cannot be sent between threads safely\n\n表面原因是 Rc&lt;T&gt; 不能在线程间安全的传递，实际上是因为它没有实现 Send 特征，而该特征是恰恰是多线程间传递数据的关键，我们会在多线程章节中进行讲解。\n当然，还有更深层的原因：由于 Rc&lt;T&gt; 需要管理引用计数，但是该计数器并没有使用任何并发原语，因此无法实现原子化的计数操作，最终会导致计数错误。\nArc\nArc 是 Atomic Rc 的缩写，顾名思义：原子化的 Rc&lt;T&gt; 智能指针。原子化是一种并发原语，我们在后续章节会进行深入讲解，这里你只要知道它能保证我们的数据能够安全的在线程间共享即可。\nArc 的性能损耗\n你可能好奇，为何不直接使用 Arc，还要画蛇添足弄一个 Rc，还有 Rust 的基本数据类型、标准库数据类型为什么不自动实现原子化操作？这样就不存在线程不安全的问题了。\n原因在于原子化或者其它锁虽然可以带来的线程安全，但是都会伴随着性能损耗，而且这种性能损耗还不小。因此 Rust 把这种选择权交给你，毕竟需要线程安全的代码其实占比并不高，大部分时候我们开发的程序都在一个线程内。\nArc 和 Rc 拥有完全一样的 API，修改起来很简单：\nuse std::sync::Arc;\nuse std::thread;\n \nfn main() {\n    let s = Arc::new(String::from(&quot;多线程漫游者&quot;));\n    for _ in 0..10 {\n        let s = Arc::clone(&amp;s);\n        let handle = thread::spawn(move || {\n           println!(&quot;{}&quot;, s)\n        });\n    }\n}\n对了，两者还有一点区别：Arc 和 Rc 并没有定义在同一个模块，前者通过 use std::sync::Arc 来引入，后者通过 use std::rc::Rc。\n总结\n在 Rust 中，所有权机制保证了一个数据只会有一个所有者，但如果你想要在图数据结构、多线程等场景中共享数据，这种机制会成为极大的阻碍。好在 Rust 为我们提供了智能指针 Rc 和 Arc，使用它们就能实现多个所有者共享一个数据的功能。\nRc 和 Arc 的区别在于，后者是原子化实现的引用计数，因此是线程安全的，可以用于多线程中共享数据。\n这两者都是只读的，如果想要实现内部数据可修改，必须配合内部可变性 RefCell 或者互斥锁 Mutex 来一起使用。\nCell 和 RefCell\nRust 提供了 Cell 和 RefCell 用于内部可变性，简而言之，可以在拥有不可变引用的同时修改目标数据，对于正常的代码实现来说，这个是不可能做到的（要么一个可变借用，要么多个不可变借用）。\n\n内部可变性的实现是因为 Rust 使用了 unsafe 来做到这一点，但是对于使用者来说，这些都是透明的，因为这些不安全代码都被封装到了安全的 API 中。\n\nCell\nCell 和 RefCell 在功能上没有区别，区别在于 Cell&lt;T&gt; 适用于 T 实现 Copy 的情况：\nuse std::cell::Cell;\n \nfn main() {\n  let c = Cell::new(&quot;asdf&quot;);\n  let one = c.get();\n  c.set(&quot;qwer&quot;);\n  let two = c.get();\n  println!(&quot;{},{}&quot;, one, two);\n}\n以上代码展示了 Cell 的基本用法，有几点值得注意：\n\n“asdf” 是 &amp;str 类型，它实现了 Copy 特征；\nc.get 用来取值，c.set 用来设置新值；\n\n取到值保存在 one 变量后，还能同时进行修改，这个违背了 Rust 的借用规则，但是由于 Cell 的存在，我们很优雅地做到了这一点，但是如果你尝试在 Cell 中存放String：\nlet c = Cell::new(String::from(&quot;asdf&quot;));\n编译器会立刻报错，因为 String 没有实现 Copy 特征：\n| pub struct String {\n| ----------------- doesn&#039;t satisfy `String: Copy`\n|\n= note: the following trait bounds were not satisfied:\n        `String: Copy`\n\nRefCell\n由于 Cell 类型针对的是实现了 Copy 特征的值类型，因此在实际开发中，Cell 使用的并不多，因为我们要解决的往往是可变、不可变引用共存导致的问题，此时就需要借助于 RefCell 来达成目的。\n我们可以将所有权、借用规则与这些智能指针做一个对比：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRust 规则智能指针带来的额外规则一个数据只有一个所有者Rc/Arc让一个数据可以拥有多个所有者要么多个不可变借用，要么一个可变借用RefCell实现编译期可变、不可变引用共存违背规则导致编译错误违背规则导致运行时panic\n可以看出，Rc/Arc 和 RefCell 合在一起，解决了 Rust 中严苛的所有权和借用规则带来的某些场景下难使用的问题。但是它们并不是银弹，例如 RefCell 实际上并没有解决可变引用和引用可以共存的问题，只是将报错从编译期推迟到运行时，从编译器错误变成了 panic 异常：\nuse std::cell::RefCell;\n \nfn main() {\n    let s = RefCell::new(String::from(&quot;hello, world&quot;));\n    let s1 = s.borrow();\n    let s2 = s.borrow_mut();\n \n    println!(&quot;{},{}&quot;, s1, s2);\n}\n上面代码在编译期不会报任何错误，你可以顺利运行程序，但是依然会因为违背了借用规则导致了运行期 panic。\nRefCell 为何存在\n相信肯定有读者有疑问了，这么做有任何意义吗？还不如在编译期报错，至少能提前发现问题，而且性能还更好。\n存在即合理，究其根因，在于 Rust 编译期的宁可错杀，绝不放过的原则，当编译器不能确定你的代码是否正确时，就统统会判定为错误，因此难免会导致一些误报。\n而 RefCell 正是用于你确信代码是正确的，而编译器却发生了误判时。\n对于大型的复杂程序，也可以选择使用 RefCell 来让事情简化。例如在 Rust 编译器的ctxt结构体中有大量的 RefCell 类型的 map 字段，主要的原因是：这些 map 会被分散在各个地方的代码片段所广泛使用或修改。\n由于这种分散在各处的使用方式，导致了管理可变和不可变成为一件非常复杂的任务（甚至不可能），你很容易就碰到编译器抛出来的各种错误。而且 RefCell 的运行时错误在这种情况下也变得非常可爱：一旦有人做了不正确的使用，代码会 panic，然后告诉我们哪些借用冲突了。\n总之，当你确信编译器误报但不知道该如何解决时，或者你有一个引用类型，需要被四处使用和修改然后导致借用关系难以管理时，都可以优先考虑使用 RefCell。\nRefCell 简单总结\n\n与 Cell 用于可 Copy 的值不同，RefCell 用于引用；\nRefCell 只是将借用规则从编译期推迟到程序运行期，并不能帮你绕过这个规则；\nRefCell 适用于编译期误报或者一个引用被在多处代码使用、修改以至于难于管理借用关系时；\n使用 RefCell 时，违背借用规则会导致运行期的 panic；\n\n选择 Cell 还是 RefCell\n根据本文的内容，我们可以大概总结下两者的区别：\n\nCell 只适用于 Copy 类型，用于提供值，而 RefCell 用于提供引用；\nCell 不会 panic，而 RefCell 会；\n\n性能比较\nCell 没有额外的性能损耗，例如以下两段代码的性能其实是一致的：\n// code snipet 1\nlet x = Cell::new(1);\nlet y = &amp;x;\nlet z = &amp;x;\nx.set(2);\ny.set(3);\nz.set(4);\nprintln!(&quot;{}&quot;, x.get());\n \n// code snipet 2\nlet mut x = 1;\nlet y = &amp;mut x;\nlet z = &amp;mut x;\nx = 2;\n*y = 3;\n*z = 4;\nprintln!(&quot;{}&quot;, x);\n虽然性能一致，但代码 1 拥有代码 2 不具有的优势：它能编译成功:)\n与 Cell 的 zero cost 不同，RefCell 其实是有一点运行期开销的，原因是它包含了一个字节大小的“借用状态”指示器，该指示器在每次运行时借用时都会被修改，进而产生一点开销。\n总之，当非要使用内部可变性时，首选 Cell，只有你的类型没有实现 Copy 时，才去选择 RefCell。\n内部可变性\n之前我们提到 RefCell 具有内部可变性，何为内部可变性？简单来说，对一个不可变的值进行可变借用，但这个并不符合 Rust 的基本借用规则：\nfn main() {\n    let x = 5;\n    let y = &amp;mut x;\n}\n上面的代码会报错，因为我们不能对一个不可变的值进行可变借用，这会破坏 Rust 的安全性保证，相反，你可以对一个可变值进行不可变借用。原因是：当值不可变时，可能会有多个不可变的引用指向它，此时若将其中一个修改为可变的，会造成可变引用与不可变引用共存的情况；而当值可变时，最多只会有一个可变引用指向它，将其修改为不可变，那么最终依然是只有一个不可变的引用指向它。\n虽然基本借用规则是 Rust 的基石，然而在某些场景中，一个值可以在其方法内部被修改，同时对于其它代码不可变，是很有用的：\n// 定义在外部库中的特征\npub trait Messenger {\n    fn send(&amp;self, msg: String);\n}\n \n// --------------------------\n// 我们的代码中的数据结构和实现\nstruct MsgQueue {\n    msg_cache: Vec&lt;String&gt;,\n}\n \nimpl Messenger for MsgQueue {\n    fn send(&amp;self, msg: String) {\n        self.msg_cache.push(msg)\n    }\n}\n如上所示，外部库中定义了一个消息发送器特征 Messenger，它只有一个发送消息的功能：fn send(&amp;self, msg: String)，因为发送消息不需要修改自身，因此原作者在定义时，使用了 &amp;self 的不可变借用，这个无可厚非。\n我们要在自己的代码中使用该特征实现一个异步消息队列，出于性能的考虑，消息先写到本地缓存(内存)中，然后批量发送出去，因此在 send 方法中，需要将消息先行插入到本地缓存 msg_cache 中。但是问题来了，该 send 方法的签名是 &amp;self，因此上述代码会报错，而且在报错的同时，编译器大聪明还善意地给出了提示：将 &amp;self 修改为 &amp;mut self，但是。。。我们实现的特征是定义在外部库中，因此该签名根本不能修改。值此危急关头， RefCell 闪亮登场：\nuse std::cell::RefCell;\npub trait Messenger {\n    fn send(&amp;self, msg: String);\n}\n \npub struct MsgQueue {\n    msg_cache: RefCell&lt;Vec&lt;String&gt;&gt;,\n}\n \nimpl Messenger for MsgQueue {\n    fn send(&amp;self, msg: String) {\n        self.msg_cache.borrow_mut().push(msg)\n    }\n}\n \nfn main() {\n    let mq = MsgQueue {\n        msg_cache: RefCell::new(Vec::new()),\n    };\n    mq.send(&quot;hello, world&quot;.to_string());\n}\n这个 MQ 功能很弱，但是并不妨碍我们演示内部可变性的核心用法：通过包裹一层 RefCell，成功的让 &amp;self 中的 msg_cache 成为一个可变值，然后实现对其的修改。\nRc + RefCell 组合使用\n在 Rust 中，一个常见的组合就是 Rc 和 RefCell 在一起使用，前者可以实现一个数据拥有多个所有者，后者可以实现数据的可变性：\nuse std::cell::RefCell;\nuse std::rc::Rc;\n \nfn main() {\n    let s = Rc::new(RefCell::new(&quot;我很善变，还拥有多个主人&quot;.to_string()));\n \n    let s1 = s.clone();\n    let s2 = s.clone();\n    // let mut s2 = s.borrow_mut();\n    s2.borrow_mut().push_str(&quot;, oh yeah!&quot;);\n \n    println!(&quot;{:?}\\n{:?}\\n{:?}&quot;, s, s1, s2);\n}\n上面代码中，我们使用 RefCell&lt;String&gt; 包裹一个字符串，同时通过 Rc 创建了它的三个所有者：s、s1和s2，并且通过其中一个所有者 s2 对字符串内容进行了修改。\n由于 Rc 的所有者们共享同一个底层的数据，因此当一个所有者修改了数据时，会导致全部所有者持有的数据都发生了变化。\n程序的运行结果也在预料之中：\nRefCell { value: &quot;我很善变，还拥有多个主人, oh yeah!&quot; }\nRefCell { value: &quot;我很善变，还拥有多个主人, oh yeah!&quot; }\nRefCell { value: &quot;我很善变，还拥有多个主人, oh yeah!&quot; }\n\n性能损耗\n相信这两者组合在一起使用时，很多人会好奇到底性能如何，下面我们来简单分析下。\n首先给出一个大概的结论，这两者结合在一起使用的性能其实非常高，大致相当于没有线程安全版本的 C++ std::shared_ptr 指针，事实上，C++ 这个指针的主要开销也在于原子性这个并发原语上，毕竟线程安全在哪个语言中开销都不小。\n内存损耗\n两者结合的数据结构与下面类似：\nstruct Wrapper&lt;T&gt; {\n    // Rc\n    strong_count: usize,\n    weak_count: usize,\n    // Refcell\n    borrow_count: isize,\n    // 包裹的数据\n    item: T,\n}\n从上面可以看出，从对内存的影响来看，仅仅多分配了三个usize/isize，并没有其它额外的负担。\nCPU 损耗\n从 CPU 来看，损耗如下：\n\n对 Rc&lt;T&gt; 解引用是免费的（编译期），但是 * 带来的间接取值并不免费\n克隆 Rc&lt;T&gt; 需要将当前的引用计数跟 0 和 usize::Max 进行一次比较，然后将计数值加 1\n释放（drop） Rc&lt;T&gt; 需要将计数值减 1， 然后跟 0 进行一次比较\n对 RefCell 进行不可变借用，需要将 isize 类型的借用计数加 1，然后跟 0 进行比较\n对 RefCell 的不可变借用进行释放，需要将 isize 减 1\n对 RefCell 的可变借用大致流程跟上面差不多，但是需要先跟 0 比较，然后再减 1\n对 RefCell 的可变借用进行释放，需要将 isize 加 1\n\n其实这些细节不必过于关注，只要知道 CPU 消耗也非常低，甚至编译器还会对此进行进一步优化！\nCPU 缓存 Miss\n唯一需要担心的可能就是这种组合数据结构对于 CPU 缓存是否亲和，这个我们无法证明，只能提出来存在这个可能性，最终的性能影响还需要在实际场景中进行测试。\n总之，分析这两者组合的性能还挺复杂的，大概总结下：\n\n从表面来看，它们带来的内存和 CPU 损耗都不大；\n但是由于 Rc 额外的引入了一次间接取值（*），在少数场景下可能会造成性能上的显著损失；\nCPU 缓存可能也不够亲和；\n\n通过 Cell::from_mut 解决借用冲突\n在 Rust 1.37 版本中新增了两个非常实用的方法：\n\nCell::from_mut，该方法将 &amp;mut T 转为 &amp;Cell&lt;T&gt;；\nCell::as_slice_of_cells，该方法将 &amp;Cell&lt;[T]&gt; 转为 &amp;[Cell&lt;T&gt;]；\n\n这里我们不做深入的介绍，但是来看看如何使用这两个方法来解决一个常见的借用冲突问题：\nfn is_even(i: i32) -&gt; bool {\n    i % 2 == 0\n}\n \nfn retain_even(nums: &amp;mut Vec&lt;i32&gt;) {\n    let mut i = 0;\n    for num in nums.iter().filter(|&amp;num| is_even(*num)) {\n        nums[i] = *num;\n        i += 1;\n    }\n    nums.truncate(i);\n}\nerror[E0502]: cannot borrow `*nums` as mutable because it is also borrowed as immutable\n --&gt; src/main.rs:8:9\n  |\n7 |     for num in nums.iter().filter(|&amp;num| is_even(*num)) {\n  |                ----------------------------------------\n  |                |\n  |                immutable borrow occurs here\n  |                immutable borrow later used here\n8 |         nums[i] = *num;\n  |         ^^^^ mutable borrow occurs here\n\n在 Rust 中，迭代器默认是进行不可变借用的，这是为了强调对数据的只读性，以提高代码的安全性。Rust 的设计理念之一是“借用检查器（Borrow Checker）”，它确保在编译时就能够检测并防止数据竞争和内存安全问题。\n\n很明显，报错是因为同时借用了不可变与可变引用，你可以通过索引的方式来避免这个问题：\nfn retain_even(nums: &amp;mut Vec&lt;i32&gt;) {\n    let mut i = 0;\n    for j in 0..nums.len() {\n        if is_even(nums[j]) {\n            nums[i] = nums[j];\n            i += 1;\n        }\n    }\n    nums.truncate(i);\n}\n但是这样就违背我们的初衷了，毕竟迭代器会让代码更加简洁，那么还有其它的办法吗？\n这时就可以使用 Cell 新增的这两个方法：\nuse std::cell::Cell;\n \nfn retain_even(nums: &amp;mut Vec&lt;i32&gt;) {\n    let slice: &amp;[Cell&lt;i32&gt;] = Cell::from_mut(&amp;mut nums[..])\n        .as_slice_of_cells();\n \n    let mut i = 0;\n    for num in slice.iter().filter(|num| is_even(num.get())) {\n        slice[i].set(num.get());\n        i += 1;\n    }\n \n    nums.truncate(i);\n}\n此时代码将不会报错，因为 Cell 上的 set 方法获取的是不可变引用 pub fn set(&amp;self, val: T)。\n当然，以上代码的本质还是对 Cell 的运用，只不过这两个方法可以很方便的帮我们把 &amp;mut [T] 类型转换成 &amp;[Cell&lt;T&gt;] 类型。\n总结\nCell 和 RefCell 都为我们带来了内部可变性这个重要特性，同时还将借用规则的检查从编译期推迟到运行期，但是这个检查并不能被绕过，该来早晚还是会来，RefCell 在运行期的报错会造成 panic。\nRefCell 适用于编译器误报或者一个引用被在多个代码中使用、修改以至于难于管理借用关系时，还有就是需要内部可变性时。\n从性能上看，RefCell 由于是非线程安全的，因此无需保证原子性，性能虽然有一点损耗，但是依然非常好，而 Cell 则完全不存在任何额外的性能损耗。\nRc 跟 RefCell 结合使用可以实现多个所有者共享同一份数据，非常好用，但是潜在的性能损耗也要考虑进去，建议对于热点代码使用时，做好 benchmark。"},"rust/rust-bible/advanced/05-循环引用与自引用":{"title":"05-循环引用与自引用","links":[],"tags":[],"content":"Weak 与循环引用\nRust 的安全性是众所周知的，但是不代表它不会内存泄漏。一个典型的例子就是同时使用 Rc&lt;T&gt; 和 RefCell&lt;T&gt; 创建循环引用，最终这些引用的计数都无法被归零，因此 Rc&lt;T&gt; 拥有的值也不会被释放清理\n何为循环引用\n关于内存泄漏，如果你没有充足的 Rust 经验，可能都无法造出一份代码来再现它：\nuse crate::List::{Cons, Nil};\nuse std::cell::RefCell;\nuse std::rc::Rc;\n \n#[derive(Debug)]\nenum List {\n    Cons(i32, RefCell&lt;Rc&lt;List&gt;&gt;),\n    Nil,\n}\n \nimpl List {\n    fn tail(&amp;self) -&gt; Option&lt;&amp;RefCell&lt;Rc&lt;List&gt;&gt;&gt; {\n        match self {\n            Cons(_, item) =&gt; Some(item),\n            Nil =&gt; None,\n        }\n    }\n}\n \nfn main() {}\n这里我们创建一个有些复杂的枚举类型 List，这个类型很有意思，它的每个值都指向了另一个 List，此外，得益于 Rc 的使用还允许多个值指向一个 List。\n一个 List 类型，它们或者是拥有值且指向另一个 List 的Cons，或者是一个没有值的终结点 Nil。同时，由于 RefCell 的使用，每个 List 所指向的 List 还能够被修改。\n下面来使用一下这个复杂的 List 枚举：\nfn main() {\n    let a = Rc::new(Cons(5, RefCell::new(Rc::new(Nil))));\n \n    println!(&quot;a的初始化rc计数 = {}&quot;, Rc::strong_count(&amp;a));\n    println!(&quot;a指向的节点 = {:?}&quot;, a.tail());\n \n    // 创建`b`到`a`的引用\n    let b = Rc::new(Cons(10, RefCell::new(Rc::clone(&amp;a))));\n \n    println!(&quot;在b创建后，a的rc计数 = {}&quot;, Rc::strong_count(&amp;a));\n    println!(&quot;b的初始化rc计数 = {}&quot;, Rc::strong_count(&amp;b));\n    println!(&quot;b指向的节点 = {:?}&quot;, b.tail());\n \n    // 利用RefCell的可变性，创建了`a`到`b`的引用\n    if let Some(link) = a.tail() {\n        *link.borrow_mut() = Rc::clone(&amp;b);\n    }\n \n    println!(&quot;在更改a后，b的rc计数 = {}&quot;, Rc::strong_count(&amp;b));\n    println!(&quot;在更改a后，a的rc计数 = {}&quot;, Rc::strong_count(&amp;a));\n \n    // 下面一行println!将导致循环引用\n    // 我们可怜的8MB大小的main线程栈空间将被它冲垮，最终造成栈溢出\n    // println!(&quot;a next item = {:?}&quot;, a.tail());\n}\n这个类型定义看着复杂，使用起来更复杂！不过排除这些因素，我们可以清晰看出：\n\n在创建了 a 后，紧接着就使用 a 创建了 b，因此 b 引用了 a\n然后我们又利用 Rc 克隆了 b，然后通过 RefCell 的可变性，让 a 引用了 b\n\n至此我们成功创建了循环引用a→ b → a → b ····\n先来观察下引用计数：\na的初始化rc计数 = 1\na指向的节点 = Some(RefCell { value: Nil })\n在b创建后，a的rc计数 = 2\nb的初始化rc计数 = 1\nb指向的节点 = Some(RefCell { value: Cons(5, RefCell { value: Nil }) })\n在更改a后，b的rc计数 = 2\n在更改a后，a的rc计数 = 2\n在 main 函数结束前，a 和 b 的引用计数均是 2，随后 b 触发 Drop，此时引用计数会变为 1，并不会归 0，因此 b 所指向内存不会被释放，同理可得 a 指向的内存也不会被释放，最终发生了内存泄漏。\n现在我们还需要轻轻的推一下，让塔米诺骨牌轰然倒塌。反注释最后一行代码，通过 a.tail 的调用，Rust 试图打印出 a -&gt; b -&gt; a ··· 的所有内容，但是在不懈的努力后，main 线程终于不堪重负，发生了栈溢出。\n以上的代码可能并不会造成什么大的问题，但是在一个更加复杂的程序中，类似的问题可能会造成你的程序不断地分配内存、泄漏内存，最终程序会不幸OOM，当然这其中的 CPU 损耗也不可小觑。\n总之，创建循环引用并不简单，但是也并不是完全遇不到，当你使用 RefCell&lt;Rc&lt;T&gt;&gt; 或者类似的类型嵌套组合（具备内部可变性和引用计数）时，就要打起万分精神，前面可能是深渊！\n那么问题来了？ 如果我们确实需要实现上面的功能，该怎么办？答案是使用 Weak。\nWeak\nWeak 非常类似于 Rc，但是与 Rc 持有所有权不同，Weak 不持有所有权，它仅仅保存一份指向数据的弱引用：如果你想要访问数据，需要通过 Weak 指针的 upgrade 方法实现，该方法返回一个类型为 Option&lt;Rc&lt;T&gt;&gt; 的值。\n看到这个返回，相信大家就懂了：何为弱引用？就是不保证引用关系依然存在，如果不存在，就返回一个 None！\n因为 Weak 引用不计入所有权，因此它无法阻止所引用的内存值被释放掉，而且 Weak 本身不对值的存在性做任何担保，引用的值还存在就返回 Some，不存在就返回 None。\nWeak 与 Rc 对比\n我们来将 Weak 与 Rc 进行以下简单对比：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWeakRc不计数引用计数不拥有所有权拥有值的所有权不阻止值被释放(drop)所有权计数归零，才能 drop引用的值存在返回 Some，不存在返回 None引用的值必定存在通过 upgrade 取到 Option&lt;Rc&lt;T&gt;&gt;，然后再取值通过 Deref 自动解引用，取值无需任何操作\n通过这个对比，可以非常清晰的看出 Weak 为何这么弱，而这种弱恰恰非常适合我们实现以下的场景：\n\n持有一个 Rc 对象的临时引用，并且不在乎引用的值是否依然存在；\n阻止 Rc 导致的循环引用，因为 Rc 的所有权机制，会导致多个 Rc 都无法计数归零；\n\n使用方式简单总结下：对于父子引用关系，可以让父节点通过 Rc 来引用子节点，然后让子节点通过 Weak 来引用父节点。\nWeak 总结\n因为 Weak 本身并不是很好理解，因此我们再来帮大家梳理总结下，然后再通过一个例子，来彻底掌握。\nWeak 通过 use std::rc::Weak 来引入，它具有以下特点:\n\n可访问，但没有所有权，不增加引用计数，因此不会影响被引用值的释放回收\n可由 Rc&lt;T&gt; 调用 downgrade 方法转换成 Weak&lt;T&gt;\nWeak&lt;T&gt; 可使用 upgrade 方法转换成 Option&lt;Rc&lt;T&gt;&gt;，如果资源已经被释放，则 Option 的值是 None\n常用于解决循环引用的问题\n\n一个简单的例子：\nuse std::rc::Rc;\n \nfn main() {\n    // 创建Rc，持有一个值5\n    let five = Rc::new(5);\n \n    // 通过Rc，创建一个Weak指针\n    let weak_five = Rc::downgrade(&amp;five);\n \n    // Weak引用的资源依然存在，取到值5\n    let strong_five: Option&lt;Rc&lt;_&gt;&gt; = weak_five.upgrade();\n    assert_eq!(*strong_five.unwrap(), 5);\n \n    // 手动释放资源`five`\n    drop(five);\n \n    // Weak引用的资源已不存在，因此返回None\n    let strong_five: Option&lt;Rc&lt;_&gt;&gt; = weak_five.upgrade();\n    assert_eq!(strong_five, None);\n}\n需要承认的是，使用 Weak 让 Rust 本来就堪忧的代码可读性又下降了不少，但是。。。真香，因为可以解决循环引用了。\n使用 Weak 解决循环引用\n理论知识已经足够，现在用两个例子来模拟下真实场景下可能会遇到的循环引用。\n工具间的故事\n工具间里，每个工具都有其主人，且多个工具可以拥有一个主人；同时一个主人也可以拥有多个工具，在这种场景下，就很容易形成循环引用，好在我们有 Weak：\nuse std::rc::Rc;\nuse std::rc::Weak;\nuse std::cell::RefCell;\n \n// 主人\nstruct Owner {\n    name: String,\n    gadgets: RefCell&lt;Vec&lt;Weak&lt;Gadget&gt;&gt;&gt;,\n}\n \n// 工具\nstruct Gadget {\n    id: i32,\n    owner: Rc&lt;Owner&gt;,\n}\n \nfn main() {\n    // 创建一个 Owner\n    // 需要注意，该 Owner 也拥有多个 `gadgets`\n    let gadget_owner : Rc&lt;Owner&gt; = Rc::new(\n        Owner {\n            name: &quot;Gadget Man&quot;.to_string(),\n            gadgets: RefCell::new(Vec::new()),\n        }\n    );\n \n    // 创建工具，同时与主人进行关联：创建两个 gadget，他们分别持有 gadget_owner 的一个引用。\n    let gadget1 = Rc::new(Gadget{id: 1, owner: gadget_owner.clone()});\n    let gadget2 = Rc::new(Gadget{id: 2, owner: gadget_owner.clone()});\n \n    // 为主人更新它所拥有的工具\n    // 因为之前使用了 `Rc`，现在必须要使用 `Weak`，否则就会循环引用\n    gadget_owner.gadgets.borrow_mut().push(Rc::downgrade(&amp;gadget1));\n    gadget_owner.gadgets.borrow_mut().push(Rc::downgrade(&amp;gadget2));\n \n    // 遍历 gadget_owner 的 gadgets 字段\n    for gadget_opt in gadget_owner.gadgets.borrow().iter() {\n \n        // gadget_opt 是一个 Weak&lt;Gadget&gt; 。 因为 weak 指针不能保证他所引用的对象\n        // 仍然存在。所以我们需要显式的调用 upgrade() 来通过其返回值(Option&lt;_&gt;)来判\n        // 断其所指向的对象是否存在。\n        // 当然，Option 为 None 的时候这个引用原对象就不存在了。\n        let gadget = gadget_opt.upgrade().unwrap();\n        println!(&quot;Gadget {} owned by {}&quot;, gadget.id, gadget.owner.name);\n    }\n \n    // 在 main 函数的最后，gadget_owner，gadget1 和 gadget2 都被销毁。\n    // 具体是，因为这几个结构体之间没有了强引用（`Rc&lt;T&gt;`），所以，当他们销毁的时候。\n    // 首先 gadget2 和 gadget1 被销毁。\n    // 然后因为 gadget_owner 的引用数量为 0，所以这个对象可以被销毁了。\n    // 循环引用问题也就避免了\n}\nunsafe 解决循环引用\n除了使用 Rust 标准库提供的这些类型，你还可以使用 unsafe 里的裸指针来解决这些棘手的问题；\n虽然 unsafe 不安全，但是在各种库的代码中依然很常见用它来实现自引用结构，主要优点如下:\n\n性能高，毕竟直接用裸指针操作；\n代码更简单更符合直觉：对比下 Option&lt;Rc&lt;RefCell&lt;Node&gt;&gt;&gt;\n\n总结\n本文深入讲解了何为循环引用以及如何使用 Weak 来解决，同时还结合 Rc、RefCell、Weak 等实现了两个有实战价值的例子，让大家对智能指针的使用更加融会贯通。\n至此，智能指针一章即将结束（严格来说还有一个 Mutex 放在多线程一章讲解），而 Rust 语言本身的学习之旅也即将结束，后面我们将深入多线程、项目工程、应用实践、性能分析等特色专题，来一睹 Rust 在这些领域的风采。\n结构体自引用\n结构体自引用在 Rust 中是一个众所周知的难题，而且众说纷纭，也没有一篇文章能把相关的话题讲透。\n平平无奇的自引用\n可能也有不少人第一次听说自引用结构体，那咱们先来看看它们长啥样。\nstruct SelfRef&lt;&#039;a&gt; {\n    value: String,\n \n    // 该引用指向上面的value\n    pointer_to_value: &amp;&#039;a str,\n}\n以上就是一个很简单的自引用结构体，看上去好像没什么，那来试着运行下：\nfn main(){\n    let s = &quot;aaa&quot;.to_string();\n    let v = SelfRef {\n        value: s,\n        pointer_to_value: &amp;s\n    };\n}\n运行后报错：\n let v = SelfRef {\n12 |         value: s,\n   |                - value moved here\n13 |         pointer_to_value: &amp;s\n   |                           ^^ value borrowed here after move\n因为我们试图同时使用值和值的引用，最终所有权转移和借用一起发生了。所以，这个问题貌似并没有那么好解决，不信你可以回想下自己具有的知识，是否可以解决？\n使用 Option\n最简单的方式就是使用 Option 分两步来实现：\n#[derive(Debug)]\nstruct WhatAboutThis&lt;&#039;a&gt; {\n    name: String,\n    nickname: Option&lt;&amp;&#039;a str&gt;,\n}\n \nfn main() {\n    let mut tricky = WhatAboutThis {\n        name: &quot;Annabelle&quot;.to_string(),\n        nickname: None,\n    };\n    tricky.nickname = Some(&amp;tricky.name[..4]);\n \n    println!(&quot;{:?}&quot;, tricky);\n}\n在某种程度上来说，Option 这个方法可以工作，但是这个方法的限制较多，例如从一个函数创建并返回它是不可能的：\nfn creator&lt;&#039;a&gt;() -&gt; WhatAboutThis&lt;&#039;a&gt; {\n    let mut tricky = WhatAboutThis {\n        name: &quot;Annabelle&quot;.to_string(),\n        nickname: None,\n    };\n    tricky.nickname = Some(&amp;tricky.name[..4]);\n \n    tricky\n}\n报错如下：\nerror[E0515]: cannot return value referencing local data `tricky.name`\n  --&gt; src/main.rs:24:5\n   |\n22 |     tricky.nickname = Some(&amp;tricky.name[..4]);\n   |                             ----------- `tricky.name` is borrowed here\n23 |\n24 |     tricky\n   |     ^^^^^^ returns a value referencing data owned by the current function\n其实从函数签名就能看出来端倪，&#039;a 生命周期是凭空产生的！\n\n// TODO: 为什么凭空产生？\n\n如果是通过方法使用，你需要一个无用 &amp;&#039;a self 生命周期标识，一旦有了这个标识，代码将变得更加受限，你将很容易就获得借用错误，就连 NLL 规则都没用：\n#[derive(Debug)]\nstruct WhatAboutThis&lt;&#039;a&gt; {\n    name: String,\n    nickname: Option&lt;&amp;&#039;a str&gt;,\n}\n \nimpl&lt;&#039;a&gt; WhatAboutThis&lt;&#039;a&gt; {\n    fn tie_the_knot(&amp;&#039;a mut self) {\n       self.nickname = Some(&amp;self.name[..4]);\n    }\n}\n \nfn main() {\n    let mut tricky = WhatAboutThis {\n        name: &quot;Annabelle&quot;.to_string(),\n        nickname: None,\n    };\n    tricky.tie_the_knot();\n \n    // cannot borrow `tricky` as immutable because it is also borrowed as mutable\n    // println!(&quot;{:?}&quot;, tricky);\n}\nunsafe 实现\n既然借用规则妨碍了我们，那就一脚踢开：\n#[derive(Debug)]\nstruct SelfRef {\n    value: String,\n    pointer_to_value: *const String,\n}\n \nimpl SelfRef {\n    fn new(txt: &amp;str) -&gt; Self {\n        SelfRef {\n            value: String::from(txt),\n            pointer_to_value: std::ptr::null(),\n        }\n    }\n \n    fn init(&amp;mut self) {\n        let self_ref: *const String = &amp;self.value;\n        self.pointer_to_value = self_ref;\n    }\n \n    fn value(&amp;self) -&gt; &amp;str {\n        &amp;self.value\n    }\n \n    fn pointer_to_value(&amp;self) -&gt; &amp;String {\n        assert!(!self.pointer_to_value.is_null(),\n            &quot;Test::b called without Test::init being called first&quot;);\n        unsafe { &amp;*(self.pointer_to_value) }\n    }\n}\n \nfn main() {\n    let mut t = SelfRef::new(&quot;hello&quot;);\n    t.init();\n    // 打印值和指针地址\n    println!(&quot;{}, {:p}&quot;, t.value(), t.pointer_to_value());\n}\n在这里，我们在 pointer_to_value 中直接存储裸指针，而不是 Rust 的引用，因此不再受到 Rust 借用规则和生命周期的限制，而且实现起来非常清晰、简洁。但是缺点就是，通过指针获取值时需要使用 unsafe 代码。\n当然，上面的代码你还能通过裸指针来修改 String，但是需要将 *const 修改为 *mut：\n#[derive(Debug)]\nstruct SelfRef {\n    value: String,\n    pointer_to_value: *mut String,\n}\n \nimpl SelfRef {\n    fn new(txt: &amp;str) -&gt; Self {\n        SelfRef {\n            value: String::from(txt),\n            pointer_to_value: std::ptr::null_mut(),\n        }\n    }\n \n    fn init(&amp;mut self) {\n        let self_ref: *mut String = &amp;mut self.value;\n        self.pointer_to_value = self_ref;\n    }\n \n    fn value(&amp;self) -&gt; &amp;str {\n        &amp;self.value\n    }\n \n    fn pointer_to_value(&amp;self) -&gt; &amp;String {\n        assert!(!self.pointer_to_value.is_null(), &quot;Test::b called without Test::init being called first&quot;);\n        unsafe { &amp;*(self.pointer_to_value) }\n    }\n}\n \nfn main() {\n    let mut t = SelfRef::new(&quot;hello&quot;);\n    t.init();\n    println!(&quot;{}, {:p}&quot;, t.value(), t.pointer_to_value());\n \n    t.value.push_str(&quot;, world&quot;);\n    unsafe {\n        (&amp;mut *t.pointer_to_value).push_str(&quot;!&quot;);\n    }\n \n    println!(&quot;{}, {:p}&quot;, t.value(), t.pointer_to_value());\n}\n运行后输出：\nhello, 0x16f3aec70\nhello, world!, 0x16f3aec70\n上面的 unsafe 虽然简单好用，但是它不太安全，是否还有其他选择？还真的有，那就是 Pin。\n无法被移动的 Pin\nPin 在后续章节会深入讲解，目前你只需要知道它可以固定住一个值，防止该值在内存中被移动。\n// TODO: 完全没看懂\n通过开头我们知道，自引用最麻烦的就是创建引用的同时，值的所有权会被转移，而通过 Pin 就可以很好的防止这一点：\nuse std::marker::PhantomPinned;\nuse std::pin::Pin;\nuse std::ptr::NonNull;\n \n// 下面是一个自引用数据结构体，因为 slice 字段是一个指针，指向了 data 字段\n// 我们无法使用普通引用来实现，因为违背了 Rust 的编译规则\n// 因此，这里我们使用了一个裸指针，通过 NonNull 来确保它不会为 null\nstruct Unmovable {\n    data: String,\n    slice: NonNull&lt;String&gt;,\n    _pin: PhantomPinned,\n}\n \nimpl Unmovable {\n    // 为了确保函数返回时数据的所有权不会被转移，我们将它放在堆上，唯一的访问方式就是通过指针\n    fn new(data: String) -&gt; Pin&lt;Box&lt;Self&gt;&gt; {\n        let res = Unmovable {\n            data,\n            // 只有在数据到位时，才创建指针，否则数据会在开始之前就被转移所有权\n            slice: NonNull::dangling(),\n            _pin: PhantomPinned,\n        };\n        let mut boxed = Box::pin(res);\n \n        let slice = NonNull::from(&amp;boxed.data);\n        // 这里其实安全的，因为修改一个字段不会转移整个结构体的所有权\n        unsafe {\n            let mut_ref: Pin&lt;&amp;mut Self&gt; = Pin::as_mut(&amp;mut boxed);\n            Pin::get_unchecked_mut(mut_ref).slice = slice;\n        }\n        boxed\n    }\n}\n \nfn main() {\n    let unmoved = Unmovable::new(&quot;hello&quot;.to_string());\n    // 只要结构体没有被转移，那指针就应该指向正确的位置，而且我们可以随意移动指针\n    let mut still_unmoved = unmoved;\n    assert_eq!(still_unmoved.slice, NonNull::from(&amp;still_unmoved.data));\n \n    // 因为我们的类型没有实现 `Unpin` 特征，下面这段代码将无法编译\n    // let mut new_unmoved = Unmovable::new(&quot;world&quot;.to_string());\n    // std::mem::swap(&amp;mut *still_unmoved, &amp;mut *new_unmoved);\n}\n上面的代码也非常清晰，虽然使用了 unsafe，其实更多的是无奈之举，跟之前的 unsafe 实现完全不可同日而语。\n其实 Pin 在这里并没有魔法，它也并不是实现自引用类型的主要原因，最关键的还是里面的裸指针的使用，而 Pin 起到的作用就是确保我们的值不会被移走，否则指针就会指向一个错误的地址！\n使用 ouroboros\n对于自引用结构体，三方库也有支持的，其中一个就是 ouroboros，当然它也有自己的限制，我们后面会提到，先来看看该如何使用：\nuse ouroboros::self_referencing;\n \n#[self_referencing]\nstruct SelfRef {\n    value: String,\n \n    #[borrows(value)]\n    pointer_to_value: &amp;&#039;this str,\n}\n \nfn main(){\n    let v = SelfRefBuilder {\n        value: &quot;aaa&quot;.to_string(),\n        pointer_to_value_builder: |value: &amp;String| value,\n    }.build();\n \n    // 借用value值\n    let s = v.borrow_value();\n    // 借用指针\n    let p = v.borrow_pointer_to_value();\n    // value值和指针指向的值相等\n    assert_eq!(s, *p);\n}\n可以看到，ouroboros 使用起来并不复杂，就是需要你去按照它的方式创建结构体和引用类型：SelfRef 变成 SelfRefBuilder，引用字段从 pointer_to_value 变成 pointer_to_value_builder，并且连类型都变了。\n在使用时，通过 borrow_value 来借用 value 的值，通过 borrow_pointer_to_value 来借用 pointer_to_value 这个指针。\n看上去很美好对吧？但是你可以尝试着去修改 String 字符串的值试试，ouroboros 限制还是较多的，但是对于基本类型依然是支持的不错，以下例子来源于官方：\nuse ouroboros::self_referencing;\n \n#[self_referencing]\nstruct MyStruct {\n    int_data: i32,\n    float_data: f32,\n    #[borrows(int_data)]\n    int_reference: &amp;&#039;this i32,\n    #[borrows(mut float_data)]\n    float_reference: &amp;&#039;this mut f32,\n}\n \nfn main() {\n    let mut my_value = MyStructBuilder {\n        int_data: 42,\n        float_data: 3.14,\n        int_reference_builder: |int_data: &amp;i32| int_data,\n        float_reference_builder: |float_data: &amp;mut f32| float_data,\n    }.build();\n \n    // Prints 42\n    println!(&quot;{:?}&quot;, my_value.borrow_int_data());\n    // Prints 3.14\n    println!(&quot;{:?}&quot;, my_value.borrow_float_reference());\n    // Sets the value of float_data to 84.0\n    my_value.with_mut(|fields| {\n        **fields.float_reference = (**fields.int_reference as f32) * 2.0;\n    });\n \n    // We can hold on to this reference...\n    let int_ref = *my_value.borrow_int_reference();\n    println!(&quot;{:?}&quot;, *int_ref);\n    // As long as the struct is still alive.\n    drop(my_value);\n    // This will cause an error!\n    // println!(&quot;{:?}&quot;, *int_ref);\n}\n总之，使用这个库前，强烈建议看一些官方的例子中支持什么样的类型和 API，如果能满足的你的需求，就果断使用它，如果不能满足，就继续往下看。\n只能说，它确实帮助我们解决了问题，但是一个是破坏了原有的结构，另外就是并不是所有数据类型都支持：它需要目标值的内存地址不会改变，因此 Vec 动态数组就不适合，因为当内存空间不够时，Rust 会重新分配一块空间来存放该数组，这会导致内存地址的改变。\n类似的库还有：\n\nrental， 这个库其实是最有名的，但是好像不再维护了，用倒是没问题\nowning-ref，将所有者和它的引用绑定到一个封装类型\n\n这三个库，各有各的特点，也各有各的缺陷，建议大家需要时，一定要仔细调研，并且写 demo 进行测试，不可大意。\n\nrental 虽然不怎么维护，但是可能依然是这三个里面最强大的，而且网上的用例也比较多，容易找到参考代码\n\nRc + RefCell 或 Arc + Mutex\n类似于循环引用的解决方式，自引用也可以用这种组合来解决，但是会导致代码的类型标识到处都是，大大的影响了可读性。\n终极大法\n如果两个放在一起会报错，那就分开它们。对，终极大法就这么简单，当然思路上的简单不代表实现上的简单，最终结果就是导致代码复杂度的上升。\n学习一本书：如何实现链表\n最后，推荐一本专门将如何实现链表的书（真是富有 Rust 特色，链表都能复杂到出书了 o_o），Learn Rust by writing Entirely Too Many Linked Lists\n总结\n上面讲了这么多方法，但是我们依然无法正确的告诉你在某个场景应该使用哪个方法，这个需要你自己的判断，因为自引用实在是过于复杂。\n我们能做的就是告诉你，有这些办法可以解决自引用问题，而这些办法每个都有自己适用的范围，需要你未来去深入的挖掘和发现。\n偷偷说一句，就算是我，遇"},"rust/rust-bible/advanced/06-多线程并发编程":{"title":"06-多线程并发编程","links":[],"tags":[],"content":"并发和并行\n\n并发是同一时间应对多件事情的能力 - Rob Pike\n\n并发和并行都是对“多任务”处理的描述，其中并发是轮流处理，而并行是同时处理。\n使用多线程\n多线程编程的风险\n由于多线程的代码是同时运行的，因此我们无法保证线程间的执行顺序，这会导致一些问题：\n\n竞态条件(race conditions)，多个线程以非一致性的顺序同时访问数据资源\n死锁(deadlocks)，两个线程都想使用某个资源，但是又都在等待对方释放资源后才能使用，结果最终都无法继续执行\n一些因为多线程导致的很隐晦的 BUG，难以复现和解决\n\n创建线程\n使用 thread::spawn 可以创建线程：\nuse std::thread;\nuse std::time::Duration;\n \nfn main() {\n    thread::spawn(|| {\n        for i in 1..10 {\n            println!(&quot;hi number {} from the spawned thread!&quot;, i);\n            thread::sleep(Duration::from_millis(1));\n        }\n    });\n \n    for i in 1..5 {\n        println!(&quot;hi number {} from the main thread!&quot;, i);\n        thread::sleep(Duration::from_millis(1));\n    }\n}\n有几点值得注意：\n\n线程内部的代码使用闭包来执行\nmain 线程一旦结束，程序就立刻结束，因此需要保持它的存活，直到其它子线程完成自己的任务\nthread::sleep 会让当前线程休眠指定的时间，随后其它线程会被调度运行，因此就算你的电脑只有一个 CPU 核心，该程序也会表现的如同多 CPU 核心一般，这就是并发！\n\n线程调度的方式往往取决于你使用的操作系统。总之，千万不要依赖线程的执行顺序。\n等待子线程的结束\n上面的代码你不但可能无法让子线程从 1 顺序打印到 10，而且可能打印的数字会变少，因为主线程会提前结束，导致子线程也随之结束，更过分的是，如果当前系统繁忙，甚至该子线程还没被创建，主线程就已经结束了！\n因此我们需要一个方法，让主线程安全、可靠地等所有子线程完成任务后，再 kill self：\nuse std::thread;\nuse std::time::Duration;\n \nfn main() {\n    let handle = thread::spawn(|| {\n        for i in 1..5 {\n            println!(&quot;hi number {} from the spawned thread!&quot;, i);\n            thread::sleep(Duration::from_millis(1));\n        }\n    });\n \n    handle.join().unwrap();\n \n    for i in 1..5 {\n        println!(&quot;hi number {} from the main thread!&quot;, i);\n        thread::sleep(Duration::from_millis(1));\n    }\n}\n通过调用 handle.join，可以让当前线程阻塞，直到它等待的子线程的结束，在上面代码中，由于 main 线程会被阻塞，因此它直到子线程结束后才会输出自己的 1..5。\n在线程闭包中使用 move\nmove 关键字在闭包中的使用可以让该闭包拿走环境中某个值的所有权，同样地，你可以使用 move 来将所有权从一个线程转移到另外一个线程。\n首先，来看看在一个线程中直接使用另一个线程中的数据会如何：\nuse std::thread;\n \nfn main() {\n    let v = vec![1, 2, 3];\n \n    let handle = thread::spawn(|| {\n        println!(&quot;Here&#039;s a vector: {:?}&quot;, v);\n    });\n \n    handle.join().unwrap();\n}\n以上代码在子线程的闭包中捕获了环境中的 v 变量，来看看结果：\nerror[E0373]: closure may outlive the current function, but it borrows `v`, which is owned by the current function\n --&gt; src/main.rs:6:32\n  |\n6 |     let handle = thread::spawn(|| {\n  |                                ^^ may outlive borrowed value `v`\n7 |         println!(&quot;Here&#039;s a vector: {:?}&quot;, v);\n  |                                           - `v` is borrowed here\n  |\nnote: function requires argument type to outlive `&#039;static`\n --&gt; src/main.rs:6:18\n  |\n6 |       let handle = thread::spawn(|| {\n  |  __________________^\n7 | |         println!(&quot;Here&#039;s a vector: {:?}&quot;, v);\n8 | |     });\n  | |______^\nhelp: to force the closure to take ownership of `v` (and any other referenced variables), use the `move` keyword\n  |\n6 |     let handle = thread::spawn(move || {\n  |                                ++++\n其实代码本身并没有什么问题，问题在于 Rust 无法确定新的线程会活多久（多个线程的结束顺序并不是固定的），所以也无法确定新线程所引用的 v 是否在使用过程中一直合法：\nuse std::thread;\n \nfn main() {\n    let v = vec![1, 2, 3];\n \n    let handle = thread::spawn(|| {\n        println!(&quot;Here&#039;s a vector: {:?}&quot;, v);\n    });\n \n    drop(v); // oh no!\n \n    handle.join().unwrap();\n}\n大家要记住，线程的启动时间点和结束时间点是不确定的，因此存在一种可能，当主线程执行完， v 被释放掉时，新的线程很可能还没有结束甚至还没有被创建成功，此时新线程对 v 的引用立刻就不再合法！\n好在报错里进行了提示：to force the closure to take ownership of v (and any other referenced variables), use the move keyword，让我们使用 move 关键字拿走 v 的所有权即可：\nuse std::thread;\n \nfn main() {\n    let v = vec![1, 2, 3];\n \n    let handle = thread::spawn(move || {\n        println!(&quot;Here&#039;s a vector: {:?}&quot;, v);\n    });\n \n    handle.join().unwrap();\n \n    // 下面代码会报错borrow of moved value: `v`\n    // println!(&quot;{:?}&quot;,v);\n}\n如上所示，很简单的代码，而且 Rust 的所有权机制保证了数据使用上的安全：v 的所有权被转移给新的线程后，main 线程将无法继续使用：最后一行代码将报错。\n线程是如何结束的\n之前我们提到 main 线程是程序的主线程，一旦结束，则程序随之结束，同时各个子线程也将被强行终止。那么有一个问题，如果父线程不是 main 线程，那么父线程的结束会导致什么？自生自灭还是被干掉？\n在系统编程中，操作系统提供了直接杀死线程的接口，简单粗暴，但是 Rust 并没有提供这样的接口，原因在于，粗暴地终止一个线程可能会导致资源没有释放、状态混乱等不可预期的结果，一向以安全自称的 Rust，自然不会砸自己的饭碗。\n那么 Rust 中线程是如何结束的呢？答案很简单：线程的代码执行完，线程就会自动结束。但是如果线程中的代码不会执行完呢？那么情况可以分为两种进行讨论：\n\n线程的任务是一个循环 IO 读取，任务流程类似：IO 阻塞，等待读取新的数据 → 读到数据，处理完成 → 继续阻塞等待 ··· → 收到 socket 关闭的信号 → 结束线程，在此过程中，绝大部分时间线程都处于阻塞的状态，因此虽然看上去是循环，CPU 占用其实很小，也是网络服务中最最常见的模型\n线程的任务是一个循环，里面没有任何阻塞，包括休眠这种操作也没有，此时 CPU 很不幸的会被跑满，而且你如果没有设置终止条件，该线程将持续跑满一个 CPU 核心，并且不会被终止，直到 main 线程的结束\n\n第一情况很常见，我们来模拟看看第二种情况：\nuse std::thread;\nuse std::time::Duration;\nfn main() {\n    // 创建一个线程A\n    let new_thread = thread::spawn(move || {\n        // 再创建一个线程B\n        thread::spawn(move || {\n            loop {\n                println!(&quot;I am a new thread.&quot;);\n            }\n        })\n    });\n \n    // 等待新创建的线程执行完成\n    new_thread.join().unwrap();\n    println!(&quot;Child thread is finish!&quot;);\n \n    // 睡眠一段时间，看子线程创建的子线程是否还在运行\n    thread::sleep(Duration::from_millis(100));\n}\n以上代码中，main 线程创建了一个新的线程 A，同时该新线程又创建了一个新的线程 B，可以看到 A 线程在创建完 B 线程后就立即结束了，而 B 线程则在不停地循环输出。\n从之前的线程结束规则，我们可以猜测程序将这样执行：A 线程结束后，由它创建的 B 线程仍在疯狂输出，直到 main 线程在 100 毫秒后结束。\n多线程的性能\n创建线程的性能\n据不精确估算，创建一个线程大概需要 0.24 毫秒，随着线程的变多，这个值会变得更大，因此线程的创建耗时是不可忽略的，只有当真的需要处理一个值得用线程去处理的任务时，才使用线程，一些鸡毛蒜皮的任务，就无需创建线程了。\n创建多少线程合适\n因为 CPU 的核心数限制，当任务是 CPU 密集型时，就算线程数超过了 CPU 核心数，也并不能帮你获得更好的性能，因为每个线程的任务都可以轻松让 CPU 的某个核心跑满，既然如此，让线程数等于 CPU 核心数是最好的。\n但是当你的任务大部分时间都处于阻塞状态时，就可以考虑增多线程数量，这样当某个线程处于阻塞状态时，会被切走，进而运行其它的线程，典型就是网络 IO 操作，我们可以为每一个进来的用户连接创建一个线程去处理，该连接绝大部分时间都是处于 IO 读取阻塞状态，因此有限的 CPU 核心完全可以处理成百上千的用户连接线程，但是事实上，对于这种网络 IO 情况，一般都不再使用多线程的方式了，毕竟操作系统的线程数是有限的，意味着并发数也很容易达到上限，而且过多的线程也会导致线程上下文切换的代价过大，使用 async/await 的 M:N 并发模型，就没有这个烦恼。\n多线程的开销\n下面的代码是一个无锁实现(CAS)的 Hashmap 在多线程下的使用：\nfor i in 0..num_threads {\n    let ht = Arc::clone(&amp;ht);\n\t// TODO: 看不懂\n    let handle = thread::spawn(move || {\n        for j in 0..adds_per_thread {\n            let key = thread_rng().gen::&lt;u32&gt;();\n            let value = thread_rng().gen::&lt;u32&gt;();\n            ht.set_item(key, value);\n        }\n    });\n \n    handles.push(handle);\n}\n \nfor handle in handles {\n    handle.join().unwrap();\n}\n按理来说，既然是无锁实现了，那么锁的开销应该几乎没有，性能会随着线程数的增加接近线性增长，但是真的是这样吗？实际吞吐并不是线性增长，尤其从 16 核开始，甚至开始肉眼可见的下降，这是为什么呢？\n限于篇幅有限，我们只能给出大概的原因：\n\n虽然是无锁，但是内部是 CAS 实现，大量线程的同时访问，会让 CAS 重试次数大幅增加\n线程过多时，CPU 缓存的命中率会显著下降，同时多个线程竞争一个 CPU Cache-line 的情况也会经常发生\n大量读写可能会让内存带宽也成为瓶颈\n读和写不一样，无锁数据结构的读往往可以很好地线性增长，但是写不行，因为写竞争太大\n\n总之，多线程的开销往往是在锁、数据竞争、缓存失效上，这些限制了现代化软件系统随着 CPU 核心的增多性能也线性增加的野心。\n线程屏障(Barrier)\n在 Rust 中，可以使用 Barrier 让多个线程都执行到某个点后，才继续一起往后执行：\nuse std::sync::{Arc, Barrier};\nuse std::thread;\n \nfn main() {\n    let mut handles = Vec::with_capacity(6);\n    let barrier = Arc::new(Barrier::new(6));\n \n    for _ in 0..6 {\n        let b = barrier.clone();\n        handles.push(thread::spawn(move|| {\n            println!(&quot;before wait&quot;);\n            b.wait();\n            println!(&quot;after wait&quot;);\n        }));\n    }\n \n    for handle in handles {\n        handle.join().unwrap();\n    }\n}\n上面代码，我们在线程打印出 before wait 后增加了一个屏障，目的就是等所有的线程都打印出 before wait 后，各个线程再继续执行：\nbefore wait\nbefore wait\nbefore wait\nbefore wait\nbefore wait\nbefore wait\nafter wait\nafter wait\nafter wait\nafter wait\nafter wait\nafter wait\n线程局部变量(Thread Local Variable)\n对于多线程编程，线程局部变量在一些场景下非常有用，而 Rust 通过标准库和三方库对此进行了支持。\n标准库 thread_local\n使用 thread_local 宏可以初始化线程局部变量，然后在线程内部使用该变量的 with 方法获取变量值：\nuse std::cell::RefCell;\nuse std::thread;\n \nthread_local!(static FOO: RefCell&lt;u32&gt; = RefCell::new(1));\n \nFOO.with(|f| {\n    assert_eq!(*f.borrow(), 1);\n    *f.borrow_mut() = 2;\n});\n \n// 每个线程开始时都会拿到线程局部变量的FOO的初始值\nlet t = thread::spawn(move|| {\n    FOO.with(|f| {\n        assert_eq!(*f.borrow(), 1);\n        *f.borrow_mut() = 3;\n    });\n});\n \n// 等待线程完成\nt.join().unwrap();\n \n// 尽管子线程中修改为了3，我们在这里依然拥有main线程中的局部值：2\nFOO.with(|f| {\n    assert_eq!(*f.borrow(), 2);\n});\n上面代码中，FOO 即是我们创建的线程局部变量，每个新的线程访问它时，都会使用它的初始值作为开始，各个线程中的 FOO 值彼此互不干扰。注意 FOO 使用 static 声明为生命周期为 &#039;static 的静态变量。\n可以注意到，线程中对 FOO 的使用是通过借用的方式，但是若我们需要每个线程独自获取它的拷贝，最后进行汇总，就有些强人所难了。\n你还可以在结构体中使用线程局部变量：\nuse std::cell::RefCell;\n \nstruct Foo;\nimpl Foo {\n    thread_local! {\n        static FOO: RefCell&lt;usize&gt; = RefCell::new(0);\n    }\n}\n \nfn main() {\n    Foo::FOO.with(|x| println!(&quot;{:?}&quot;, x));\n}\n或者通过引用的方式使用它:\nuse std::cell::RefCell;\nuse std::thread::LocalKey;\n \nthread_local! {\n    static FOO: RefCell&lt;usize&gt; = RefCell::new(0);\n}\nstruct Bar {\n    foo: &amp;&#039;static LocalKey&lt;RefCell&lt;usize&gt;&gt;,\n}\nimpl Bar {\n    fn constructor() -&gt; Self {\n        Self {\n            foo: &amp;FOO,\n        }\n    }\n}\n三方库 thread-local\n除了标准库外，一位大神还开发了 thread-local 库，它允许每个线程持有值的独立拷贝：\nuse thread_local::ThreadLocal;\nuse std::sync::Arc;\nuse std::cell::Cell;\nuse std::thread;\n \nlet tls = Arc::new(ThreadLocal::new());\nlet mut v = vec![];\n// 创建多个线程\nfor _ in 0..5 {\n    let tls2 = tls.clone();\n    let handle = thread::spawn(move || {\n        // 将计数器加1\n        // 请注意，由于线程 ID 在线程退出时会被回收，因此一个线程有可能回收另一个线程的对象\n        // 这只能在线程退出后发生，因此不会导致任何竞争条件\n        let cell = tls2.get_or(|| Cell::new(0));\n        cell.set(cell.get() + 1);\n    });\n    v.push(handle);\n}\nfor handle in v {\n    handle.join().unwrap();\n}\n// 一旦所有子线程结束，收集它们的线程局部变量中的计数器值，然后进行求和\nlet tls = Arc::try_unwrap(tls).unwrap();\nlet total = tls.into_iter().fold(0, |x, y| {\n    // 打印每个线程局部变量中的计数器值，发现不一定有5个线程，\n    // 因为一些线程已退出，并且其他线程会回收退出线程的对象\n    println!(&quot;x: {}, y: {}&quot;, x, y.get());\n    x + y.get()\n});\n \n// 和为5\nassert_eq!(total, 5);\n该库不仅仅使用了值的拷贝，而且还能自动把多个拷贝汇总到一个迭代器中，最后进行求和，非常好用。\n用条件控制线程的挂起和执行\n条件变量(Condition Variables)经常和 Mutex 一起使用，可以让线程挂起，直到某个条件发生后再继续执行：\nuse std::thread;\nuse std::sync::{Arc, Mutex, Condvar};\n \nfn main() {\n    let pair = Arc::new((Mutex::new(false), Condvar::new()));\n    let pair2 = pair.clone();\n \n    thread::spawn(move|| {\n        let (lock, cvar) = &amp;*pair2;\n        let mut started = lock.lock().unwrap();\n        println!(&quot;changing started&quot;);\n        *started = true;\n        cvar.notify_one();\n    });\n \n    let (lock, cvar) = &amp;*pair;\n    let mut started = lock.lock().unwrap();\n    while !*started {\n        started = cvar.wait(started).unwrap();\n    }\n \n    println!(&quot;started changed&quot;);\n}\n上述代码流程如下：\nchanging started\nstarted changed\n\nmain 线程首先进入 while 循环，调用 wait 方法挂起等待子线程的通知，并释放了锁 started\n子线程获取到锁，并将其修改为 true，然后调用条件变量的 notify_one 方法来通知主线程继续执行\n\n只被调用一次的函数\n有时，我们会需要某个函数在多线程环境下只被调用一次，例如初始化全局变量，无论是哪个线程先调用函数来初始化，都会保证全局变量只会被初始化一次，随后的其它线程调用就会忽略该函数：\nuse std::thread;\nuse std::sync::Once;\n \nstatic mut VAL: usize = 0;\nstatic INIT: Once = Once::new();\n \nfn main() {\n    let handle1 = thread::spawn(move || {\n        INIT.call_once(|| {\n            unsafe {\n                VAL = 1;\n            }\n        });\n    });\n \n    let handle2 = thread::spawn(move || {\n        INIT.call_once(|| {\n            unsafe {\n                VAL = 2;\n            }\n        });\n    });\n \n    handle1.join().unwrap();\n    handle2.join().unwrap();\n \n    println!(&quot;{}&quot;, unsafe { VAL });\n}\n代码运行的结果取决于哪个线程先调用 INIT.call_once （虽然代码具有先后顺序，但是线程的初始化顺序并无法被保证！因为线程初始化是异步的，且耗时较久），若 handle1 先，则输出 1，否则输出 2。\ncall_once 方法\n执行初始化过程一次，并且只执行一次。\n如果当前有另一个初始化过程正在运行，线程将阻止该方法被调用。\n当这个函数返回时，保证一些初始化已经运行并完成，它还保证由执行的闭包所执行的任何内存写入都能被其他线程在这时可靠地观察到。\n总结\nRust 的线程模型是 1:1 模型，因为 Rust 要保持尽量小的运行时。\n我们可以使用 thread::spawn 来创建线程，创建出的多个线程之间并不存在执行顺序关系，因此代码逻辑千万不要依赖于线程间的执行顺序。\nmain 线程若是结束，则所有子线程都将被终止，如果希望等待子线程结束后，再结束 main 线程，你需要使用创建线程时返回的句柄的 join 方法。\n在线程中无法直接借用外部环境中的变量值，因为新线程的启动时间点和结束时间点是不确定的，所以 Rust 无法保证该线程中借用的变量在使用过程中依然是合法的。你可以使用 move 关键字将变量的所有权转移给新的线程，来解决此问题。\n父线程结束后，子线程仍在持续运行，直到子线程的代码运行完成或者 main 线程的结束。\n线程同步：消息传递\n在多线程间有多种方式可以共享、传递数据，最常用的方式就是通过消息传递或者将锁和Arc联合使用，而对于前者，在编程界还有一个大名鼎鼎的Actor线程模型为其背书，典型的有 Erlang 语言，还有 Go 语言中很经典的一句话：\n\nDo not communicate by sharing memory; instead, share memory by communicating\n\n消息通道\n与 Go 语言内置的chan不同，Rust 是在标准库里提供了消息通道(channel)，你可以将其想象成一场直播，多个主播联合起来在搞一场直播，最终内容通过通道传输给屏幕前的我们，其中主播被称之为发送者，观众被称之为接收者，显而易见的是：一个通道应该支持多个发送者和接收者。\n但是，在实际使用中，我们需要使用不同的库来满足诸如：多发送者 → 单接收者，多发送者 → 多接收者等场景形式，此时一个标准库显然就不够了，不过别急，让我们先从标准库讲起。\n多发送者，单接收者\n标准库提供了通道std::sync::mpsc，其中mpsc是multiple producer, single consumer的缩写，代表了该通道支持多个发送者，但是只支持唯一的接收者。 当然，支持多个发送者也意味着支持单个发送者，我们先来看看单发送者、单接收者的简单例子:\nuse std::sync::mpsc;\nuse std::thread;\n \nfn main() {\n    // 创建一个消息通道, 返回一个元组：(发送者，接收者)\n    let (tx, rx) = mpsc::channel();\n \n    // 创建线程，并发送消息\n    thread::spawn(move || {\n        // 发送一个数字1, send方法返回Result&lt;T,E&gt;，通过unwrap进行快速错误处理\n        tx.send(1).unwrap();\n \n        // 下面代码将报错，因为编译器自动推导出通道传递的值是i32类型，那么Option&lt;i32&gt;类型将产生不匹配错误\n        // tx.send(Some(1)).unwrap()\n    });\n \n    // 在主线程中接收子线程发送的消息并输出\n    println!(&quot;receive {}&quot;, rx.recv().unwrap());\n}\n以上代码并不复杂，但仍有几点需要注意：\n\ntx,rx对应发送者和接收者，它们的类型由编译器自动推导: tx.send(1)发送了整数，因此它们分别是mpsc::Sender&lt;i32&gt;和mpsc::Receiver&lt;i32&gt;类型，需要注意，由于内部是泛型实现，一旦类型被推导确定，该通道就只能传递对应类型的值, 例如此例中非i32类型的值将导致编译错误\n接收消息的操作rx.recv()会阻塞当前线程，直到读取到值，或者通道被关闭\n需要使用move将tx的所有权转移到子线程的闭包中\n\n在注释中提到send方法返回一个Result&lt;T,E&gt;，说明它有可能返回一个错误，例如接收者被drop导致了发送的值不会被任何人接收，此时继续发送毫无意义，因此返回一个错误最为合适，在代码中我们仅仅使用unwrap进行了快速处理，但在实际项目中你需要对错误进行进一步的处理。\n同样的，对于recv方法来说，当发送者关闭时，它也会接收到一个错误，用于说明不会再有任何值被发送过来。\n不阻塞的 try_recv 方法\n除了上述recv方法，还可以使用try_recv尝试接收一次消息，该方法并不会阻塞线程，当通道中没有消息时，它会立刻返回一个错误：\nuse std::sync::mpsc;\nuse std::thread;\n \nfn main() {\n    let (tx, rx) = mpsc::channel();\n \n    thread::spawn(move || {\n        tx.send(1).unwrap();\n    });\n \n    println!(&quot;receive {:?}&quot;, rx.try_recv());\n}\n由于子线程的创建需要时间，因此println!和try_recv方法会先执行，而此时子线程的消息还未被发出。try_recv会尝试立即读取一次消息，因为消息没有发出，此次读取最终会报错，且主线程运行结束(可悲的是，相对于主线程中的代码，子线程的创建速度实在是过慢，直到主线程结束，都无法完成子线程的初始化。。):\nreceive Err(Empty)\n如上，try_recv返回了一个错误，错误内容是Empty，代表通道并没有消息。如果你尝试把println!复制一些行，就会发现一个有趣的输出：\n···\nreceive Err(Empty)\nreceive Ok(1)\nreceive Err(Disconnected)\n···\n如上，当子线程创建成功且发送消息后，主线程会接收到Ok(1)的消息内容，紧接着子线程结束，发送者也随着被drop，此时接收者又会报错，但是这次错误原因有所不同：Disconnected代表发送者已经被关闭。\n传输具有所有权的数据\n使用通道来传输数据，一样要遵循 Rust 的所有权规则：\n\n若值的类型实现了Copy特征，则直接复制一份该值，然后传输过去，例如之前的i32类型\n若值没有实现Copy，则它的所有权会被转移给接收端，在发送端继续使用该值将报错\n\n一起来看看第二种情况:\nuse std::sync::mpsc;\nuse std::thread;\n \nfn main() {\n    let (tx, rx) = mpsc::channel();\n \n    thread::spawn(move || {\n        let s = String::from(&quot;我，飞走咯!&quot;);\n        tx.send(s).unwrap();\n        println!(&quot;val is {}&quot;, s);\n    });\n \n    let received = rx.recv().unwrap();\n    println!(&quot;Got: {}&quot;, received);\n}\n以上代码中，String底层的字符串是存储在堆上，并没有实现Copy特征，当它被发送后，会将所有权从发送端的s转移给接收端的received，之后s将无法被使用:\nerror[E0382]: borrow of moved value: `s`\n  --&gt; src/main.rs:10:31\n   |\n8  |         let s = String::from(&quot;我，飞走咯!&quot;);\n   |             - move occurs because `s` has type `String`, which does not implement the `Copy` trait // 所有权被转移，由于`String`没有实现`Copy`特征\n9  |         tx.send(s).unwrap();\n   |                 - value moved here // 所有权被转移走\n10 |         println!(&quot;val is {}&quot;, s);\n   |                               ^ value borrowed here after move // 所有权被转移后，依然对s进行了借用\n各种细节不禁令人感叹：Rust 还是安全！假如没有所有权的保护，String字符串将被两个线程同时持有，任何一个线程对字符串内容的修改都会导致另外一个线程持有的字符串被改变，除非你故意这么设计，否则这就是不安全的隐患。\n使用 for 进行循环接收\n下面来看看如何连续接收通道中的值:\nuse std::sync::mpsc;\nuse std::thread;\nuse std::time::Duration;\n \nfn main() {\n    let (tx, rx) = mpsc::channel();\n \n    thread::spawn(move || {\n        let vals = vec![\n            String::from(&quot;hi&quot;),\n            String::from(&quot;from&quot;),\n            String::from(&quot;the&quot;),\n            String::from(&quot;thread&quot;),\n        ];\n \n        for val in vals {\n            tx.send(val).unwrap();\n            thread::sleep(Duration::from_secs(1));\n        }\n    });\n \n    for received in rx {\n        println!(&quot;Got: {}&quot;, received);\n    }\n}\n在上面代码中，主线程和子线程是并发运行的，子线程在不停的发送消息 → 休眠 1 秒，与此同时，主线程使用for循环阻塞的从rx迭代器中接收消息，当子线程运行完成时，发送者tx会随之被drop，此时for循环将被终止，最终main线程成功结束。\n使用多发送者\n由于子线程会拿走发送者的所有权，因此我们必须对发送者进行克隆，然后让每个线程拿走它的一份拷贝:\nuse std::sync::mpsc;\nuse std::thread;\n \nfn main() {\n    let (tx, rx) = mpsc::channel();\n    let tx1 = tx.clone();\n    thread::spawn(move || {\n        tx.send(String::from(&quot;hi from raw tx&quot;)).unwrap();\n    });\n \n    thread::spawn(move || {\n        tx1.send(String::from(&quot;hi from cloned tx&quot;)).unwrap();\n    });\n \n    for received in rx {\n        println!(&quot;Got: {}&quot;, received);\n    }\n}\n代码并无太大区别，就多了一个对发送者的克隆let tx1 = tx.clone();，然后一个子线程拿走tx的所有权，另一个子线程拿走tx1的所有权，皆大欢喜。\n但是有几点需要注意:\n\n需要所有的发送者都被drop掉后，接收者rx才会收到错误，进而跳出for循环，最终结束主线程\n这里虽然用了clone但是并不会影响性能，因为它并不在热点代码路径中，仅仅会被执行一次\n由于两个子线程谁先创建完成是未知的，因此哪条消息先发送也是未知的，最终主线程的输出顺序也不确定\n\n消息顺序\nRust 标准库的mpsc通道其实分为两种类型：同步和异步。\n异步通道\n之前我们使用的都是异步通道：无论接收者是否正在接收消息，消息发送者在发送消息时都不会阻塞:\nuse std::sync::mpsc;\nuse std::thread;\nuse std::time::Duration;\nfn main() {\n    let (tx, rx)= mpsc::channel();\n \n    let handle = thread::spawn(move || {\n        println!(&quot;发送之前&quot;);\n        tx.send(1).unwrap();\n        println!(&quot;发送之后&quot;);\n    });\n \n    println!(&quot;睡眠之前&quot;);\n    thread::sleep(Duration::from_secs(3));\n    println!(&quot;睡眠之后&quot;);\n \n    println!(&quot;receive {}&quot;, rx.recv().unwrap());\n    handle.join().unwrap();\n}\n运行后输出如下:\n睡眠之前\n发送之前\n发送之后\n//···睡眠3秒\n睡眠之后\nreceive 1\n主线程因为睡眠阻塞了 3 秒，因此并没有进行消息接收，而子线程却在此期间轻松完成了消息的发送。等主线程睡眠结束后，才姗姗来迟的从通道中接收了子线程老早之前发送的消息。\n从输出还可以看出，发送之前和发送之后是连续输出的，没有受到接收端主线程的任何影响，因此通过mpsc::channel创建的通道是异步通道。\n同步通道\n与异步通道相反，同步通道发送消息是阻塞的，只有在消息被接收后才解除阻塞，例如：\nuse std::sync::mpsc;\nuse std::thread;\nuse std::time::Duration;\nfn main() {\n    let (tx, rx)= mpsc::sync_channel(0);\n \n    let handle = thread::spawn(move || {\n        println!(&quot;发送之前&quot;);\n        tx.send(1).unwrap();\n        println!(&quot;发送之后&quot;);\n    });\n \n    println!(&quot;睡眠之前&quot;);\n    thread::sleep(Duration::from_secs(3));\n    println!(&quot;睡眠之后&quot;);\n \n    println!(&quot;receive {}&quot;, rx.recv().unwrap());\n    handle.join().unwrap();\n}\n运行后输出如下：\n睡眠之前\n发送之前\n//···睡眠3秒\n睡眠之后\nreceive 1\n发送之后\n可以看出，主线程由于睡眠被阻塞导致无法接收消息，因此子线程的发送也一直被阻塞，直到主线程结束睡眠并成功接收消息后，发送才成功：发送之后的输出是在receive 1之后，说明只有接收消息彻底成功后，发送消息才算完成。\n消息缓存\n细心的读者可能已经发现在创建同步通道时，我们传递了一个参数0: mpsc::sync_channel(0);，这是什么意思呢？\n答案不急给出，先将0改成1，然后再运行试试:\n睡眠之前\n发送之前\n发送之后\n睡眠之后\nreceive 1\n纳尼。。竟然得到了和异步通道一样的效果：根本没有等待主线程的接收开始，消息发送就立即完成了！ 难道同步通道变成了异步通道？ 别急，将子线程中的代码修改下试试：\nprintln!(&quot;首次发送之前&quot;);\ntx.send(1).unwrap();\nprintln!(&quot;首次发送之后&quot;);\ntx.send(1).unwrap();\nprintln!(&quot;再次发送之后&quot;);\n在子线程中，我们又多发了一条消息，此时输出如下：\n睡眠之前\n首次发送之前\n首次发送之后\n//···睡眠3秒\n睡眠之后\nreceive 1\n再次发送之后\nBingo，更奇怪的事出现了，第一条消息瞬间发送完成，没有阻塞，而发送第二条消息时却符合同步通道的特点：阻塞了，直到主线程接收后，才发送完成。\n其实，一切的关键就在于1上，该值可以用来指定同步通道的消息缓存条数，当你设定为N时，发送者就可以无阻塞的往通道中发送N条消息，当消息缓冲队列满了后，新的消息发送将被阻塞(如果没有接收者消费缓冲队列中的消息，那么第N+1条消息就将触发发送阻塞)。\n问题又来了，异步通道创建时完全没有这个缓冲值参数mpsc::channel()，它的缓冲值怎么设置呢？ 额。。。都异步了，都可以无限发送了，都有摩托车了，还要自行车做啥子哦？事实上异步通道的缓冲上限取决于你的内存大小，不要撑爆就行。\n因此，使用异步消息虽然能非常高效且不会造成发送线程的阻塞，但是存在消息未及时消费，最终内存过大的问题。在实际项目中，可以考虑使用一个带缓冲值的同步通道来避免这种风险。\n关闭通道\n之前我们数次提到了通道关闭，并且提到了当通道关闭后，发送消息或接收消息将会报错。那么如何关闭通道呢？ 很简单：所有发送者被drop或者所有接收者被drop后，通道会自动关闭。\n神奇的是，这件事是在编译期实现的，完全没有运行期性能损耗！只能说 Rust 的Drop特征 YYDS!\n传输多种类型的数据\n之前提到过，一个消息通道只能传输一种类型的数据，如果你想要传输多种类型的数据，可以为每个类型创建一个通道，你也可以使用枚举类型来实现：\nuse std::sync::mpsc::{self, Receiver, Sender};\n \nenum Fruit {\n    Apple(u8),\n    Orange(String)\n}\n \nfn main() {\n    let (tx, rx): (Sender&lt;Fruit&gt;, Receiver&lt;Fruit&gt;) = mpsc::channel();\n \n    tx.send(Fruit::Orange(&quot;sweet&quot;.to_string())).unwrap();\n    tx.send(Fruit::Apple(2)).unwrap();\n \n    for _ in 0..2 {\n        match rx.recv().unwrap() {\n            Fruit::Apple(count) =&gt; println!(&quot;received {} apples&quot;, count),\n            Fruit::Orange(flavor) =&gt; println!(&quot;received {} oranges&quot;, flavor),\n        }\n    }\n}\n如上所示，枚举类型还能让我们带上想要传输的数据，但是有一点需要注意，Rust 会按照枚举中占用内存最大的那个成员进行内存对齐，这意味着就算你传输的是枚举中占用内存最小的成员，它占用的内存依然和最大的成员相同, 因此会造成内存上的浪费。\n新手容易遇到的坑\nmpsc虽然相当简洁明了，但是在使用起来还是可能存在坑：\nuse std::sync::mpsc;\nfn main() {\n \n    use std::thread;\n \n    let (send, recv) = mpsc::channel();\n    let num_threads = 3;\n    for i in 0..num_threads {\n        let thread_send = send.clone();\n        thread::spawn(move || {\n            thread_send.send(i).unwrap();\n            println!(&quot;thread {:?} finished&quot;, i);\n        });\n    }\n \n    // 在这里drop send...\n \n    for x in recv {\n        println!(&quot;Got: {}&quot;, x);\n    }\n    println!(&quot;finished iterating&quot;);\n}\n以上代码看起来非常正常，但是运行后主线程会一直阻塞，最后一行打印输出也不会被执行，原因在于： 子线程拿走的是复制后的send的所有权，这些拷贝会在子线程结束后被drop，因此无需担心，但是send本身却直到main函数的结束才会被drop。\n之前提到，通道关闭的两个条件：发送者全部drop或接收者被drop，要结束for循环显然是要求发送者全部drop，但是由于send自身没有被drop，会导致该循环永远无法结束，最终主线程会一直阻塞。\n解决办法很简单，drop掉send即可：在代码中的注释下面添加一行drop(send);。\nmpmc 更好的性能\n如果你需要 mpmc (多发送者，多接收者)或者需要更高的性能，可以考虑第三方库:\n\ncrossbeam-channel, 老牌强库，功能较全，性能较强，之前是独立的库，但是后面合并到了crossbeam主仓库中\nflume, 官方给出的性能数据某些场景要比 crossbeam 更好些\n\n线程同步：锁、Condvar 和信号量\n在多线程编程中，同步性极其的重要，当你需要同时访问一个资源、控制不同线程的执行次序时，都需要使用到同步性。\n在 Rust 中有多种方式可以实现同步性。在上一节中讲到的消息传递就是同步性的一种实现方式，例如我们可以通过消息传递来控制不同线程间的执行次序。还可以使用共享内存来实现同步性，例如通过锁和原子操作等并发原语来实现多个线程同时且安全地去访问一个资源。\n该如何选择\n共享内存可以说是同步的灵魂，因为消息传递的底层实际上也是通过共享内存来实现，两者的区别如下：\n\n共享内存相对消息传递能节省多次内存拷贝的成本\n共享内存的实现简洁的多\n共享内存的锁竞争更多\n\n消息传递适用的场景很多，我们下面列出了几个主要的使用场景:\n\n需要可靠和简单的(简单不等于简洁)实现时\n需要模拟现实世界，例如用消息去通知某个目标执行相应的操作时\n需要一个任务处理流水线(管道)时，等等\n\n而使用共享内存(并发原语)的场景往往就比较简单粗暴：需要简洁的实现以及更高的性能时。\n总之，消息传递类似一个单所有权的系统：一个值同时只能有一个所有者，如果另一个线程需要该值的所有权，需要将所有权通过消息传递进行转移。而共享内存类似于一个多所有权的系统：多个线程可以同时访问同一个值。\n互斥锁 Mutex\n既然是共享内存，那并发原语自然是重中之重，先来一起看看皇冠上的明珠: 互斥锁 Mutex(mutual exclusion 的缩写)。\nMutex 让多个线程并发的访问同一个值变成了排队访问：同一时间，只允许一个线程 A 访问该值，其它线程需要等待 A 访问完成后才能继续。\n单线程中使用 Mutex\n先来看看单线程中Mutex该如何使用:\nuse std::sync::Mutex;\n \nfn main() {\n    // 使用`Mutex`结构体的关联函数创建新的互斥锁实例\n    let m = Mutex::new(5);\n \n    {\n        // 获取锁，然后deref为`m`的引用\n        // lock返回的是Result\n        let mut num = m.lock().unwrap();\n        *num = 6;\n        // 锁自动被drop\n    }\n \n    println!(&quot;m = {:?}&quot;, m);\n}\n在注释中，已经大致描述了代码的功能，不过有一点需要注意：和Box类似，数据被Mutex所拥有，要访问内部的数据，需要使用方法m.lock()向m申请一个锁，该方法会阻塞当前线程，直到获取到锁，因此当多个线程同时访问该数据时，只有一个线程能获取到锁，其它线程只能阻塞着等待，这样就保证了数据能被安全的修改！\nm.lock()方法也有可能报错，例如当前正在持有锁的线程panic了。在这种情况下，其它线程不可能再获得锁，因此lock方法会返回一个错误。\n这里你可能奇怪，m.lock明明返回一个锁，怎么就变成我们的num数值了？聪明的读者可能会想到智能指针，没错，因为Mutex&lt;T&gt;是一个智能指针，准确的说是m.lock()返回一个智能指针MutexGuard&lt;T&gt;:\n\n它实现了Deref特征，会被自动解引用后获得一个引用类型，该引用指向Mutex内部的数据\n它还实现了Drop特征，在超出作用域后，自动释放锁，以便其它线程能继续获取锁\n\n正因为智能指针的使用，使得我们无需任何操作就能获取其中的数据。 如果释放锁，你需要做的仅仅是做好锁的作用域管理，例如上述代码的内部花括号使用，建议读者尝试下去掉内部的花括号，然后再次尝试获取第二个锁num1，看看会发生什么，友情提示：不会报错，但是主线程会永远阻塞，因为不幸发生了死锁。\nuse std::sync::Mutex;\n \nfn main() {\n    let m = Mutex::new(5);\n \n    let mut num = m.lock().unwrap();\n    *num = 6;\n    // 锁还没有被 drop 就尝试申请下一个锁，导致主线程阻塞\n    // drop(num); // 手动 drop num ，可以让 num1 申请到下个锁\n    let mut num1 = m.lock().unwrap();\n    *num1 = 7;\n    // drop(num1); // 手动 drop num1 ，观察打印结果的不同\n \n    println!(&quot;m = {:?}&quot;, m);\n}\n多线程中使用 Mutex\n单线程中使用锁，说实话纯粹是为了演示功能，毕竟多线程才是锁的舞台。 现在，我们再来看看，如何在多线程下使用Mutex来访问同一个资源。\n无法运行的Rc\nuse std::rc::Rc;\nuse std::sync::Mutex;\nuse std::thread;\n \nfn main() {\n    // 通过`Rc`实现`Mutex`的多所有权\n    let counter = Rc::new(Mutex::new(0));\n    let mut handles = vec![];\n \n    for _ in 0..10 {\n        let counter = Rc::clone(&amp;counter);\n        // 创建子线程，并将`Mutex`的所有权拷贝传入到子线程中\n        let handle = thread::spawn(move || {\n            let mut num = counter.lock().unwrap();\n \n            *num += 1;\n        });\n        handles.push(handle);\n    }\n \n    // 等待所有子线程完成\n    for handle in handles {\n        handle.join().unwrap();\n    }\n \n    // 输出最终的计数结果\n    println!(&quot;Result: {}&quot;, *counter.lock().unwrap());\n}\n由于子线程需要通过move拿走锁的所有权，因此我们需要使用多所有权来保证每个线程都拿到数据的独立所有权，恰好智能指针Rc可以做到(上面代码会报错！)。\n以上代码实现了在多线程中计数的功能，由于多个线程都需要去修改该计数器，因此我们需要使用锁来保证同一时间只有一个线程可以修改计数器，否则会导致脏数据：想象一下 A 线程和 B 线程同时拿到计数器，获取了当前值1, 并且同时对其进行了修改，最后值变成2，你会不会在风中凌乱？毕竟正确的值是3，因为两个线程各自加 1。\n可能有人会说，有那么巧的事情吗？事实上，对于人类来说，因为干啥啥慢，并没有那么多巧合，所以人总会存在巧合心理。但是对于计算机而言，每秒可以轻松运行上亿次，在这种频次下，一切巧合几乎都将必然发生，因此千万不要有任何侥幸心理。\n事实上，上面的代码会报错:\nerror[E0277]: `Rc&lt;Mutex&lt;i32&gt;&gt;` cannot be sent between threads safely\n错误中提到了一个关键点：Rc&lt;T&gt;无法在线程中传输，因为它没有实现Send特征，而该特征可以确保数据在线程中安全的传输。\n多线程安全的 Arc&lt;T&gt;\n好在，我们有Arc&lt;T&gt;，得益于它的内部计数器是多线程安全的，因此可以在多线程环境中使用：\nuse std::sync::{Arc, Mutex};\nuse std::thread;\n \nfn main() {\n    let counter = Arc::new(Mutex::new(0));\n    let mut handles = vec![];\n \n    for _ in 0..10 {\n        let counter = Arc::clone(&amp;counter);\n        let handle = thread::spawn(move || {\n            let mut num = counter.lock().unwrap();\n \n            *num += 1;\n        });\n        handles.push(handle);\n    }\n \n    for handle in handles {\n        handle.join().unwrap();\n    }\n \n    println!(&quot;Result: {}&quot;, *counter.lock().unwrap());\n}\n内部可变性\n由于Mutex&lt;T&gt;可以支持修改内部数据，当结合Arc&lt;T&gt;一起使用时，可以实现多线程的内部可变性。\n简单总结下：Rc&lt;T&gt;/RefCell&lt;T&gt;用于单线程内部可变性， Arc&lt;T&gt;/Mutex&lt;T&gt;用于多线程内部可变性。\n需要小心使用的 Mutex\n如果有其它语言的编程经验，就知道互斥锁这家伙不好对付，想要正确使用，你得牢记在心：\n\n在使用数据前必须先获取锁\n在数据使用完成后，必须及时的释放锁，比如前文的例子，使用内部语句块的目的就是为了及时的释放锁\n\n这两点看起来不起眼，但要正确的使用，其实是相当不简单的，对于其它语言，忘记释放锁是经常发生的，虽然 Rust 通过智能指针的drop机制帮助我们避免了这一点，但是由于不及时释放锁导致的性能问题也是常见的。\n死锁\n在 Rust 中有多种方式可以创建死锁，了解这些方式有助于你提前规避可能的风险，一起来看看。\n单线程死锁\n这种死锁比较容易规避，但是当代码复杂后还是有可能遇到：\nuse std::sync::Mutex;\n \nfn main() {\n    let data = Mutex::new(0);\n    let d1 = data.lock();\n    let d2 = data.lock();\n} // d1锁在此处释放\n非常简单，只要你在另一个锁还未被释放时去申请新的锁，就会触发，当代码复杂后，这种情况可能就没有那么显眼。\n多线程死锁\nuse std::{sync::{Mutex, MutexGuard}, thread};\nuse std::thread::sleep;\nuse std::time::Duration;\n \nuse lazy_static::lazy_static;\nlazy_static! {\n    static ref MUTEX1: Mutex&lt;i64&gt; = Mutex::new(0);\n    static ref MUTEX2: Mutex&lt;i64&gt; = Mutex::new(0);\n}\n \nfn main() {\n    // 存放子线程的句柄\n    let mut children = vec![];\n    for i_thread in 0..2 {\n        children.push(thread::spawn(move || {\n            for _ in 0..1 {\n                // 线程1\n                if i_thread % 2 == 0 {\n                    // 锁住MUTEX1\n                    let guard: MutexGuard&lt;i64&gt; = MUTEX1.lock().unwrap();\n \n                    println!(&quot;线程 {} 锁住了MUTEX1，接着准备去锁MUTEX2 !&quot;, i_thread);\n \n                    // 当前线程睡眠一小会儿，等待线程2锁住MUTEX2\n                    sleep(Duration::from_millis(10));\n \n                    // 去锁MUTEX2\n                    let guard = MUTEX2.lock().unwrap();\n                // 线程2\n                } else {\n                    // 锁住MUTEX2\n                    let _guard = MUTEX2.lock().unwrap();\n \n                    println!(&quot;线程 {} 锁住了MUTEX2, 准备去锁MUTEX1&quot;, i_thread);\n \n                    let _guard = MUTEX1.lock().unwrap();\n                }\n            }\n        }));\n    }\n \n    // 等子线程完成\n    for child in children {\n        let _ = child.join();\n    }\n \n    println!(&quot;死锁没有发生&quot;);\n}\n在上面的描述中，我们用了”可能”二字，原因在于死锁在这段代码中不是必然发生的，总有一次运行你能看到最后一行打印输出。这是由于子线程的初始化顺序和执行速度并不确定，我们无法确定哪个线程中的锁先被执行，因此也无法确定两个线程对锁的具体使用顺序。\n但是，可以简单的说明下死锁发生的必然条件：线程 1 锁住了MUTEX1并且线程2锁住了MUTEX2，然后线程 1 试图去访问MUTEX2，同时线程2试图去访问MUTEX1，就会死锁。 因为线程 2 需要等待线程 1 释放MUTEX1后，才会释放MUTEX2，而与此同时，线程 1 需要等待线程 2 释放MUTEX2后才能释放MUTEX1，这种情况造成了两个线程都无法释放对方需要的锁，最终死锁。\n那么为何某些时候，死锁不会发生？原因很简单，线程 2 在线程 1 锁MUTEX1之前，就已经全部执行完了，随之线程 2 的MUTEX2和MUTEX1被全部释放，线程 1 对锁的获取将不再有竞争者。 同理，线程 1 若全部被执行完，那线程 2 也不会被锁，因此我们在线程 1 中间加一个睡眠，增加死锁发生的概率。如果你在线程 2 中同样的位置也增加一个睡眠，那死锁将必然发生!\ntry_lock\n与lock方法不同，try_lock会尝试去获取一次锁，如果无法获取会返回一个错误，因此不会发生阻塞:\nuse std::{sync::{Mutex, MutexGuard}, thread};\nuse std::thread::sleep;\nuse std::time::Duration;\n \nuse lazy_static::lazy_static;\nlazy_static! {\n    static ref MUTEX1: Mutex&lt;i64&gt; = Mutex::new(0);\n    static ref MUTEX2: Mutex&lt;i64&gt; = Mutex::new(0);\n}\n \nfn main() {\n    // 存放子线程的句柄\n    let mut children = vec![];\n    for i_thread in 0..2 {\n        children.push(thread::spawn(move || {\n            for _ in 0..1 {\n                // 线程1\n                if i_thread % 2 == 0 {\n                    // 锁住MUTEX1\n                    let guard: MutexGuard&lt;i64&gt; = MUTEX1.lock().unwrap();\n \n                    println!(&quot;线程 {} 锁住了MUTEX1，接着准备去锁MUTEX2 !&quot;, i_thread);\n \n                    // 当前线程睡眠一小会儿，等待线程2锁住MUTEX2\n                    sleep(Duration::from_millis(10));\n \n                    // 去锁MUTEX2\n                    let guard = MUTEX2.try_lock();\n                    println!(&quot;线程 {} 获取 MUTEX2 锁的结果: {:?}&quot;, i_thread, guard);\n                // 线程2\n                } else {\n                    // 锁住MUTEX2\n                    let _guard = MUTEX2.lock().unwrap();\n \n                    println!(&quot;线程 {} 锁住了MUTEX2, 准备去锁MUTEX1&quot;, i_thread);\n                    sleep(Duration::from_millis(10));\n                    let guard = MUTEX1.try_lock();\n                    println!(&quot;线程 {} 获取 MUTEX1 锁的结果: {:?}&quot;, i_thread, guard);\n                }\n            }\n        }));\n    }\n \n    // 等子线程完成\n    for child in children {\n        let _ = child.join();\n    }\n \n    println!(&quot;死锁没有发生&quot;);\n}\n为了演示try_lock的作用，我们特定使用了之前必定会死锁的代码，并且将lock替换成try_lock，与之前的结果不同，这段代码将不会再有死锁发生：\n线程 0 锁住了MUTEX1，接着准备去锁MUTEX2 !\n线程 1 锁住了MUTEX2, 准备去锁MUTEX1\n线程 1 获取 MUTEX1 锁的结果: Err(&quot;WouldBlock&quot;)\n线程 0 获取 MUTEX2 锁的结果: Ok(0)\n死锁没有发生\n如上所示，当try_lock失败时，会报出一个错误:Err(&quot;WouldBlock&quot;)，接着线程中的剩余代码会继续执行，不会被阻塞。\n\n一个有趣的命名规则：在 Rust 标准库中，使用try_xxx都会尝试进行一次操作，如果无法完成，就立即返回，不会发生阻塞。例如消息传递章节中的try_recv以及本章节中的try_lock\n\n读写锁 RwLock\nMutex会对每次读写都进行加锁，但某些时候，我们需要大量的并发读，Mutex就无法满足需求了，此时就可以使用RwLock:\nuse std::sync::RwLock;\n \nfn main() {\n    let lock = RwLock::new(5);\n \n    // 同一时间允许多个读\n    {\n        let r1 = lock.read().unwrap();\n        let r2 = lock.read().unwrap();\n        assert_eq!(*r1, 5);\n        assert_eq!(*r2, 5);\n    } // 读锁在此处被drop\n \n    // 同一时间只允许一个写\n    {\n        let mut w = lock.write().unwrap();\n        *w += 1;\n        assert_eq!(*w, 6);\n \n        // 以下代码会阻塞发生死锁，因为读和写不允许同时存在\n        // 写锁w直到该语句块结束才被释放，因此下面的读锁依然处于`w`的作用域中\n        // let r1 = lock.read();\n        // println!(&quot;{:?}&quot;,r1);\n    }// 写锁在此处被drop\n}\nRwLock在使用上和Mutex区别不大，只有在多个读的情况下不阻塞程序，其他如读写、写读、写写情况下均会对后获取锁的操作进行阻塞。\n我们也可以使用try_write和try_read来尝试进行一次写/读，若失败则返回错误。\n简单总结下RwLock:\n\n同时允许多个读，但最多只能有一个写\n读和写不能同时存在\n读可以使用read、try_read，写write、try_write, 在实际项目中，try_xxx会安全的多\n\nMutex 还是 RwLock\n首先简单性上Mutex完胜，因为使用RwLock你得操心几个问题：\n\n读和写不能同时发生，如果使用try_xxx解决，就必须做大量的错误处理和失败重试机制\n当读多写少时，写操作可能会因为一直无法获得锁导致连续多次失败(writer starvation)\nRwLock 其实是操作系统提供的，实现原理要比Mutex复杂的多，因此单就锁的性能而言，比不上原生实现的Mutex\n\n再来简单总结下两者的使用场景：\n\n追求高并发读取时，使用RwLock，因为Mutex一次只允许一个线程去读取\n如果要保证写操作的成功性，使用Mutex\n不知道哪个合适，统一使用Mutex\n\n需要注意的是，RwLock虽然看上去貌似提供了高并发读取的能力，但这个不能说明它的性能比Mutex高，事实上Mutex性能要好不少，后者唯一的问题也仅仅在于不能并发读取。\n一个常见的、错误的使用RwLock的场景就是使用HashMap进行简单读写，因为HashMap的读和写都非常快，RwLock的复杂实现和相对低的性能反而会导致整体性能的降低，因此一般来说更适合使用Mutex。\n总之，如果你要使用RwLock要确保满足以下两个条件：并发读，且需要对读到的资源进行”长时间”的操作，HashMap也许满足了并发读的需求，但是往往并不能满足后者：“长时间”的操作。\n\nbenchmark 永远是你在迷茫时最好的朋友！\n\n三方库提供的锁实现\n标准库在设计时总会存在取舍，因为往往性能并不是最好的，如果你追求性能，可以使用三方库提供的并发原语:\n\nparking_lot, 功能更完善、稳定，社区较为活跃，star 较多，更新较为活跃\nspin, 在多数场景中性能比parking_lot高一点，最近没怎么更新\n\n如果不是追求特别极致的性能，建议选择前者。\n用条件变量(Condvar)控制线程的同步\nMutex用于解决资源安全访问的问题，但是我们还需要一个手段来解决资源访问顺序的问题。而 Rust 考虑到了这一点，为我们提供了条件变量(Condition Variables)，它经常和Mutex一起使用，可以让线程挂起，直到某个条件发生后再继续执行：\nuse std::sync::{Arc,Mutex,Condvar};\nuse std::thread::{spawn,sleep};\nuse std::time::Duration;\n \nfn main() {\n    let flag = Arc::new(Mutex::new(false));\n    let cond = Arc::new(Condvar::new());\n    let cflag = flag.clone();\n    let ccond = cond.clone();\n \n    let hdl = spawn(move || {\n        let mut lock = cflag.lock().unwrap();\n        let mut counter = 0;\n \n        while counter &lt; 3 {\n            while !*lock {\n                // wait方法会接收一个MutexGuard&lt;&#039;a, T&gt;，且它会自动地暂时释放这个锁，使其他线程可以拿到锁并进行数据更新。\n                // 同时当前线程在此处会被阻塞，直到被其他地方notify后，它会将原本的MutexGuard&lt;&#039;a, T&gt;还给我们，即重新获取到了锁，同时唤醒了此线程。\n                lock = ccond.wait(lock).unwrap();\n            }\n            \n            *lock = false;\n \n            counter += 1;\n            println!(&quot;inner counter: {}&quot;, counter);\n        }\n    });\n \n    let mut counter = 0;\n    loop {\n        sleep(Duration::from_millis(1000));\n        *flag.lock().unwrap() = true;\n        counter += 1;\n        if counter &gt; 3 {\n            break;\n        }\n        println!(&quot;outside counter: {}&quot;, counter);\n        cond.notify_one();\n    }\n    hdl.join().unwrap();\n    println!(&quot;{:?}&quot;, flag);\n}\n例子中通过主线程来触发子线程实现交替打印输出：\noutside counter: 1\ninner counter: 1\noutside counter: 2\ninner counter: 2\noutside counter: 3\ninner counter: 3\nMutex { data: true, poisoned: false, .. }\n信号量 Semaphore\n在多线程中，另一个重要的概念就是信号量，使用它可以让我们精准的控制当前正在运行的任务最大数量。想象一下，当一个新游戏刚开服时(有些较火的老游戏也会，比如wow)，往往会控制游戏内玩家的同时在线数，一旦超过某个临界值，就开始进行排队进服。而在实际使用中，也有很多时候，我们需要通过信号量来控制最大并发数，防止服务器资源被撑爆。\n本来 Rust 在标准库中有提供一个信号量实现, 但是由于各种原因这个库现在已经不再推荐使用了，因此我们推荐使用tokio中提供的Semaphore实现: tokio::sync::Semaphore。\nuse std::sync::Arc;\nuse tokio::sync::Semaphore;\n \n#[tokio::main]\nasync fn main() {\n    let semaphore = Arc::new(Semaphore::new(3));\n    let mut join_handles = Vec::new();\n \n    for _ in 0..5 {\n        let permit = semaphore.clone().acquire_owned().await.unwrap();\n        join_handles.push(tokio::spawn(async move {\n            //\n            // 在这里执行任务...\n            //\n            drop(permit);\n        }));\n    }\n \n    for handle in join_handles {\n        handle.await.unwrap();\n    }\n}\n上面代码创建了一个容量为 3 的信号量，当正在执行的任务超过 3 时，剩下的任务需要等待正在执行任务完成并减少信号量后到 3 以内时，才能继续执行。\n这里的关键其实说白了就在于：信号量的申请和归还，使用前需要申请信号量，如果容量满了，就需要等待；使用后需要释放信号量，以便其它等待者可以继续。\n总结\n在很多时候，消息传递都是非常好用的手段，它可以让我们的数据在任务流水线上不断流转，实现起来非常优雅。\n但是它并不能优雅的解决所有问题，因为我们面临的真实世界是非常复杂的，无法用某一种银弹统一解决。当面临消息传递不太适用的场景时，或者需要更好的性能和简洁性时，我们往往需要用锁来解决这些问题，因为锁允许多个线程同时访问同一个资源，简单粗暴。\n线程同步：Atomic 原子类型与内存顺序\nMutex 用起来简单，但是无法并发读，RwLock可以并发读，但是使用场景较为受限且性能不够，那么有没有一种全能性选手呢？ 欢迎我们的Atomic闪亮登场。\n从 Rust1.34 版本后，就正式支持原子类型。原子指的是一系列不可被 CPU 上下文交换的机器指令，这些指令组合在一起就形成了原子操作。在多核 CPU 下，当某个 CPU 核心开始运行原子操作时，会先暂停其它 CPU 内核对内存的操作，以保证原子操作不会被其它 CPU 内核所干扰。\n由于原子操作是通过指令提供的支持，因此它的性能相比锁和消息传递会好很多。相比较于锁而言，原子类型不需要开发者处理加锁和释放锁的问题，同时支持修改，读取等操作，还具备较高的并发性能，几乎所有的语言都支持原子类型。\n可以看出原子类型是无锁类型，但是无锁不代表无需等待，因为原子类型内部使用了CAS循环，当大量的冲突发生时，该等待还是得等待！但是总归比锁要好。\n\nCAS 全称是 Compare and swap, 它通过一条指令读取指定的内存地址，然后判断其中的值是否等于给定的前置值，如果相等，则将其修改为新的值。\n\n使用 Atomic 作为全局变量\n原子类型的一个常用场景，就是作为全局变量来使用：\nuse std::ops::Sub;\nuse std::sync::atomic::{AtomicU64, Ordering};\nuse std::thread::{self, JoinHandle};\nuse std::time::Instant;\n \nconst N_TIMES: u64 = 10000000;\nconst N_THREADS: usize = 10;\n \nstatic R: AtomicU64 = AtomicU64::new(0);\n \nfn add_n_times(n: u64) -&gt; JoinHandle&lt;()&gt; {\n    thread::spawn(move || {\n        for _ in 0..n {\n            R.fetch_add(1, Ordering::Relaxed);\n        }\n    })\n}\n \nfn main() {\n    let s = Instant::now();\n    let mut threads = Vec::with_capacity(N_THREADS);\n \n    for _ in 0..N_THREADS {\n        threads.push(add_n_times(N_TIMES));\n    }\n \n    for thread in threads {\n        thread.join().unwrap();\n    }\n \n    assert_eq!(N_TIMES * N_THREADS as u64, R.load(Ordering::Relaxed));\n \n    println!(&quot;{:?}&quot;,Instant::now().sub(s));\n}\n以上代码启动了数个线程，每个线程都在疯狂对全局变量进行加 1 操作, 最后将它与线程数 * 加1次数进行比较，如果发生了因为多个线程同时修改导致了脏数据，那么这两个必将不相等。好在，它没有让我们失望，不仅快速的完成了任务，而且保证了 100%的并发安全性。\nAtomic实现：673ms\nMutex实现: 1136ms\n可以看到Atomic实现会比Mutex快41%，实际上在复杂场景下还能更快(甚至达到 4 倍的性能差距)！\n还有一点值得注意: 和Mutex一样，Atomic的值具有内部可变性，你无需将其声明为mut：\nuse std::sync::Mutex;\nuse std::sync::atomic::{Ordering, AtomicU64};\n \nstruct Counter {\n    count: u64\n}\n \nfn main() {\n    let n = Mutex::new(Counter {\n        count: 0\n    });\n \n    n.lock().unwrap().count += 1;\n \n    let n = AtomicU64::new(0);\n \n    n.fetch_add(0, Ordering::Relaxed);\n}\n这里有一个奇怪的枚举成员Ordering::Relaxed, 看上去很像是排序作用，但是我们并没有做排序操作啊？实际上它用于控制原子操作使用的内存顺序。\n内存顺序\n内存顺序是指 CPU 在访问内存时的顺序，该顺序可能受以下因素的影响：\n\n代码中的先后顺序\n编译器优化导致在编译阶段发生改变(内存重排序 reordering)\n运行阶段因 CPU 的缓存机制导致顺序被打乱\n\n编译器优化导致内存顺序的改变\n对于第二点，我们举个例子：\nstatic mut X: u64 = 0;\nstatic mut Y: u64 = 1;\n \nfn main() {\n    ...     // A\n \n    unsafe {\n        ... // B\n        X = 1;\n        ... // C\n        Y = 3;\n        ... // D\n        X = 2;\n        ... // E\n    }\n}\n假如在C和D代码片段中，根本没有用到X = 1，那么编译器很可能会将X = 1和X = 2进行合并:\n ...     // A\n \nunsafe {\n    ... // B\n    X = 2;\n    ... // C\n    Y = 3;\n    ... // D\n    ... // E\n}\n若代码A中创建了一个新的线程用于读取全局静态变量X，则该线程将无法读取到X = 1的结果，因为在编译阶段就已经被优化掉。\nCPU 缓存导致的内存顺序的改变\n假设之前的X = 1没有被优化掉，并且在代码片段A中有一个新的线程:\ninitial state: X = 0, Y = 1\n \nTHREAD Main     THREAD A\nX = 1;          if X == 1 {\nY = 3;              Y *= 2;\nX = 2;          }\n我们来讨论下以上线程状态，Y最终的可能值(可能性依次降低):\n\nY = 3: 线程Main运行完后才运行线程A，或者线程A运行完后再运行线程Main\nY = 6: 线程Main的Y = 3运行完，但X = 2还没被运行， 此时线程 A 开始运行Y *= 2, 最后才运行Main线程的X = 2\nY = 2: 线程Main正在运行Y = 3还没结束，此时线程A正在运行Y *= 2, 因此Y取到了值 1，然后Main的线程将Y设置为 3， 紧接着就被线程A的Y = 2所覆盖\nY = 2: 上面的还只是一般的数据竞争，这里虽然产生了相同的结果2，但是背后的原理大相径庭: 线程Main运行完Y = 3，但是 CPU 缓存中的Y = 3还没有被同步到其它 CPU 缓存中，此时线程A中的Y *= 2就开始读取Y，结果读到了值1，最终计算出结果2\n\n甚至更改成:\ninitial state: X = 0, Y = 1\n \nTHREAD Main     THREAD A\nX = 1;          if X == 2 {\nY = 3;              Y *= 2;\nX = 2;          }\n还是可能出现Y = 2，因为Main线程中的X和Y被同步到其它 CPU 缓存中的顺序未必一致。\n限定内存顺序的 5 个规则\n在理解了内存顺序可能存在的改变后，你就可以明白为什么 Rust 提供了Ordering::Relaxed用于限定内存顺序了，事实上，该枚举有 5 个成员：\n\nRelaxed， 这是最宽松的规则，它对编译器和 CPU 不做任何限制，可以乱序\nRelease 释放，设定内存屏障(Memory barrier)，保证它之前的操作永远在它之前，但是它后面的操作可能被重排到它前面\nAcquire 获取, 设定内存屏障，保证在它之后的访问永远在它之后，但是它之前的操作却有可能被重排到它后面，往往和Release在不同线程中联合使用\nAcqRel, 是 Acquire 和 Release 的结合，同时拥有它们俩提供的保证。比如你要对一个 atomic 自增 1，同时希望该操作之前和之后的读取或写入操作不会被重新排序\nSeqCst 顺序一致性， SeqCst就像是AcqRel的加强版，它不管原子操作是属于读取还是写入的操作，只要某个线程有用到SeqCst的原子操作，线程中该SeqCst操作前的数据操作绝对不会被重新排在该SeqCst操作之后，且该SeqCst操作后的数据操作也绝对不会被重新排在SeqCst操作前。\n\n这些规则由于是系统提供的，因此其它语言提供的相应规则也大同小异，大家如果不明白可以看看其它语言的相关解释。\n内存屏障的例子\n下面我们以Release和Acquire为例，使用它们构筑出一对内存屏障，防止编译器和 CPU 将屏障前(Release)和屏障后(Acquire)中的数据操作重新排在屏障围成的范围之外:\nuse std::thread::{self, JoinHandle};\nuse std::sync::atomic::{Ordering, AtomicBool};\n \nstatic mut DATA: u64 = 0;\nstatic READY: AtomicBool = AtomicBool::new(false);\n \nfn reset() {\n    unsafe {\n        DATA = 0;\n    }\n    READY.store(false, Ordering::Relaxed);\n}\n \nfn producer() -&gt; JoinHandle&lt;()&gt; {\n    thread::spawn(move || {\n        unsafe {\n            DATA = 100;                                 // A\n        }\n        READY.store(true, Ordering::Release);           // B: 内存屏障 ↑\n    })\n}\n \nfn consumer() -&gt; JoinHandle&lt;()&gt; {\n    thread::spawn(move || {\n        while !READY.load(Ordering::Acquire) {}         // C: 内存屏障 ↓\n \n        assert_eq!(100, unsafe { DATA });               // D\n    })\n}\n \n \nfn main() {\n    loop {\n        reset();\n \n        let t_producer = producer();\n        let t_consumer = consumer();\n \n        t_producer.join().unwrap();\n        t_consumer.join().unwrap();\n    }\n}\n原则上，Acquire用于读取，而Release用于写入。但是由于有些原子操作同时拥有读取和写入的功能，此时就需要使用AcqRel来设置内存顺序了。在内存屏障中被写入的数据，都可以被其它线程读取到，不会有 CPU 缓存的问题。\n内存顺序的选择\n\n不知道怎么选择时，优先使用SeqCst，虽然会稍微减慢速度，但是慢一点也比出现错误好\n多线程只计数fetch_add而不使用该值触发其他逻辑分支的简单使用场景，可以使用Relaxed\n参考 Which std::sync::atomic::Ordering to use?\n\n多线程中使用 Atomic\n在多线程环境中要使用Atomic需要配合Arc：\nuse std::sync::Arc;\nuse std::sync::atomic::{AtomicUsize, Ordering};\nuse std::{hint, thread};\n \nfn main() {\n    let spinlock = Arc::new(AtomicUsize::new(1));\n \n    let spinlock_clone = Arc::clone(&amp;spinlock);\n    let thread = thread::spawn(move|| {\n        spinlock_clone.store(0, Ordering::SeqCst);\n    });\n \n    // 等待其它线程释放锁\n    while spinlock.load(Ordering::SeqCst) != 0 {\n        hint::spin_loop();\n    }\n \n    if let Err(panic) = thread.join() {\n        println!(&quot;Thread had an error: {:?}&quot;, panic);\n    }\n}\nAtomic 能替代锁吗\n那么原子类型既然这么全能，它可以替代锁吗？答案是不行：\n\n对于复杂的场景下，锁的使用简单粗暴，不容易有坑；\nstd::sync::atomic 包中仅提供了数值类型的原子操作：AtomicBool, AtomicIsize, AtomicUsize, AtomicI8, AtomicU16等，而锁可以应用于各种类型；\n在有些情况下，必须使用锁来配合，例如使用 Mutex 配合Condvar；\n\nAtomic 的应用场景\n事实上，Atomic 虽然对于用户不太常用，但是对于高性能库的开发者、标准库开发者都非常常用，它是并发原语的基石，除此之外，还有一些场景适用：\n\n无锁(lock free)数据结构\n全局变量，例如全局自增 ID, 在后续章节会介绍\n跨线程计数器，例如可以用于统计指标\n\n以上列出的只是 Atomic 适用的部分场景，具体场景需要大家未来根据自己的需求进行权衡选择。"},"rust/rust-bible/advanced/07-全局变量":{"title":"全局变量","links":["tags/TODO","rust/rust-bible/advanced/04-智能指针"],"tags":["TODO"],"content":"全局变量\n在一些场景，我们可能需要全局变量来简化状态共享的代码，包括全局 ID，全局数据存储等等，下面一起来看看有哪些创建全局变量的方法。\n首先，有一点可以肯定，全局变量的生命周期肯定是’static，但是不代表它需要用 static 来声明，例如常量、字符串字面值等无需使用 static 进行声明，原因是它们已经被打包到二进制可执行文件中。\n下面我们从编译期初始化及运行期初始化两个类别来介绍下全局变量有哪些类型及该如何使用。\n编译期初始化\n我们大多数使用的全局变量都只需要在编译期初始化即可，例如静态配置、计数器、状态值等等。\n静态常量\n全局常量可以在程序任何一部分使用，当然，如果它是定义在某个模块中，你需要引入对应的模块才能使用。常量，顾名思义它是不可变的，很适合用作静态配置：\nconst MAX_ID: usize = usize::MAX / 2;\n \nfn main() {\n println!(&quot;用户ID允许的最大值是{}&quot;,MAX_ID);\n}\n常量与普通变量的区别\n\n关键字是const而不是let\n定义常量必须指明类型（如 i32）不能省略\n定义常量时变量的命名规则一般是全部大写\n常量可以在任意作用域进行定义，其生命周期贯穿整个程序的生命周期。编译时编译器会尽可能将其内联到代码中，所以在不同地方对同一常量的引用并不能保证引用到相同的内存地址\n常量的赋值只能是常量表达式/数学表达式，也就是说必须是在编译期就能计算出的值，如果需要在运行时才能得出结果的值比如函数，则不能赋值给常量表达式\n对于变量出现重复的定义(绑定)会发生变量遮盖，后面定义的变量会遮住前面定义的变量，常量则不允许出现重复的定义\n\n静态变量\n静态变量允许声明一个全局的变量，常用于全局数据统计，例如我们希望用一个变量来统计程序当前的总请求数：\nstatic mut REQUEST_RECV: usize = 0;\nfn main() {\n   unsafe {\n        REQUEST_RECV += 1;\n        assert_eq!(REQUEST_RECV, 1);\n   }\n}\nRust 要求必须使用 unsafe 语句块才能访问和修改 static 变量，因为这种使用方式往往并不安全，其实编译器是对的，当在多线程中同时去修改时，会不可避免的遇到脏数据。\n只有在同一线程内或者不在乎数据的准确性时，才应该使用全局静态变量。\n和常量相同，定义静态变量的时候必须赋值为在编译期就可以计算出的值(常量表达式/数学表达式)，不能是运行时才能计算出的值(如函数)\n静态变量和常量的区别\n\n静态变量不会被内联，在整个程序中，静态变量只有一个实例，所有的引用都会指向同一个地址；\n存储在静态变量中的值必须要实现 Sync trait；\n\n原子类型\n想要全局计数器、状态控制等功能，又想要线程安全的实现，原子类型是非常好的办法。\nuse std::sync::atomic::{AtomicUsize, Ordering};\nstatic REQUEST_RECV: AtomicUsize  = AtomicUsize::new(0);\n \nfn main() {\n    for _ in 0..100 {\n        REQUEST_RECV.fetch_add(1, Ordering::Relaxed);\n    }\n \n    println!(&quot;当前用户请求数{:?}&quot;, REQUEST_RECV);\n}\n示例：全局 ID 生成器\n来看看如何使用上面的内容实现一个全局 ID 生成器:\nuse std::sync::atomic::{Ordering, AtomicUsize};\n \nstruct Factory{\n    factory_id: usize,\n}\n \nstatic GLOBAL_ID_COUNTER: AtomicUsize = AtomicUsize::new(0);\nconst MAX_ID: usize = usize::MAX / 2;\n \nfn generate_id() -&gt; usize {\n    // 检查两次溢出，否则直接加一可能导致溢出\n    let current_val = GLOBAL_ID_COUNTER.load(Ordering::Relaxed);\n    if current_val &gt; MAX_ID {\n        panic!(&quot;Factory ids overflowed&quot;);\n    }\n    GLOBAL_ID_COUNTER.fetch_add(1, Ordering::Relaxed);\n    let next_id = GLOBAL_ID_COUNTER.load(Ordering::Relaxed);\n    if next_id &gt; MAX_ID{\n        panic!(&quot;Factory ids overflowed&quot;);\n    }\n    next_id\n}\n \nimpl Factory{\n    fn new() -&gt; Self{\n        Self {\n            factory_id: generate_id()\n        }\n    }\n}\n运行期初始化\n以上的静态初始化有一个致命的问题：无法用函数进行静态初始化，例如你如果想声明一个全局的Mutex锁：\nuse std::sync::Mutex;\nstatic NAMES: Mutex&lt;String&gt; = Mutex::new(String::from(&quot;Sunface, Jack, Allen&quot;));\n \nfn main() {\n    let v = NAMES.lock().unwrap();\n    println!(&quot;{}&quot;,v);\n}\n运行后报错如下：\nerror[E0015]: calls in statics are limited to constant functions, tuple structs and tuple variants\n --&gt; src/main.rs:3:42\n  |\n3 | static NAMES: Mutex&lt;String&gt; = Mutex::new(String::from(&quot;sunface&quot;));\n但你又必须在声明时就对NAMES进行初始化，此时就陷入了两难的境地。好在天无绝人之路，我们可以使用lazy_static包来解决这个问题。\nlazy_static\nlazy_static是社区提供的非常强大的宏，用于懒初始化静态变量，之前的静态变量都是在编译期初始化的，因此无法使用函数调用进行赋值，而lazy_static允许我们在运行期初始化静态变量！\nuse std::sync::Mutex;\nuse lazy_static::lazy_static;\nlazy_static! {\n    static ref NAMES: Mutex&lt;String&gt; = Mutex::new(String::from(&quot;Sunface, Jack, Allen&quot;));\n}\n \nfn main() {\n    let mut v = NAMES.lock().unwrap();\n    v.push_str(&quot;, Myth&quot;);\n    println!(&quot;{}&quot;,v);\n}\n当然，使用lazy_static在每次访问静态变量时，会有轻微的性能损失，因为其内部实现用了一个底层的并发原语std::sync::Once，在每次访问该变量时，程序都会执行一次原子指令用于确认静态变量的初始化是否完成。\nlazy_static宏，匹配的是static ref，所以定义的静态变量都是不可变引用。\n\nTODO ?\n\n可能有读者会问，为何需要在运行期初始化一个静态变量，除了上面的全局锁，你会遇到最常见的场景就是：一个全局的动态配置，它在程序开始后，才加载数据进行初始化，最终可以让各个线程直接访问使用。\n再来看一个使用lazy_static实现全局缓存的例子：\nuse lazy_static::lazy_static;\nuse std::collections::HashMap;\n \nlazy_static! {\n    static ref HASHMAP: HashMap&lt;u32, &amp;&#039;static str&gt; = {\n        let mut m = HashMap::new();\n        m.insert(0, &quot;foo&quot;);\n        m.insert(1, &quot;bar&quot;);\n        m.insert(2, &quot;baz&quot;);\n        m\n    };\n}\n \nfn main() {\n    // 首次访问`HASHMAP`的同时对其进行初始化\n    println!(&quot;The entry for `0` is \\&quot;{}\\&quot;.&quot;, HASHMAP.get(&amp;0).unwrap());\n \n    // 后续的访问仅仅获取值，再不会进行任何初始化操作\n    println!(&quot;The entry for `1` is \\&quot;{}\\&quot;.&quot;, HASHMAP.get(&amp;1).unwrap());\n}\n需要注意的是，lazy_static直到运行到main中的第一行代码时，才进行初始化，非常lazy static。\nBox::leak\n在Box智能指针章节中，我们提到了Box::leak可以用于全局变量，例如用作运行期初始化的全局动态配置，先来看看如果不使用lazy_static也不使用Box::leak，会发生什么：\n#[derive(Debug)]\nstruct Config {\n    a: String,\n    b: String,\n}\nstatic mut CONFIG: Option&lt;&amp;mut Config&gt; = None;\n \nfn main() {\n    unsafe {\n        CONFIG = Some(&amp;mut Config {\n            a: &quot;A&quot;.to_string(),\n            b: &quot;B&quot;.to_string(),\n        });\n \n        println!(&quot;{:?}&quot;, CONFIG)\n    }\n}\n以上代码我们声明了一个全局动态配置CONFIG，并且其值初始化为None，然后在程序开始运行后，给它赋予相应的值，运行后报错：\nerror[E0716]: temporary value dropped while borrowed\n  --&gt; src/main.rs:10:28\n   |\n10 |            CONFIG = Some(&amp;mut Config {\n   |   _________-__________________^\n   |  |_________|\n   | ||\n11 | ||             a: &quot;A&quot;.to_string(),\n12 | ||             b: &quot;B&quot;.to_string(),\n13 | ||         });\n   | ||         ^-- temporary value is freed at the end of this statement\n   | ||_________||\n   |  |_________|assignment requires that borrow lasts for `&#039;static`\n   |            creates a temporary which is freed while still in use\n \n可以看到，Rust 的借用和生命周期规则限制了我们做到这一点，因为试图将一个局部生命周期的变量赋值给全局生命周期的CONFIG，这明显是不安全的。\n好在Rust为我们提供了Box::leak方法，它可以将一个变量从内存中泄漏(听上去怪怪的，竟然做主动内存泄漏)，然后将其变为&#039;static生命周期，最终该变量将和程序活得一样久，因此可以赋值给全局静态变量CONFIG。\n#[derive(Debug)]\nstruct Config {\n    a: String,\n    b: String\n}\nstatic mut CONFIG: Option&lt;&amp;mut Config&gt; = None;\n \nfn main() {\n    let c = Box::new(Config {\n        a: &quot;A&quot;.to_string(),\n        b: &quot;B&quot;.to_string(),\n    });\n \n    unsafe {\n        // 将`c`从内存中泄漏，变成`&#039;static`生命周期\n        CONFIG = Some(Box::leak(c));\n        println!(&quot;{:?}&quot;, CONFIG);\n    }\n}\n从函数中返回全局变量\n问题又来了，如果我们需要在运行期，从一个函数返回一个全局变量该如何做？例如：\n#[derive(Debug)]\nstruct Config {\n    a: String,\n    b: String,\n}\nstatic mut CONFIG: Option&lt;&amp;mut Config&gt; = None;\n \nfn init() -&gt; Option&lt;&amp;&#039;static mut Config&gt; {\n    Some(&amp;mut Config {\n        a: &quot;A&quot;.to_string(),\n        b: &quot;B&quot;.to_string(),\n    })\n}\n \nfn main() {\n    unsafe {\n        CONFIG = init();\n        println!(&quot;{:?}&quot;, CONFIG)\n    }\n}\n \n报错这里就不展示了，跟之前大同小异，还是生命周期引起的，那么该如何解决呢？依然可以用Box::leak:\n#[derive(Debug)]\nstruct Config {\n    a: String,\n    b: String,\n}\nstatic mut CONFIG: Option&lt;&amp;mut Config&gt; = None;\n \nfn init() -&gt; Option&lt;&amp;&#039;static mut Config&gt; {\n    let c = Box::new(Config {\n        a: &quot;A&quot;.to_string(),\n        b: &quot;B&quot;.to_string(),\n    });\n \n    Some(Box::leak(c))\n}\n \nfn main() {\n    unsafe {\n        CONFIG = init();\n \n        println!(&quot;{:?}&quot;, CONFIG)\n    }\n}\n标准库中的 OnceCell\n在  Rust  标准库中提供了实验性的  lazy::OnceCell  和  lazy::SyncOnceCell (在  Rust 1.70.0 版本及以上的标准库中，替换为稳定的  cell::OnceCell  和  sync::OnceLock )两种  Cell ，前者用于单线程，后者用于多线程，它们用来存储堆上的信息，并且具有最 多只能赋值一次的特性。 如实现一个多线程的日志组件  Logger：\n// 低于Rust 1.70版本中， OnceCell 和 SyncOnceCell 的API为实验性的 ，\n// 需启用特性 `#![feature(once_cell)]`。\n#![feature(once_cell)]\nuse std::{lazy::SyncOnceCell, thread};\n \n// Rust 1.70版本以上,\n// use std::{sync::OnceLock, thread};\n \nfn main() {\n    // 子线程中调用\n    let handle = thread::spawn(|| {\n        let logger = Logger::global();\n        logger.log(&quot;thread message&quot;.to_string());\n    });\n \n    // 主线程调用\n    let logger = Logger::global();\n    logger.log(&quot;some message&quot;.to_string());\n \n    let logger2 = Logger::global();\n    logger2.log(&quot;other message&quot;.to_string());\n \n    handle.join().unwrap();\n}\n \n#[derive(Debug)]\nstruct Logger;\n \n// 低于Rust 1.70版本\nstatic LOGGER: SyncOnceCell&lt;Logger&gt; = SyncOnceCell::new();\n \n// Rust 1.70版本以上\n// static LOGGER: OnceLock&lt;Logger&gt; = OnceLock::new();\n \nimpl Logger {\n    fn global() -&gt; &amp;&#039;static Logger {\n        // 获取或初始化 Logger\n        LOGGER.get_or_init(|| {\n            println!(&quot;Logger is being created...&quot;); // 初始化打印\n            Logger\n        })\n    }\n \n    fn log(&amp;self, message: String) {\n        println!(&quot;{}&quot;, message)\n    }\n}\n以上代码我们声明了一个  global()  关联函数，并在其内部调用  get_or_init  进行初始化  Logger，之后在不同线程上多次调用  Logger::global()  获取其实例：\nLogger is being created...\nsome message\nother message\nthread message\n可以看到，Logger is being created...  在多个线程中使用也只被打印了一次。\n特别注意，目前  OnceCell  和  SyncOnceCell API 暂未稳定，需启用特性  #![feature(once_cell)]。\n总结\n在 Rust 中有很多方式可以创建一个全局变量，本章也只是介绍了其中一部分，更多的还等待大家自己去挖掘学习(当然，未来可能本章节会不断完善，最后变成一个巨无霸- , -)。\n简单来说，全局变量可以分为两种：\n\n编译期初始化的全局变量，const创建常量，static创建静态变量，Atomic创建原子类型\n运行期初始化的全局变量，lazy_static用于懒初始化，Box::leak利用内存泄漏将一个变量的生命周期变为&#039;static\n"},"rust/rust-bible/advanced/08-错误处理":{"title":"错误处理","links":["rust/rust-bible/basic/19-返回值与错误处理"],"tags":[],"content":"在之前的返回值与错误处理章节中，我们学习了几个重要的概念，例如  Result  用于返回结果处理，?  用于错误的传播，若大家对此还较为模糊，强烈建议回头温习下。\n在本章节中一起来看看如何对  Result ( Option ) 做进一步的处理，以及如何定义自己的错误类型。\n组合器\n在设计模式中，有一个组合器模式，相信有 Java 背景的同学对此并不陌生。\n\n将对象组合成树形结构以表示“部分整体”的层次结构。组合模式使得用户对单个对象和组合对象的使用具有一致性。– GoF &lt;&lt;设计模式&gt;&gt;\n\n与组合器模式有所不同，在 Rust 中，组合器更多的是用于对返回结果的类型进行变换：例如使用  ok_or  将一个  Option  类型转换成  Result  类型。\n下面我们来看看一些常见的组合器。\nor() 和 and()\n跟布尔关系的与/或很像，这两个方法会对两个表达式做逻辑组合，最终返回  Option / Result。\n\nor()，表达式按照顺序求值，若任何一个表达式的结果是  Some  或  Ok，则该值会立刻返回\nand()，若两个表达式的结果都是  Some  或  Ok，则第二个表达式中的值被返回。若任何一个的结果是  None  或  Err ，则立刻返回。\n\n实际上，只要将布尔表达式的  true / false，替换成  Some / None  或  Ok / Err  就很好理解了。\nfn main() {\n  let s1 = Some(&quot;some1&quot;);\n  let s2 = Some(&quot;some2&quot;);\n  let n: Option&lt;&amp;str&gt; = None;\n \n  let o1: Result&lt;&amp;str, &amp;str&gt; = Ok(&quot;ok1&quot;);\n  let o2: Result&lt;&amp;str, &amp;str&gt; = Ok(&quot;ok2&quot;);\n  let e1: Result&lt;&amp;str, &amp;str&gt; = Err(&quot;error1&quot;);\n  let e2: Result&lt;&amp;str, &amp;str&gt; = Err(&quot;error2&quot;);\n \n  assert_eq!(s1.or(s2), s1); // Some1 or Some2 = Some1\n  assert_eq!(s1.or(n), s1);  // Some or None = Some\n  assert_eq!(n.or(s1), s1);  // None or Some = Some\n  assert_eq!(n.or(n), n);    // None1 or None2 = None2\n \n  assert_eq!(o1.or(o2), o1); // Ok1 or Ok2 = Ok1\n  assert_eq!(o1.or(e1), o1); // Ok or Err = Ok\n  assert_eq!(e1.or(o1), o1); // Err or Ok = Ok\n  assert_eq!(e1.or(e2), e2); // Err1 or Err2 = Err2\n \n  assert_eq!(s1.and(s2), s2); // Some1 and Some2 = Some2\n  assert_eq!(s1.and(n), n);   // Some and None = None\n  assert_eq!(n.and(s1), n);   // None and Some = None\n  assert_eq!(n.and(n), n);    // None1 and None2 = None1\n \n  assert_eq!(o1.and(o2), o2); // Ok1 and Ok2 = Ok2\n  assert_eq!(o1.and(e1), e1); // Ok and Err = Err\n  assert_eq!(e1.and(o1), e1); // Err and Ok = Err\n  assert_eq!(e1.and(e2), e1); // Err1 and Err2 = Err1\n}\n除了  or  和  and  之外，Rust 还为我们提供了  xor ，但是它只能应用在  Option  上，其实想想也是这个理，如果能应用在  Result  上，那你又该如何对一个值和错误进行异或操作？\nor_else() 和 and_then()\n它们跟  or()  和  and()  类似，唯一的区别在于，它们的第二个表达式是一个闭包。\nfn main() {\n    // or_else with Option\n    let s1 = Some(&quot;some1&quot;);\n    let s2 = Some(&quot;some2&quot;);\n    let fn_some = || Some(&quot;some2&quot;);\n    // 类似于: let fn_some = || -&gt; Option&lt;&amp;str&gt; { Some(&quot;some2&quot;) };\n \n    let n: Option&lt;&amp;str&gt; = None;\n    let fn_none = || None;\n \n    assert_eq!(s1.or_else(fn_some), s1);  // Some1 or_else Some2 = Some1\n    assert_eq!(s1.or_else(fn_none), s1);  // Some or_else None = Some\n    assert_eq!(n.or_else(fn_some), s2);   // None or_else Some = Some\n    assert_eq!(n.or_else(fn_none), None); // None1 or_else None2 = None2\n \n    // or_else with Result\n    let o1: Result&lt;&amp;str, &amp;str&gt; = Ok(&quot;ok1&quot;);\n    let o2: Result&lt;&amp;str, &amp;str&gt; = Ok(&quot;ok2&quot;);\n    let fn_ok = |_| Ok(&quot;ok2&quot;);\n    // 类似于: let fn_ok = |_| -&gt; Result&lt;&amp;str, &amp;str&gt; { Ok(&quot;ok2&quot;) };\n \n    let e1: Result&lt;&amp;str, &amp;str&gt; = Err(&quot;error1&quot;);\n    let e2: Result&lt;&amp;str, &amp;str&gt; = Err(&quot;error2&quot;);\n    let fn_err = |_| Err(&quot;error2&quot;);\n \n    assert_eq!(o1.or_else(fn_ok), o1);  // Ok1 or_else Ok2 = Ok1\n    assert_eq!(o1.or_else(fn_err), o1); // Ok or_else Err = Ok\n    assert_eq!(e1.or_else(fn_ok), o2);  // Err or_else Ok = Ok\n    assert_eq!(e1.or_else(fn_err), e2); // Err1 or_else Err2 = Err2\n}\nfn main() {\n    // and_then with Option\n    let s1 = Some(&quot;some1&quot;);\n    let s2 = Some(&quot;some2&quot;);\n    let fn_some = |_| Some(&quot;some2&quot;);\n    // 类似于: let fn_some = |_| -&gt; Option&lt;&amp;str&gt; { Some(&quot;some2&quot;) };\n \n    let n: Option&lt;&amp;str&gt; = None;\n    let fn_none = |_| None;\n \n    assert_eq!(s1.and_then(fn_some), s2); // Some1 and_then Some2 = Some2\n    assert_eq!(s1.and_then(fn_none), n);  // Some and_then None = None\n    assert_eq!(n.and_then(fn_some), n);   // None and_then Some = None\n    assert_eq!(n.and_then(fn_none), n);   // None1 and_then None2 = None1\n \n    // and_then with Result\n    let o1: Result&lt;&amp;str, &amp;str&gt; = Ok(&quot;ok1&quot;);\n    let o2: Result&lt;&amp;str, &amp;str&gt; = Ok(&quot;ok2&quot;);\n    let fn_ok = |_| Ok(&quot;ok2&quot;);\n    // 类似于: let fn_ok = |_| -&gt; Result&lt;&amp;str, &amp;str&gt; { Ok(&quot;ok2&quot;) };\n \n    let e1: Result&lt;&amp;str, &amp;str&gt; = Err(&quot;error1&quot;);\n    let e2: Result&lt;&amp;str, &amp;str&gt; = Err(&quot;error2&quot;);\n    let fn_err = |_| Err(&quot;error2&quot;);\n \n    assert_eq!(o1.and_then(fn_ok), o2);  // Ok1 and_then Ok2 = Ok2\n    assert_eq!(o1.and_then(fn_err), e2); // Ok and_then Err = Err\n    assert_eq!(e1.and_then(fn_ok), e1);  // Err and_then Ok = Err\n    assert_eq!(e1.and_then(fn_err), e1); // Err1 and_then Err2 = Err1\n}\nfilter\nfilter  用于对  Option  进行过滤：\nfn main() {\n    let s1 = Some(3);\n    let s2 = Some(6);\n    let n = None;\n \n    let fn_is_even = |x: &amp;i8| x % 2 == 0;\n \n    assert_eq!(s1.filter(fn_is_even), n);  // Some(3) -&gt; 3 is not even -&gt; None\n    assert_eq!(s2.filter(fn_is_even), s2); // Some(6) -&gt; 6 is even -&gt; Some(6)\n    assert_eq!(n.filter(fn_is_even), n);   // None -&gt; no value -&gt; None\n}\nmap() 和 map_err()\nmap  可以将  Some  或  Ok  中的值映射为另一个：\nfn main() {\n    let s1 = Some(&quot;abcde&quot;);\n    let s2 = Some(5);\n \n    let n1: Option&lt;&amp;str&gt; = None;\n    let n2: Option&lt;usize&gt; = None;\n \n    let o1: Result&lt;&amp;str, &amp;str&gt; = Ok(&quot;abcde&quot;);\n    let o2: Result&lt;usize, &amp;str&gt; = Ok(5);\n \n    let e1: Result&lt;&amp;str, &amp;str&gt; = Err(&quot;abcde&quot;);\n    let e2: Result&lt;usize, &amp;str&gt; = Err(&quot;abcde&quot;);\n \n    let fn_character_count = |s: &amp;str| s.chars().count();\n \n    assert_eq!(s1.map(fn_character_count), s2); // Some1 map = Some2\n    assert_eq!(n1.map(fn_character_count), n2); // None1 map = None2\n \n    assert_eq!(o1.map(fn_character_count), o2); // Ok1 map = Ok2\n    assert_eq!(e1.map(fn_character_count), e2); // Err1 map = Err2\n}\n但是如果你想要将  Err  中的值进行改变， map  就无能为力了，此时我们需要用  map_err：\nfn main() {\n    let o1: Result&lt;&amp;str, &amp;str&gt; = Ok(&quot;abcde&quot;);\n    let o2: Result&lt;&amp;str, isize&gt; = Ok(&quot;abcde&quot;);\n \n    let e1: Result&lt;&amp;str, &amp;str&gt; = Err(&quot;404&quot;);\n    let e2: Result&lt;&amp;str, isize&gt; = Err(404);\n \n\t// 该函数返回一个 isize\n    let fn_character_count = |s: &amp;str| -&gt; isize { s.parse().unwrap() };\n \n    assert_eq!(o1.map_err(fn_character_count), o2); // Ok1 map = Ok2\n    assert_eq!(e1.map_err(fn_character_count), e2); // Err1 map = Err2\n}\n通过对  o1  的操作可以看出，与  map  面对  Err  时的短小类似， map_err  面对  Ok  时也是相当无力的。\nmap_or() 和 map_or_else()\nmap_or  在  map  的基础上提供了一个默认值：\nfn main() {\n    const V_DEFAULT: u32 = 1;\n \n    let s: Result&lt;u32, ()&gt; = Ok(10);\n    let n: Option&lt;u32&gt; = None;\n    let fn_closure = |v: u32| v + 2;\n \n    assert_eq!(s.map_or(V_DEFAULT, fn_closure), 12);\n    assert_eq!(n.map_or(V_DEFAULT, fn_closure), V_DEFAULT);\n}\n如上所示，当处理  None  的时候，V_DEFAULT  作为默认值被直接返回。\nmap_or_else  与  map_or  类似，但是它是通过一个闭包来提供默认值：\nfn main() {\n    let s = Some(10);\n    let n: Option&lt;i8&gt; = None;\n \n    let fn_closure = |v: i8| v + 2;\n    let fn_default = || 1;\n \n    assert_eq!(s.map_or_else(fn_default, fn_closure), 12);\n    assert_eq!(n.map_or_else(fn_default, fn_closure), 1);\n \n    let o = Ok(10);\n    let e = Err(5);\n \n    // 闭包可以对 Err 中的值进行处理，并返回一个新值\n    let fn_default_for_result = |v: i8| v + 1;\n    assert_eq!(o.map_or_else(fn_default_for_result, fn_closure), 12);\n    assert_eq!(e.map_or_else(fn_default_for_result, fn_closure), 6);\n}\nok_or() and ok_or_else()\n这两兄弟可以将  Option  类型转换为  Result  类型。其中  ok_or  接收一个默认的  Err  参数：\nfn main() {\n    const ERR_DEFAULT: &amp;str = &quot;error message&quot;;\n \n    let s = Some(&quot;abcde&quot;);\n    let n: Option&lt;&amp;str&gt; = None;\n \n    let o: Result&lt;&amp;str, &amp;str&gt; = Ok(&quot;abcde&quot;);\n    let e: Result&lt;&amp;str, &amp;str&gt; = Err(ERR_DEFAULT);\n \n    assert_eq!(s.ok_or(ERR_DEFAULT), o); // Some(T) -&gt; Ok(T)\n    assert_eq!(n.ok_or(ERR_DEFAULT), e); // None -&gt; Err(default)\n}\n而  ok_or_else  接收一个闭包作为  Err  参数：\nfn main() {\n    let s = Some(&quot;abcde&quot;);\n    let n: Option&lt;&amp;str&gt; = None;\n    let fn_err_message = || &quot;error message&quot;;\n \n    let o: Result&lt;&amp;str, &amp;str&gt; = Ok(&quot;abcde&quot;);\n    let e: Result&lt;&amp;str, &amp;str&gt; = Err(&quot;error message&quot;);\n \n    assert_eq!(s.ok_or_else(fn_err_message), o); // Some(T) -&gt; Ok(T)\n    assert_eq!(n.ok_or_else(fn_err_message), e); // None -&gt; Err(default)\n}\n以上列出的只是常用的一部分，强烈建议大家看看标准库中有哪些可用的 API，在实际项目中，这些 API 将会非常有用: Option  和  Result。\n自定义错误类型\n虽然标准库定义了大量的错误类型，但是一个严谨的项目，光使用这些错误类型往往是不够的，例如我们可能会为暴露给用户的错误定义相应的类型。\n为了帮助我们更好的定义错误，Rust 在标准库中提供了一些可复用的特征，例如  std::error::Error  特征：\nuse std::fmt::{Debug, Display};\n \npub trait Error: Debug + Display {\n    fn source(&amp;self) -&gt; Option&lt;&amp;(Error + &#039;static)&gt; { ... }\n}\n当自定义类型实现该特征后，该类型就可以作为  Err  来使用，下面一起来看看。\n\n实际上，自定义错误类型只需要实现  Debug  和  Display  特征即可，source  方法是可选的，而  Debug  特征往往也无需手动实现，可以直接通过  derive  来派生。\n\n最简单的错误\nuse std::fmt;\n \n// AppError 是自定义错误类型，它可以是当前包中定义的任何类型，在这里为了简化，我们使用了单元结构体作为例子。\n// 为 AppError 自动派生 Debug 特征\n#[derive(Debug)]\nstruct AppError;\n \n// 为 AppError 实现 std::fmt::Display 特征\nimpl fmt::Display for AppError {\n    fn fmt(&amp;self, f: &amp;mut fmt::Formatter) -&gt; fmt::Result {\n        write!(f, &quot;An Error Occurred, Please Try Again!&quot;) // user-facing output\n    }\n}\n \n// 一个示例函数用于产生 AppError 错误\nfn produce_error() -&gt; Result&lt;(), AppError&gt; {\n    Err(AppError)\n}\n \nfn main(){\n    match produce_error() {\n        Err(e) =&gt; eprintln!(&quot;{}&quot;, e),\n        _ =&gt; println!(&quot;No error&quot;),\n    }\n \n    eprintln!(&quot;{:?}&quot;, produce_error()); // Err({ file: src/main.rs, line: 17 })\n}\n上面的例子很简单，我们定义了一个错误类型，当为它派生了  Debug  特征，同时手动实现了  Display  特征后，该错误类型就可以作为  Err来使用了。\n事实上，实现  Debug  和  Display  特征并不是作为  Err  使用的必要条件，大家可以把这两个特征实现和相应使用去除，然后看看代码会否报错。既然如此，我们为何要为自定义类型实现这两个特征呢？原因有二:\n\n错误得打印输出后，才能有实际用处，而打印输出就需要实现这两个特征\n可以将自定义错误转换成  Box&lt;dyn std::error:Error&gt;  特征对象，在后面的归一化不同错误类型部分，我们会详细介绍\n\n更详尽的错误\n上一个例子中定义的错误非常简单，我们无法从错误中得到更多的信息，现在再来定义一个具有错误码和信息的错误：\nuse std::fmt;\n \nstruct AppError {\n    code: usize,\n    message: String,\n}\n \n// 根据错误码显示不同的错误信息\nimpl fmt::Display for AppError {\n    fn fmt(&amp;self, f: &amp;mut fmt::Formatter) -&gt; fmt::Result {\n        let err_msg = match self.code {\n            404 =&gt; &quot;Sorry, Can not find the Page!&quot;,\n            _ =&gt; &quot;Sorry, something is wrong! Please Try Again!&quot;,\n        };\n \n        write!(f, &quot;{}&quot;, err_msg)\n    }\n}\n \nimpl fmt::Debug for AppError {\n    fn fmt(&amp;self, f: &amp;mut fmt::Formatter) -&gt; fmt::Result {\n        write!(\n            f,\n            &quot;AppError {{ code: {}, message: {} }}&quot;,\n            self.code, self.message\n        )\n    }\n}\n \nfn produce_error() -&gt; Result&lt;(), AppError&gt; {\n    Err(AppError {\n        code: 404,\n        message: String::from(&quot;Page not found&quot;),\n    })\n}\n \nfn main() {\n    match produce_error() {\n        Err(e) =&gt; eprintln!(&quot;{}&quot;, e), // 抱歉，未找到指定的页面!\n        _ =&gt; println!(&quot;No error&quot;),\n    }\n \n    eprintln!(&quot;{:?}&quot;, produce_error()); // Err(AppError { code: 404, message: Page not found })\n \n    eprintln!(&quot;{:#?}&quot;, produce_error());\n    // Err(\n    //     AppError { code: 404, message: Page not found }\n    // )\n}\n在本例中，我们除了增加了错误码和消息外，还手动实现了  Debug  特征，原因在于，我们希望能自定义  Debug  的输出内容，而不是使用派生后系统提供的默认输出形式。\n错误转换  From  特征\n标准库、三方库、本地库，各有各的精彩，各也有各的错误。那么问题就来了，我们该如何将其它的错误类型转换成自定义的错误类型？总不能神鬼牛魔，同台共舞吧。。\n好在 Rust 为我们提供了  std::convert::From  特征：\npub trait From&lt;T&gt;: Sized {\n  fn from(_: T) -&gt; Self;\n}\n\n事实上，该特征在之前的  [[19-返回值与错误处理#传播界的大明星-|? 操作符]]章节中就有所介绍。\n大家都使用过  String::from  函数吧？它可以通过  &amp;str  来创建一个  String，其实该函数就是  From  特征提供的\n\n下面一起来看看如何为自定义类型实现  From  特征：\nuse std::fs::File;\nuse std::io;\n \n#[derive(Debug)]\nstruct AppError {\n    kind: String,    // 错误类型\n    message: String, // 错误信息\n}\n \n// 为 AppError 实现 std::convert::From 特征，由于 From 包含在 std::prelude 中，因此可以直接简化引入。\n// 实现 From&lt;io::Error&gt; 意味着我们可以将 io::Error 错误转换成自定义的 AppError 错误\nimpl From&lt;io::Error&gt; for AppError {\n    fn from(error: io::Error) -&gt; Self {\n        AppError {\n            kind: String::from(&quot;io&quot;),\n            message: error.to_string(),\n        }\n    }\n}\n \nfn main() -&gt; Result&lt;(), AppError&gt; {\n    let _file = File::open(&quot;nonexistent_file.txt&quot;)?;\n \n    Ok(())\n}\n \n// --------------- 上述代码运行后输出 ---------------\nError: AppError { kind: &quot;io&quot;, message: &quot;No such file or directory (os error 2)&quot; }\n上面的代码中除了实现  From  外，还有一点特别重要，那就是  ?  可以将错误进行隐式的强制转换：File::open  返回的是  std::io::Error， 我们并没有进行任何显式的转换，它就能自动变成  AppError ，这就是  ?  的强大之处！\n上面的例子只有一个标准库错误，再来看看多个不同的错误转换成  AppError  的实现：\nuse std::fs::File;\nuse std::io::{self, Read};\nuse std::num;\n \n#[derive(Debug)]\nstruct AppError {\n    kind: String,\n    message: String,\n}\n \nimpl From&lt;io::Error&gt; for AppError {\n    fn from(error: io::Error) -&gt; Self {\n        AppError {\n            kind: String::from(&quot;io&quot;),\n            message: error.to_string(),\n        }\n    }\n}\n \nimpl From&lt;num::ParseIntError&gt; for AppError {\n    fn from(error: num::ParseIntError) -&gt; Self {\n        AppError {\n            kind: String::from(&quot;parse&quot;),\n            message: error.to_string(),\n        }\n    }\n}\n \nfn main() -&gt; Result&lt;(), AppError&gt; {\n    let mut file = File::open(&quot;hello_world.txt&quot;)?;\n \n    let mut content = String::new();\n    file.read_to_string(&amp;mut content)?;\n \n    let _number: usize;\n    _number = content.parse()?;\n \n    Ok(())\n}\n \n \n// --------------- 上述代码运行后的可能输出 ---------------\n \n// 01. 若 hello_world.txt 文件不存在\nError: AppError { kind: &quot;io&quot;, message: &quot;No such file or directory (os error 2)&quot; }\n \n// 02. 若用户没有相关的权限访问 hello_world.txt\nError: AppError { kind: &quot;io&quot;, message: &quot;Permission denied (os error 13)&quot; }\n \n// 03. 若 hello_world.txt 包含有非数字的内容，例如 Hello, world!\nError: AppError { kind: &quot;parse&quot;, message: &quot;invalid digit found in string&quot; }\n归一化不同的错误类型\n至此，关于 Rust 的错误处理大家已经了若指掌了，下面再来看看一些实战中的问题。\n在实际项目中，我们往往会为不同的错误定义不同的类型，这样做非常好，但是如果你要在一个函数中返回不同的错误呢？例如：\nuse std::fs::read_to_string;\n \nfn main() -&gt; Result&lt;(), std::io::Error&gt; {\n  let html = render()?;\n  println!(&quot;{}&quot;, html);\n  Ok(())\n}\n \nfn render() -&gt; Result&lt;String, std::io::Error&gt; {\n  let file = std::env::var(&quot;MARKDOWN&quot;)?;\n  let source = read_to_string(file)?;\n  Ok(source)\n}\n上面的代码会报错，原因在于  render  函数中的两个  ?  返回的实际上是不同的错误：env::var()  返回的是  std::env::VarError，而  read_to_string  返回的是  std::io::Error。\n为了满足  render  函数的签名，我们就需要将  env::VarError  和  io::Error  归一化为同一种错误类型。要实现这个目的有三种方式:\n\n使用特征对象  Box&lt;dyn Error&gt;\n自定义错误类型\n使用  thiserror\n\n下面依次来看看相关的解决方式。\nBox&lt;dyn Error&gt;\n大家还记得我们之前提到的  std::error::Error  特征吧，当时有说：自定义类型实现  Debug + Display  特征的主要原因就是为了能转换成  Error  的特征对象，而特征对象恰恰是在同一个地方使用不同类型的关键：\nuse std::fs::read_to_string;\nuse std::error::Error;\n \nfn main() -&gt; Result&lt;(), Box&lt;dyn Error&gt;&gt; {\n  let html = render()?;\n  println!(&quot;{}&quot;, html);\n  Ok(())\n}\n \nfn render() -&gt; Result&lt;String, Box&lt;dyn Error&gt;&gt; {\n  let file = std::env::var(&quot;MARKDOWN&quot;)?;\n  let source = read_to_string(file)?;\n  Ok(source)\n}\n这个方法很简单，在绝大多数场景中，性能也非常够用，但是有一个问题：Result  实际上不会限制错误的类型，也就是一个类型就算不实现  Error  特征，它依然可以在  Result&lt;T, E&gt;  中作为  E  来使用，此时这种特征对象的解决方案就无能为力了。\n自定义错误类型\n与特征对象相比，自定义错误类型麻烦归麻烦，但是它非常灵活，因此也不具有上面的类似限制：\nuse std::fs::read_to_string;\n \nfn main() -&gt; Result&lt;(), MyError&gt; {\n  let html = render()?;\n  println!(&quot;{}&quot;, html);\n  Ok(())\n}\n \nfn render() -&gt; Result&lt;String, MyError&gt; {\n  let file = std::env::var(&quot;MARKDOWN&quot;)?;\n  let source = read_to_string(file)?;\n  Ok(source)\n}\n \n#[derive(Debug)]\nenum MyError {\n  EnvironmentVariableNotFound,\n  IOError(std::io::Error),\n}\n \nimpl From&lt;std::env::VarError&gt; for MyError {\n  fn from(_: std::env::VarError) -&gt; Self {\n    Self::EnvironmentVariableNotFound\n  }\n}\n \nimpl From&lt;std::io::Error&gt; for MyError {\n  fn from(value: std::io::Error) -&gt; Self {\n    Self::IOError(value)\n  }\n}\n \nimpl std::error::Error for MyError {}\n \nimpl std::fmt::Display for MyError {\n  fn fmt(&amp;self, f: &amp;mut std::fmt::Formatter&lt;&#039;_&gt;) -&gt; std::fmt::Result {\n    match self {\n      MyError::EnvironmentVariableNotFound =&gt; write!(f, &quot;Environment variable not found&quot;),\n      MyError::IOError(err) =&gt; write!(f, &quot;IO Error: {}&quot;, err.to_string()),\n    }\n  }\n}\n上面代码中有一行值得注意：impl std::error::Error for MyError {} ，只有为自定义错误类型实现  Error  特征后，才能转换成相应的特征对象。\n不得不说，真是啰嗦啊。因此在能用特征对象的时候，建议大家还是使用特征对象，无论如何，代码可读性还是很重要的！\n上面的第二种方式灵活归灵活，啰嗦也是真啰嗦，好在 Rust 的社区为我们提供了  thiserror  解决方案，下面一起来看看该如何简化 Rust 中的错误处理。\n简化错误处理\n对于开发者而言，错误处理是代码中打交道最多的部分之一，因此选择一把趁手的武器也很重要，它可以帮助我们节省大量的时间和精力，好钢应该用在代码逻辑而不是冗长的错误处理上。\nthiserror\nthiserror 可以帮助我们简化上面的第二种解决方案：\nuse std::fs::read_to_string;\n \nfn main() -&gt; Result&lt;(), MyError&gt; {\n  let html = render()?;\n  println!(&quot;{}&quot;, html);\n  Ok(())\n}\n \nfn render() -&gt; Result&lt;String, MyError&gt; {\n  let file = std::env::var(&quot;MARKDOWN&quot;)?;\n  let source = read_to_string(file)?;\n  Ok(source)\n}\n \n#[derive(thiserror::Error, Debug)]\nenum MyError {\n  #[error(&quot;Environment variable not found&quot;)]\n  EnvironmentVariableNotFound(#[from] std::env::VarError),\n  #[error(transparent)]\n  IOError(#[from] std::io::Error),\n}\n如上所示，只要简单写写注释，就可以实现错误处理了，惊不惊喜？\nerror-chain\nerror-chain  也是简单好用的库，可惜不再维护了，但是我觉得它依然可以在合适的地方大放光彩，值得大家去了解下。\nuse std::fs::read_to_string;\n \nerror_chain::error_chain! {\n  foreign_links {\n    EnvironmentVariableNotFound(::std::env::VarError);\n    IOError(::std::io::Error);\n  }\n}\n \nfn main() -&gt; Result&lt;()&gt; {\n  let html = render()?;\n  println!(&quot;{}&quot;, html);\n  Ok(())\n}\n \nfn render() -&gt; Result&lt;String&gt; {\n  let file = std::env::var(&quot;MARKDOWN&quot;)?;\n  let source = read_to_string(file)?;\n  Ok(source)\n}\n喏，简单吧？使用  error-chain  的宏你可以获得：Error  结构体，错误类型  ErrorKind  枚举 以及一个自定义的  Result  类型。\nanyhow\nanyhow  和  thiserror  是同一个作者开发的，这里是作者关于  anyhow  和  thiserror  的原话：\n\n如果你想要设计自己的错误类型，同时给调用者提供具体的信息时，就使用  thiserror，例如当你在开发一个三方库代码时。如果你只想要简单，就使用  anyhow，例如在自己的应用服务中。\n\nuse std::fs::read_to_string;\n \nuse anyhow::Result;\n \nfn main() -&gt; Result&lt;()&gt; {\n    let html = render()?;\n    println!(&quot;{}&quot;, html);\n    Ok(())\n}\n \nfn render() -&gt; Result&lt;String&gt; {\n    let file = std::env::var(&quot;MARKDOWN&quot;)?;\n    let source = read_to_string(file)?;\n    Ok(source)\n}\n关于如何选用  thiserror  和  anyhow  只需要遵循一个原则即可：是否关注自定义错误消息，关注则使用  thiserror（常见业务代码），否则使用  anyhow（编写第三方库代码）。\n总结\nRust 一个为人津津乐道的点就是强大、易用的错误处理，对于新手来说，这个机制可能会有些复杂，但是一旦体会到了其中的好处，你将跟我一样沉醉其中不能自拔。\n"},"rust/rust-bible/advanced/09-Unsafe-Rust":{"title":"Unsafe Rust","links":["rust/rust-bible/advanced/05-循环引用与自引用","rust/rust-bible/advanced/07-全局变量","rust/rust-bible/advanced/06-多线程并发编程"],"tags":[],"content":"Unsafe Rust\n简介\n为何会有 unsafe\n几乎每个语言都有  unsafe  关键字，但 Rust 语言使用  unsafe  的原因可能与其它编程语言还有所不同。\n过强的编译器\n说来尴尬，unsafe  的存在主要是因为 Rust 的静态检查太强了，但是强就算了，它还很保守，这就会导致当编译器在分析代码时，一些正确代码会因为编译器无法分析出它的所有正确性，结果将这段代码拒绝，导致编译错误。\n这种保守的选择确实也没有错，毕竟安全就是要防微杜渐，但是对于使用者来说，就不是那么愉快的事了，特别是当配合 Rust 的所有权系统一起使用时，有个别问题是真的棘手和难以解决。\n举个例子，在之前的自引用章节中，我们就提到了相关的编译检查是很难绕过的，如果想要绕过，最常用的方法之一就是使用  unsafe 和 Pin。\n好在，当遇到这些情况时，我们可以使用  unsafe  来解决。此时，你需要替代编译器的部分职责对  unsafe  代码的正确性负责，例如在正常代码中不可能遇到的空指针解引用问题在  unsafe  中就可能会遇到，我们需要自己来处理好这些类似的问题。\n特定任务的需要\n至于  unsafe  存在的另一个原因就是：它必须要存在。原因是计算机底层的一些硬件就是不安全的，如果 Rust 只允许你做安全的操作，那一些任务就无法完成，换句话说，我们还怎么跟 C++ 干架？\nRust 的一个主要定位就是系统编程，众所周知，系统编程就是底层编程，往往需要直接跟操作系统打交道，甚至于去实现一个操作系统。而为了实现底层系统编程，unsafe  就是必不可少的。\n在了解了为何会有  unsafe  后，我们再来看看，除了这些必要性，unsafe  还能给我们带来哪些超能力。\nunsafe 的超能力\n使用  unsafe  非常简单，只需要将对应的代码块标记下即可:\nfn main() {\n  let mut num = 5;\n  let r1 = &amp;num as *const i32;\n  unsafe {\n    println!(&quot;r1 is: {}&quot;, *r1);\n  }\n}\n上面代码中, r1  是一个裸指针(raw pointer)，由于它具有破坏 Rust 内存安全的潜力，因此只能在  unsafe  代码块中使用，如果你去掉  unsafe {}，编译器会立刻报错。\n言归正传， unsafe  能赋予我们 5 种超能力，这些能力在安全的 Rust 代码中是无法获取的：\n\n解引用裸指针，就如上例所示\n调用一个  unsafe  或外部的函数\n访问或修改一个可变的静态变量\n实现一个  unsafe  特征\n访问  union  中的字段\n\n在本章中，我们将着重讲解裸指针和 FFI 的使用。\nunsafe 的安全保证\n曾经在  reddit  上有一个讨论还挺热闹的，是关于  unsafe  的命名是否合适，总之公有公理，婆有婆理，但有一点是不可否认的：虽然名称自带不安全，但是 Rust 依然提供了强大的安全支撑。\n首先，unsafe  并不能绕过 Rust 的借用检查，也不能关闭任何 Rust 的安全检查规则，例如当你在  unsafe  中使用引用时，该有的检查一样都不会少。\n因此  unsafe  能给大家提供的也仅仅是之前的 5 种超能力，在使用这 5 种能力时，编译器才不会进行内存安全方面的检查，最典型的就是使用裸指针(引用和裸指针有很大的区别)。\n谈虎色变？\n在网上充斥着这样的言论：千万不要使用 unsafe，因为它不安全，甚至有些库会以没有  unsafe  代码作为噱头来吸引用户。事实上，大可不必，如果按照这个标准，Rust 的标准库也将不复存在！\nRust 中的  unsafe  其实没有那么可怕，虽然听上去很不安全，但是实际上 Rust 依然提供了很多机制来帮我们提升了安全性，因此不必像对待 Go 语言的  unsafe  那样去畏惧于使用 Rust 中的  unsafe 。\n大致使用原则总结如下：没必要用时，就不要用，当有必要用时，就大胆用，但是尽量控制好边界，让  unsafe  的范围尽可能小。\n控制 unsafe 的使用边界\nunsafe  不安全，但是该用的时候就要用，在一些时候，它能帮助我们大幅降低代码实现的成本。\n而作为使用者，你的水平决定了  unsafe  到底有多不安全，因此你需要在  unsafe  中小心谨慎地去访问内存。\n即使做到小心谨慎，依然会有出错的可能性，但是  unsafe  语句块决定了：就算内存访问出错了，你也能立刻意识到，错误是在  unsafe  代码块中，而不花大量时间像无头苍蝇一样去寻找问题所在。\n正因为此，写代码时要尽量控制好  unsafe  的边界大小，越小的  unsafe  越会让我们在未来感谢自己当初的选择。\n除了控制边界大小，另一个很常用的方式就是在  unsafe  代码块外包裹一层  safe  的 API，例如一个函数声明为 safe 的，然后在其内部有一块儿是  unsafe  代码。\n\n忍不住抱怨一句，内存安全方面的 bug ，是真心难查！\n\n五种兵器\n解引用裸指针\n裸指针(raw pointer，又称原生指针) 在功能上跟引用类似，同时它也需要显式地注明可变性。但是又和引用有所不同，裸指针长这样: *const T  和  *mut T，它们分别代表了不可变和可变。\n大家在之前学过  *  操作符，知道它可以用于解引用，但是在裸指针  *const T  中，这里的  * 只是类型名称的一部分，并没有解引用的含义。\n至此，我们已经学过三种类似指针的概念：引用、智能指针和裸指针。与前两者不同，裸指针：\n\n可以绕过 Rust 的借用规则，可以同时拥有一个数据的可变、不可变指针，甚至还能拥有多个可变的指针\n并不能保证指向合法的内存\n可以是  null\n没有实现任何自动的回收 (drop)\n\n总之，裸指针跟 C 指针是非常像的，使用它需要以牺牲安全性为前提，但我们获得了更好的性能，也可以跟其它语言或硬件打交道。\n基于引用创建裸指针\n下面的代码基于值的引用同时创建了可变和不可变的裸指针：\nlet mut num = 5;\n \nlet r1 = &amp;num as *const i32;\nlet r2 = &amp;mut num as *mut i32;\nas  可以用于强制类型转换，在之前章节中有讲解。在这里，我们将引用  &amp;num / &amp;mut num  强转为相应的裸指针  *const i32 / *mut i32。\n细心的同学可能会发现，在这段代码中并没有  unsafe  的身影，原因在于：创建裸指针是安全的行为，而解引用裸指针才是不安全的行为 :\nfn main() {\n let mut num = 5;\n let r1 = &amp;num as *const i32;\n unsafe {\n     println!(&quot;r1 is: {}&quot;, *r1);\n }\n}\n基于内存地址创建裸指针\n在上面例子中，我们基于现有的引用来创建裸指针，这种行为是很安全的。但是接下来的方式就不安全了：\nlet address = 0x012345usize;\nlet r = address as *const i32;\n这里基于一个内存地址来创建裸指针，可以想像，这种行为是相当危险的。试图使用任意的内存地址往往是一种未定义的行为(undefined behavior)，因为该内存地址有可能存在值，也有可能没有，就算有值，也大概率不是你需要的值。\n同时编译器也有可能会优化这段代码，会造成没有任何内存访问发生，甚至程序还可能发生段错误(segmentation fault)。总之，你几乎没有好的理由像上面这样实现代码，虽然它是可行的。\n如果真的要使用内存地址，也是类似下面的用法，先取地址，再使用，而不是凭空捏造一个地址：\nuse std::{slice::from_raw_parts, str::from_utf8_unchecked};\n \n// 获取字符串的内存地址和长度\nfn get_memory_location() -&gt; (usize, usize) {\n  let string = &quot;Hello World!&quot;;\n  let pointer = string.as_ptr() as usize;\n  let length = string.len();\n  (pointer, length)\n}\n \n// 在指定的内存地址读取字符串\nfn get_str_at_location(pointer: usize, length: usize) -&gt; &amp;&#039;static str {\n  unsafe { from_utf8_unchecked(from_raw_parts(pointer as *const u8, length)) }\n}\n \nfn main() {\n  let (pointer, length) = get_memory_location();\n  let message = get_str_at_location(pointer, length);\n  println!(\n    &quot;The {} bytes at 0x{:X} stored: {}&quot;,\n    length, pointer, message\n  );\n  // 如果大家想知道为何处理裸指针需要 `unsafe`，可以试着反注释以下代码\n  // let message = get_str_at_location(1000, 10);\n}\n使用 * 解引用\nlet a = 1;\nlet b: *const i32 = &amp;a as *const i32;\nlet c: *const i32 = &amp;a;\nunsafe {\n    println!(&quot;{}&quot;, *c);\n}\n使用  *  可以对裸指针进行解引用，由于该指针的内存安全性并没有任何保证，因此我们需要使用  unsafe  来包裹解引用的逻辑(切记，unsafe  语句块的范围一定要尽可能的小，具体原因在上一章节有讲)。\n以上代码另一个值得注意的点就是：除了使用  as  来显式的转换，我们还使用了隐式的转换方式  let c: *const i32 = &amp;a;。在实际使用中，我们建议使用  as  来转换，因为这种显式的方式更有助于提醒用户：你在使用的指针是裸指针，需要小心。\n基于智能指针创建裸指针\n还有一种创建裸指针的方式，那就是基于智能指针来创建：\nlet a: Box&lt;i32&gt; = Box::new(10);\n// 需要先解引用a\nlet b: *const i32 = &amp;*a;\n// 使用 into_raw 来创建\nlet c: *const i32 = Box::into_raw(a);\n小结\n像之前代码演示的那样，使用裸指针可以让我们创建两个可变指针都指向同一个数据，如果使用安全的 Rust，你是无法做到这一点的，违背了借用规则，编译器会对我们进行无情的阻止。因此裸指针可以绕过借用规则，但是由此带来的数据竞争问题，就需要大家自己来处理了，总之，需要小心！\n既然这么危险，为何还要使用裸指针？除了之前提到的性能等原因，还有一个重要用途就是跟  C  语言的代码进行交互( FFI )，在讲解 FFI 之前，先来看看如何调用 unsafe 函数或方法。\n调用 unsafe 函数或方法\nunsafe  函数从外表上来看跟普通函数并无区别，唯一的区别就是它需要使用  unsafe fn  来进行定义。这种定义方式是为了告诉调用者：当调用此函数时，你需要注意它的相关需求，因为 Rust 无法担保调用者在使用该函数时能满足它所需的一切需求。\n强制调用者加上  unsafe  语句块，就可以让他清晰的认识到，正在调用一个不安全的函数，需要小心看看文档，看看函数有哪些特别的要求需要被满足。\nunsafe fn dangerous() {}\n \nfn main() {\n    dangerous();\n}\n如果试图像上面这样调用，编译器就会报错：\nerror[E0133]: call to unsafe function is unsafe and requires unsafe function or block\n --&gt; src/main.rs:3:5\n  |\n3 |     dangerous();\n  |     ^^^^^^^^^^^ call to unsafe function\n按照报错提示，加上  unsafe  语句块后，就能顺利执行了：\nunsafe {\n    dangerous();\n}\n道理很简单，但一定要牢记在心：使用 unsafe 声明的函数时，一定要看看相关的文档，确定自己没有遗漏什么。\n还有，unsafe  无需俄罗斯套娃，在  unsafe  函数体中使用  unsafe  语句块是多余的行为。\n用安全抽象包裹 unsafe 代码\n一个函数包含了  unsafe  代码不代表我们需要将整个函数都定义为  unsafe fn。事实上，在标准库中有大量的安全函数，它们内部都包含了  unsafe  代码块，下面我们一起来看看一个很好用的标准库函数：split_at_mut。\n大家可以想象一下这个场景：需要将一个数组分成两个切片，且每一个切片都要求是可变的。类似需求在安全 Rust 中是很难实现的，因为要对同一个数组做两个可变借用：\nfn split_at_mut(slice: &amp;mut [i32], mid: usize) -&gt; (&amp;mut [i32], &amp;mut [i32]) {\n    let len = slice.len();\n \n    assert!(mid &lt;= len);\n \n    (&amp;mut slice[..mid], &amp;mut slice[mid..])\n}\n \nfn main() {\n    let mut v = vec![1, 2, 3, 4, 5, 6];\n \n    let r = &amp;mut v[..];\n \n    let (a, b) = split_at_mut(r, 3);\n \n    assert_eq!(a, &amp;mut [1, 2, 3]);\n    assert_eq!(b, &amp;mut [4, 5, 6]);\n}\n上面代码一眼看过去就知道会报错，因为我们试图在自定义的  split_at_mut  函数中，可变借用  slice  两次：\nerror[E0499]: cannot borrow `*slice` as mutable more than once at a time\n --&gt; src/main.rs:6:30\n  |\n1 | fn split_at_mut(slice: &amp;mut [i32], mid: usize) -&gt; (&amp;mut [i32], &amp;mut [i32]) {\n  |                        - let&#039;s call the lifetime of this reference `&#039;1`\n...\n6 |     (&amp;mut slice[..mid], &amp;mut slice[mid..])\n  |     -------------------------^^^^^--------\n  |     |     |                  |\n  |     |     |                  second mutable borrow occurs here\n  |     |     first mutable borrow occurs here\n  |     returning this value requires that `*slice` is borrowed for `&#039;1`\n对于 Rust 的借用检查器来说，它无法理解我们是分别借用了同一个切片的两个不同部分，但事实上，这种行为是没任何问题的，毕竟两个借用没有任何重叠之处。总之，不太聪明的 Rust 编译器阻碍了我们用这种简单且安全的方式去实现，那只能剑走偏锋，试试  unsafe  了。\nuse std::slice;\n \nfn split_at_mut(slice: &amp;mut [i32], mid: usize) -&gt; (&amp;mut [i32], &amp;mut [i32]) {\n    let len = slice.len();\n    let ptr = slice.as_mut_ptr();\n \n    assert!(mid &lt;= len);\n \n    unsafe {\n        (\n            slice::from_raw_parts_mut(ptr, mid),\n            slice::from_raw_parts_mut(ptr.add(mid), len - mid),\n        )\n    }\n}\n \nfn main() {\n    let mut v = vec![1, 2, 3, 4, 5, 6];\n \n    let r = &amp;mut v[..];\n \n    let (a, b) = split_at_mut(r, 3);\n \n    assert_eq!(a, &amp;mut [1, 2, 3]);\n    assert_eq!(b, &amp;mut [4, 5, 6]);\n}\n相比安全实现，这段代码就显得没那么好理解了，甚至于我们还需要像 C 语言那样，通过指针地址的偏移去控制数组的分割。\n\nas_mut_ptr  会返回指向  slice  首地址的裸指针  *mut i32\nslice::from_raw_parts_mut  函数通过指针和长度来创建一个新的切片，简单来说，该切片的初始地址是  ptr，长度为  mid\nptr.add(mid)  可以获取第二个切片的初始地址，由于切片中的元素是  i32  类型，每个元素都占用了 4 个字节的内存大小，因此我们不能简单的用  ptr + mid  来作为初始地址，而应该使用  ptr + 4 * mid，但是这种使用方式并不安全，因此  .add  方法是最佳选择\n\n由于  slice::from_raw_parts_mut  使用裸指针作为参数，因此它是一个  unsafe fn，我们在使用它时，就必须用  unsafe  语句块进行包裹，类似的，.add  方法也是如此(还是那句话，不要将无关的代码包含在  unsafe  语句块中)。\n部分同学可能会有疑问，那这段代码我们怎么保证  unsafe  中使用的裸指针  ptr  和  ptr.add(mid)  是合法的呢？秘诀就在于  assert!(mid &lt;= len); ，通过这个断言，我们保证了裸指针一定指向了  slice  切片中的某个元素，而不是一个莫名其妙的内存地址。\n再回到我们的主题：虽然 split_at_mut 使用了  unsafe，但我们无需将其声明为  unsafe fn，这种情况下就是使用安全的抽象包裹  unsafe  代码，这里的  unsafe  使用是非常安全的，因为我们从合法数据中创建了的合法指针。\n与之对比，下面的代码就非常危险了：\nuse std::slice;\n \nlet address = 0x01234usize;\nlet r = address as *mut i32;\n \nlet slice: &amp;[i32] = unsafe { slice::from_raw_parts_mut(r, 10000) };\nprintln!(&quot;{:?}&quot;,slice);\n这段代码从一个任意的内存地址，创建了一个 10000 长度的  i32  切片，我们无法保证切片中的元素都是合法的  i32  值，这种访问就是一种未定义行为(UB = undefined behavior)。\nzsh: segmentation fault\n不出所料，运行后看到了一个段错误。\nFFI\nFFI（Foreign Function Interface）可以用来与其它语言进行交互，但是并不是所有语言都这么称呼，例如 Java 称之为  JNI（Java Native Interface）。\nFFI  之所以存在是由于现实中很多代码库都是由不同语言编写的，如果我们需要使用某个库，但是它是由其它语言编写的，那么往往只有两个选择：\n\n对该库进行重写或者移植\n使用  FFI\n\n前者相当不错，但是在很多时候，并没有那么多时间去重写，因此  FFI  就成了最佳选择。回到 Rust 语言上，由于这门语言依然很年轻，一些生态是缺失的，我们在写一些不是那么大众的项目时，可能会同时遇到没有相应的 Rust 库可用的尴尬境况，此时通过  FFI  去调用 C 语言的库就成了相当棒的选择。\n还有在将 C/C++ 的代码重构为 Rust 时，先将相关代码引入到 Rust 项目中，然后逐步重构，也是不错的(为什么用不错来形容？因为重构一个有一定规模的 C/C++ 项目远没有想象中美好，因此最好的选择还是对于新项目使用 Rust 实现，老项目。。就让它先运行着吧)。\n当然，除了  FFI  还有一个办法可以解决跨语言调用的问题，那就是将其作为一个独立的服务，然后使用网络调用的方式去访问，HTTP，gRPC 都可以。\n言归正传，之前我们提到  unsafe  的另一个重要目的就是对  FFI  提供支持，它的全称是  Foreign Function Interface，顾名思义，通过  FFI , 我们的 Rust 代码可以跟其它语言的外部代码进行交互。\n下面的例子演示了如何调用 C 标准库中的  abs  函数：\nextern &quot;C&quot; {\n    fn abs(input: i32) -&gt; i32;\n}\n \nfn main() {\n    unsafe {\n        println!(&quot;Absolute value of -3 according to C: {}&quot;, abs(-3));\n    }\n}\nC 语言的代码定义在了  extern  代码块中， 而  extern  必须使用  unsafe  才能进行进行调用，原因在于其它语言的代码并不会强制执行 Rust 的规则，因此 Rust 无法对这些代码进行检查，最终还是要靠开发者自己来保证代码的正确性和程序的安全性。\nABI\n在  extern &quot;C&quot;  代码块中，我们列出了想要调用的外部函数的签名。其中  &quot;C&quot;  定义了外部函数所使用的应用二进制接口ABI (Application Binary Interface)：ABI  定义了如何在汇编层面来调用该函数。在所有  ABI  中，C 语言的是最常见的。\n在其它语言中调用 Rust 函数\n在 Rust 中调用其它语言的函数是让 Rust 利用其他语言的生态，那反过来可以吗？其他语言可以利用 Rust 的生态不？答案是肯定的。\n我们可以使用  extern  来创建一个接口，其它语言可以通过该接口来调用相关的 Rust 函数。但是此处的语法与之前有所不同，之前用的是语句块，而这里是在函数定义时加上  extern  关键字，当然，别忘了指定相应的  ABI：\n#[no_mangle]\npub extern &quot;C&quot; fn call_from_c() {\n    println!(&quot;Just called a Rust function from C!&quot;);\n}\n上面的代码可以让  call_from_c  函数被  C  语言的代码调用，当然，前提是将其编译成一个共享库，然后链接到 C 语言中。\n这里还有一个比较奇怪的注解  #[no_mangle]，它用于告诉 Rust 编译器：不要乱改函数的名称。 Mangling  的定义是：当 Rust 因为编译需要去修改函数的名称，例如为了让名称包含更多的信息，这样其它的编译部分就能从该名称获取相应的信息，这种修改会导致函数名变得相当不可读。\n因此，为了让 Rust 函数能顺利被其它语言调用，我们必须要禁止掉该功能。\n访问或修改一个可变的静态变量\n这部分我们在之前的全局变量章节中有过详细介绍，这里就不再赘述，大家可以前往此章节阅读。\n实现 unsafe 特征\n说实话，unsafe  的特征确实不多见，如果大家还记得的话，我们在之前的Send 和 Sync  章节中实现过  unsafe  特征  Send。\n之所以会有  unsafe  的特征，是因为该特征至少有一个方法包含有编译器无法验证的内容。unsafe  特征的声明很简单：\nunsafe trait Foo {\n    // 方法列表\n}\n \nunsafe impl Foo for i32 {\n    // 实现相应的方法\n}\n \nfn main() {}\n通过  unsafe impl  的使用，我们告诉编译器：相应的正确性由我们自己来保证。\n再回到刚提到的  Send  特征，若我们的类型中的所有字段都实现了  Send  特征，那该类型也会自动实现  Send。但是如果我们想要为某个类型手动实现  Send ，例如为裸指针，那么就必须使用  unsafe，相关的代码在之前的链接中也有，大家可以移步查看。\n总之，Send  特征标记为  unsafe  是因为 Rust 无法验证我们的类型是否能在线程间安全的传递，因此就需要通过  unsafe  来告诉编译器，它无需操心，剩下的交给我们自己来处理。\n访问 union 中的字段\n截止目前，我们还没有介绍过  union ，原因很简单，它主要用于跟  C  代码进行交互。\n访问  union  的字段是不安全的，因为 Rust 无法保证当前存储在  union  实例中的数据类型。\n#[repr(C)]\nunion MyUnion {\n    f1: u32,\n    f2: f32,\n}\n上从可以看出，union  的使用方式跟结构体确实很相似，但是前者的所有字段都共享同一个存储空间，意味着往  union  的某个字段写入值，会导致其它字段的值会被覆盖。\n关于  union  的更多信息，可以在这里查看。\n一些实用工具(库)\n由于  unsafe  和  FFI  在 Rust 的使用场景中是相当常见的(例如相对于 Go 的  unsafe  来说)，因此社区已经开发出了相当一部分实用的工具，可以改善相应的开发体验。\nrust-bindgen 和 cbindgen\n对于  FFI  调用来说，保证接口的正确性是非常重要的，这两个库可以帮我们自动生成相应的接口，其中  rust-bindgen  用于在 Rust 中访问 C 代码，而  cbindgen则反之。\n下面以  rust-bindgen  为例，来看看如何自动生成调用 C 的代码，首先下面是 C 代码：\ntypedef struct Doggo {\n    int many;\n    char wow;\n} Doggo;\n \nvoid eleven_out_of_ten_majestic_af(Doggo* pupper);\n下面是自动生成的可以调用上面代码的 Rust 代码：\n/* automatically generated by rust-bindgen 0.99.9 */\n \n#[repr(C)]\npub struct Doggo {\n    pub many: ::std::os::raw::c_int,\n    pub wow: ::std::os::raw::c_char,\n}\n \nextern &quot;C&quot; {\n    pub fn eleven_out_of_ten_majestic_af(pupper: *mut Doggo);\n}\ncxx\n如果需要跟 C++ 代码交互，非常推荐使用  cxx，它提供了双向的调用，最大的优点就是安全：是的，你无需通过  unsafe  来使用它！\nMiri\nmiri  可以生成 Rust 的中间层表示 MIR，对于编译器来说，我们的 Rust 代码首先会被编译为 MIR ，然后再提交给 LLVM 进行处理。\n可以通过  rustup component add miri  来安装它，并通过  cargo miri  来使用，同时还可以使用  cargo miri test  来运行测试代码。\nmiri  可以帮助我们检查常见的未定义行为(UB = Undefined Behavior)，以下列出了一部分:\n\n内存越界检查和内存释放后再使用(use-after-free)\n使用未初始化的数据\n数据竞争\n内存对齐问题\n\n但是需要注意的是，它只能帮助识别被执行代码路径的风险，那些未被执行到的代码是没办法被识别的。\nClippy\n官方的  clippy  检查器提供了有限的  unsafe  支持，虽然不多，但是至少有一定帮助。例如  missing_safety_docs  检查可以帮助我们检查哪些  unsafe  函数遗漏了文档。\n需要注意的是： Rust 编译器并不会默认开启所有检查，大家可以调用  rustc -W help  来看看最新的信息。\nPrusti\nprusti  需要大家自己来构建一个证明，然后通过它证明代码中的不变量是正确被使用的，当你在安全代码中使用不安全的不变量时，就会非常有用。具体的使用文档见这里。\n模糊测试(fuzz testing)\n在  Rust Fuzz Book  中列出了一些 Rust 可以使用的模糊测试方法。\n同时，我们还可以使用  rutenspitz  这个过程宏来测试有状态的代码，例如数据结构。\n总结\n至此，unsafe  的五种兵器已介绍完毕，大家是否意犹未尽？我想说的是，就算意犹未尽，也没有其它兵器了。\n就像上一章中所提到的，unsafe  只应该用于这五种场景，其它场景，你应该坚决的使用安全的代码，否则就会像  actix-web  的前作者一样，被很多人议论，甚至被喷。。。\n总之，能不使用  unsafe  一定不要使用，就算使用也要控制好边界，让范围尽可能的小，就像本章的例子一样，只有真的需要  unsafe  的代码，才应该包含其中, 而不是将无关代码也纳入进来。\n进一步学习\n\nUnsafe Rust: How and when (not) to use it\n\n内联汇编\n\n本章内容对于学习 Rust 不是必须的，而且难度很高，大家简单知道有这回事就好，不必非要学会 :D\n\nRust 提供了  asm!  宏，可以让大家在 Rust 代码中嵌入汇编代码，对于一些极致高性能或者底层的场景还是非常有用的，例如操作系统内核开发。但通常来说，大家并不应该在自己的项目中使用到该项技术，它为极客而生！\n本章的例子是基于  x86/x86-64  汇编的，但是其它架构也是支持的，目前支持的包括：\n\nx86 和 x86-64\nARM\nAArch64\nRISC-V\n\n当使用在不支持的平台上时，编译器会给出报错。\n基本用法\n先从一个简单例子开始：\nuse std::arch::asm;\n \nunsafe {\n    asm!(&quot;nop&quot;);\n}\n注意  unsafe  语句块依然是必不可少的，因为可能在里面插入危险的指令，最终破坏代码的安全性。\n上面代码将插入一个  NOP  指令( 空操作 ) 到编译器生成的汇编代码中，其中指令作为  asm!  的第一个参数传入。\n输入和输出\n上面的代码有够无聊的，来点实际的:\nuse std::arch::asm;\n \nlet x: u64; unsafe {\n asm!(&quot;mov {}, 5&quot;, out(reg) x);\n}\nassert_eq!(x, 5);\n这段代码将  5  赋给  u64  类型的变量  x，值得注意的是  asm!  的指令参数实际上是一个格式化字符串。至于传给格式化字符串的参数，看起来还是比较陌生的：\n\n首先，需要说明目标变量是作为内联汇编的输入还是输出，在本例中，是一个输出  out\n最后，要指定变量将要使用的寄存器，本例中使用通用寄存器  reg，编译器会自动选择合适的寄存器\n\nuse std::arch::asm;\n \nlet i: u64 = 3;\nlet o: u64;\nunsafe {\n    asm!(\n        &quot;mov {0}, {1}&quot;,\n        &quot;add {0}, 5&quot;,\n        out(reg) o,\n        in(reg) i,\n    );\n}\nassert_eq!(o, 8);\n \n上面的代码中进一步使用了输入  in，将  5  加到输入的变量  i  上，然后将结果写到输出变量  o。实际的操作方式是首先将  i  的值拷贝到输出，然后再加上  5。\n上例还能看出几点：\n\nasm!  允许使用多个格式化字符串，每一个作为单独一行汇编代码存在，看起来跟阅读真实的汇编代码类似\n输入变量通过  in  来声明\n和以前见过的格式化字符串一样，可以使用多个参数，通过 {0}, {1} 来指定，这种方式特别有用，毕竟在代码中，变量是经常复用的，而这种参数的指定方式刚好可以复用\n\n事实上，还可以进一步优化代码，去掉  mov  指令:\nuse std::arch::asm;\n \nlet mut x: u64 = 3;\nunsafe {\n    asm!(&quot;add {0}, 5&quot;, inout(reg) x);\n}\nassert_eq!(x, 8);\n \n又多出一个  inout  关键字，但是不难猜，它说明  x  即是输入又是输出。与之前的分离方式还有一点很大的区别，这种方式可以保证使用同一个寄存器来完成任务。\n当然，你可以在使用  inout  的情况下，指定不同的输入和输出:\nuse std::arch::asm;\n \nlet x: u64 = 3;\nlet y: u64;\nunsafe {\n    asm!(&quot;add {0}, 5&quot;, inout(reg) x =&gt; y);\n}\nassert_eq!(y, 8);\n \n延迟输出操作数\nRust 编译器对于操作数分配是较为保守的，它会假设  out  可以在任何时间被写入，因此  out  不会跟其它参数共享它的位置。然而为了保证最佳性能，使用尽量少的寄存器是有必要的，这样它们不必在内联汇编的代码块内保存和重加载。\n为了达成这个目标( 共享位置或者说寄存器，以实现减少寄存器使用的性能优化 )，Rust 提供一个  lateout  关键字，可以用于任何只在所有输入被消费后才被写入的输出，与之类似的还有一个  inlateout。\n但是  inlateout  在某些场景中是无法使用的，例如下面的例子：\nuse std::arch::asm;\n \nlet mut a: u64 = 4;\nlet b: u64 = 4;\nlet c: u64 = 4;\nunsafe {\n    asm!(\n        &quot;add {0}, {1}&quot;,\n        &quot;add {0}, {2}&quot;,\n        inout(reg) a,\n        in(reg) b,\n        in(reg) c,\n    );\n}\nassert_eq!(a, 12);\n \n一旦用了  inlateout  后，上面的代码就只能运行在  Debug  模式下，原因是  Debug  并没有做任何优化，但是  release  发布不同，为了性能是要做很多编译优化的。\n在编译优化时，编译器可以很容易的为输入  b  和  c  分配同样的是寄存器，因为它知道它们有同样的值。如果这里使用  inlateout， 那么  a  和  c  就可以被分配到相同的寄存器，在这种情况下，第一条指令将覆盖掉  c  的值，最终导致汇编代码产生错误的结果。\n因此这里使用  inout，那么编译器就会为  a  分配一个独立的寄存器.\n但是下面的代码又不同，它是可以使用  inlateout  的：\nuse std::arch::asm;\n \nlet mut a: u64 = 4;\nlet b: u64 = 4;\nunsafe {\n    asm!(&quot;add {0}, {1}&quot;, inlateout(reg) a, in(reg) b);\n}\nassert_eq!(a, 8);\n \n原因在于输出只有在所有寄存器都被读取后，才被修改。因此，即使  a  和  b  被分配了同样的寄存器，代码也会正常工作，不存在之前的覆盖问题。\n显式指定寄存器\n一些指令会要求操作数只能存在特定的寄存器中，因此 Rust 的内联汇编提供了一些限制操作符。\n大家应该记得之前出现过的  reg  是适用于任何架构的通用寄存器，意味着编译器可以自己选择合适的寄存器，但是当你需要显式地指定寄存器时，很可能会变成平台相关的代码，适用移植性会差很多。例如  x86  下的寄存器：eax, ebx, ecx, ebp, esi  等等。\nuse std::arch::asm;\n \nlet cmd = 0xd1;\nunsafe {\n    asm!(&quot;out 0x64, eax&quot;, in(&quot;eax&quot;) cmd);\n}\n上面的例子调用  out  指令将  cmd  变量的值输出到  0x64  内存地址中。由于  out  指令只接收  eax  和它的子寄存器，因此我们需要使用  eax  来指定特定的寄存器。\n\n显式寄存器操作数无法用于格式化字符串中，例如我们之前使用的 {}，只能直接在字符串中使用  eax。同时，该操作数只能出现在最后，也就是在其它操作数后面出现\n\nuse std::arch::asm;\n \nfn mul(a: u64, b: u64) -&gt; u128 {\n    let lo: u64;\n    let hi: u64;\n \n    unsafe {\n        asm!(\n            // The x86 mul instruction takes rax as an implicit input and writes\n            // the 128-bit result of the multiplication to rax:rdx.\n            &quot;mul {}&quot;,\n            in(reg) a,\n            inlateout(&quot;rax&quot;) b =&gt; lo,\n            lateout(&quot;rdx&quot;) hi\n        );\n    }\n \n    ((hi as u128) &lt;&lt; 64) + lo as u128\n}\n这段代码使用了  mul  指令，将两个 64 位的输入相乘，生成一个 128 位的结果。\n首先将变量  a  的值存到寄存器  reg  中，其次显式使用寄存器  rax，它的值来源于变量  b。结果的低 64 位存储在  rax  中，然后赋给变量  lo ，而结果的高 64 位则存在  rdx  中，最后赋给  hi。\nClobbered 寄存器\n在很多情况下，无需作为输出的状态都会被内联汇编修改，这个状态被称之为 “clobbered”。\n我们需要告诉编译器相关的情况，因为编译器需要在内联汇编语句块的附近存储和恢复这种状态。\nuse std::arch::asm;\n \nfn main() {\n    // three entries of four bytes each\n    let mut name_buf = [0_u8; 12];\n    // String is stored as ascii in ebx, edx, ecx in order\n    // Because ebx is reserved, the asm needs to preserve the value of it.\n    // So we push and pop it around the main asm.\n    // (in 64 bit mode for 64 bit processors, 32 bit processors would use ebx)\n \n    unsafe {\n        asm!(\n            &quot;push rbx&quot;,\n            &quot;cpuid&quot;,\n            &quot;mov [rdi], ebx&quot;,\n            &quot;mov [rdi + 4], edx&quot;,\n            &quot;mov [rdi + 8], ecx&quot;,\n            &quot;pop rbx&quot;,\n            // We use a pointer to an array for storing the values to simplify\n            // the Rust code at the cost of a couple more asm instructions\n            // This is more explicit with how the asm works however, as opposed\n            // to explicit register outputs such as `out(&quot;ecx&quot;) val`\n            // The *pointer itself* is only an input even though it&#039;s written behind\n            in(&quot;rdi&quot;) name_buf.as_mut_ptr(),\n            // select cpuid 0, also specify eax as clobbered\n            inout(&quot;eax&quot;) 0 =&gt; _,\n            // cpuid clobbers these registers too\n            out(&quot;ecx&quot;) _,\n            out(&quot;edx&quot;) _,\n        );\n    }\n \n    let name = core::str::from_utf8(&amp;name_buf).unwrap();\n    println!(&quot;CPU Manufacturer ID: {}&quot;, name);\n}\n例子中，我们使用  cpuid  指令来读取 CPU ID，该指令会将值写入到  eax 、edx  和  ecx  中。\n即使  eax  从没有被读取，我们依然需要告知编译器这个寄存器被修改过，这样编译器就可以在汇编代码之前存储寄存器中的值。这个需要通过将输出声明为  _  而不是一个具体的变量名，代表着该输出值被丢弃。\n这段代码也会绕过一个限制： ebx  是一个 LLVM 保留寄存器，意味着 LLVM 会假设它拥有寄存器的全部控制权，并在汇编代码块结束时将寄存器的状态恢复到最开始的状态。由于这个限制，该寄存器无法被用于输入或者输出，除非编译器使用该寄存器的满足一个通用寄存器的需求(例如  in(reg) )。 但这样使用后， reg  操作数就在使用保留寄存器时变得危险起来，原因是我们可能会无意识的破坏输入或者输出，毕竟它们共享同一个寄存器。\n为了解决这个问题，我们使用  rdi  来存储指向输出数组的指针，通过  push  的方式存储  ebx：在汇编代码块的内部读取  ebx  的值，然后写入到输出数组。后面再可以通过  pop  的方式来回复  ebx  到初始的状态。\npush  和  pop  使用完成的 64 位  rbx  寄存器，来确保整个寄存器的内容都被保存。如果是在 32 位机器上，代码将使用  ebx  替代。\n还还可以在汇编代码内部使用通用寄存器:\nuse std::arch::asm;\n \n// Multiply x by 6 using shifts and adds\nlet mut x: u64 = 4;\nunsafe {\n    asm!(\n        &quot;mov {tmp}, {x}&quot;,\n        &quot;shl {tmp}, 1&quot;,\n        &quot;shl {x}, 2&quot;,\n        &quot;add {x}, {tmp}&quot;,\n        x = inout(reg) x,\n        tmp = out(reg) _,\n    );\n}\nassert_eq!(x, 4 * 6);\n \n总结\n由于这块儿内容过于专业，本书毕竟是通用的 Rust 学习书籍，因此关于内联汇编就不再赘述。事实上，如果你要真的写出可用的汇编代码，要学习的还很多…\n感兴趣的同学可以看看如下英文资料: Rust Reference  和  Rust By Example。\n"},"rust/rust-bible/advanced/10-Macro-宏编程":{"title":"Macro 宏编程","links":["rust/rust-bible/basic/17-集合类型","rust/rust-bible/basic/13-模式匹配","rust/rust-bible/basic/16-特征","rust/rust-bible/basic/20-包与模块","tags/TODO"],"tags":["TODO"],"content":"Macro 宏编程\n事实上，我们虽然没有见过宏，但是已经多次用过它，例如在全书的第一个例子中就用到了：println!(&quot;你好，世界&quot;)，这里  println!  就是一个最常用的宏，可以看到它和函数最大的区别是：它在调用时多了一个  !，除此之外还有  vec! 、assert_eq!  都是相当常用的，可以说宏在 Rust 中无处不在。\n细心的读者可能会注意到  println!  后面跟着的是  ()，而  vec!  后面跟着的是  []，这是因为宏的参数可以使用  ()、[]  以及  {}：\nfn main() {\n    println!(&quot;aaaa&quot;);\n    println![&quot;aaaa&quot;];\n    println!{&quot;aaaa&quot;}\n}\n虽然三种使用形式皆可，但是 Rust 内置的宏都有自己约定俗成的使用方式，例如  vec![...]、assert_eq!(...)  等。\n在 Rust 中宏分为两大类：声明式宏( declarative macros ) macro_rules!  和三种过程宏( procedural macros )：\n\n#[derive]，在之前多次见到的派生宏，可以为目标结构体或枚举派生指定的代码，例如  Debug  特征；\n类属性宏(Attribute-like macro)，用于为目标添加自定义的属性；\n类函数宏(Function-like macro)，看上去就像是函数调用；\n\n如果感觉难以理解，也不必担心，接下来我们将逐个看看它们的庐山真面目，在此之前，先来看下为何需要宏，特别是 Rust 的函数明明已经很强大了。\n宏和函数的区别\n宏和函数的区别并不少，而且对于宏擅长的领域，函数其实是有些无能为力的。\n元编程\n从根本上来说，宏是通过一种代码来生成另一种代码，如果大家熟悉元编程，就会发现两者的共同点。\n如  derive  属性，就会自动为结构体派生出相应特征所需的代码，例如  #[derive(Debug)]，还有熟悉的  println!  和  vec!，所有的这些宏都会展开成相应的代码，且很可能是长得多的代码。\n总之，元编程可以帮我们减少所需编写的代码，也可以一定程度上减少维护的成本，虽然函数复用也有类似的作用，但是宏依然拥有自己独特的优势。\n可变参数\nRust 的函数签名是固定的：定义了两个参数，就必须传入两个参数，多一个少一个都不行，对于从 JS/TS 过来的同学，这一点其实是有些恼人的。\n而宏就可以拥有可变数量的参数，例如可以调用一个参数的  println!(&quot;hello&quot;)，也可以调用两个参数的  println!(&quot;hello {}&quot;, name)。\n宏展开\n由于宏会被展开成其它代码，且这个展开过程是发生在编译器对代码进行解释之前。因此，宏可以为指定的类型实现某个特征：先将宏展开成实现特征的代码后，再被编译。\n而函数就做不到这一点，因为它直到运行时才能被调用，而特征需要在编译期被实现。\n宏的缺点\n相对函数来说，由于宏是基于代码再展开成代码，因此实现相比函数来说会更加复杂，再加上宏的语法更为复杂，最终导致定义宏的代码相当地难读，也难以理解和维护。\n声明式宏 macro_rules!\n在 Rust 中使用最广的就是声明式宏，它们也有一些其它的称呼，例如示例宏( macros by example )、macro_rules!  或干脆直接称呼为宏。\n声明式宏允许我们写出类似  match  的代码。match  表达式是一个控制结构，其接收一个表达式，然后将表达式的结果与多个模式进行匹配，一旦匹配了某个模式，则该模式相关联的代码将被执行：\nmatch target {\n    模式1 =&gt; 表达式1,\n    模式2 =&gt; {\n        语句1;\n        语句2;\n        表达式2\n    },\n    _ =&gt; 表达式3\n}\n而宏也是将一个值跟对应的模式进行匹配，且该模式会与特定的代码相关联。但是与  match  不同的是，宏里的值是一段 Rust 源代码(字面量)，模式用于跟这段源代码的结构相比较，一旦匹配，传入宏的那段源代码将被模式关联的代码所替换，最终实现宏展开。值得注意的是，所有的这些都是在编译期发生，并没有运行期的性能损耗。\n简化版的 vec!\n在动态数组 中，我们学习了使用  vec!  来便捷的初始化一个动态数组：\nlet v: Vec&lt;u32&gt; = vec![1, 2, 3];\n最重要的是，通过  vec!  创建的动态数组支持任何元素类型，也并没有限制数组的长度，如果使用函数，我们是无法做到这一点的。\n好在我们有  macro_rules!，来看看该如何使用它来实现  vec!，以下是一个简化实现：\n#[macro_export]\nmacro_rules! vec {\n    ( $( $x:expr ),* ) =&gt; {\n        {\n            let mut temp_vec = Vec::new();\n            $(\n                temp_vec.push($x);\n            )*\n            temp_vec\n        }\n    };\n}\n简化实现版本？这也太难了吧！！只能说，欢迎来到宏的世界，在这里你能见到优雅 Rust 的另一面:) 标准库中的  vec!  还包含了预分配内存空间的代码，如果引入进来，那大家将更难以接受。\n#[macro_export]  注释将宏进行了导出，这样其它的包就可以将该宏引入到当前作用域中，然后才能使用。可能有同学会提问：我们在使用标准库  vec!  时也没有引入宏啊，那是因为 Rust 已经通过  std::prelude的方式为我们自动引入了。\n紧接着，就使用  macro_rules!  进行了宏定义，需要注意的是宏的名称是  vec，而不是  vec!，后者的感叹号只在调用时才需要。\n由于  vec  宏只有一个模式，因此它只能匹配一种源代码，其它类型的都将导致报错，而更复杂的宏往往会拥有更多的分支。\n虽然宏和  match  都称之为模式，但是前者跟后者的模式规则是不同的。如果大家想要更深入的了解宏的模式，可以查看这里。\n模式解析\n而现在，我们先来简单讲解下  ( $( $x:expr ),* )  的含义。\n首先，我们使用圆括号  ()  将整个宏模式包裹其中。紧随其后的是  $()，跟括号中模式相匹配的值(传入的 Rust 源代码)会被捕获，然后用于代码替换。在这里，模式  $x:expr  会匹配任何 Rust 表达式并给予该模式一个名称：$x。\n$()  之后的逗号说明在  $()  所匹配的代码的后面会有一个可选的逗号分隔符，紧随逗号之后的  *  说明  *  之前的模式会被匹配零次或任意多次(类似正则表达式)。\n当我们使用  vec![1, 2, 3]  来调用该宏时，$x  模式将被匹配三次，分别是  1、2、3。为了帮助大家巩固，我们再来一起过一下：\n\n$()  中包含的是模式  $x:expr，该模式中的  expr  表示会匹配任何 Rust 表达式，并给予该模式一个名称  $x\n因此  $x  模式可以跟整数  1  进行匹配，也可以跟字符串 “hello” 进行匹配: vec![&quot;hello&quot;, &quot;world&quot;]\n$()  之后的逗号，意味着1  和  2  之间可以使用逗号进行分割，也意味着  3  既可以没有逗号，也可以有逗号：vec![1, 2, 3,]\n*  说明之前的模式可以出现零次也可以任意次，这里出现了三次\n\n接下来，我们再来看看与模式相关联、在  =&gt;  之后的代码：\n{\n    {\n        let mut temp_vec = Vec::new();\n        $(\n            temp_vec.push($x);\n        )*\n        temp_vec\n    }\n};\n这里就比较好理解了，$()  中的  temp_vec.push()  将根据模式匹配的次数生成对应的代码，当调用  vec![1, 2, 3]  时，下面这段生成的代码将替代传入的源代码，也就是替代  vec![1, 2, 3] ：\n{\n    let mut temp_vec = Vec::new();\n    temp_vec.push(1);\n    temp_vec.push(2);\n    temp_vec.push(3);\n    temp_vec\n}\n如果是  let v = vec![1, 2, 3]，那生成的代码最后返回的值  temp_vec  将被赋予给变量  v，等同于：\nlet v = {\n    let mut temp_vec = Vec::new();\n    temp_vec.push(1);\n    temp_vec.push(2);\n    temp_vec.push(3);\n    temp_vec\n}\n至此，我们定义了一个宏，它可以接受任意类型和数量的参数，并且理解了其语法的含义。\n未来将被替代的  macro_rules\n对于  macro_rules  来说，它是存在一些问题的，因此，Rust 计划在未来使用新的声明式宏来替换它：工作方式类似，但是解决了目前存在的一些问题，在那之后，macro_rules  将变为  deprecated  状态。\n由于绝大多数 Rust 开发者都是宏的用户而不是编写者，因此在这里我们不会对  macro_rules  进行更深入的学习，如果大家感兴趣，可以看看这本书  “The Little Book of Rust Macros”。\n用过程宏为属性标记生成代码\n第二种常用的宏就是过程宏 ( procedural macros )，从形式上来看，过程宏跟函数较为相像，但过程宏是使用源代码作为输入参数，基于代码进行一系列操作后，再输出一段全新的代码。注意，过程宏中的 derive 宏输出的代码并不会替换之前的代码，这一点与声明宏有很大的不同！\n至于前文提到的过程宏的三种类型(自定义  derive、属性宏、函数宏)，它们的工作方式都是类似的。\n当创建过程宏时，它的定义必须要放入一个独立的包中，且包的类型也是特殊的，这么做的原因相当复杂，大家只要知道这种限制在未来可能会有所改变即可。\n\n事实上，根据这个说法，过程宏放入独立包的原因在于它必须先被编译后才能使用，如果过程宏和使用它的代码在一个包，就必须先单独对过程宏的代码进行编译，然后再对我们的代码进行编译，但悲剧的是 Rust 的编译单元是包，因此你无法做到这一点。\n\n假设我们要创建一个  derive  类型的过程宏：\nuse proc_macro;\n \n#[proc_macro_derive(HelloMacro)]\npub fn some_name(input: TokenStream) -&gt; TokenStream {\n}\n用于定义过程宏的函数  some_name  使用  TokenStream  作为输入参数，并且返回的也是同一个类型。TokenStream  是在  proc_macro  包中定义的，顾名思义，它代表了一个  Token  序列。\n在理解了过程宏的基本定义后，我们再来看看该如何创建三种类型的过程宏，首先，从大家最熟悉的  derive  开始。\n自定义  derive  过程宏\n假设我们有一个特征  HelloMacro，现在有两种方式让用户使用它：\n\n为每个类型手动实现该特征，就像之前特征章节所做的\n使用过程宏来统一实现该特征，这样用户只需要对类型进行标记即可：#[derive(HelloMacro)]\n\n以上两种方式并没有孰优孰劣，主要在于不同的类型是否可以使用同样的默认特征实现，如果可以，那过程宏的方式可以帮我们减少很多代码实现：\nuse hello_macro::HelloMacro;\nuse hello_macro_derive::HelloMacro;\n \n#[derive(HelloMacro)]\nstruct Sunfei;\n \n#[derive(HelloMacro)]\nstruct Sunface;\n \nfn main() {\n    Sunfei::hello_macro();\n    Sunface::hello_macro();\n}\n简单吗？简单！不过为了实现这段代码展示的功能，我们还需要创建相应的过程宏才行。 首先，创建一个新的工程用于演示：\n$ cargo new hello_macro\n$ cd hello_macro/\n$ touch src/lib.rs\n此时，src  目录下包含两个文件  lib.rs  和  main.rs，前者是  lib  包根，后者是二进制包根，如果大家对包根不熟悉，可以看看这里。\n接下来，先在  src/lib.rs  中定义过程宏所需的  HelloMacro  特征和其关联函数：\npub trait HelloMacro {\n    fn hello_macro();\n}\n然后在  src/main.rs  中编写主体代码，首先映入大家脑海的可能会是如下实现：\nuse hello_macro::HelloMacro;\n \nstruct Sunfei;\n \nimpl HelloMacro for Sunfei {\n    fn hello_macro() {\n        println!(&quot;Hello, Macro! My name is Sunfei!&quot;);\n    }\n}\n \nstruct Sunface;\n \nimpl HelloMacro for Sunface {\n    fn hello_macro() {\n        println!(&quot;Hello, Macro! My name is Sunface!&quot;);\n    }\n}\n \nfn main() {\n    Sunfei::hello_macro();\n}\n但是这种方式有个问题，如果想要实现不同的招呼内容，就需要为每一个类型都实现一次相应的特征，Rust 不支持反射，因此我们无法在运行时获得类型名。\n使用宏，就不存在这个问题：\nuse hello_macro::HelloMacro;\nuse hello_macro_derive::HelloMacro;\n \n#[derive(HelloMacro)]\nstruct Sunfei;\n \n#[derive(HelloMacro)]\nstruct Sunface;\n \nfn main() {\n    Sunfei::hello_macro();\n    Sunface::hello_macro();\n}\n简单明了的代码总是令人愉快，为了让代码运行起来，还需要定义下过程宏。就如前文提到的，目前只能在单独的包中定义过程宏，尽管未来这种限制会被取消，但是现在我们还得遵循这个规则。\n宏所在的包名自然也有要求，必须以  derive  为后缀，对于  hello_macro  宏而言，包名就应该是  hello_macro_derive。在之前创建的  hello_macro  项目根目录下，运行如下命令，创建一个单独的  lib  包：\n$ cargo new hello_macro_derive --lib\n至此， hello_macro  项目的目录结构如下：\nhello_macro\n├── Cargo.toml\n├── src\n│   ├── main.rs\n│   └── lib.rs\n└── hello_macro_derive\n    ├── Cargo.toml\n    ├── src\n        └── lib.rs\n由于过程宏所在的包跟我们的项目紧密相连，因此将它放在项目之中。现在，问题又来了，该如何在项目的  src/main.rs  中引用  hello_macro_derive  包的内容？\n方法有两种，第一种是将  hello_macro_derive  发布到  crates.io  或  GitHub  中，就像我们引用的其它依赖一样；另一种就是使用相对路径引入的本地化方式，修改  hello_macro/Cargo.toml  文件添加以下内容：\n[dependencies]\nhello_macro_derive = { path = &quot;../hello_macro/hello_macro_derive&quot; }\n# 也可以使用下面的相对路径\n# hello_macro_derive = { path = &quot;./hello_macro_derive&quot; }\n此时，hello_macro  项目就可以成功的引用到  hello_macro_derive  本地包了，对于项目依赖引入的详细介绍，可以参见TODO Cargo 章节。\n另外，学习过程更好的办法是通过展开宏来阅读和调试自己写的宏，这里需要用到一个 cargo-expand 的工具，可以通过下面的命令安装：\n$ cargo install cargo-expand\n接下来，就到了重头戏环节，一起来看看该如何定义过程宏。\n定义过程宏\n首先，在  hello_macro_derive/Cargo.toml  文件中添加以下内容：\n[lib]\nproc-macro = true\n \n[dependencies]\nsyn = &quot;1.0&quot;\nquote = &quot;1.0&quot;\n其中  syn  和  quote  依赖包都是定义过程宏所必需的，同时，还需要在  [lib]  中将过程宏的开关开启 : proc-macro = true。\n其次，在  hello_macro_derive/src/lib.rs  中添加如下代码：\nextern crate proc_macro;\n \nuse proc_macro::TokenStream;\nuse quote::quote;\nuse syn;\nuse syn::DeriveInput;\n \n#[proc_macro_derive(HelloMacro)]\npub fn hello_macro_derive(input: TokenStream) -&gt; TokenStream {\n    // 基于 input 构建 AST 语法树\n    let ast:DeriveInput = syn::parse(input).unwrap();\n \n    // 构建特征实现代码\n    impl_hello_macro(&amp;ast)\n}\n这个函数的签名我们在之前已经介绍过，总之，这种形式的过程宏定义是相当通用的，下面来分析下这段代码。\n首先有一点，对于绝大多数过程宏而言，这段代码往往只在  impl_hello_macro(&amp;ast)  中的实现有所区别，对于其它部分基本都是一致的，如包的引入、宏函数的签名、语法树构建等。\nproc_macro  包是 Rust 自带的，因此无需在  Cargo.toml  中引入依赖，它包含了相关的编译器  API，可以用于读取和操作 Rust 源代码。\n由于我们为  hello_macro_derive  函数标记了  #[proc_macro_derive(HelloMacro)]，当用户使用  #[derive(HelloMacro)]  标记了他的类型后，hello_macro_derive  函数就将被调用。这里的秘诀就是特征名  HelloMacro，它就像一座桥梁，将用户的类型和过程宏联系在一起。\nsyn  将字符串形式的 Rust 代码解析为一个 AST 树的数据结构，该数据结构可以在随后的  impl_hello_macro  函数中进行操作。最后，操作的结果又会被  quote  包转换回 Rust 代码。这些包非常关键，可以帮我们节省大量的精力，否则你需要自己去编写支持代码解析和还原的解析器，这可不是一件简单的任务！\nderive 过程宏只能用在 struct/enum/union 上，多数用在结构体上，我们先来看一下一个结构体由哪些部分组成：\n// vis，可视范围             ident，标识符     generic，范型    fields: 结构体的字段\npub              struct    User            &lt;&#039;a, T&gt;          {\n \n// vis   ident   type\n   pub   name:   &amp;&#039;a T,\n \n}\n其中 type 还可以细分，具体请阅读syn文档或源码。\nsyn::parse  调用会返回一个  DeriveInput  结构体来代表解析后的 Rust 代码：\n DeriveInput {\n    // --snip--\n    vis: Visibility,\n    ident: Ident {\n        ident: &quot;Sunfei&quot;,\n        span: #0 bytes(95..103)\n    },\n    generics: Generics,\n    // Data是一个枚举，分别是DataStruct，DataEnum，DataUnion，这里以 DataStruct 为例\n    data: Data(\n        DataStruct {\n            struct_token: Struct,\n            fields: Fields,\n            semi_token: Some(\n                Semi\n            )\n        }\n    )\n}\n \n以上就是源代码  struct Sunfei;  解析后的结果，里面有几点值得注意:\n\nfields: Fields  是一个枚举类型，Fields::Named, Fields::Unnamed, Fields::Unit  分别表示结构体中的显式命名字段（如例子所示），元组或元组变体中的匿名字段(例如Some(T))，单元类型或单元变体字段（例如None ）。\nident: &quot;Sunfei&quot;  说明类型名称为  Sunfei， ident  是标识符  identifier  的简写\n\n如果想要了解更多的信息，可以查看  syn  文档。\n大家可能会注意到在  hello_macro_derive  函数中有  unwrap  的调用，也许会以为这是为了演示目的，没有做错误处理，实际上并不是的。由于该函数只能返回  TokenStream  而不是  Result，那么在报错时直接  panic  来抛出错误就成了相当好的选择。当然，这里实际上还是做了简化，在生产项目中，你应该通过  panic!  或  expect  抛出更具体的报错信息。\n至此，这个函数大家应该已经基本理解了，下面来看看如何构建特征实现的代码，也是过程宏的核心目标：\nfn impl_hello_macro(ast: &amp;syn::DeriveInput) -&gt; TokenStream {\n    let name = &amp;ast.ident;\n    let gen = quote! {\n        impl HelloMacro for #name {\n            fn hello_macro() {\n                println!(&quot;Hello, Macro! My name is {}!&quot;, stringify!(#name));\n            }\n        }\n    };\n    gen.into()\n}\n首先，将结构体的名称赋予给  name，也就是  name  中会包含一个字段，它的值是字符串 “Sunfei”。\n其次，使用  quote!  可以定义我们想要返回的 Rust 代码。由于编译器需要的内容和  quote!  直接返回的不一样，因此还需要使用  .into  方法其转换为  TokenStream。\n大家注意到  #name  的使用了吗？这也是  quote!  提供的功能之一，如果想要深入了解  quote，可以看看官方文档。\n特征的  hell_macro()  函数只有一个功能，就是使用  println!  打印一行欢迎语句。\n其中  stringify!  是 Rust 提供的内置宏，可以将一个表达式(例如  1 + 2)在编译期转换成一个字符串字面值(&quot;1 + 2&quot;)，该字面量会直接打包进编译出的二进制文件中，具有  &#039;static  生命周期。而  format!  宏会对表达式进行求值，最终结果是一个  String  类型。在这里使用  stringify!  有两个好处:\n\n#name  可能是一个表达式，我们需要它的字面值形式\n可以减少一次  String  带来的内存分配\n\n在运行之前，可以先用 expand 展开宏，观察是否有错误或符合预期：\n$ cargo expand --bin hello_macro\nstruct Sunfei;\nimpl HelloMacro for Sunfei {\n    fn hello_macro() {\n        {\n            ::std::io::_print(\n                ::core::fmt::Arguments::new_v1(\n                    &amp;[&quot;Hello, Macro! My name is &quot;, &quot;!\\n&quot;],\n                    &amp;[::core::fmt::ArgumentV1::new_display(&amp;&quot;Sunfei&quot;)],\n                ),\n            );\n        };\n    }\n}\nstruct Sunface;\nimpl HelloMacro for Sunface {\n    fn hello_macro() {\n        {\n            ::std::io::_print(\n                ::core::fmt::Arguments::new_v1(\n                    &amp;[&quot;Hello, Macro! My name is &quot;, &quot;!\\n&quot;],\n                    &amp;[::core::fmt::ArgumentV1::new_display(&amp;&quot;Sunface&quot;)],\n                ),\n            );\n        };\n    }\n}\nfn main() {\n    Sunfei::hello_macro();\n    Sunface::hello_macro();\n}\n从展开的代码也能看出 derive 宏的特性，struct Sunfei;  和  struct Sunface;  都被保留了，也就是说最后  impl_hello_macro()  返回的 token 被加到结构体后面，这和类属性宏可以修改输入 的 token 是不一样的，input 的 token 并不能被修改。\n至此，过程宏的定义、特征定义、主体代码都已经完成，运行下试试：\n$ cargo run\n \n     Running `target/debug/hello_macro`\nHello, Macro! My name is Sunfei!\nHello, Macro! My name is Sunface!\nBingo，虽然过程有些复杂，但是结果还是很喜人，我们终于完成了自己的第一个过程宏！\n下面来实现一个更实用的例子，实现官方的#[derive(Default)]宏，废话不说直接开干：\nextern crate proc_macro;\nuse proc_macro::TokenStream;\nuse quote::quote;\nuse syn::{self, Data};\nuse syn::DeriveInput;\n \n#[proc_macro_derive(MyDefault)]\npub fn my_default(input: TokenStream) -&gt; TokenStream {\n    let ast: DeriveInput = syn::parse(input).unwrap();\n    let id = ast.ident;\n \n    let Data::Struct(s) = ast.data else{\n        panic!(&quot;MyDefault derive macro must use in struct&quot;);\n    };\n \n    // 声明一个新的ast，用于动态构建字段赋值的token\n    let mut field_ast = quote!();\n \n    // 这里就是要动态添加token的地方了，需要动态完成Self的字段赋值\n    for (idx,f) in s.fields.iter().enumerate() {\n        let (field_id, field_ty) = (&amp;f.ident, &amp;f.ty);\n \n \n        if field_id.is_none(){\n             //没有ident表示是匿名字段，对于匿名字段，都需要添加 `#field_idx: #field_type::default(),` 这样的代码\n            let field_idx  = syn::Index::from(idx);\n            field_ast.extend(quote! {\n            });\n        }else{\n            //对于命名字段，都需要添加 `#field_name: #field_type::default(),` 这样的代码\n            field_ast.extend(quote! {\n            });\n        }\n    }\n \n    quote! {\n        impl Default for # id {\n            fn default() -&gt; Self {\n                Self {\n                }\n            }\n        }\n    }.into()\n}\n然后来写使用代码：\n#[derive(MyDefault)]\nstruct SomeData (u32,String);\n \n#[derive(MyDefault)]\nstruct User {\n    name: String,\n    data: SomeData,\n}\n \nfn main() {\n \n}\n然后我们先展开代码看一看：\nstruct SomeData(u32, String);\nimpl Default for SomeData {\n    fn default() -&gt; Self {\n        Self {\n            0: u32::default(),\n            1: String::default(),\n        }\n    }\n}\nstruct User {\n    name: String,\n    data: SomeData,\n}\nimpl Default for User {\n    fn default() -&gt; Self {\n        Self {\n            name: String::default(),\n            data: SomeData::default(),\n        }\n    }\n}\nfn main() {}\n展开的代码符合预期，然后我们修改一下使用代码并测试结果：\n#[derive(MyDefault, Debug)]\nstruct SomeData (u32,String);\n \n#[derive(MyDefault, Debug)]\nstruct User {\n    name: String,\n    data: SomeData,\n}\n \nfn main() {\n    println!(&quot;{:?}&quot;, User::default());\n}\n$ cargo run\n \n    Running `target/debug/aaa`\nUser { name: &quot;&quot;, data: SomeData(0, &quot;&quot;) }\n接下来，再来看看过程宏的另外两种类型跟  derive  类型有何区别。\n类属性宏(Attribute-like macros)\n类属性过程宏跟  derive  宏类似，但是前者允许我们定义自己的属性。除此之外，derive  只能用于结构体和枚举，而类属性宏可以用于其它类型项，例如函数。\n假设我们在开发一个  web  框架，当用户通过  HTTP GET  请求访问  /  根路径时，使用  index  函数为其提供服务：\n#[route(GET, &quot;/&quot;)]\nfn index() {}\n如上所示，代码功能非常清晰、简洁，这里的  #[route]  属性就是一个过程宏，它的定义函数大概如下：\n#[proc_macro_attribute]\npub fn route(attr: TokenStream, item: TokenStream) -&gt; TokenStream {}\n与  derive  宏不同，类属性宏的定义函数有两个参数：\n\n第一个参数时用于说明属性包含的内容：Get, &quot;/&quot;  部分\n第二个是属性所标注的类型项，在这里是  fn index() {...}，注意，函数体也被包含其中\n\n除此之外，类属性宏跟  derive  宏的工作方式并无区别：创建一个包，类型是  proc-macro，接着实现一个函数用于生成想要的代码。\n类函数宏(Function-like macros)\n类函数宏可以让我们定义像函数那样调用的宏，从这个角度来看，它跟声明宏  macro_rules  较为类似。\n区别在于，macro_rules  的定义形式与  match  匹配非常相像，而类函数宏的定义形式则类似于之前讲过的两种过程宏：\n#[proc_macro]\npub fn sql(input: TokenStream) -&gt; TokenStream {}\n而使用形式则类似于函数调用：\nlet sql = sql!(SELECT * FROM posts WHERE id=1);\n大家可能会好奇，为何我们不使用声明宏  macro_rules  来定义呢？原因是这里需要对  SQL  语句进行解析并检查其正确性，这个复杂的过程是  macro_rules  难以对付的，而过程宏相比起来就会灵活的多。\n补充学习资料\n\ndtolnay/proc-macro-workshop，学习如何编写过程宏\nThe Little Book of Rust Macros，学习如何编写声明宏  macro_rules!\nsyn  和  quote ，用于编写过程宏的包，它们的文档有很多值得学习的东西\nStructuring, testing and debugging procedural macro crates，从测试、debug、结构化的角度来编写过程宏\nblog.turbo.fish，里面的过程宏系列文章值得一读\nRust 宏小册中文版，非常详细的解释了宏各种知识\n\n总结\nRust 中的宏主要分为两大类：声明宏和过程宏。\n声明宏目前使用  macro_rules  进行创建，它的形式类似于  match  匹配，对于用户而言，可读性和维护性都较差。由于其存在的问题和限制，在未来， macro_rules  会被  deprecated，Rust 会使用一个新的声明宏来替代它。\n而过程宏的定义更像是我们平时写函数的方式，因此它更加灵活，它分为三种类型：derive  宏、类属性宏、类函数宏，具体在文中都有介绍。\n虽然 Rust 中的宏很强大，但是它并不应该成为我们的常规武器，原因是它会影响 Rust 代码的可读性和可维护性，我相信没有几个人愿意去维护别人写的宏 ：）\n因此，大家应该熟悉宏的使用场景，但是不要滥用，当你真的需要时，再回来查看本章了解实现细节，这才是最完美的使用方式。"},"rust/rust-bible/advanced/11-async-await-异步编程":{"title":"11-async await 异步编程","links":["rust/rust-bible/advanced/06-多线程并发编程","tags/TODO"],"tags":["TODO"],"content":"async await 异步编程\nAsync 编程入门\n众所周知，Rust 可以让我们写出性能高且安全的软件，那么异步编程这块儿呢？是否依然在高性能的同时保证了安全？\n简单来说，异步编程是一个并发编程模型，目前主流语言基本都支持了，当然，支持的方式有所不同。异步编程允许我们同时并发运行大量的任务，却仅仅需要几个甚至一个 OS 线程或 CPU 核心，现代化的异步编程在使用体验上跟同步编程也几无区别，例如 Go 语言的 go 关键字，也包括我们后面将介绍的 async/await 语法，该语法是 JavaScript 和 Rust 的核心特性之一。\nasync 简介\nasync 是 Rust 选择的异步编程模型，下面我们来介绍下它的优缺点，以及何时适合使用。\nasync vs 其它并发模型\n由于并发编程在现代社会非常重要，因此每个主流语言都对自己的并发模型进行过权衡取舍和精心设计，Rust 语言也不例外。下面的列表可以帮助大家理解不同并发模型的取舍：\n\nOS 线程， 它最简单，也无需改变任何编程模型(业务/代码逻辑)，因此非常适合作为语言的原生并发模型，我们在多线程章节也提到过，Rust 就选择了原生支持线程级的并发编程。但是，这种模型也有缺点，例如线程间的同步将变得更加困难，线程间的上下文切换损耗较大。使用线程池在一定程度上可以提升性能，但是对于 IO 密集的场景来说，线程池还是不够。\n事件驱动(Event driven)， 这个名词你可能比较陌生，如果说事件驱动常常跟回调( Callback )一起使用，相信大家就恍然大悟了。这种模型性能相当的好，但最大的问题就是存在回调地狱的风险：非线性的控制流和结果处理导致了数据流向和错误传播变得难以掌控，还会导致代码可维护性和可读性的大幅降低，大名鼎鼎的 JavaScript 曾经就存在回调地狱。\n协程(Coroutines) 可能是目前最火的并发模型，Go 语言的协程设计就非常优秀，这也是 Go 语言能够迅速火遍全球的杀手锏之一。协程跟线程类似，无需改变编程模型，同时，它也跟 async 类似，可以支持大量的任务并发运行。但协程抽象层次过高，导致用户无法接触到底层的细节，这对于系统编程语言和自定义异步运行时是难以接受的\nactor 模型是 erlang 的杀手锏之一，它将所有并发计算分割成一个一个单元，这些单元被称为 actor ，单元之间通过消息传递的方式进行通信和数据传递，跟分布式系统的设计理念非常相像。由于 actor 模型跟现实很贴近，因此它相对来说更容易实现，但是一旦遇到流控制、失败重试等场景时，就会变得不太好用\nasync/await， 该模型性能高，还能支持底层编程，同时又像线程和协程那样无需过多的改变编程模型，但有得必有失，async 模型的问题就是内部实现机制过于复杂，对于用户来说，理解和使用起来也没有线程和协程简单，好在前者的复杂性开发者们已经帮我们封装好，而理解和使用起来不够简单，正是本章试图解决的问题。\n\n总之，Rust 经过权衡取舍后，最终选择了同时提供多线程编程和 async 编程:\n\n前者通过标准库实现，当你无需那么高的并发时，例如需要并行计算时，可以选择它，优点是线程内的代码执行效率更高、实现更直观更简单，这块内容已经在多线程章节进行过深入讲解，不再赘述\n后者通过语言特性 + 标准库 + 三方库的方式实现，在你需要高并发、异步 I/O 时，选择它就对了\n\nasync: Rust vs 其它语言\n目前已经有诸多语言都通过 async 的方式提供了异步编程，例如 JavaScript ，但 Rust 在实现上有所区别：\n\nFuture 在 Rust 中是惰性的，只有在被轮询(poll)时才会运行， 因此丢弃一个 future 会阻止它未来再被运行，你可以将Future理解为一个在未来某个时间点被调度执行的任务。\nAsync 在 Rust 中使用开销是零， 意味着只有你能看到的代码(自己的代码)才有性能损耗，你看不到的(async 内部实现)都没有性能损耗，例如，你可以无需分配任何堆内存、也无需任何动态分发来使用 async ，这对于热点路径的性能有非常大的好处，正是得益于此，Rust 的异步编程性能才会这么高。\nRust 没有内置异步调用所必需的运行时，但是无需担心，Rust 社区生态中已经提供了非常优异的运行时实现，例如大明星 tokio\n运行时同时支持单线程和多线程，这两者拥有各自的优缺点，稍后会讲\n\nRust: async vs 多线程\n虽然 async 和多线程都可以实现并发编程，后者甚至还能通过线程池来增强并发能力，但是这两个方式并不互通，从一个方式切换成另一个需要大量的代码重构工作，因此提前为自己的项目选择适合的并发模型就变得至关重要。\nOS 线程非常适合少量任务并发，因为线程的创建和上下文切换是非常昂贵的，甚至于空闲的线程都会消耗系统资源。虽说线程池可以有效的降低性能损耗，但是也无法彻底解决问题。当然，线程模型也有其优点，例如它不会破坏你的代码逻辑和编程模型，你之前的顺序代码，经过少量修改适配后依然可以在新线程中直接运行，同时在某些操作系统中，你还可以改变线程的优先级，这对于实现驱动程序或延迟敏感的应用(例如硬实时系统)很有帮助。\n对于长时间运行的 CPU 密集型任务，例如并行计算，使用线程将更有优势。 这种密集任务往往会让所在的线程持续运行，任何不必要的线程切换都会带来性能损耗，因此高并发反而在此时成为了一种多余。同时你所创建的线程数应该等于 CPU 核心数，充分利用 CPU 的并行能力，甚至还可以将线程绑定到 CPU 核心上，进一步减少线程上下文切换。\n而高并发更适合 IO 密集型任务，例如 web 服务器、数据库连接等等网络服务，因为这些任务绝大部分时间都处于等待状态，如果使用多线程，那线程大量时间会处于无所事事的状态，再加上线程上下文切换的高昂代价，让多线程做 IO 密集任务变成了一件非常奢侈的事。而使用async，既可以有效的降低 CPU 和内存的负担，又可以让大量的任务并发的运行，一个任务一旦处于IO或者其他等待(阻塞)状态，就会被立刻切走并执行另一个任务，而这里的任务切换的性能开销要远远低于使用多线程时的线程上下文切换。\n事实上， async 底层也是基于线程实现，但是它基于线程封装了一个运行时，可以将多个任务映射到少量线程上，然后将线程切换变成了任务切换，后者仅仅是内存中的访问，因此要高效的多。\n不过async也有其缺点，原因是编译器会为async函数生成状态机，然后将整个运行时打包进来，这会造成我们编译出的二进制可执行文件体积显著增大。\n总之，async编程并没有比多线程更好，最终还是根据你的使用场景作出合适的选择，如果无需高并发，或者也不在意线程切换带来的性能损耗，那么多线程使用起来会简单、方便的多！最后再简单总结下：\n\n若大家使用 tokio，那 CPU 密集的任务尤其需要用线程的方式去处理，例如使用 spawn_blocking 创建一个阻塞的线程去完成相应 CPU 密集任务。\n至于具体的原因，不仅是上文说到的那些，还有一个是：tokio 是协作式的调度器，如果某个 CPU 密集的异步任务是通过 tokio 创建的，那理论上来说，该异步任务需要跟其它的异步任务交错执行，最终大家都得到了执行，皆大欢喜。但实际情况是，CPU 密集的任务很可能会一直霸占着 CPU，此时 tokio 的调度方式决定了该任务会一直被执行，这意味着，其它的异步任务无法得到执行的机会，最终这些任务都会因为得不到资源而饿死。\n而使用 spawn_blocking 后，会创建一个单独的 OS 线程，该线程并不会被 tokio 所调度( 被 OS 所调度 )，因此它所执行的 CPU 密集任务也不会导致 tokio 调度的那些异步任务被饿死。\n\n\n有大量 IO 任务需要并发运行时，选 async 模型\n有部分 IO 任务需要并发运行时，选多线程，如果想要降低线程创建和销毁的开销，可以使用线程池\n有大量 CPU 密集任务需要并行运行时，例如并行计算，选多线程模型，且让线程数等于或者稍大于 CPU 核心数\n无所谓时，统一选多线程\n\nasync 和多线程的性能对比\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n操作async线程创建0.3 微秒17 微秒线程切换0.2 微秒1.7 微秒可以看出，async 在线程切换的开销显著低于多线程，对于 IO 密集的场景，这种性能开销累计下来会非常可怕！\n一个例子\n在大概理解async后，我们再来看一个简单的例子。如果想并发的下载文件，你可以使用多线程如下实现：\nfn get_two_sites() {\n    // 创建两个新线程执行任务\n    let thread_one = thread::spawn(|| download(&quot;course.rs&quot;));\n    let thread_two = thread::spawn(|| download(&quot;fancy.rs&quot;));\n \n    // 等待两个线程的完成\n    thread_one.join().expect(&quot;thread one panicked&quot;);\n    thread_two.join().expect(&quot;thread two panicked&quot;);\n}\n如果是在一个小项目中简单的去下载文件，这么写没有任何问题，但是一旦下载文件的并发请求多起来，那一个下载任务占用一个线程的模式就太重了，会很容易成为程序的瓶颈。好在，我们可以使用async的方式来解决：\nasync fn get_two_sites_async() {\n    // 创建两个不同的`future`，你可以把`future`理解为未来某个时刻会被执行的计划任务\n    // 当两个`future`被同时执行后，它们将并发的去下载目标页面\n    let future_one = download_async(&quot;www.foo.com&quot;);\n    let future_two = download_async(&quot;www.bar.com&quot;);\n \n    // 同时运行两个`future`，直至完成\n    join!(future_one, future_two);\n}\n此时，不再有线程创建和切换的昂贵开销，所有的函数都是通过静态的方式进行分发，同时也没有任何内存分配发生。这段代码的性能简直无懈可击！\n事实上，async 和多线程并不是二选一，在同一应用中，可以根据情况两者一起使用，当然，我们还可以使用其它的并发模型，例如上面提到事件驱动模型，前提是有三方库提供了相应的实现。\nAsync Rust 当前的进展\n简而言之，Rust 语言的 async 目前还没有达到多线程的成熟度，其中一部分内容还在不断进化中，当然，这并不影响我们在生产级项目中使用，因为社区中还有 tokio 这种大杀器。\n使用 async 时，你会遇到好的，也会遇到不好的，例如：\n\n收获卓越的性能\n会经常跟进阶语言特性打交道，例如生命周期等，这些家伙可不好对付\n一些兼容性问题，例如同步和异步代码、不同的异步运行时( tokio 与 async-std )\n更昂贵的维护成本，原因是 async 和社区开发的运行时依然在不停的进化\n\n总之，async 在 Rust 中并不是一个善茬，你会遇到更多的困难或者说坑，也会带来更高的代码阅读成本及维护成本，但是为了性能，一切都值了，不是吗？\n不过好在，这些进化早晚会彻底稳定成熟，而且在实际项目中，我们往往会使用成熟的三方库，例如tokio，因此可以避免一些类似的问题，但是对于本章的学习来说，async 的一些难点还是我们必须要去面对和征服的。\n语言和库的支持\nasync 的底层实现非常复杂，且会导致编译后文件体积显著增加，因此 Rust 没有选择像 Go 语言那样内置了完整的特性和运行时，而是选择了通过 Rust 语言提供了必要的特性支持，再通过社区来提供 async 运行时的支持。 因此要完整的使用 async 异步编程，你需要依赖以下特性和外部库：\n\n所必须的特征(例如 Future )、类型和函数，由标准库提供实现\n关键字 async/await 由 Rust 语言提供，并进行了编译器层面的支持\n众多实用的类型、宏和函数由官方开发的 futures 包提供(不是标准库)，它们可以用于任何 async 应用中。\nasync 代码的执行、IO 操作、任务创建和调度等等复杂功能由社区的 async 运行时提供，例如 tokio 和 async-std\n\n还有，你在同步( synchronous )代码中使用的一些语言特性在 async 中可能将无法再使用，而且 Rust 也不允许你在特征中声明 async 函数(可以通过三方库实现)， 总之，你会遇到一些在同步代码中不会遇到的奇奇怪怪、形形色色的问题，不过不用担心，本章会专门用一个章节罗列这些问题，并给出相应的解决方案。\n编译和错误\n在大多数情况下，async 中的编译错误和运行时错误跟之前没啥区别，但是依然有以下几点值得注意：\n\n编译错误，由于 async 编程时需要经常使用复杂的语言特性，例如生命周期和Pin，因此相关的错误可能会出现的更加频繁\n运行时错误，编译器会为每一个async函数生成状态机，这会导致在栈跟踪时会包含这些状态机的细节，同时还包含了运行时对函数的调用，因此，栈跟踪记录(例如 panic 时)将变得更加难以解读\n一些隐蔽的错误也可能发生，例如在一个 async 上下文中去调用一个阻塞的函数，或者没有正确的实现 Future 特征都有可能导致这种错误。这种错误可能会悄无声息的通过编译检查甚至有时候会通过单元测试。好在一旦你深入学习并掌握了本章的内容和 async 原理，可以有效的降低遇到这些错误的概率\n\n兼容性考虑\n异步代码和同步代码并不总能和睦共处。例如，我们无法在一个同步函数中去调用一个 async 异步函数，同步和异步代码也往往使用不同的设计模式，这些都会导致两者融合上的困难。\n甚至于有时候，异步代码之间也存在类似的问题，如果一个库依赖于特定的 async 运行时来运行，那么这个库非常有必要告诉它的用户，它用了这个运行时。否则一旦用户选了不同的或不兼容的运行时，就会导致不可预知的麻烦。\n性能特性\nasync 代码的性能主要取决于你使用的 async 运行时，好在这些运行时都经过了精心的设计，在你能遇到的绝大多数场景中，它们都能拥有非常棒的性能表现。\n但是世事皆有例外。目前主流的 async 运行时几乎都使用了多线程实现，相比单线程虽然增加了并发表现，但是对于执行性能会有所损失，因为多线程实现会有同步和切换上的性能开销，若你需要极致的顺序执行性能，那么 async 目前并不是一个好的选择。\n同样的，对于延迟敏感的任务来说，任务的执行次序需要能被严格掌控，而不是交由运行时去自动调度，后者会导致不可预知的延迟，例如一个 web 服务器总是有 1% 的请求，它们的延迟会远高于其它请求，因为调度过于繁忙导致了部分任务被延迟调度，最终导致了较高的延时。正因为此，这些延迟敏感的任务非常依赖于运行时或操作系统提供调度次序上的支持。\n以上的两个需求，目前的 async 运行时并不能很好的支持，在未来可能会有更好的支持，但在此之前，我们可以尝试用多线程解决。\nasync/.await 简单入门\nasync/.await 是 Rust 内置的语言特性，可以让我们用同步的方式去编写异步的代码。\n通过 async 标记的语法块会被转换成实现了Future特征的状态机。 与同步调用阻塞当前线程不同，当Future执行并遇到阻塞时，它会让出当前线程的控制权，这样其它的Future就可以在该线程中运行，这种方式完全不会导致当前线程的阻塞。\n下面我们来通过例子学习 async/.await 关键字该如何使用，在开始之前，需要先引入 futures 包。编辑 Cargo.toml 文件并添加以下内容：\n[dependencies] \nfutures = &quot;0.3&quot;\n使用 async\n首先，使用 async fn 语法来创建一个异步函数：\nasync fn do_something() {\n    println!(&quot;go go go !&quot;);\n}\n需要注意，异步函数的返回值是一个 Future，若直接调用该函数，不会输出任何结果，因为 Future 还未被执行：\nfn main() {\n      do_something();\n}\n运行后，go go go并没有打印，同时编译器给予一个提示：warning: unused implementer of Future that must be used，告诉我们 Future 未被使用，那么到底该如何使用？答案是使用一个执行器 (executor)：\n// `block_on`会阻塞当前线程直到指定的`Future`执行完成\n// 这种阻塞当前线程以等待任务完成的方式较为简单、粗暴，\n// 好在其它运行时的执行器(executor)会提供更加复杂的行为，\n// 例如将多个`future`调度到同一个线程上执行。\nuse futures::executor::block_on;\n \nasync fn hello_world() {\n    println!(&quot;hello, world!&quot;);\n}\n \nfn main() {\n    let future = hello_world(); // 返回一个Future, 因此不会打印任何输出\n    block_on(future); // 执行`Future`并等待其运行完成，此时&quot;hello, world!&quot;会被打印输出\n}\n使用.await\n在上述代码的main函数中，我们使用block_on这个执行器等待Future的完成，让代码看上去非常像是同步代码，但是如果你要在一个async fn函数中去调用另一个async fn并等待其完成后再执行后续的代码，该如何做？例如：\nuse futures::executor::block_on;\n \nasync fn hello_world() {\n    hello_cat();\n    println!(&quot;hello, world!&quot;);\n}\n \nasync fn hello_cat() {\n    println!(&quot;hello, kitty!&quot;);\n}\nfn main() {\n    let future = hello_world();\n    block_on(future);\n}\n这里，我们在hello_world异步函数中先调用了另一个异步函数hello_cat，然后再输出hello, world!，看看运行结果：\nwarning: unused implementer of `futures::Future` that must be used\n --&gt; src/main.rs:6:5\n  |\n6 |     hello_cat();\n  |     ^^^^^^^^^^^^\n= note: futures do nothing unless you `.await` or poll them\n...\nhello, world!\n不出所料，main函数中的future我们通过block_on函数进行了运行，但是这里的hello_cat返回的Future却没有任何人去执行它，不过好在编译器友善的给出了提示：futures do nothing unless you `.await` or poll them，两种解决方法：使用.await语法或者对Future进行轮询(poll)。\n后者较为复杂，暂且不表，先来使用.await试试：\nuse futures::executor::block_on;\n \nasync fn hello_world() {\n    hello_cat().await;\n    println!(&quot;hello, world!&quot;);\n}\n \nasync fn hello_cat() {\n    println!(&quot;hello, kitty!&quot;);\n}\nfn main() {\n    let future = hello_world();\n    block_on(future);\n}\n为hello_cat()添加上.await后，结果立刻大为不同：\nhello, kitty!\nhello, world!\n输出的顺序跟代码定义的顺序完全符合，因此，我们在上面代码中使用同步的代码顺序实现了异步的执行效果，非常简单、高效，而且很好理解，未来也绝对不会有回调地狱的发生。\n总之，在async fn函数中使用.await可以等待另一个异步调用的完成。但是与block_on不同，.await并不会阻塞当前的线程，而是异步的等待Future A的完成，在等待的过程中，该线程还可以继续执行其它的Future B，最终实现了并发处理的效果。\n一个例子\n考虑一个载歌载舞的例子，如果不用.await，我们可能会有如下实现：\nuse futures::executor::block_on;\n \nstruct Song {\n    author: String,\n    name: String,\n}\n \nasync fn learn_song() -&gt; Song {\n    Song {\n        author: &quot;周杰伦&quot;.to_string(),\n        name: String::from(&quot;《菊花台》&quot;),\n    }\n}\n \nasync fn sing_song(song: Song) {\n    println!(\n        &quot;给大家献上一首{}的{} ~ {}&quot;,\n        song.author, song.name, &quot;菊花残，满地伤~ ~&quot;\n    );\n}\n \nasync fn dance() {\n    println!(&quot;唱到情深处，身体不由自主的动了起来~ ~&quot;);\n}\n \nfn main() {\n    let song = block_on(learn_song());\n    block_on(sing_song(song));\n    block_on(dance());\n}\n当然，以上代码运行结果无疑是正确的，但。。。它的性能何在？需要通过连续三次阻塞去等待三个任务的完成，一次只能做一件事，实际上我们完全可以载歌载舞啊：\nuse futures::executor::block_on;\n \nstruct Song {\n    author: String,\n    name: String,\n}\n \nasync fn learn_song() -&gt; Song {\n    Song {\n        author: &quot;曲婉婷&quot;.to_string(),\n        name: String::from(&quot;《我的歌声里》&quot;),\n    }\n}\n \nasync fn sing_song(song: Song) {\n    println!(\n        &quot;给大家献上一首{}的{} ~ {}&quot;,\n        song.author, song.name, &quot;你存在我深深的脑海里~ ~&quot;\n    );\n}\n \nasync fn dance() {\n    println!(&quot;唱到情深处，身体不由自主的动了起来~ ~&quot;);\n}\n \nasync fn learn_and_sing() {\n    // 这里使用`.await`来等待学歌的完成，但是并不会阻塞当前线程，\n    // 该线程在学歌的任务`.await`后，完全可以去执行跳舞的任务。\n    let song = learn_song().await;\n \n    // 唱歌必须要在学歌之后\n    sing_song(song).await;\n}\n \nasync fn async_main() {\n    let f1 = learn_and_sing();\n    let f2 = dance();\n \n    // `join!`可以并发的处理和等待多个`Future`，若`learn_and_sing Future`被阻塞，\n    // 那`dance Future`可以拿过线程的所有权继续执行。若`dance`也变成阻塞状态，\n    // 那`learn_and_sing`又可以再次拿回线程所有权，继续执行。\n    // 若两个都被阻塞，那么`async main`会变成阻塞状态，\n    // 然后让出线程所有权，并将其交给`main`函数中的`block_on`执行器\n    futures::join!(f1, f2);\n}\n \nfn main() {\n    block_on(async_main());\n}\n上面代码中，学歌和唱歌具有明显的先后顺序，但是这两者都可以跟跳舞一同存在，也就是你可以在跳舞的时候学歌，也可以在跳舞的时候唱歌。如果上面代码不使用.await，而是使用block_on(learn_song())， 那在学歌时，当前线程就会阻塞，不再可以做其它任何事，包括跳舞。\n因此.await对于实现异步编程至关重要，它允许我们在同一个线程内并发的运行多个任务，而不是一个一个先后完成。若大家看到这里还是不太明白，强烈建议回头再仔细看一遍，同时亲自上手修改代码试试效果。\n至此，读者应该对 Rust 的async/.await异步编程有了一个清晰的初步印象，下面让我们一起来看看这背后的原理：Future和任务在底层如何被执行。\n底层探秘: Future 执行器与任务调度\n异步编程背后到底藏有什么秘密？究竟是哪只幕后之手在操纵这一切？如果你对这些感兴趣，就继续看下去，否则可以直接跳过，因为本章节的内容对于一个 API 工程师并没有太多帮助。\n但是如果你希望能深入理解 Rust 的 async/.await 代码是如何工作、理解运行时和性能，甚至未来想要构建自己的 async 运行时或相关工具，那么本章节终究不会辜负于你。\nFuture 特征\nFuture 特征是 Rust 异步编程的核心，毕竟异步函数是异步编程的核心，而 Future 恰恰是异步函数的返回值和被执行的关键。\n首先，来给出 Future 的定义：它是一个能产出值的异步计算(虽然该值可能为空，例如 () )。光看这个定义，可能会觉得很空洞，我们来看看一个简化版的 Future 特征：\ntrait SimpleFuture {\n    type Output;\n    fn poll(&amp;mut self, wake: fn()) -&gt; Poll&lt;Self::Output&gt;;\n}\n \nenum Poll&lt;T&gt; {\n    Ready(T),\n    Pending,\n}\n在上一章中，我们提到过 Future 需要被执行器poll(轮询)后才能运行，诺，这里 poll 就来了，通过调用该方法，可以推进 Future 的进一步执行，直到被切走为止( 这里不好理解，但是你只需要知道 Future 并不能保证在一次 poll 中就被执行完，后面会详解介绍)。\n若在当前 poll 中， Future 可以被完成，则会返回 Poll::Ready(result) ，反之则返回 Poll::Pending， 并且安排一个 wake 函数：当未来 Future 准备好进一步执行时， 该函数会被调用，然后管理该 Future 的执行器(例如上一章节中的block_on函数)会再次调用 poll 方法，此时 Future 就可以继续执行了。\n如果没有 wake 方法，那执行器无法知道某个 Future 是否可以继续被执行，除非执行器定期的轮询每一个 Future，确认它是否能被执行，但这种作法效率较低。而有了 wake，Future 就可以主动通知执行器，然后执行器就可以精确的执行该 Future。 这种“事件通知 → 执行”的方式要远比定期对所有 Future 进行一次全遍历来的高效。\n也许大家还是迷迷糊糊的，没事，我们用一个例子来说明下。考虑一个需要从 socket 读取数据的场景：如果有数据，可以直接读取数据并返回 Poll::Ready(data)， 但如果没有数据，Future 会被阻塞且不会再继续执行，此时它会注册一个 wake 函数，当 socket 数据准备好时，该函数将被调用以通知执行器：我们的 Future 已经准备好了，可以继续执行。\n下面的 SocketRead 结构体就是一个 Future：\npub struct SocketRead&lt;&#039;a&gt; {\n    socket: &amp;&#039;a Socket,\n}\n \nimpl SimpleFuture for SocketRead&lt;&#039;_&gt; {\n    type Output = Vec&lt;u8&gt;;\n \n    fn poll(&amp;mut self, wake: fn()) -&gt; Poll&lt;Self::Output&gt; {\n        if self.socket.has_data_to_read() {\n            // socket有数据，写入buffer中并返回\n            Poll::Ready(self.socket.read_buf())\n        } else {\n            // socket中还没数据\n            //\n            // 注册一个`wake`函数，当数据可用时，该函数会被调用，\n            // 然后当前Future的执行器会再次调用`poll`方法，此时就可以读取到数据\n            self.socket.set_readable_callback(wake);\n            Poll::Pending\n        }\n    }\n}\n这种 Future 模型允许将多个异步操作组合在一起，同时还无需任何内存分配。不仅仅如此，如果你需要同时运行多个 Future或链式调用多个 Future ，也可以通过无内存分配的状态机实现，例如：\ntrait SimpleFuture {\n    type Output;\n    fn poll(&amp;mut self, wake: fn()) -&gt; Poll&lt;Self::Output&gt;;\n}\n \nenum Poll&lt;T&gt; {\n    Ready(T),\n    Pending,\n}\n \n/// 一个SimpleFuture，它会并发地运行两个Future直到它们完成\n///\n/// 之所以可以并发，是因为两个Future的轮询可以交替进行，一个阻塞，另一个就可以立刻执行，反之亦然\npub struct Join&lt;FutureA, FutureB&gt; {\n    // 结构体的每个字段都包含一个Future，可以运行直到完成.\n    // 等到Future完成后，字段会被设置为 `None`. 这样Future完成后，就不会再被轮询\n    a: Option&lt;FutureA&gt;,\n    b: Option&lt;FutureB&gt;,\n}\n \nimpl&lt;FutureA, FutureB&gt; SimpleFuture for Join&lt;FutureA, FutureB&gt;\nwhere\n    FutureA: SimpleFuture&lt;Output = ()&gt;,\n    FutureB: SimpleFuture&lt;Output = ()&gt;,\n{\n    type Output = ();\n    fn poll(&amp;mut self, wake: fn()) -&gt; Poll&lt;Self::Output&gt; {\n        // 尝试去完成一个 Future `a`\n        if let Some(a) = &amp;mut self.a {\n            if let Poll::Ready(()) = a.poll(wake) {\n                self.a.take();\n            }\n        }\n \n        // 尝试去完成一个 Future `b`\n        if let Some(b) = &amp;mut self.b {\n            if let Poll::Ready(()) = b.poll(wake) {\n                self.b.take();\n            }\n        }\n \n        if self.a.is_none() &amp;&amp; self.b.is_none() {\n            // 两个 Future都已完成 - 我们可以成功地返回了\n            Poll::Ready(())\n        } else {\n            // 至少还有一个 Future 没有完成任务，因此返回 `Poll::Pending`.\n            // 当该 Future 再次准备好时，通过调用`wake()`函数来继续执行\n            Poll::Pending\n        }\n    }\n}\n上面代码展示了如何同时运行多个 Future， 且在此过程中没有任何内存分配，让并发编程更加高效。 类似的，多个Future也可以一个接一个的连续运行：\n/// 一个SimpleFuture, 它使用顺序的方式，一个接一个地运行两个Future\n//\n// 注意: 由于本例子用于演示，因此功能简单，`AndThenFut` 会假设两个 Future 在创建时就可用了.\n// 而真实的`Andthen`允许根据第一个`Future`的输出来创建第二个`Future`，因此复杂的多。\npub struct AndThenFut&lt;FutureA, FutureB&gt; {\n    first: Option&lt;FutureA&gt;,\n    second: FutureB,\n}\n \nimpl&lt;FutureA, FutureB&gt; SimpleFuture for AndThenFut&lt;FutureA, FutureB&gt;\nwhere\n    FutureA: SimpleFuture&lt;Output = ()&gt;,\n    FutureB: SimpleFuture&lt;Output = ()&gt;,\n{\n    type Output = ();\n    fn poll(&amp;mut self, wake: fn()) -&gt; Poll&lt;Self::Output&gt; {\n        if let Some(first) = &amp;mut self.first {\n            match first.poll(wake) {\n                // 我们已经完成了第一个 Future， 可以将它移除， 然后准备开始运行第二个\n                Poll::Ready(()) =&gt; self.first.take(),\n                // 第一个 Future 还不能完成\n                Poll::Pending =&gt; return Poll::Pending,\n            };\n        }\n \n        // 运行到这里，说明第一个Future已经完成，尝试去完成第二个\n        self.second.poll(wake)\n    }\n}\n这些例子展示了在不需要内存对象分配以及深层嵌套回调的情况下，该如何使用 Future 特征去表达异步控制流。 在了解了基础的控制流后，我们再来看看真实的 Future 特征有何不同之处。\ntrait Future {\n    type Output;\n    fn poll(\n        // 首先值得注意的地方是，`self`的类型从`&amp;mut self`变成了`Pin&lt;&amp;mut Self&gt;`:\n        self: Pin&lt;&amp;mut Self&gt;,\n        // 其次将`wake: fn()` 修改为 `cx: &amp;mut Context&lt;&#039;_&gt;`:\n        cx: &amp;mut Context&lt;&#039;_&gt;,\n    ) -&gt; Poll&lt;Self::Output&gt;;\n}\n首先这里多了一个 Pin ，关于它我们会在后面章节详细介绍，现在你只需要知道使用它可以创建一个无法被移动的 Future ，因为无法被移动，所以它将具有固定的内存地址，意味着我们可以存储它的指针(如果内存地址可能会变动，那存储指针地址将毫无意义！)，也意味着可以实现一个自引用数据结构: struct MyFut { a: i32, ptr_to_a: *const i32 }。 而对于 async/await 来说，Pin 是不可或缺的关键特性。\n其次，从 wake: fn() 变成了 &amp;mut Context&lt;&#039;_&gt; 。意味着 wake 函数可以携带数据了，为何要携带数据？考虑一个真实世界的场景，一个复杂应用例如 web 服务器可能有数千连接同时在线，那么同时就有数千 Future 在被同时管理着，如果不能携带数据，当一个 Future 调用 wake 后，执行器该如何知道是哪个 Future 调用了 wake ,然后进一步去 poll 对应的 Future ？没有办法！那之前的例子为啥就可以使用没有携带数据的 wake ？ 因为足够简单，不存在歧义性。\n总之，在正式场景要进行 wake ，就必须携带上数据。 而 Context 类型通过提供一个 Waker 类型的值，就可以用来唤醒特定的的任务。\n使用 Waker 来唤醒任务\nTODO 基本看不懂，或者说没搞明白\n对于 Future 来说，第一次被 poll 时无法完成任务是很正常的。但它需要确保在未来一旦准备好时，可以通知执行器再次对其进行 poll 进而继续往下执行，该通知就是通过 Waker 类型完成的。\nWaker 提供了一个 wake() 方法可以用于告诉执行器：相关的任务可以被唤醒了，此时执行器就可以对相应的 Future 再次进行 poll 操作。\n构建一个定时器\n下面一起来实现一个简单的定时器 Future 。为了让例子尽量简单，当计时器创建时，我们会启动一个线程接着让该线程进入睡眠，等睡眠结束后再通知给 Future 。\n注意本例子还会在后面继续使用，因此我们重新创建一个工程来演示：使用 cargo new --lib timer_future 来创建一个新工程，在 lib 包的根路径 src/lib.rs 中添加以下内容：\nuse std::{\n    future::Future,\n    pin::Pin,\n    sync::{Arc, Mutex},\n    task::{Context, Poll, Waker},\n    thread,\n    time::Duration,\n};\n继续来实现 Future 定时器，之前提到：新建线程在睡眠结束后会需要将状态同步给定时器 Future ，由于是多线程环境，我们需要使用 Arc&lt;Mutex&lt;T&gt;&gt; 来作为一个共享状态，用于在新线程和 Future 定时器间共享。\npub struct TimerFuture {\n    shared_state: Arc&lt;Mutex&lt;SharedState&gt;&gt;,\n}\n \n/// 在Future和等待的线程间共享状态\nstruct SharedState {\n    /// 定时(睡眠)是否结束\n    completed: bool,\n \n    /// 当睡眠结束后，线程可以用`waker`通知`TimerFuture`来唤醒任务\n    waker: Option&lt;Waker&gt;,\n}\n下面给出 Future 的具体实现：\nimpl Future for TimerFuture {\n    type Output = ();\n    fn poll(self: Pin&lt;&amp;mut Self&gt;, cx: &amp;mut Context&lt;&#039;_&gt;) -&gt; Poll&lt;Self::Output&gt; {\n        // 通过检查共享状态，来确定定时器是否已经完成\n        let mut shared_state = self.shared_state.lock().unwrap();\n        if shared_state.completed {\n            Poll::Ready(())\n        } else {\n            // 设置`waker`，这样新线程在睡眠(计时)结束后可以唤醒当前的任务，接着再次对`Future`进行`poll`操作,\n            //\n            // 下面的`clone`每次被`poll`时都会发生一次，实际上，应该是只`clone`一次更加合理。\n            // 选择每次都`clone`的原因是： `TimerFuture`可以在执行器的不同任务间移动，如果只克隆一次，\n            // 那么获取到的`waker`可能已经被篡改并指向了其它任务，最终导致执行器运行了错误的任务\n            shared_state.waker = Some(cx.waker().clone());\n            Poll::Pending\n        }\n    }\n}\n代码很简单，只要新线程设置了 shared_state.completed = true ，那任务就能顺利结束。如果没有设置，会为当前的任务克隆一份 Waker ，这样新线程就可以使用它来唤醒当前的任务。\n最后，再来创建一个 API 用于构建定时器和启动计时线程：\nimpl TimerFuture {\n    /// 创建一个新的`TimerFuture`，在指定的时间结束后，该`Future`可以完成\n    pub fn new(duration: Duration) -&gt; Self {\n        let shared_state = Arc::new(Mutex::new(SharedState {\n            completed: false,\n            waker: None,\n        }));\n \n        // 创建新线程\n        let thread_shared_state = shared_state.clone();\n        thread::spawn(move || {\n            // 睡眠指定时间实现计时功能\n            thread::sleep(duration);\n            let mut shared_state = thread_shared_state.lock().unwrap();\n            // 通知执行器定时器已经完成，可以继续`poll`对应的`Future`了\n            shared_state.completed = true;\n            if let Some(waker) = shared_state.waker.take() {\n                waker.wake()\n            }\n        });\n \n        TimerFuture { shared_state }\n    }\n}\n至此，一个简单的定时器 Future 就已创建成功，那么该如何使用它呢？相信部分爱动脑筋的读者已经猜到了：我们需要创建一个执行器，才能让程序动起来。\n执行器 Executor\nRust 的 Future 是惰性的：只有屁股上拍一拍，它才会努力动一动。其中一个推动它的方式就是在 async 函数中使用 .await 来调用另一个 async 函数，但是这个只能解决 async 内部的问题，那么这些最外层的 async 函数，谁来推动它们运行呢？答案就是我们之前多次提到的执行器 executor 。\n执行器会管理一批 Future (最外层的 async 函数)，然后通过不停地 poll 推动它们直到完成。 最开始，执行器会先 poll 一次 Future ，后面就不会主动去 poll 了，而是等待 Future 通过调用 wake 函数来通知它可以继续，它才会继续去 poll 。这种 wake 通知然后 poll 的方式会不断重复，直到 Future 完成。\n构建执行器\n下面我们将实现一个简单的执行器，它可以同时并发运行多个 Future 。例子中，需要用到 futures 包的 ArcWake 特征，它可以提供一个方便的途径去构建一个 Waker 。编辑 Cargo.toml ，添加下面依赖：\n[dependencies]\nfutures = &quot;0.3&quot;\n在之前的内容中，我们在 src/lib.rs 中创建了定时器 Future ，现在在 src/main.rs 中来创建程序的主体内容，开始之前，先引入所需的包：\nuse {\n    futures::{\n        future::{BoxFuture, FutureExt},\n        task::{waker_ref, ArcWake},\n    },\n    std::{\n        future::Future,\n        sync::mpsc::{sync_channel, Receiver, SyncSender},\n        sync::{Arc, Mutex},\n        task::{Context, Poll},\n        time::Duration,\n    },\n    // 引入之前实现的定时器模块\n    timer_future::TimerFuture,\n};\n执行器需要从一个消息通道( channel )中拉取事件，然后运行它们。当一个任务准备好后（可以继续执行），它会将自己放入消息通道中，然后等待执行器 poll 。\n/// 任务执行器，负责从通道中接收任务然后执行\nstruct Executor {\n    ready_queue: Receiver&lt;Arc&lt;Task&gt;&gt;,\n}\n \n/// `Spawner`负责创建新的`Future`然后将它发送到任务通道中\n#[derive(Clone)]\nstruct Spawner {\n    task_sender: SyncSender&lt;Arc&lt;Task&gt;&gt;,\n}\n \n/// 一个Future，它可以调度自己(将自己放入任务通道中)，然后等待执行器去`poll`\nstruct Task {\n    /// 进行中的Future，在未来的某个时间点会被完成\n    ///\n    /// 按理来说`Mutex`在这里是多余的，因为我们只有一个线程来执行任务。但是由于\n    /// Rust并不聪明，它无法知道`Future`只会在一个线程内被修改，并不会被跨线程修改。因此\n    /// 我们需要使用`Mutex`来满足这个笨笨的编译器对线程安全的执着。\n    ///\n    /// 如果是生产级的执行器实现，不会使用`Mutex`，因为会带来性能上的开销，取而代之的是使用`UnsafeCell`\n    future: Mutex&lt;Option&lt;BoxFuture&lt;&#039;static, ()&gt;&gt;&gt;,\n \n    /// 可以将该任务自身放回到任务通道中，等待执行器的poll\n    task_sender: SyncSender&lt;Arc&lt;Task&gt;&gt;,\n}\n \nfn new_executor_and_spawner() -&gt; (Executor, Spawner) {\n    // 任务通道允许的最大缓冲数(任务队列的最大长度)\n    // 当前的实现仅仅是为了简单，在实际的执行中，并不会这么使用\n    const MAX_QUEUED_TASKS: usize = 10_000;\n    let (task_sender, ready_queue) = sync_channel(MAX_QUEUED_TASKS);\n    (Executor { ready_queue }, Spawner { task_sender })\n}\n下面再来添加一个方法用于生成 Future , 然后将它放入任务通道中：\nimpl Spawner {\n    fn spawn(&amp;self, future: impl Future&lt;Output = ()&gt; + &#039;static + Send) {\n        let future = future.boxed();\n        let task = Arc::new(Task {\n            future: Mutex::new(Some(future)),\n            task_sender: self.task_sender.clone(),\n        });\n        self.task_sender.send(task).expect(&quot;任务队列已满&quot;);\n    }\n}\n在执行器 poll 一个 Future 之前，首先需要调用 wake 方法进行唤醒，然后再由 Waker 负责调度该任务并将其放入任务通道中。创建 Waker 的最简单的方式就是实现 ArcWake 特征，先来为我们的任务实现 ArcWake 特征，这样它们就能被转变成 Waker 然后被唤醒：\nimpl ArcWake for Task {\n    fn wake_by_ref(arc_self: &amp;Arc&lt;Self&gt;) {\n        // 通过发送任务到任务管道的方式来实现`wake`，这样`wake`后，任务就能被执行器`poll`\n        let cloned = arc_self.clone();\n        arc_self\n            .task_sender\n            .send(cloned)\n            .expect(&quot;任务队列已满&quot;);\n    }\n}\n当任务实现了 ArcWake 特征后，它就变成了 Waker ，在调用 wake() 对其唤醒后会将任务复制一份所有权( Arc )，然后将其发送到任务通道中。最后我们的执行器将从通道中获取任务，然后进行 poll 执行：\nimpl Executor {\n    fn run(&amp;self) {\n        while let Ok(task) = self.ready_queue.recv() {\n            // 获取一个future，若它还没有完成(仍然是Some，不是None)，则对它进行一次poll并尝试完成它\n            let mut future_slot = task.future.lock().unwrap();\n            if let Some(mut future) = future_slot.take() {\n                // 基于任务自身创建一个 `LocalWaker`\n                let waker = waker_ref(&amp;task);\n                let context = &amp;mut Context::from_waker(&amp;*waker);\n                // `BoxFuture&lt;T&gt;`是`Pin&lt;Box&lt;dyn Future&lt;Output = T&gt; + Send + &#039;static&gt;&gt;`的类型别名\n                // 通过调用`as_mut`方法，可以将上面的类型转换成`Pin&lt;&amp;mut dyn Future + Send + &#039;static&gt;`\n                if future.as_mut().poll(context).is_pending() {\n                    // Future还没执行完，因此将它放回任务中，等待下次被poll\n                    *future_slot = Some(future);\n                }\n            }\n        }\n    }\n}\n \n恭喜！我们终于拥有了自己的执行器，下面再来写一段代码使用该执行器去运行之前的定时器 Future ：\nfn main() {\n    let (executor, spawner) = new_executor_and_spawner();\n \n    // 生成一个任务\n    spawner.spawn(async {\n        println!(&quot;howdy!&quot;);\n        // 创建定时器Future，并等待它完成\n        TimerFuture::new(Duration::new(2, 0)).await;\n        println!(&quot;done!&quot;);\n    });\n \n    // drop掉任务，这样执行器就知道任务已经完成，不会再有新的任务进来\n    drop(spawner);\n \n    // 运行执行器直到任务队列为空\n    // 任务运行后，会先打印`howdy!`, 暂停2秒，接着打印 `done!`\n    executor.run();\n}\n执行器和系统 IO\n前面我们一起看过一个使用 Future 从 Socket 中异步读取数据的例子：\npub struct SocketRead&lt;&#039;a&gt; {\n    socket: &amp;&#039;a Socket,\n}\n \nimpl SimpleFuture for SocketRead&lt;&#039;_&gt; {\n    type Output = Vec&lt;u8&gt;;\n \n    fn poll(&amp;mut self, wake: fn()) -&gt; Poll&lt;Self::Output&gt; {\n        if self.socket.has_data_to_read() {\n            // socket有数据，写入buffer中并返回\n            Poll::Ready(self.socket.read_buf())\n        } else {\n            // socket中还没数据\n            //\n            // 注册一个`wake`函数，当数据可用时，该函数会被调用，\n            // 然后当前Future的执行器会再次调用`poll`方法，此时就可以读取到数据\n            self.socket.set_readable_callback(wake);\n            Poll::Pending\n        }\n    }\n}\n该例子中，Future 将从 Socket 读取数据，若当前还没有数据，则会让出当前线程的所有权，允许执行器去执行其它的 Future 。当数据准备好后，会调用 wake() 函数将该 Future 的任务放入任务通道中，等待执行器的 poll 。\n关于该流程已经反复讲了很多次，相信大家应该非常清楚了。然而该例子中还有一个疑问没有解决：\n\nset_readable_callback 方法到底是怎么工作的？怎么才能知道 socket 中的数据已经可以被读取了？\n\n关于第二点，其中一个简单粗暴的方法就是使用一个新线程不停的检查 socket 中是否有了数据，当有了后，就调用 wake() 函数。该方法确实可以满足需求，但是性能着实太低了，需要为每个阻塞的 Future 都创建一个单独的线程！\n在现实世界中，该问题往往是通过操作系统提供的 IO 多路复用机制来完成，例如 Linux 中的 epoll，FreeBSD 和 macOS 中的 kqueue ，Windows 中的 IOCP, Fuchisa中的 ports 等(可以通过 Rust 的跨平台包 mio 来使用它们)。借助 IO 多路复用机制，可以实现一个线程同时阻塞地去等待多个异步 IO 事件，一旦某个事件完成就立即退出阻塞并返回数据。相关实现类似于以下代码：\nstruct IoBlocker {\n    /* ... */\n}\n \nstruct Event {\n    // Event的唯一ID，该事件发生后，就会被监听起来\n    id: usize,\n \n    // 一组需要等待或者已发生的信号\n    signals: Signals,\n}\n \nimpl IoBlocker {\n    /// 创建需要阻塞等待的异步IO事件的集合\n    fn new() -&gt; Self { /* ... */ }\n \n    /// 对指定的IO事件表示兴趣\n    fn add_io_event_interest(\n        &amp;self,\n \n        /// 事件所绑定的socket\n        io_object: &amp;IoObject,\n \n        event: Event,\n    ) { /* ... */ }\n \n    /// 进入阻塞，直到某个事件出现\n    fn block(&amp;self) -&gt; Event { /* ... */ }\n}\n \nlet mut io_blocker = IoBlocker::new();\nio_blocker.add_io_event_interest(\n    &amp;socket_1,\n    Event { id: 1, signals: READABLE },\n);\nio_blocker.add_io_event_interest(\n    &amp;socket_2,\n    Event { id: 2, signals: READABLE | WRITABLE },\n);\nlet event = io_blocker.block();\n \n// 当socket的数据可以读取时，打印 &quot;Socket 1 is now READABLE&quot;\nprintln!(&quot;Socket {:?} is now {:?}&quot;, event.id, event.signals);\n这样，我们只需要一个执行器线程，它会接收 IO 事件并将其分发到对应的 Waker 中，接着后者会唤醒相关的任务，最终通过执行器 poll 后，任务可以顺利地继续执行, 这种 IO 读取流程可以不停的循环，直到 socket 关闭。"},"rust/rust-bible/basic/01-变量的绑定与结构":{"title":"01-变量的绑定与结构","links":[],"tags":[],"content":"手动设置变量可变性\n支持声明可变的变量，要么只支持声明不可变的变量( 例如函数式语言 )，前者为编程提供了灵活性，后者为编程提供了安全性，而 Rust 比较野，选择了两者我都要，既要灵活性又要安全性。\n运行性能上的提升，因为将本身无需改变的变量声明为不可变在运行期会避免一些多余的 runtime 检查。\n变量绑定\nlet a = &quot;hello world&quot; 在 Rust 中称为变量绑定，涉及 Rust 最核心的原则——所有权。\n变量可变性\nRust 的变量在默认情况下是不可变的，可通过 mut 关键字让变量变为可变。\n一个变量往往被多处代码所使用，其中一部分代码假定该变量的值永远不会改变，而另外一部分代码却无情的改变了这个值，在实际开发过程中，这个错误是很难被发现的，特别是在多线程编程中。\n只有你想让你的变量改变时，它才能改变，这样就不会造成心智上的负担，也给别人阅读代码带来便利。\n下划线忽略变量\nfn main() {\n    let _x = 5;\n    let y = 10;\n}\n变量解构\nfn main() {\n    let (a, mut b): (bool,bool) = (true, false);\t// tuple 元组\n    // a = true,不可变; b = false，可变\n    println!(&quot;a = {:?}, b = {:?}&quot;, a, b);\n \n    b = true;\n    assert_eq!(a, b);\n}\n在 Rust 1.59 版本后，我们可以在赋值语句的左式中使用元组、切片和结构体模式了。\n变量和常量间的差异\n\n常量不允许使用 mut。常量不仅仅默认不可变，而且自始至终不可变，因为常量在编译完成后，已经确定它的值。\n常量使用 const 关键字而不是 let 关键字来声明，并且值的类型必须标注。\n\n常量可以在任意作用域内声明，包括全局作用域，在声明的作用域内，常量在程序运行的整个过程中都有效。\n变量遮蔽\nRust 允许声明相同的变量名，在后面声明的变量会遮蔽掉前面声明的；\n变量遮蔽的用处在于，如果你在某个作用域内无需再使用之前的变量（在被遮蔽后，无法再访问到之前的同名变量），就可以重复的使用变量名字，而不用绞尽脑汁去想更多的名字"},"rust/rust-bible/basic/02-数据类型":{"title":"02-数据类型","links":[],"tags":[],"content":"基本类型\n\n数值类型: 有符号整数 (i8, i16, i32, i64, isize)、 无符号整数 (u8, u16, u32, u64, usize) 、浮点数 (f32, f64)、以及有理数、复数\n字符串：字符串字面量和字符串切片 &amp;str\n布尔类型： true和false\n字符类型: 表示单个 Unicode 字符，存储为 4 个字节\n单元类型: 即 () ，其唯一的值也是 ()\n\n类型推导与标注\n数值类型\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n长度有符号类型无符号类型8 位i8u816 位i16u1632 位i32u3264 位i64u64128 位i128u128视架构而定isizeusize\n类型定义的形式统一为：有无符号 + 类型大小(位数)。无符号数表示数字只能取正数，而有符号则表示数字既可以取正数又可以取负数。\n整型字面量可以用下表的形式书写：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n数字字面量示例十进制98_222十六进制0xff八进制0o77二进制0b1111_0000字节 (仅限于 u8)b&#039;A&#039;\nRust 整型默认使用 i32，该类型也往往是性能最好的。\n整型溢出\n假设有一个 u8 ，它可以存放从 0 到 255 的值。那么当你将其修改为范围之外的值，比如 256，则会发生整型溢出。\n要显式处理可能的溢出，可以使用标准库针对原始数字类型提供的这些方法：\n\n使用 wrapping_* 方法在所有模式下都按照补码循环溢出规则处理，例如 wrapping_add\n如果使用 checked_* 方法时发生溢出，则返回 None 值\n使用 overflowing_* 方法返回该值和一个指示是否存在溢出的布尔值\n使用 saturating_* 方法使值达到最小值或最大值\n\n浮点类型\n默认浮点类型是 f64，在现代的 CPU 中它的速度与 f32 几乎相同，但精度更高。\n浮点数陷阱\n\n浮点数往往是你想要数字的近似表达；\n浮点数在某些特性上是反直觉的；\n\n因为 f32 ， f64 上的比较运算实现的是 std::cmp::PartialEq 特征，并没有实现 std::cmp::Eq 特征。\n\nRust 的 HashMap 数据结构，是一个 KV 类型的 Hash Map 实现，它对于 K 没有特定类型的限制，但是要求能用作 K 的类型必须实现了 std::cmp::Eq 特征，因此这意味着你无法使用浮点数作为 HashMap 的 Key，来存储键值对，但是作为对比，Rust 的整数类型、字符串类型、布尔类型都实现了该特征，因此可以作为 HashMap 的 Key。\n\n为了避免上面说的两个陷阱，需要遵守以下准则：\n\n避免在浮点数上测试相等性\n当结果在数学上可能存在未定义时，需要格外的小心\n\nNaN\n\n\n对于数学上未定义的结果，产生一个特殊的结果 NaN；\n\n\n所有跟 NaN 交互的操作，都会返回一个 NaN，而且 NaN 不能用来比较；\n\n\n数字运算\n位运算\n序列(Range)\nRust 提供了一个非常简洁的方式，用来生成连续的数值，\n\n1..5，生成从 1 到 4 的连续数字，不包含 5 ；\n&#039;a&#039;..=&#039;z&#039;，生成从 ‘a’ 到 ‘z’ 的连续字符，包含 ‘z’；\n\n序列只允许用于数字或字符类型，原因是：它们可以连续，同时编译器在编译期可以检查该序列是否为空，字符和数字值是 Rust 中仅有的可以用于判断是否为空的类型。\n有理数和复数"},"rust/rust-bible/basic/03-字符-布尔-单元类型":{"title":"03-字符-布尔-单元类型","links":[],"tags":[],"content":"字符类型(char)\n由于 Unicode 都是 4 个字节编码，因此字符类型也是占用 4 个字节：\nfn main() {\n    let x = &#039;中&#039;;\n    println!(&quot;字符&#039;中&#039;占用了{}字节的内存大小&quot;,std::mem::size_of_val(&amp;x));\n}\n\nRust 的字符只能用 &#039;&#039; 来表示， &quot;&quot; 是留给字符串的。\n\n布尔(bool\nRust 中的布尔类型有两个可能的值：true 和 false，布尔值占用内存的大小为 1 个字节\n单元类型\n单元类型就是 () ，对，你没看错，就是 () ，唯一的值也是 ()\nmain 函数就返回这个单元类型 ()，你不能说 main 函数无返回值，因为没有返回值的函数在 Rust 中是有单独的定义的：发散函数( diverge function )，顾名思义，无法收敛的函数。"},"rust/rust-bible/basic/04-语句-表达式-函数":{"title":"04-语句-表达式-函数","links":[],"tags":[],"content":"Rust 的函数体是由一系列语句组成，最后由一个表达式来返回值，例如：\nfn add_with_extra(x: i32, y: i32) -&gt; i32 {\n    let x = x + 1; // 语句\n    let y = y + 5; // 语句\n    x + y // 表达式\n}\n语句会执行一些操作但是不会返回一个值，而表达式会在求值后返回一个值。\n语句\n语句没有返回值，因此以下代码是错误的：\nlet b = (let a = 8);\n表达式\n表达式可以成为语句的一部分，例如 let y = 6 中，6 就是一个表达式，它在求值后返回一个值 6；\n调用一个函数是表达式，因为会返回一个值，调用宏也是表达式，用花括号包裹最终返回一个值的语句块也是表达式，总之，能返回值，它就是表达式。\n表达式不能包含分号。一旦你在表达式后加上分号，它就会变成一条语句，再也不会返回一个值。\n表达式如果不返回任何值，会隐式地返回一个 () 单元类型。\n函数\nRust 是强类型语言，每一个函数参数都标识出它的具体类型；\n函数即是表达式，因此可把函数的返回值直接赋给调用者；\n\n无返回值()：单元类型 ()，是一个零长度的元组，表示一个函数没有返回值；\n永不返回的发散函数：当用 ! 作函数返回类型的时候，表示该函数永不返回；\n\nfn clear(text: &amp;mut String) -&gt; () {\n  *text = String::from(&quot;&quot;);\n}\nfn dead_end() -&gt; ! {\n  panic!(&quot;你已经到了穷途末路，崩溃吧！&quot;);\n}"},"rust/rust-bible/basic/05-所有权和借用":{"title":"05-所有权和借用","links":[],"tags":[],"content":"内存管理三种流派：\n\n垃圾回收机制(GC)，在程序运行时不断寻找不再使用的内存，典型代表：Java、Go；\n手动管理内存的分配和释放, 在程序中，通过函数调用的方式来申请和释放内存，典型代表：C++；\n通过所有权来管理内存，编译器在编译时会根据一系列规则进行检查；\n\nRust 即是第三种，最妙的是，这种检查只发生在编译期，因此对于程序运行期，不会有任何性能上的损失。\n所有权原则\n\nRust 中每一个值都被一个变量所拥有，该变量被称为值的所有者\n一个值同时只能被一个变量所拥有，或者说一个值只能拥有一个所有者\n当所有者(变量)离开作用域范围时，这个值将被丢弃(drop)\n\n\n转移所有权仅是复制一份栈中的指针，再将新指针赋予新变量，然后让拥有旧指针的变量失效（限制了对该地址的访问）；\n\n转移所有权\nRust 基本类型都是通过自动拷贝的方式来赋值的，只在栈中操作，完全无需在堆上分配内存。\nlet a = 5;\nlet b = x;\n \nlet s1 = String::from(&quot;hello&quot;);\nlet s2 = s1;\n \nprintln!(&quot;{}, world!&quot;, s1);\n                       ^^ value used here after move\nlet x: &amp;str = &quot;hello, world&quot;;\nlet y = x;\nprintln!(&quot;{},{}&quot;,x,y);\nString 类型不是基本类型，是一个复杂类型，由存储在栈中的堆指针、字符串长度、字符串容量共同组成。\n\n深拷贝会造成性能问题；\n浅拷贝，s1 和 s2 共同拥有一个值（假设允许），二者离开作用域后会 ”二次释放“ ，导致安全漏洞。\n\nRust 的做法是当 s1 赋予 s2 后，Rust 认为 s1 不再有效，因此也无需在 s1 离开作用域后 drop 任何东西，这就是把所有权从 s1 转移给了 s2，s1 在被赋予 s2 后就马上失效了。\n因为 Rust 同时使第一个变量 s1 无效了，因此这个操作被称为 移动(move)，而不是浅拷贝。\n如果是字符串字面量，则不会出现移动现象，x 只是引用了存储在二进制中的字符串 &quot;hello, world&quot;，并没有持有所有权。\n克隆(深拷贝)\nRust 永远也不会自动创建数据的 “深拷贝”；\n若需要深度复制 String 中堆上的数据，而不仅仅是栈上的数据，可以使用一个叫做 clone 的方法：\nlet s1 = String::from(&quot;hello&quot;);\nlet s2 = s1.clone();\n \nprintln!(&quot;s1 = {}, s2 = {}&quot;, s1, s2);\n拷贝(浅拷贝)\n浅拷贝只发生在栈上，因此性能很高；\n基本类型在编译时是已知大小的，会被存储在栈上，理解成在栈上做了深拷贝，这很快。\n这里调用 clone 并不会与通常的浅拷贝有什么不同。\nRust 中存在一个 Copy 的特征，可以用在类似整型这样在栈中存储的类型。如果一个类型拥有 Copy 特征，一个旧的变量在被赋值给其他变量后仍然可用。\n任何基本类型的组合可以 Copy ，不需要分配内存或某种形式资源的类型是可以 Copy 的；\n函数传值与返回\n将值传递给函数，一样会发生 移动 或者 复制；\nfn main() {\n    let s = String::from(&quot;hello&quot;);  // s 进入作用域\n \n    takes_ownership(s);             // s 的值移动到函数里 ...\n                                    // ... 所以到这里不再有效\n \n    let x = 5;                      // x 进入作用域\n \n    makes_copy(x);                  // x 应该移动函数里，\n                                    // 但 i32 是 Copy 的，所以在后面可继续使用 x\n \n} // 这里, x 先移出了作用域，然后是 s。但因为 s 的值已被移走，\n  // 所以不会有特殊操作\n \nfn takes_ownership(some_string: String) { // some_string 进入作用域\n    println!(&quot;{}&quot;, some_string);\n} // 这里，some_string 移出作用域并调用 `drop` 方法。占用的内存被释放\n \nfn makes_copy(some_integer: i32) { // some_integer 进入作用域\n    println!(&quot;{}&quot;, some_integer);\n} // 这里，some_integer 移出作用域（在栈上）。不会有特殊操作\n函数返回值也有所有权：\nfn main() {\n    let s1 = gives_ownership();         // gives_ownership 将返回值\n                                        // 移给 s1\n \n    let s2 = String::from(&quot;hello&quot;);     // s2 进入作用域\n \n    let s3 = takes_and_gives_back(s2);  // s2 被移动到\n                                        // takes_and_gives_back 中,\n                                        // 它也将返回值移给 s3\n} // 这里, s3 移出作用域并被丢弃。s2 也移出作用域，但已被移走，\n  // 所以什么也不会发生。s1 移出作用域并被丢弃\n \nfn gives_ownership() -&gt; String {             // gives_ownership 将返回值移动给\n                                             // 调用它的函数\n \n    let some_string = String::from(&quot;hello&quot;); // some_string 进入作用域.\n \n    some_string                              // 返回 some_string 并移出给调用的函数\n}\n \n// takes_and_gives_back 将传入字符串并返回该值\nfn takes_and_gives_back(a_string: String) -&gt; String { // a_string 进入作用域\n \n    a_string  // 返回 a_string 并移出给调用的函数\n}\n麻烦： 总是把一个值传来传去来使用它。"},"rust/rust-bible/basic/06-引用与借用":{"title":"06-引用与借用","links":[],"tags":[],"content":"所有权会导致变量在使用过程中被移动来移动去，Rust 通过 借用(Borrowing) 这个概念来来解决该问题，获取变量的引用，称之为借用(borrowing)。\n引用与解引用\n常规引用是一个指针类型，指向了对象存储的内存地址；\nfn main() {\n    let x = 5;\n    let y = &amp;x;\t\t\t// 获取引用\n \n    assert_eq!(5, x);\n    assert_eq!(5, *y);\t// 解引用\n}\n变量被引用借走后，就不能再通过其本身进行赋值改变了，以防止数据竞争和其他错误：\nfn main() {\n    let mut x = 1;\n    let y = &amp;mut x;\n    x = 2;\n    ^^^^^ `x` is assigned to here but it was already borrowed\n    *y = 3;\n}\n不可变引用\n引用，但并不拥有这个值，当引用离开作用域后，其指向的值也不会被丢弃。\n并且，引用指向的值默认也是不可变的：\nlet s = String::from(&quot;hello&quot;);\nchange(&amp;s);\n \nfn change(some_string: &amp;String) {\n    some_string.push_str(&quot;, world&quot;);\t// cannot borrow `*some_string` as mutable\n}\n可变引用\n声明 s 是可变类型，其次创建一个可变的引用：\nlet mut s = String::from(&quot;hello&quot;);\nchange(&amp;mut s);\n唯一的可变引用\n同一作用域，特定数据只能有一个可变引用：\nlet mut s = String::from(&quot;hello&quot;);\n \nlet r1 = &amp;mut s;\nlet r2 = &amp;mut s;\n \nprintln!(&quot;{}, {}&quot;, r1, r2);\t// cannot borrow `s` as mutable more than once at a time\n大括号可以解决一些编译不通过的问题，通过手动限制变量的作用域；\n{\n    let r1 = &amp;mut s;\n} // r1 在这里离开了作用域，所以我们完全可以创建一个新的引用\nlet r2 = &amp;mut s;\n可变与不可变引用不可共存\n不可变引用可存在多个，而可变引用可有多个，但是不可变与可变不能共存：\nlet mut s = String::from(&quot;hello&quot;);\n \nlet r1 = &amp;s; // 没问题\nlet r2 = &amp;s; // 没问题\nlet r3 = &amp;mut s; // cannot borrow `s` as mutable because it is also borrowed as immutable\n \nprintln!(&quot;{}, {}, and {}&quot;, r1, r2, r3);\n\nNon-Lexical Lifetimes (NLL)，专门用于找到某个引用在作用域(})结束前就不再被使用的代码位置。\n\n悬垂引用\n指针指向某个值后，这个值被释放掉了，而指针仍然存在，其指向的内存可能不存在任何值或已被其它变量重新使用。\n在 Rust 中编译器杜绝了悬垂引用：获取数据的引用后，编译器可以确保数据不会在引用结束前被释放，要想释放数据，必须先停止其引用的使用。\nfn main() {\n    let reference_to_nothing = dangle();\n}\n \nfn dangle() -&gt; &amp;String {\t// dangle 返回一个字符串的引用\n    \t\t\t^ expected named lifetime parameter\n    let s = String::from(&quot;hello&quot;);\t// s 是一个新字符串\n    &amp;s\t// 返回字符串 s 的引用\n}\t// 这里 s 离开作用域并被丢弃。其内存被释放。\n解决方法是直接返回 String，其所有权被转移给外面的调用者。"},"rust/rust-bible/basic/07-字符串与切片":{"title":"07-字符串与切片","links":[],"tags":[],"content":"切片\n切片是一个通用的概念，允许你引用集合中部分连续的元素序列，而不是引用整个集合。\nlet s = String::from(&quot;hello&quot;);\n \nlet slice = &amp;s[0..2];\nlet slice = &amp;s[..2];\n\n在对字符串使用切片语法时需要格外小心，切片的索引必须落在字符之间的边界位置，也就是 UTF-8 字符的边界。\n\n字符串切片的类型标识是 &amp;str，\n其它切片\nlet a = [1, 2, 3, 4, 5];\nlet slice = &amp;a[1..3];\n字符串字面量是切片\nlet s: &amp;str = &quot;Hello, world!&quot;;\n该切片指向了程序可执行文件中的某个点，这也是为什么字符串字面量是不可变的，因为 &amp;str 是一个不可变引用。\nRust 在语言级别，只有一种字符串类型： str，它通常是以引用类型出现 &amp;str；\nstr 类型是硬编码进可执行文件，也无法被修改，但是 String 则是一个可增长、可改变且具有所有权的 UTF-8 编码字符串；\nString 与 &amp;str 的转换\n从 &amp;str 类型生成 String 类型的操作：\n\nString::from(&quot;hello,world&quot;)\n&quot;hello,world&quot;.to_string()\n\nString 类型转为 &amp;str 类型，取引用即可：\nfn main() {\n    let s = String::from(&quot;hello,world!&quot;);\n    say_hello(&amp;s);\n    say_hello(&amp;s[..]);\n    say_hello(s.as_str());\n}\n \nfn say_hello(s: &amp;str) {\n    println!(&quot;{}&quot;,s);\n}\n字符串索引\n字符串的底层的数据存储格式实际上是[ u8 ]，一个字节数组；\nlet hello = String::from(&quot;Chinese&quot;);\t// 7个字节\nlet world = String::from(&quot;中国人&quot;);\t  // 9个字节\nlet h = hello[0];\n        ^^^^^ `String` cannot be indexed by `{integer}`\n无法使用索引的方式访问字符串的某个字符或者子串；\n因为索引操作，我们总是期望它的性能表现是 O(1)，然而对于 String 类型来说，无法保证这一点，因为 Rust 可能需要从 0 开始去遍历字符串来定位合法的字符。\n操作字符串\n追加 (Push)\n在原有的字符串上追加，并不会返回新的字符串，需要字符串必须是可变的，即字符串变量必须由 mut 关键字修饰：\nlet mut s = String::from(&quot;Hello &quot;);\n \ns.push_str(&quot;rust&quot;);\nprintln!(&quot;追加字符串 push_str() -&gt; {}&quot;, s);\n \ns.push(&#039;!&#039;);\nprintln!(&quot;追加字符 push() -&gt; {}&quot;, s);\n \n插入 (Insert)\n修改原来的字符串，则该字符串必须是可变的，即字符串变量必须由 mut 关键字修饰：\nlet mut s = String::from(&quot;Hello rust!&quot;);\ns.insert(5, &#039;,&#039;);\nprintln!(&quot;插入字符 insert() -&gt; {}&quot;, s);\ns.insert_str(6, &quot; I like&quot;);\nprintln!(&quot;插入字符串 insert_str() -&gt; {}&quot;, s);\n替换 (Replace)\n\nreplace：返回一个新的字符串；\nreplacen：适用于 String 和 &amp;str 类型，返回一个新的字符串，可指定替换的个数；\nreplace_range：仅适用于 String 类型，直接操作原来的字符串\n\n删除 (Delete)\n\npop —— 删除并返回字符串的最后一个字符，直接操作原来的字符串；\nremove —— 删除并返回字符串中指定位置的字符，直接操作原来的字符串；存在返回值，其返回值是删除位置的字符串；\ntruncate —— 删除字符串中从指定位置开始到结尾的全部字符；是直接操作原来的字符串，无返回值；\nclear —— 清空字符串，直接操作原来的字符串。\n\n连接 (Concatenate)\n\n使用 + 或者 += 连接字符串：\n\n右边的参数必须为字符串的切片（Slice）引用类型；\n+ 和 += 都是返回一个新的字符串。变量声明不需要 mut 关键字修饰；\n\n\n\nfn main() {\n    let string_append = String::from(&quot;hello &quot;);\n    let string_rust = String::from(&quot;rust&quot;);\n    // &amp;string_rust会自动解引用为&amp;str，\n    // 在下句中，string_append 的所有权被转移走了，因此后面不能再使用\n    let result = string_append + &amp;string_rust;\n    let mut result = result + &quot;!&quot;;\n    result += &quot;!!!&quot;;\n \n    println!(&quot;连接字符串 + -&gt; {}&quot;, result);\n}\n\n使用 format! 连接字符串：\n\n适用于 String 和 &amp;str，\n\n\n\nfn main() {\n    let s1 = &quot;hello&quot;;\n    let s2 = String::from(&quot;rust&quot;);\n    let s = format!(&quot;{} {}!&quot;, s1, s2);\n    println!(&quot;{}&quot;, s);\n}"},"rust/rust-bible/basic/08-元组":{"title":"08-元组","links":[],"tags":[],"content":"复合类型，长度固定，元素的顺序固定。\nfn main() {\n    let tup: (i32, f64, u8) = (500, 6.4, 1);\n}\n使用模式匹配或者 . 操作符来获取元组中的值：\nlet (x, y, z) = tup;\n \nlet x = tup.0;\nlet y = tup.1;\n可以使用元组返回多个值：\nfn main() {\n    let s1 = String::from(&quot;hello&quot;);\n    let (s2, len) = calculate_length(s1);\n \n    println!(&quot;The length of &#039;{}&#039; is {}.&quot;, s2, len);\n}\n \nfn calculate_length(s: String) -&gt; (String, usize) {\n    let length = s.len(); // len() 返回字符串的长度\n    (s, length)\n}\ncalculate_length 函数接收 s1 字符串的所有权，然后计算字符串的长度，接着把字符串所有权和字符串长度再返回给 s2 和 len 变量。"},"rust/rust-bible/basic/09-结构体":{"title":"09-结构体","links":[],"tags":[],"content":"结构体语法\n一个结构体由几部分组成：\n\n通过关键字 struct 定义\n一个清晰明确的结构体 名称\n几个有名字的结构体 字段\n\nstruct User {\n    active: bool,\n    username: String,\n    email: String,\n    sign_in_count: u64,\n}\n\n初始化实例时，每个字段都需要进行初始化\n初始化时的字段顺序不需要和结构体定义时的顺序一致\n\nlet user1 = User {\n        email: String::from(&quot;someone@example.com&quot;),\n        username: String::from(&quot;someusername123&quot;),\n        active: true,\n        sign_in_count: 1,\n    };\n通过 . 操作符即可访问结构体实例内部的字段值，将结构体实例声明为可变的，则可以修改字段；\n结构体更新语法，类似 js/ts：\nlet user2 = User {\n    email: String::from(&quot;another@example.com&quot;),\n    ..user1\n};\n\nuser1 的部分字段所有权被转移到 user2 中：username 字段发生了所有权转移，作为结果，user1 无法再被使用；但是， user1 内部的其它字段（除了 username，都具有 Copy 特征）能被继续使用。\n\n结构体内存排布\n struct File {\n   name: String,\n   data: Vec&lt;u8&gt;,\n }\nFile 结构体两个字段 name 和 data 分别拥有底层两个 [u8] 数组的所有权(String 类型的底层也是 [u8] 数组)。了解底层，则明白为什么把结构体中具有所有权的字段转移出去后，将无法再访问该字段，但是可以正常访问其它的字段。\n元组结构体(Tuple Struct)\n结构体必须要有名称，但是结构体的字段可以没有名称，这种结构体长得很像元组，因此被称为元组结构体，例如：\nstruct Color(i32, i32, i32);\nstruct Point(i32, i32, i32);\n \nlet black = Color(0, 0, 0);\nlet origin = Point(0, 0, 0);\n元组结构体在你希望有一个整体名称，但是又不关心里面字段的名称时将非常有用；\n单元结构体(Unit-like Struct)\n没有任何字段和属性，如果你定义一个类型，但是不关心该类型的内容, 只关心它的行为时，就可以使用 单元结构体：\nfn main() {\n    struct AlwaysEqual;\n    let subject = AlwaysEqual;\n \n    // 我们不关心 AlwaysEqual 的字段数据，只关心它的行为，\n    // 因此将它声明为单元结构体，然后再为它实现某个特征\n    impl SomeTrait for AlwaysEqual { }\n}\n结构体数据的所有权\n结构体定义中，使用了自身拥有所有权的 String 类型而不是基于引用的 &amp;str 字符串切片类型。我们想要这个结构体拥有它所有的数据，而不是从其它地方借用数据。\n也可以让 User 结构体从其它对象借用数据（使用引用类型），不过这么做，就需要引入**生命周期(lifetimes)**这个新概念（也是一个复杂的概念），简而言之，生命周期能确保结构体的作用范围要比它所借用的数据的作用范围要小。\n使用 #[derive(Debug)] 来打印结构体的信息\n用 #[derive(Debug)] 对结构体进行了标记后，才能使用 println!(&quot;{:?}&quot;, s); 的方式对其进行打印输出，\n否则会报错，提示我们结构体没有实现 Display 特征。\n\n{} 占位符，用于将实现 std::fmt::Display trait 的值格式化为字符串，例如整数、浮点数、字符串等类型。\n{:?} 是另一个占位符，用于将实现 std::fmt::Debug trait 的值格式化为字符串。该占位符将生成一个调试输出，这在编写和调试代码时非常有用。\n{:#?} 是用于 pretty-printing 的占位符。它用于打印出 Rust 数据结构的美观格式，以便更好地查看和理解数据结构。\n\nRust 默认不会为我们实现 Debug 特征，为了实现，有两种方式可以选择：\n\n手动实现\n使用 derive 派生实现\n\n还有一个简单的输出 debug 信息的方法，那就是使用 dbg! 宏，它会拿走表达式的所有权，然后打印出相应的文件名、行号等 debug 信息，当然还有我们需要的表达式的求值结果。除此之外，它最终还会把表达式值的所有权返回！\n\ndbg! 输出到标准错误输出 stderr，而 println! 输出到标准输出 stdout。\n"},"rust/rust-bible/basic/10-枚举":{"title":"10-枚举","links":[],"tags":[],"content":"枚举值\n枚举类型是一个类型，它会包含所有可能的枚举成员, 而枚举值是该类型中的具体某个成员的实例。\n\n枚举值可将数据信息（任何类型）关联到枚举成员上；\n同一个枚举类型下的不同成员还能持有不同的数据类型；\n\nenum PokerCard {\n    Clubs(u8),\n    Spades(u8),\n    Diamonds(char),\n    Hearts(char),\n}\n同一化类型\n无例如某个函数它的功能是接受消息并进行发送，那么用枚举的方式，就可以接收不同的消息，但是用结构体，该函数无法接受多个不同的结构体作为参数，可以将各种消息类型作为一个枚举类型；\nOption 枚举\n在其它编程语言中，往往都有一个 null 关键字，该关键字用于表明一个变量当前的值为空（不是零值，例如整型的零值是 0），也就是不存在值。\n\nTony Hoare， null 的发明者，曾经说过一段非常有名的话：\n我称之为我十亿美元的错误。当时，我在使用一个面向对象语言设计第一个综合性的面向引用的类型系统。我的目标是通过编译器的自动检查来保证所有引用的使用都应该是绝对安全的。不过在设计过程中，我未能抵抗住诱惑，引入了空引用的概念，因为它非常容易实现。就是因为这个决策，引发了无数错误、漏洞和系统崩溃，在之后的四十多年中造成了数十亿美元的苦痛和伤害。\n\n尽管如此，空值的表达依然非常有意义，因为空值表示当前时刻变量的值是缺失的。\n有鉴于此，Rust 吸取了众多教训，决定抛弃 null，而改为使用 Option 枚举变量来表述这种结果。\nOption 枚举包含两个成员，一个成员表示含有值：Some(T), 另一个表示没有值：None，定义如下：\nenum Option&lt;T&gt; {\n    Some(T),\n    None,\n}\n其中 T 是泛型参数，Some(T)表示该枚举成员的数据类型是 T，换句话说，Some 可以包含任何类型的数据。\n一个可能为空的值，要显式的将其放入对应类型的 Option&lt;T&gt; 中。使用这个值时，必须明确的处理值为空的情况。\n只要一个值不是 Option&lt;T&gt; 类型，你就 可以 安全的认定它的值不为空。\n使用match 表达式处理枚举的控制流结构：它会根据枚举的成员运行不同的代码，这些代码可以使用匹配到的值中的数据。\nfn plus_one(x: Option&lt;i32&gt;) -&gt; Option&lt;i32&gt; {\n    match x {\n        None =&gt; None,\n        Some(i) =&gt; Some(i + 1),\n    }\n}\n \nlet five = Some(5);\nlet six = plus_one(five);\nlet none = plus_one(None);"},"rust/rust-bible/basic/11-数组":{"title":"11-数组","links":[],"tags":[],"content":"数组创建\n将多个类型相同的元素依次组合在一起，就是一个数组，具有三要素：\n\n长度固定\n元素必须有相同的类型\n依次线性排列\n\n在 Rust 中，最常用的数组有两种：\n\n速度很快但是长度固定的 array\n可动态增长的但是有性能损耗的 Vector\n\n数组 array 是存储在栈上，性能也会非常优秀。与此对应，动态数组 Vector 是存储在堆上；\nlet a: [i32; 5] = [1, 2, 3, 4, 5];\nlet b = [3; 5];  // b 数组包含 5 个元素，这些元素的初始化值为 3\n \nlet first = a[0]; // 获取a数组第一个元素\nlet second = a[1]; // 获取第二个元素\n \n越界访问\n当你尝试使用索引访问元素时，Rust 将检查你指定的索引是否小于数组长度。如果索引大于或等于数组长度，Rust 会出现 panic；这种检查只能在运行时进行。\n非基础类型数组\nlet a = [String::from(&quot;r&quot;); 8];\n         ^^^^^^^^^^^^^^^^^ the trait `std::marker::Copy` is not implemented for `String`\nprintln!(&quot;{:#?}&quot;, a);\n基本类型在 Rust 中赋值是以 Copy 的形式，复杂类型都没有深拷贝，只能一个个创建。\n正确的写法，应该调用std::array::from_fn\nlet a: [String; 8] = std::array::from_fn(|i| String::from(&quot;r&quot;));\n数组切片\nlet a: [i32; 5] = [1, 2, 3, 4, 5];\n \nlet slice: &amp;[i32] = &amp;a[0..3];\n总结下切片的特点：\n\n切片的长度可以与数组不同，并不是固定的，而是取决于你使用时指定的起始和结束位置\n创建切片的代价非常小，因为切片只是针对底层数组的一个引用\n切片类型[T]拥有不固定的大小，而切片引用类型&amp;[T]则具有固定的大小，因为 Rust 很多时候都需要固定大小数据类型，因此&amp;[T]更有用，&amp;str字符串切片也同理\n\n\n数组类型容易跟数组切片混淆，[T;n]描述了一个数组的类型，而[T]描述了切片的类型；\n切片是对数组的引用，并且可以表示不同大小的数组的一部分。切片类型 [T] 本身不知道其大小，因为其大小是在运行时确定的，它可以引用任意大小的数组。\n例如， 上述代码创建一个指向 5 个整数数组的切片，但实际上它仅引用该数组的前 3 个元素（运行时）；\n在编译时，编译器无法知道切片的大小，因此切片类型 [T] 不具有固定的大小。\n切片引用类型 &amp;[T] 具有固定的大小，因为引用本身的大小是固定的，无论它指向的是什么。\n在 Rust 中，&amp;[T] 类型具有固定的大小，等于指针大小的字节数（通常是 8 个字节），而不是数组大小的字节数。\n\n\n在实际开发中，使用最多的是数组切片[T]，我们往往通过引用的方式去使用&amp;[T]，因为后者有固定的类型大小；\n"},"rust/rust-bible/basic/12-流程控制":{"title":"12-流程控制","links":[],"tags":[],"content":"循环控制\n在 Rust 语言中有三种循环方式：for、while 和 loop；\nfor 元素 in 集合 {\n  // 使用元素干一些你懂我不懂的事情\n}\n注意，使用 for 时我们往往使用集合的引用形式，除非你不想在后面的代码中继续使用该集合（比如我们这里使用了 container 的引用）。如果不使用引用的话，所有权会被转移（move）到 for 语句块中，后面就无法再使用这个集合了)：\nfor item in &amp;container {\n  // ...\n}\n\n对于实现了 copy 特征的数组而言， for item in arr 并不会把 arr 的所有权转移，而是直接对其进行了拷贝，因此循环之后仍然可以使用 arr 。\n\n如果想在循环中，修改该元素，可以使用 mut 关键字：\nfor item in &amp;mut collection {\n  // ...\n}\n总结如下：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n使用方法等价使用方式所有权for item in collectionfor item in IntoIterator::into_iter(collection)转移所有权for item in &amp;collectionfor item in collection.iter()不可变借用for item in &amp;mut collectionfor item in collection.iter_mut()可变借用\n两种循环方式优劣对比\n以下代码，使用了两种循环方式：\n// 第一种\nlet collection = [1, 2, 3, 4, 5];\nfor i in 0..collection.len() {\n  let item = collection[i];\n  // ...\n}\n \n// 第二种\nfor item in collection {\n \n}\n第一种方式是循环索引，然后通过索引下标去访问集合，第二种方式是直接循环集合中的元素，优劣如下：\n\n性能：第一种使用方式中 collection[index] 的索引访问，会因为**边界检查(Bounds Checking)**导致运行时的性能损耗 —— Rust 会检查并确认 index 是否落在集合内，但是第二种直接迭代的方式就不会触发这种检查，因为编译器会在编译时就完成分析并证明这种访问是合法的；\n安全：第一种方式里对 collection 的索引访问是非连续的，存在一定可能性在两次访问之间，collection 发生了变化，导致脏数据产生。而第二种直接迭代的方式是连续访问，因此不存在这种风险；\n\nloop 循环\nloop 就是一个简单的无限循环，你可以在内部实现逻辑通过 break 关键字来控制循环何时结束。\nfn main() {\n    let mut counter = 0;\n \n    let result = loop {\n        counter += 1;\n \n        if counter == 10 {\n            break counter * 2;\n        }\n    };\n \n    println!(&quot;The result is {}&quot;, result);\n}\n\nbreak 可以单独使用，也可以带一个返回值，有些类似 return\nloop 是一个表达式，因此可以返回一个值\n"},"rust/rust-bible/basic/13-模式匹配":{"title":"13-模式匹配","links":[],"tags":[],"content":"match 和 if let\nenum Direction {\n    East,\n    West,\n    North,\n    South,\n}\n \nfn main() {\n    let dire = Direction::South;\n    match dire {\n        Direction::East =&gt; println!(&quot;East&quot;),\n        Direction::North | Direction::South =&gt; {\n            println!(&quot;South or North&quot;);\n        },\n        _ =&gt; println!(&quot;West&quot;),\n    };\n}\n\nmatch 的匹配必须要穷举出所有可能，因此这里用 _ 来代表未列出的所有可能性；\nmatch 的每一个分支都必须是一个表达式，且所有分支的表达式最终返回值的类型必须相同；\nX | Y，类似逻辑运算符 或，代表该分支可以匹配 X 也可以匹配 Y，只要满足一个即可；\n\n每个分支相关联的代码是一个表达式，而表达式的结果值将作为整个 match 表达式的返回值。如果分支有多行代码，那么需要用 {} 包裹，同时最后一行代码需要是一个表达式。\nmatch 本身也是一个表达式，因此可以用它来赋值；\n模式绑定\n模式匹配的另外一个重要功能是从模式中取出绑定的值，例如：\nenum UsState {\n    Alabama,\n    Alaska,\n    // --snip--\n}\n \nenum Coin {\n    Penny,\n    Nickel,\n    Dime,\n    Quarter(UsState), // 25美分硬币\n}\n其中 Coin::Quarter 成员还存放了一个值：美国的某个州（因为在 1999 年到 2008 年间，美国在 25 美分(Quarter)硬币的背后为 50 个州印刷了不同的标记，其它硬币都没有这样的设计）。\n接下来，我们希望在模式匹配中，获取到 25 美分硬币上刻印的州的名称：\nfn value_in_cents(coin: Coin) -&gt; u8 {\n    match coin {\n        Coin::Penny =&gt; 1,\n        Coin::Nickel =&gt; 5,\n        Coin::Dime =&gt; 10,\n        Coin::Quarter(state) =&gt; {\n            println!(&quot;State quarter from {:?}!&quot;, state);\n            25\n        },\n    }\n}\n上面代码中，在匹配 Coin::Quarter(state) 模式时，我们把它内部存储的值绑定到了 state 变量上，因此 state 变量就是对应的 UsState 枚举类型。\n穷尽匹配\n_ 通配符\nif let 匹配\n当你只要匹配一个条件，且忽略其他条件时就用 if let ，否则都用 match。\nlet v = Some(3u8);\n \nmatch v {\n    Some(3) =&gt; println!(&quot;three&quot;),\n    _ =&gt; (),\n}\n \nif let Some(3) = v {\n    println!(&quot;three&quot;);\n}\nmatches!宏\nmatches! 可以将一个表达式跟模式进行匹配，然后返回匹配的结果 true or false。\nenum MyEnum {\n    Foo,\n    Bar\n}\n \nfn main() {\n    let v = vec![MyEnum::Foo, MyEnum::Bar, MyEnum::Foo];\n}\n例如，上述的一个动态数组，如果想对 v 进行过滤，只保留类型是 MyEnum::Foo 的元素，你可能想这么写：\nv.iter().filter(|x| x == MyEnum::Foo);\n但是，实际上这行代码会报错，因为你无法将 x 直接跟一个枚举成员进行比较。常规的做法是使用 matches!：\nv.iter().filter(|x| matches!(x, MyEnum::Foo));\n很简单也很简洁，再来看看更多的例子：\nlet foo = &#039;f&#039;;\nassert!(matches!(foo, &#039;A&#039;..=&#039;Z&#039; | &#039;a&#039;..=&#039;z&#039;));\n \nlet bar = Some(4);\nassert!(matches!(bar, Some(x) if x &gt; 2));\n变量覆盖\n无论是 match 还是 if let，他们都可以在模式匹配时覆盖掉老的值，绑定新的值：\nfn main() {\n   let age = Some(30);\n   println!(&quot;在匹配前，age是{:?}&quot;,age);\n   if let Some(age) = age {\n       println!(&quot;匹配出来的age是{}&quot;,age);\n   }\n \n   println!(&quot;在匹配后，age是{:?}&quot;,age);\n}\ncargo run 运行后输出如下：\n在匹配前，age是Some(30)\n匹配出来的age是30\n在匹配后，age是Some(30)\n可以看出在 if let 中，= 右边 Some(i32) 类型的 age 被左边 i32 类型的新 age 覆盖了，该覆盖一直持续到 if let 语句块的结束。因此第三个 println! 输出的 age 依然是 Some(i32) 类型。\n解构 Option\n使用 Option&lt;T&gt;，是为了从 Some 中取出其内部的 T 值以及处理没有值的情况；\nfn plus_one(x: Option&lt;i32&gt;) -&gt; Option&lt;i32&gt; {\n    match x {\n        None =&gt; None,\n        Some(i) =&gt; Some(i + 1),\n    }\n}\n \nlet five = Some(5);\nlet six = plus_one(five);\nlet none = plus_one(None);\n如果传入的是一个 Some(i32)，则通过模式绑定，把其中的值绑定到变量 i 上，然后返回 i+1 的值，同时用 Some 进行包裹。\nwhile let 条件循环\n一个与 if let 类似的结构是 while let 条件循环，它允许只要模式匹配就一直进行 while 循环。下面展示了一个使用 while let 的例子：\n// Vec是动态数组\nlet mut stack = Vec::new();\n \n// 向数组尾部插入元素\nstack.push(1);\nstack.push(2);\nstack.push(3);\n \n// stack.pop从数组尾部弹出元素\nwhile let Some(top) = stack.pop() {\n    println!(&quot;{}&quot;, top);\n}\n模式\n模式是 Rust 中的特殊语法，它用来匹配类型中的结构和数据，它往往和 match 表达式联用，以实现强大的模式匹配能力。模式一般由以下内容组合而成：\n\n字面值\n解构的数组、枚举、结构体或者元组\n变量\n通配符\n占位符\n\n模式匹配有可驳模式和不可驳模式两种，if let 和 while let 就属于可驳模式匹配。\nlet 语句模式\nlet x = 5;\n这其中，x 也是一种模式绑定，代表将匹配的值绑定到变量 x 上。因此，在 Rust 中，变量名也是一种模式，只不过它比较朴素很不起眼罢了。\n\n变量具有类型，而非枚举类型的变量只有一种情况，尽管 let 是不可驳模式，也能匹配成功。\n\n函数参数\n同理，函数参数也是模式：\nfn foo(x: i32) {\n    // 代码\n}\n其中 x 就是一个模式，你还可以在参数中匹配元组：\nfn print_coordinates(&amp;(x, y): &amp;(i32, i32)) {\n    println!(&quot;Current location: ({}, {})&quot;, x, y);\n}\n \nfn main() {\n    let point = (3, 5);\n    print_coordinates(&amp;point);\n}\n&amp;(3, 5) 会匹配模式 &amp;(x, y)，因此 x 得到了 3，y 得到了 5。\nlet 和 if let\n对于以下代码，编译器会报错：\nlet Some(x) = some_option_value;\n因为右边的值可能不为 Some，而是 None，这种时候就不能进行匹配，也就是上面的代码遗漏了 None 的匹配。\n类似 let , for和match 都必须要求完全覆盖匹配，才能通过编译( 不可驳模式匹配 )。\n但是对于 if let，就可以这样使用：\nif let Some(x) = some_option_value {\n    println!(&quot;{}&quot;, x);\n}\n因为 if let 允许匹配一种模式，而忽略其余的模式 (可驳模式匹配)。"},"rust/rust-bible/basic/14-方法":{"title":"14-方法","links":[],"tags":[],"content":"与其它语言 class 跟方法的联动使用不同，Rust 的方法往往跟结构体、枚举、特征(Trait)一起使用；\n定义方法\nRust 使用 impl 来定义方法，例如以下代码：\nstruct Circle {\n    x: f64,\n    y: f64,\n    radius: f64,\n}\n \nimpl Circle {\n    // new 是 Circle的关联函数，因为它的第一个参数不是self，且new并不是关键字\n    // 这种方法往往用于初始化当前结构体的实例\n    fn new(x: f64, y: f64, radius: f64) -&gt; Circle {\n        Circle {\n            x: x,\n            y: y,\n            radius: radius,\n        }\n    }\n \n    // Circle的方法，&amp;self表示借用当前的Circle结构体\n    fn area(&amp;self) -&gt; f64 {\n        std::f64::consts::PI * (self.radius * self.radius)\n    }\n}\nRust 的对象（结构体）定义和方法定义是分离的，这种数据和使用分离的方式，会给予使用者极高的灵活度。\nself、&amp;self 和 &amp;mut self\n在 area 的签名中，我们使用 &amp;self 替代 circle: &amp;Circle，&amp;self 其实是 self: &amp;Self 的简写（注意大小写）；\n在一个 impl 块内，Self 指代被实现方法的结构体类型，self 指代此类型的实例；\nself 依然有所有权的概念：\n\nself 表示 Circle 的所有权转移到该方法中，这种形式用的较少\n&amp;self 表示该方法对 Circle 的不可变借用\n&amp;mut self 表示可变借用\n\n选择 &amp;self 的理由跟在函数中使用 &amp;Circle 是相同的：我们并不想获取所有权，也无需去改变它，只是希望能够读取结构体中的数据。\n如果想要在方法中去改变当前的结构体，需要将第一个参数改为 &amp;mut self。\n仅仅通过使用 self 作为第一个参数来使方法获取实例的所有权是很少见的，这种使用方式往往用于把当前的对象转成另外一个对象时使用，转换完后，就不再关注之前的对象，且可以防止对之前对象的误调用。\n方法名跟结构体字段名相同\n一般来说，方法跟字段同名，往往适用于实现 getter 访问器，例如:\n\n结构体声明时使用 pub 关键字，整个结构体将被标记为公共的，意味着它可以被其他模块访问；\n没有使用 pub 关键字修饰的结构体属性，默认情况下是私有的；\n\npub struct Rectangle {\n    width: u32,\n    height: u32,\n}\n \nimpl Rectangle {\n    pub fn new(width: u32, height: u32) -&gt; Self {\n        Rectangle { width, height }\n    }\n    pub fn width(&amp;self) -&gt; u32 {\n        return self.width;\n    }\n}\n \nfn main() {\n    let rect1 = Rectangle::new(30, 50);\n    println!(&quot;{}&quot;, rect1.width());\n}\nRust 有一个叫 自动引用和解引用的功能，也就不需要像 C/C++ 中，根据指针和对象的区别使用.和-&gt;。方法调用是 Rust 中少数几个拥有这种行为的地方。\n当使用 object.something() 调用方法时，Rust 会自动为 object 添加 &amp;、&amp;mut 或 * 以便使 object 与方法签名匹配。也就是说，这些代码是等价的：\np1.distance(&amp;p2);\n(&amp;p1).distance(&amp;p2);\n关联函数\n定义在 impl 中且没有 self 的函数被称之为关联函数： 因为它没有 self，起到类似 OOP 中构造函数的效果；\n因为是函数，所以不能用 . 的方式来调用，我们需要用 :: 来调用，例如 let sq = Rectangle::new(3, 3);。这个方法位于结构体的命名空间中：:: 语法用于关联函数和模块创建的命名空间。\n多个 impl 定义\nRust 允许我们为一个结构体定义多个 impl 块；\n为枚举实现方法\nenum Message {\n    Quit,\n    Move { x: i32, y: i32 },\n    Write(String),\n    ChangeColor(i32, i32, i32),\n}\n \nimpl Message {\n    fn call(&amp;self) {\n        // 在这里定义方法体\n    }\n}\n \nfn main() {\n    let m = Message::Write(String::from(&quot;hello&quot;));\n    m.call();\n}"},"rust/rust-bible/basic/15-泛型":{"title":"15-泛型","links":[],"tags":[],"content":"结构体中使用泛型\nstruct Point&lt;T&gt; {\n    x: T,\n    y: T,\n}\n \nfn main() {\n    let integer = Point { x: 5, y: 10 };\n    let float = Point { x: 1.0, y: 4.0 };\n}\n枚举中使用泛型\nenum Option&lt;T&gt; {\n    Some(T),\n    None,\n}\n \nenum Result&lt;T, E&gt; {\n    Ok(T),\n    Err(E),\n}\n方法中使用泛型\nstruct Point&lt;T&gt; {\n    x: T,\n    y: T,\n}\n \nimpl&lt;T&gt; Point&lt;T&gt; {\n    fn x(&amp;self) -&gt; &amp;T {\n        &amp;self.x\n    }\n}\n这里的 Point&lt;T&gt; 不再是泛型声明，而是一个完整的结构体类型，因为我们定义的结构体就是 Point&lt;T&gt; 而不再是 Point；\n为具体的泛型类型实现方法\n对于 Point&lt;T&gt; 类型，你不仅能定义基于 T 的方法，还能针对特定的具体类型，进行方法定义：\nimpl Point&lt;f32&gt; {\n    fn distance_from_origin(&amp;self) -&gt; f32 {\n        (self.x.powi(2) + self.y.powi(2)).sqrt()\n    }\n}\n这段代码意味着 Point&lt;f32&gt; 类型会有一个方法 distance_from_origin，而其他 T 不是 f32 类型的 Point&lt;T&gt; 实例则没有定义此方法。\nconst 泛型\n\n[i32; 2] 和 [i32; 3] 是不同的数组类型；\n以往对数组的处理时，对于每个长度都单独实现一个函数；\nconst 泛型，也就是针对值的泛型，正好可以用于处理数组长度的问题；\n\nfn display_array&lt;T: std::fmt::Debug, const N: usize&gt;(arr: [T; N]) {\n    println!(&quot;{:?}&quot;, arr);\n}\nfn main() {\n    let arr: [i32; 3] = [1, 2, 3];\n    display_array(arr);\n \n    let arr: [i32; 2] = [1, 2];\n    display_array(arr);\n}\nN 这个泛型参数，它是一个基于值（值类型是 usize）的泛型参数！因为它用来替代的是数组的长度。\nconst 泛型要求参数是编译期常量，这样编译器可以在编译时进行计算和优化。\nconst 泛型表达式\nconst fn fibonacci&lt;const N: usize&gt;() -&gt; u32 {\n    match N {\n        0 =&gt; 0,\n        1 =&gt; 1,\n        _ =&gt; fibonacci::&lt;N - 1&gt;() + fibonacci::&lt;N - 2&gt;(),\n    }\n}\n \nfn main() {\n    let result = fibonacci::&lt;10&gt;();\n    println!(&quot;Fibonacci(10) = {}&quot;, result); // 输出 Fibonacci(10) = 55\n}\n泛型的性能\n在 Rust 中泛型是零成本的抽象，意味着你在使用泛型时，完全不用担心性能上的问题。\nRust 是在编译期为泛型对应的多个类型，生成各自的代码，因此损失了编译速度和增大了最终生成文件的大小。\nRust 通过在编译时进行泛型代码的 单态化(monomorphization)来保证效率。单态化是一个通过填充编译时使用的具体类型，将通用代码转换为特定代码的过程。\n这与创建泛型的过程相反，简单理解如下：\nlet integer = Some(5);\nlet float = Some(5.0);\n \n// 单态化后\nenum Option_i32 {\n    Some(i32),\n    None,\n}\nenum Option_f64 {\n    Some(f64),\n    None,\n}\n \nfn main() {\n    let integer = Option_i32::Some(5);\n    let float = Option_f64::Some(5.0);\n}\n "},"rust/rust-bible/basic/16-特征":{"title":"16-特征","links":[],"tags":[],"content":"特征定义了一组可以被共享的行为，只要实现了特征，你就能使用这组行为。类似于面向对象语言中的接口；\n定义特征是把一些方法组合在一起，目的是定义一个实现某些目标所必需的行为的集合。\n为类型实现特征\n \n#![allow(unused)]\nfn main() {\n    pub trait Summary {\n        fn summarize(&amp;self) -&gt; String;\n    }\n    pub struct Tweet {\n        pub author: String, // 作者\n        pub content: String, // 内容\n    }\n \n    impl Summary for Tweet {\n        fn summarize(&amp;self) -&gt; String {\n            format!(&quot;{}发表了推文{}&quot;, self.author, self.content)\n        }\n    }\n \n    pub struct Weibo {\n        pub username: String,\n        pub content: String\n    }\n \n    impl Summary for Weibo {\n        fn summarize(&amp;self) -&gt; String {\n            format!(&quot;{}发表了微博{}&quot;, self.username, self.content)\n        }\n    }\n}\n特征定义与实现的位置(孤儿规则)\n使用 pub 对特征进行标注代表着该特征可以被引入到其他文件中，被实现；\n关于特征实现与定义的位置，有一条非常重要的原则：如果你想要为类型 A 实现特征 T，那么 A 或者 T 至少有一个是在当前作用域中定义的！\n例如我们可以为上面的 Tweet 类型实现标准库中的 Display 特征，这是因为 Tweet 类型定义在当前的作用域中。同时，我们也可以在当前包中为 String 类型实现 Summary 特征，因为 Summary 定义在当前作用域中。\n但是你无法在当前作用域中，为 String 类型实现 Display 特征，因为它们俩都定义在标准库中；\n可以在特征中定义具有默认实现的方法，这样其它类型无需再实现该方法，或者也可以选择重载该方法；\n默认实现允许调用相同特征中的其他方法，哪怕这些方法没有默认实现\n使用特征作为函数参数\npub fn notify(item: &amp;impl Summary) {\n    println!(&quot;Breaking news! {}&quot;, item.summarize());\n}\n该函数接收 实现了Summary特征 的 item 参数；\n特征约束(trait bound)\nimpl Trait ，实际上它只是一个语法糖：\npub fn notify&lt;T: Summary&gt;(item: &amp;T) {\n    println!(&quot;Breaking news! {}&quot;, item.summarize());\n}\n真正的完整书写形式如上所述，形如 T: Summary 被称为特征约束。复杂情况下：\nfn main() {\n    pub fn notify&lt;T: Summary&gt;(item1: &amp;T, item2: &amp;T) {}\n}\n可以类比于接口，可以当作类型进行使用，不过这里使用类似泛型的语法；\n多重约束\npub fn notify(item: &amp;(impl Summary + Display)) {}\n \npub fn notify&lt;T: Summary + Display&gt;(item: &amp;T) {}\nWhere 约束\nfn some_function&lt;T: Display + Clone, U: Clone + Debug&gt;(t: &amp;T, u: &amp;U) -&gt; i32 {}\n \nfn some_function&lt;T, U&gt;(t: &amp;T, u: &amp;U) -&gt; i32\n    where T: Display + Clone,\n          U: Clone + Debug\n{}\n使用特征约束有条件地实现方法或特征\nuse std::fmt::Display;\n \nstruct Pair&lt;T&gt; {\n    x: T,\n    y: T,\n}\n \nimpl&lt;T&gt; Pair&lt;T&gt; {\n    fn new(x: T, y: T) -&gt; Self {\n        Self {\n            x,\n            y,\n        }\n    }\n}\n \nimpl&lt;T: Display + PartialOrd&gt; Pair&lt;T&gt; {\n    fn cmp_display(&amp;self) {\n        if self.x &gt;= self.y {\n            println!(&quot;The largest member is x = {}&quot;, self.x);\n        } else {\n            println!(&quot;The largest member is y = {}&quot;, self.y);\n        }\n    }\n}\ncmp_display 方法，并不是所有的 Pair&lt;T&gt; 结构体对象都可以拥有，只有 T 同时实现了 Display + PartialOrd 的 Pair&lt;T&gt; 才可以拥有此方法；\n有条件地实现特征\n标准库为任何实现了 Display 特征的类型实现了 ToString 特征\nimpl&lt;T: Display&gt; ToString for T {\n    // --snip--\n}\n函数返回中的 impl Trait\n可以通过 impl Trait 来说明一个函数的签名的返回的类型，该返回类型实现了某个特征：\nfn returns_summarizable() -&gt; impl Summary {\n    Weibo {\n        username: String::from(&quot;sunface&quot;),\n        content: String::from(\n            &quot;m1 max太厉害了，电脑再也不会卡&quot;,\n        )\n    }\n}\n这种返回值方式有一个很大的限制：只能有一个具体的类型\n通过 derive 派生特征\n形如 #[derive(Debug)] 的代码已经出现了很多次，这种是一种特征派生语法，被 derive 标记的对象会自动实现对应的默认特征代码，继承相应的功能。\n调用方法需要引入特征\n如果你要使用一个特征的方法，那么你需要将该特征引入当前的作用域中；\nRust 把最常用的标准库中的特征通过 std::prelude 模块提前引入到当前作用域；\n特征对象\nfn main() {\n    fn returns_summarizable(switch: bool) -&gt; impl Summary {\n        if switch {\n            Post {\n                // ...\n            }\n        } else {\n            Weibo {\n                // ...\n            }\n        }\n    }\n}\n其中 Post 和 Weibo 都实现了 Summary 特征，因此上面的函数试图通过返回 impl Summary 来返回这两个类型，但是编译器却无情地报错了，原因是 impl Trait 的返回值类型并不支持多种不同的类型返回；\n为了解决上面的所有问题，Rust 引入了一个概念 —— 特征对象。\n特征对象（trait object）是一种允许以动态方式处理不同类型的对象的机制。它允许你在运行时处理实现了特定特征（trait）的不同类型，并使用统一的接口进行操作。\n特征对象的基本语法是使用 dyn 关键字，后跟特征名称：\ntrait Shape {\n    fn area(&amp;self) -&gt; f64;\n}\n \nstruct Rectangle {\n    width: f64,\n    height: f64,\n}\n \nimpl Shape for Rectangle {\n    fn area(&amp;self) -&gt; f64 {\n        self.width * self.height\n    }\n}\n \nstruct Circle {\n    radius: f64,\n}\n \nimpl Shape for Circle {\n    fn area(&amp;self) -&gt; f64 {\n        std::f64::consts::PI * self.radius * self.radius\n    }\n}\n \nfn print_area(shape: &amp;dyn Shape) {\n    println!(&quot;Area: {}&quot;, shape.area());\n}\n特征对象的动态分发\n泛型是在编译期完成处理的：编译器会为每一个泛型参数对应的具体类型生成一份代码，这种方式是静态分发(static dispatch)，因为是在编译期完成的，对于运行期性能完全没有任何影响。\n与静态分发相对应的是动态分发(dynamic dispatch)，在这种情况下，直到运行时，才能确定需要调用什么方法。特征对象中的关键字 dyn 正是在强调这一“动态”的特点。\n\n特征对象大小不固定；\n几乎总是使用特征对象的引用方式；\n\n特征对象的限制\n不是所有特征都能拥有特征对象，只有对象安全的特征才行。当一个特征的所有方法都有如下属性时，它的对象才是安全的：\n\n方法的返回类型不能是 Self；\n方法没有任何泛型参数；\n"},"rust/rust-bible/basic/17-集合类型":{"title":"17-集合类型","links":["rust/rust-bible/basic/02-数据类型"],"tags":[],"content":"动态数组\n动态数组 Vector 允许你存储多个值，这些值在内存中一个紧挨着另一个排列，因此访问其中某个元素的成本非常低。动态数组只能存储相同类型的元素，如果你想存储不同类型的元素，可以使用之前讲过的枚举类型或者特征对象。\n跟结构体一样，Vector 类型在超出作用域范围后，会被自动删除；当 Vector 被删除后，它内部存储的所有内容也会随之被删除。\n创建动态数组\nlet v: Vec&lt;i32&gt; = Vec::new();\n\n如果预先知道要存储的元素个数，可以使用 Vec::with_capacity(capacity) 创建动态数组，这样可以避免因为插入大量新数据导致频繁的内存分配和拷贝，提升性能；\n\nvec![]\n还可以使用宏 vec! 来创建数组，与 Vec::new 有所不同，前者能在创建同时给予初始化值：\nlet v = vec![1, 2, 3];\n同样，此处的 v 也无需标注类型，编译器只需检查它内部的元素即可自动推导出 v 的类型是 Vec&lt;i32&gt; （Rust 中，整数默认类型是 i32，在数值类型中有详细介绍）。\n更新 Vector\nlet mut v = Vec::new();\nv.push(1);\n从 Vector 中读取元素\nlet v = vec![1, 2, 3, 4, 5];\n// 下标读取\nlet third: &amp;i32 = &amp;v[2];    \nprintln!(&quot;第三个元素是 {}&quot;, third);\n// get 读取\nmatch v.get(2) {\n    Some(third) =&gt; println!(&quot;第三个元素是 {third}&quot;),\n    None =&gt; println!(&quot;去你的第三个元素，根本没有！&quot;),\n}\n下标索引与 .get 的区别\n下标索引读取会发生数组越界访问，get 在内部做了处理，有值的时候返回 Some(T)，无值的时候返回 None；\n同时借用多个数组元素\nlet mut v = vec![1, 2, 3, 4, 5];\n \nlet first = &amp;v[0];\n \nv.push(6);\n \nprintln!(&quot;The first element is: {first}&quot;);\nfirst 不可变借用，v.push可变借用，如果 first 在v.push后没有使用，那么就没问题；\n但是之后还进行了打印；这里可以举一个例子，尽管v.push 操作没有影响到first的打印，但是是有可能的，编译器规避了这种可能。\n遍历 Vector\nlet v = vec![1, 2, 3];\nfor i in &amp;v {\n    println!(&quot;{i}&quot;);\n}\n \nlet mut v = vec![1, 2, 3];\nfor i in &amp;mut v {\n    *i += 10\n}\n枚举存储不同类型的元素\nenum IpAddr {\n    V4(String),\n    V6(String)\n}\nfn main() {\n    let v = vec![\n        IpAddr::V4(&quot;127.0.0.1&quot;.to_string()),\n        IpAddr::V6(&quot;::1&quot;.to_string())\n    ];\n \n    for ip in v {\n        show_addr(ip)\n    }\n}\n \nfn show_addr(ip: IpAddr) {\n    println!(&quot;{:?}&quot;,ip);\n}\n键值对 HashMap\nHashMap 也是 Rust 标准库中提供的集合类型，但是又与动态数组不同，HashMap 中存储的是一一映射的 KV 键值对，并提供了平均复杂度为 O(1) 的查询方法；\n创建 HashMap\nuse std::collections::HashMap;\n \nlet mut map = HashMap::new();\nmap.insert(&quot;红宝石&quot;, 1);\nHashMap 也是内聚性的，即所有的 K 必须拥有同样的类型，V 也是如此。\n使用迭代器和 collect 方法创建\nlet teams_list = vec![\n    (&quot;中国队&quot;.to_string(), 100),\n    (&quot;美国队&quot;.to_string(), 10),\n    (&quot;日本队&quot;.to_string(), 50),\n];\n \nlet mut teams_map = HashMap::new();\nfor team in &amp;teams_list {\n    teams_map.insert(&amp;team.0, team.1);\n}\n \nlet teams_map: HashMap&lt;_,_&gt; = teams_list.into_iter().collect();\n所有权转移\nHashMap 的所有权规则与其它 Rust 类型没有区别：\n\n若类型实现 Copy 特征，该类型会被复制进 HashMap，因此无所谓所有权；\n若没实现 Copy 特征，所有权将被转移给 HashMap 中；\n\n如果你使用引用类型放入 HashMap 中，请确保该引用的生命周期至少跟 HashMap 活得一样久；\n查询 HashMap\nlet mut scores = HashMap::new();\n \nscores.insert(String::from(&quot;Blue&quot;), 10);\nscores.insert(String::from(&quot;Yellow&quot;), 50);\n \nlet team_name = String::from(&quot;Blue&quot;);\nlet score: Option&lt;&amp;i32&gt; = scores.get(&amp;team_name);\n\nget 方法返回一个 Option&lt;&amp;i32&gt; 类型：当查询不到时，会返回一个 None，查询到时返回 Some(&amp;i32)\n&amp;i32 是对 HashMap 中值的借用，如果不使用借用，可能会发生所有权的转移\n\n更新 HashMap 中的值\nfn main() {\n    use std::collections::HashMap;\n \n    let mut scores = HashMap::new();\n \n    scores.insert(&quot;Blue&quot;, 10);\n \n    // 覆盖已有的值\n    let old = scores.insert(&quot;Blue&quot;, 20);\n    assert_eq!(old, Some(10));\n \n    // 查询新插入的值\n    let new = scores.get(&quot;Blue&quot;);\n    assert_eq!(new, Some(&amp;20));\n \n    // 查询Yellow对应的值，若不存在则插入新值\n    let v = scores.entry(&quot;Yellow&quot;).or_insert(5);\n    assert_eq!(*v, 5); // 不存在，插入5\n \n    // 查询Yellow对应的值，若不存在则插入新值\n    let v = scores.entry(&quot;Yellow&quot;).or_insert(50);\n    assert_eq!(*v, 5); // 已经存在，因此50没有插入\n}\n在已有值的基础上更新\nlet text = &quot;hello world wonderful world&quot;;\n \nlet mut map = HashMap::new();\n// 根据空格来切分字符串(英文单词都是通过空格切分)\nfor word in text.split_whitespace() {\n    let count = map.entry(word).or_insert(0);\n    *count += 1;\n}\n\nor_insert 返回了 &amp;mut v 引用，因此可以通过该可变引用直接修改 map 中对应的值\n使用 count 引用时，需要先进行解引用 *count，否则会出现类型不匹配\n"},"rust/rust-bible/basic/18-生命周期":{"title":"18-生命周期","links":[],"tags":[],"content":"生命周期，简而言之就是引用的有效作用域。在大多数时候，我们无需手动的声明生命周期，因为编译器可以自动进行推导。\n悬垂指针和生命周期\n生命周期的主要作用是避免悬垂引用，它会导致程序引用了本不该引用的数据：\n{\n    let r;\n \n    {\n        let x = 5;\n        r = &amp;x;\n    }\n \n    println!(&quot;r: {}&quot;, r);\n}\n此处 r 就是一个悬垂指针，它引用了提前被释放的变量 x；\n函数中的生命周期\nfn longest(x: &amp;str, y: &amp;str) -&gt; &amp;str {\n    if x.len() &gt; y.len() {\n        x\n    } else {\n        y\n    }\n}\n编译器无法知道该函数的返回值到底引用 x 还是 y，即存在多个引用时，编译器有时会无法自动推导生命周期，需要进行手动标注。\n生命周期标注语法\n标记的生命周期只是为了取悦编译器，让编译器不要难为我们；\n生命周期的语法也颇为与众不同，以 &#039; 开头，名称往往是一个单独的小写字母，大多数人都用 &#039;a 来作为生命周期的名称。 如果是引用类型的参数，那么生命周期会位于引用符号 &amp; 之后，并用一个空格来将生命周期和引用参数分隔开:\n&amp;i32        // 一个引用\n&amp;&#039;a i32     // 具有显式生命周期的引用\n&amp;&#039;a mut i32 // 具有显式生命周期的可变引用\n一个生命周期标注，它自身并不具有什么意义，因为生命周期的作用就是告诉编译器多个引用之间的关系。例如，有一个函数，它的第一个参数 first 是一个指向 i32 类型的引用，具有生命周期 &#039;a，该函数还有另一个参数 second，它也是指向 i32 类型的引用，并且同样具有生命周期 &#039;a。此处生命周期标注仅仅说明，这两个参数 first 和 second 至少活得和’a 一样久，至于到底活多久或者哪个活得更久，抱歉我们都无法得知\nfn useless&lt;&#039;a&gt;(first: &amp;&#039;a i32, second: &amp;&#039;a i32) {}\n函数签名中的生命周期标注\nfn longest&lt;&#039;a&gt;(x: &amp;&#039;a str, y: &amp;&#039;a str) -&gt; &amp;&#039;a str {\n    if x.len() &gt; y.len() {\n        x\n    } else {\n        y\n    }\n}\n需要注意的点如下：\n\n和泛型一样，使用生命周期参数，需要先声明 &lt;&#039;a&gt;；\nx、y 和返回值至少活得和 &#039;a 一样久(因为返回值要么是 x，要么是 y)；\n\n\n虽然两个参数的生命周期都是标注了 &#039;a，但是实际上这两个参数的真实生命周期可能是不一样的(生命周期 &#039;a 不代表生命周期等于 &#039;a，而是大于等于 &#039;a)。\n\n在通过函数签名指定生命周期参数时，我们并没有改变传入引用或者返回引用的真实生命周期，而是告诉编译器当不满足此约束条件时，就拒绝编译通过。\n因此 longest 函数并不知道 x 和 y 具体会活多久，只要知道它们的作用域至少能持续 &#039;a 这么长就行。\n当把具体的引用传给 longest 时，那生命周期 &#039;a 的大小就是 x 和 y 的作用域的重合部分，换句话说，&#039;a 的大小将等于 x 和 y 中较小的那个。由于返回值的生命周期也被标记为 &#039;a，因此返回值的生命周期也是 x 和 y 中作用域较小的那个。\nfn main() {\n    let string1 = String::from(&quot;long string is long&quot;);\n \n    {\n        let string2 = String::from(&quot;xyz&quot;);\n        let result = longest(string1.as_str(), string2.as_str());\n        println!(&quot;The longest string is {}&quot;, result);\n    }\n}\n在上例中，string1 的作用域直到 main 函数的结束，而 string2 的作用域到内部花括号的结束 }，那么根据之前的理论，&#039;a 是两者中作用域较小的那个，也就是 &#039;a 的生命周期等于 string2 的生命周期，同理，由于函数返回的生命周期也是 ‘a，可以得出函数返回的生命周期也等于 string2 的生命周期。\n以下代码将报错：\nfn main() {\n    let string1 = String::from(&quot;long string is long&quot;);\n    let result;\n    {\n        let string2 = String::from(&quot;xyz&quot;);\n        result = longest(string1.as_str(), string2.as_str());\n    }\n    println!(&quot;The longest string is {}&quot;, result);\n}\n深入思考生命周期标注\n函数的返回值如果是一个引用类型，那么它的生命周期只会来源于：\n\n函数参数的生命周期\n函数体中某个新建引用的生命周期\n\n第二种会造成垂悬引用，常见的解决方法是将返回值的所有权转出去；\n生命周期语法用来将函数的多个引用参数和返回值的作用域关联到一起，一旦关联到一起后，Rust 就拥有充分的信息来确保我们的操作是内存安全的。\n结构体中的生命周期\nstruct ImportantExcerpt&lt;&#039;a&gt; {\n    part: &amp;&#039;a str,\n}\n该生命周期标注说明，结构体 ImportantExcerpt 所引用的字符串 str 必须比该结构体活得更久。\nstruct ImportantExcerpt&lt;&#039;a&gt; {\n    part: &amp;&#039;a str,\n}\n \nfn main() {\n    let i;\n    {\n        let novel = String::from(&quot;Call me Ishmael. Some years ago...&quot;);\n        let first_sentence = novel.split(&#039;.&#039;).next().expect(&quot;Could not find a &#039;.&#039;&quot;);\n        i = ImportantExcerpt {\n            part: first_sentence,\n        };\n    }\n    println!(&quot;{:?}&quot;,i);\n}\n因为 i 结构体活得比字符串 first_sentence 更久，first_sentence 只在大括号作用域内，上述代码编译报错；\n生命周期消除\n每一个引用类型都有一个生命周期，常规的使用并不需要显式地标识生命周期，这是因为编译器为了简化用户的使用，运用了生命周期消除大法。\n\n消除规则不是万能的，若编译器不能确定某件事是正确时，会直接判为不正确，那么你还是需要手动标注生命周期\n函数或者方法中，参数的生命周期被称为 输入生命周期，返回值的生命周期被称为 输出生命周期\n\n三条消除规则\n\n\n每一个引用参数都会获得独自的生命周期\n例如一个引用参数的函数就有一个生命周期标注: fn foo&lt;&#039;a&gt;(x: &amp;&#039;a i32)，两个引用参数的有两个生命周期标注:fn foo&lt;&#039;a, &#039;b&gt;(x: &amp;&#039;a i32, y: &amp;&#039;b i32), 依此类推。\n\n\n若只有一个输入生命周期(函数参数中只有一个引用类型)，那么该生命周期会被赋给所有的输出生命周期，也就是所有返回值的生命周期都等于该输入生命周期\n例如函数 fn foo(x: &amp;i32) -&gt; &amp;i32，x 参数的生命周期会被自动赋给返回值 &amp;i32，因此该函数等同于 fn foo&lt;&#039;a&gt;(x: &amp;&#039;a i32) -&gt; &amp;&#039;a i32\n\n\n若存在多个输入生命周期，且其中一个是 &amp;self 或 &amp;mut self，则 &amp;self 的生命周期被赋给所有的输出生命周期\n拥有 &amp;self 形式的参数，说明该函数是一个 方法，该规则让方法的使用便利度大幅提升。\n\n\n方法中的生命周期\nstruct ImportantExcerpt&lt;&#039;a&gt; {\n    part: &amp;&#039;a str,\n}\n \nimpl&lt;&#039;a&gt; ImportantExcerpt&lt;&#039;a&gt; {\n    fn level(&amp;self) -&gt; i32 {\n        3\n    }\n}\n\nimpl 中必须使用结构体的完整名称，包括 &lt;&#039;a&gt;，因为生命周期标注也是结构体类型的一部分！\n方法签名中，往往不需要标注生命周期，得益于生命周期消除的第一和第三规则\n\n来看一个例子，以下代码编译器会报错，因为编译器无法知道 &#039;a 和 &#039;b 的关系。 &amp;self 生命周期是 &#039;a，那么 self.part 的生命周期也是 &#039;a，但是编译器不知道 &#039;a 和 &#039;b 的关系：\nimpl&lt;&#039;a&gt; ImportantExcerpt&lt;&#039;a&gt; {\n    fn announce_and_return_part&lt;&#039;b&gt;(&amp;&#039;a self, announcement: &amp;&#039;b str) -&gt; &amp;&#039;b str {\n        println!(&quot;Attention please: {}&quot;, announcement);\n        self.part\n    }\n}\n由于 &amp;&#039;a self 是被引用的一方，因此引用它的 &amp;&#039;b str 必须要活得比它短，否则会出现悬垂引用。因此说明生命周期 &#039;b 必须要比 &#039;a 小。\nimpl&lt;&#039;a: &#039;b, &#039;b&gt; ImportantExcerpt&lt;&#039;a&gt; {\n    fn announce_and_return_part(&amp;&#039;a self, announcement: &amp;&#039;b str) -&gt; &amp;&#039;b str {\n        println!(&quot;Attention please: {}&quot;, announcement);\n        self.part\n    }\n}\n\n&#039;a: &#039;b，是生命周期约束语法，跟泛型约束非常相似，用于说明 &#039;a 必须比 &#039;b 活得久\n可以把 &#039;a 和 &#039;b 都在同一个地方声明（如上），或者分开声明但通过 where &#039;a: &#039;b 约束生命周期关系，如下：\n\nfn main() {\n    impl&lt;&#039;a&gt; ImportantExcerpt&lt;&#039;a&gt; {\n        fn announce_and_return_part&lt;&#039;b&gt;(&amp;&#039;a self, announcement: &amp;&#039;b str) -&gt; &amp;&#039;b str\n        where\n        &#039;a: &#039;b,\n        {\n            println!(&quot;Attention please: {}&quot;, announcement);\n            self.part\n        }\n    }\n}\n静态生命周期\n&#039;static，拥有该生命周期的引用可以和整个程序活得一样久。\n\n生命周期 &#039;static 意味着能和程序活得一样久，例如字符串字面量和特征对象\n实在遇到解决不了的生命周期标注问题，可以尝试 T: &#039;static，有时候它会给你奇迹\n"},"rust/rust-bible/basic/19-返回值与错误处理":{"title":"返回值与错误处理","links":[],"tags":[],"content":"返回值与错误处理\nRust 中的错误主要分为两类：\n\n可恢复错误，通常用于从系统全局角度来看可以接受的错误，例如处理用户的访问、操作等错误，这些错误只会影响某个用户自身的操作进程，而不会对系统的全局稳定性产生影响；\n不可恢复错误，刚好相反，该错误通常是全局性或者系统性的错误，例如数组越界访问，系统启动时发生了影响启动流程的错误等等，这些错误的影响往往对于系统来说是致命的。\n\npanic! 与不可恢复错误\n对于严重到影响程序运行的错误（不可恢复的错误），触发 panic 是很好的解决方式。在 Rust 中触发 panic 有两种方式：被动触发和主动调用；\n被动触发\n如数组越界操作。\n主动调用\n当调用执行panic! 宏时，程序会打印出一个错误信息，展开报错点往前的函数调用堆栈，最后退出程序。\nbacktrace 栈展开\n栈展开(也称栈回溯)，它包含了函数调用的顺序，当然按照逆序排列：最近调用的函数排在列表的最上方\n使用 RUST_BACKTRACE=1 cargo run 或 $env:RUST_BACKTRACE=1 ; cargo run 来运行程序。\npanic 时的两种终止方式\n当出现 panic! 时，程序提供了两种方式来处理终止流程：栈展开和直接终止。\n默认的方式就是 栈展开，这意味着 Rust 会回溯栈上数据和函数调用，因此也意味着更多的善后工作，好处是可以给出充分的报错信息和栈调用信息，便于事后的问题复盘。直接终止，顾名思义，不清理数据就直接退出程序，善后工作交与操作系统来负责。\n例如下面的配置修改 Cargo.toml 文件，实现在 release 模式下遇到 panic 直接终止：\n[profile.release]\npanic = &#039;abort&#039;\n线程 panic 后，程序是否会终止？\n长话短说，如果是 main 线程，则程序会终止，如果是其它子线程，该线程会终止，但是不会影响 main 线程。因此，尽量不要在 main 线程中做太多任务，将这些任务交由子线程去做，就算子线程 panic 也不会导致整个程序的结束。\n何时该使用 panic!\n当没有错误发生时，函数返回一个用 Result 类型包裹的值 Ok(T)，当错误时，返回一个 Err(E)。对于 Result 返回我们有很多处理方法，最简单粗暴的就是 unwrap 和 expect，这两个函数非常类似，我们以 unwrap 举例：\nenum Result&lt;T, E&gt; {\n    Ok(T),\n    Err(E),\n}\n下面 parse 方法试图将字符串 &quot;127.0.0.1&quot; 解析为一个 IP 地址类型 IpAddr，它返回一个 Result&lt;IpAddr, E&gt; 类型，如果解析成功，则把 Ok(IpAddr) 中的值赋给 home，如果失败，则不处理 Err(E)，而是直接 panic。\nuse std::net::IpAddr;\nlet home: IpAddr = &quot;127.0.0.1&quot;.parse().unwrap();\n成功则返回值，失败则 panic，总之不进行任何错误处理。\n可恢复的错误 Result\n一种更温和的错误处理方式：Result&lt;T, E&gt;。\nuse std::fs::File;\n \nfn main() {\n    let f = File::open(&quot;hello.txt&quot;);\n    let f = match f {\n        Ok(file) =&gt; file,\n        Err(error) =&gt; {\n            panic!(&quot;Problem opening the file: {:?}&quot;, error)\n        },\n    };\n}\n以上 File::open 返回一个 Result 类型。\n对返回的错误进行处理\n需要对部分错误进行特殊处理，而不是所有错误都直接崩溃：\nlet f = match f {\n    Ok(file) =&gt; file,\n    Err(error) =&gt; match error.kind() {\n        ErrorKind::NotFound =&gt; match File::create(&quot;hello.txt&quot;) {\n            Ok(fc) =&gt; fc,\n            Err(e) =&gt; panic!(&quot;Problem creating the file: {:?}&quot;, e),\n        },\n        other_error =&gt; panic!(&quot;Problem opening the file: {:?}&quot;, other_error),\n    },\n};\n失败就 panic: unwrap 和 expect\n因为 match 的穷尽匹配特性，你总要去处理下 Err 分支。那么有没有办法简化这个过程？有，答案就是 unwrap 和 expect。\n它们的作用就是，如果返回成功，就将 Ok(T) 中的值取出来，如果失败，就直接 panic，真的勇士绝不多 BB，直接崩溃。\nuse std::fs::File;\n \nfn main() {\n    let f = File::open(&quot;hello.txt&quot;).unwrap();\n}\nexpect 跟 unwrap 很像，也是遇到错误直接 panic, 但是会带上自定义的错误提示信息，相当于重载了错误打印的函数：\nuse std::fs::File;\n \nfn main() {\n    let f = File::open(&quot;hello.txt&quot;).expect(&quot;Failed to open hello.txt&quot;);\n}\n传播错误\n实际应用中，大概率会把错误层层上传然后交给调用链的上游函数进行处理，错误传播将极为常见。\nlet mut f = match f {\n    // 打开文件成功，将file句柄赋值给f\n    Ok(file) =&gt; file,\n    // 打开文件失败，将错误返回(向上传播)\n    Err(e) =&gt; return Err(e),\n};\n传播界的大明星：?\nuse std::fs::File;\nuse std::io;\nuse std::io::Read;\n \nfn read_username_from_file() -&gt; Result&lt;String, io::Error&gt; {\n    let mut f = File::open(&quot;hello.txt&quot;)?;\n    let mut s = String::new();\n    f.read_to_string(&amp;mut s)?;\n    Ok(s)\n}\n? 就是一个宏，它的作用跟上面的 match 几乎一模一样。\n如果结果是 Ok(T)，则把 T 赋值给 f，如果结果是 Err(E)，则返回该错误，所以 ? 特别适合用来传播错误。\nfn open_file() -&gt; Result&lt;File, Box&lt;dyn std::error::Error&gt;&gt; {\n    let mut f = File::open(&quot;hello.txt&quot;)?;\n    Ok(f)\n}\n上面代码中 File::open 报错时返回的错误是 std::io::Error 类型，但是 open_file 函数返回的错误类型是 std::error::Error 的特征对象，可以看到一个错误类型通过 ? 返回后，变成了另一个错误类型，这就是 ? 的神奇之处。\n根本原因是在于标准库中定义的 From 特征，该特征有一个方法 from，用于把一个类型转成另外一个类型，? 可以自动调用该方法，然后进行隐式类型转换。因此只要函数返回的错误 ReturnError 实现了 From&lt;OtherError&gt; 特征，那么 ? 就会自动把 OtherError 转换为 ReturnError。\nfn read_username_from_file() -&gt; Result&lt;String, io::Error&gt; {\n    let mut s = String::new();\n \n    File::open(&quot;hello.txt&quot;)?.read_to_string(&amp;mut s)?;\n \n    Ok(s)\n}\n? 还能实现链式调用，File::open 遇到错误就返回，没有错误就将 Ok 中的值取出来用于下一个方法调用；\n? 用于 Option 的返回\n? 不仅仅可以用于 Result 的传播，还能用于 Option 的传播\nResult 通过 ? 返回错误，那么 Option 就通过 ? 返回 None：\nfn first(arr: &amp;[i32]) -&gt; Option&lt;&amp;i32&gt; {\n   let v = arr.get(0)?;\n   Some(v)\n}\n初学者在用 ? 时，老是会犯错，例如写出这样的代码：\nfn first(arr: &amp;[i32]) -&gt; Option&lt;&amp;i32&gt; {\n   arr.get(0)?\n}\n这段代码无法通过编译，切记：? 操作符需要一个变量来承载正确的值，这个函数只会返回 Some(&amp;i32) 或者 None，只有错误值能直接返回，正确的值不行。\n因此 ? 只能用于以下形式：\n\nlet v = xxx()?;\nxxx()?.yyy()?;\n\n带返回值的 main 函数\nuse std::fs::File;\n \nfn main() {\n    let f = File::open(&quot;hello.txt&quot;)?;\n}\n因为 ? 要求 Result&lt;T, E&gt; 形式的返回值，而 main 函数的返回是 ()，因此无法满足，那是不是就无解了呢？\n实际上 Rust 还支持另外一种形式的 main 函数：\nuse std::error::Error;\nuse std::fs::File;\n \nfn main() -&gt; Result&lt;(), Box&lt;dyn Error&gt;&gt; {\n    let f = File::open(&quot;hello.txt&quot;)?;\n \n    Ok(())\n}\n至于 main 函数可以有多种返回值，那是因为实现了 std::process::Termination 特征，目前为止该特征还没进入稳定版 Rust 中。\ntry!\n在 ? 横空出世之前( Rust 1.13 )，Rust 开发者还可以使用 try! 来处理错误，该宏的大致定义如下：\nmacro_rules! try {\n    ($e:expr) =&gt; (match $e {\n        Ok(val) =&gt; val,\n        Err(err) =&gt; return Err(::std::convert::From::from(err)),\n    });\n}\n总之，try! 作为前浪已经死在了沙滩上。"},"rust/rust-bible/basic/20-包与模块":{"title":"20-包与模块","links":[],"tags":[],"content":"概览\nRust 提供了相应概念用于代码的组织管理：\n\n项目(Packages)：一个 Cargo 提供的 feature，可以用来构建、测试和分享包；\n包(Crate)：一个由多个模块组成的树形结构，可以作为三方库进行分发，也可以生成可执行文件进行运行；\n模块(Module)：可以一个文件多个模块，也可以一个文件一个模块，模块可以被认为是真实项目中的代码组织单元；\n\n包 Crate\n对于 Rust 而言，包 Crate 是一个独立的可编译单元，它编译后会生成一个可执行文件或者一个库。\n如 rand 包提供了随机数生成的功能，只需要将该包通过 use rand; 引入到当前项目的作用域中，就可以在项目中使用 rand 的功能：rand::XXX。\n同一个包中不能有同名的类型，但是在不同包中就可以。\n项目 Package\nPackage 翻译成项目，你也可以理解为工程、软件包，Package 中包含有独立的 Cargo.toml 文件，以及因为功能性被组织在一起的一个或多个包。\n一个 Package 只能包含一个库(library)类型的包，但是可以包含多个二进制可执行类型的包。\n二进制 Package\n$ cargo new my-project\nCargo 有一个惯例：cargo new 默认创建二进制包，src/main.rs 是二进制包的根文件，该二进制包的包名跟所属 Package 相同，在这里都是 my-project，所有的代码执行都从该文件中的 fn main() 函数开始。\n库 Package\n$ cargo new my-lib --lib\n库类型的 Package 只能作为三方库被其它项目引用，而不能独立运行，只有之前的二进制 Package 才可以运行。\n典型的 Package 结构\n上面创建的 Package 中仅包含 src/main.rs 文件，意味着它仅包含一个二进制同名包 my-project。如果一个 Package 同时拥有 src/main.rs 和 src/lib.rs，那就意味着它包含两个包：库包和二进制包，这两个包名也都是 my-project —— 都与 Package 同名。\n一个真实项目中典型的 Package，会包含多个二进制包，这些包文件被放在 src/bin 目录下，每一个文件都是独立的二进制包，同时也会包含一个库包，该包只能存在一个 src/lib.rs：\n.\n├── Cargo.toml\n├── Cargo.lock\n├── src\n│   ├── main.rs\n│   ├── lib.rs\n│   └── bin\n│       └── main1.rs\n│       └── main2.rs\n├── tests\n│   └── some_integration_tests.rs\n├── benches\n│   └── simple_bench.rs\n└── examples\n    └── simple_example.rs\n\n唯一库包：src/lib.rs\n默认二进制包：src/main.rs，编译后生成的可执行文件与 Package 同名\n其余二进制包：src/bin/main1.rs 和 src/bin/main2.rs，它们会分别生成一个文件同名的二进制可执行文件\n集成测试文件：tests 目录下\n基准性能测试 benchmark 文件：benches 目录下\n项目示例：examples 目录下\n\n模块 Module\n\n使用 mod 关键字来创建新模块，后面紧跟着模块名称；\n模块可以嵌套；\n模块中可以定义各种 Rust 类型，例如函数、结构体、枚举、特征等；\n所有模块均定义在同一个文件中；\n\nmod front_of_house {\n    mod hosting {\n        fn add_to_waitlist() {}\n \n        fn seat_at_table() {}\n    }\n \n    mod serving {\n        fn take_order() {}\n \n        fn serve_order() {}\n \n        fn take_payment() {}\n    }\n}\n模块树\ncrate\n └── front_of_house\n     ├── hosting\n     │   ├── add_to_waitlist\n     │   └── seat_at_table\n     └── serving\n         ├── take_order\n         ├── serve_order\n         └── take_payment\n父子模块\n用路径引用模块\n想要调用一个函数，就需要知道它的路径，在 Rust 中，这种路径有两种形式：\n\n绝对路径，从包根开始，路径名以包名或者 crate 作为开头\n相对路径，从当前模块开始，以 self，super 或当前模块的标识符作为开头\n\nmod front_of_house {\n    mod hosting {\n        fn add_to_waitlist() {}\n    }\n}\n \npub fn eat_at_restaurant() {\n    // 绝对路径\n    crate::front_of_house::hosting::add_to_waitlist();\n \n    // 相对路径\n    front_of_house::hosting::add_to_waitlist();\n}\n函数 eat_at_restaurant 位于包的根路径，内部使用两种方式进行模块内的函数调用；\n代码可见性\n上面的模块引用实际上是无法正常运行的，因为hosting 模块是私有的，无法在包根进行访问，那么为何 front_of_house 模块就可以访问？因为它和 eat_at_restaurant 同属于一个包根作用域内，同一个模块内的代码自然不存在私有化。\nRust 出于安全的考虑，默认情况下，所有的类型都是私有化的，包括函数、方法、结构体、枚举、常量，是的，就连模块本身也是私有化的。\n在 Rust 中，父模块完全无法访问子模块中的私有项，但是子模块却可以访问父模块、父父..模块的私有项。\npub 关键字\nRust 提供了 pub 关键字，通过它你可以控制模块和模块中指定项的可见性。\n模块可见性不代表模块内部项的可见性，模块的可见性仅仅是允许其它模块去引用它，但是想要引用它内部的项，还得继续将对应的项标记为 pub。\n所以上述的函数引用要想正常运行，需要将模块和函数都指定 pub：\nmod front_of_house {\n    pub mod hosting {\n        pub fn add_to_waitlist() {}\n    }\n}\n使用 super 引用模块\nsuper 代表的是父模块为开始的引用方式，非常类似于文件系统中的 .. 语法；\n使用 self 引用模块\nself 其实就是引用自身模块中的项，也就是说和我们之前章节的代码类似，都调用同一模块中的内容；\n但是它的用处绝非如此；\n结构体和枚举的可见性\n这两个家伙的成员字段拥有完全不同的可见性：\n\n将结构体设置为 pub，但它的所有字段依然是私有的；\n将枚举设置为 pub，它的所有字段也将对外可见；\n\n模块与文件分离\n当模块变多或者变大时，需要将模块放入一个单独的文件中，让代码更好维护。\n例如，把 front_of_house分离到一个单独的文件中 src/front_of_house.rs：\npub mod hosting {\n    pub fn add_to_waitlist() {}\n}\n然后，以下代码在 src/lib.rs 中：\nmod front_of_house;\n \npub use crate::front_of_house::hosting;\n \npub fn eat_at_restaurant() {\n    hosting::add_to_waitlist();\n    hosting::add_to_waitlist();\n    hosting::add_to_waitlist();\n}\n值得注意：\n\nmod front_of_house; 告诉 Rust 从另一个和模块 front_of_house 同名的文件中加载该模块的内容；\n使用绝对路径的方式来引用 hosting 模块：crate::front_of_house::hosting;\n\n现在的代码中，模块的声明和实现是分离的，实现是在单独的 front_of_house.rs 文件中，然后通过 mod front_of_house; 这条声明语句从该文件中把模块内容加载进来。\n因此我们可以认为，模块 front_of_house 的定义还是在 src/lib.rs 中，只不过模块的具体内容被移动到了 src/front_of_house.rs 文件中。\nuse 关键字用来将外部模块中的项引入到当前作用域中来，这样无需冗长的父模块前缀即可调用；\n当一个模块有许多子模块时，我们也可以通过文件夹的方式来组织这些子模块。\n在上述例子中，我们可以创建一个目录 front_of_house，然后在文件夹里创建一个 hosting.rs 文件：\npub fn add_to_waitlist() {}\n如果需要将文件夹作为一个模块，我们需要进行显示指定暴露哪些子模块，否则会报错无法找到模块，两种解决方法：\n\n在 front_of_house 目录里创建一个 mod.rs，如果你使用的 rustc 版本 1.30 之前，这是唯一的方法。\n在 front_of_house 同级目录里创建一个与模块（目录）同名的 rs 文件 front_of_house.rs，在新版本里，更建议使用这样的命名方式来避免项目中存在大量同名的 mod.rs 文件\n\n无论是上述哪个方式创建的文件，其内容都是一样的，你需要定义你的子模块（子模块名与文件名相同）：\npub mod hosting;\n使用 use 及受限可见性\n在 Rust 中，可以使用 use 关键字把路径提前引入到当前作用域中，随后的调用就可以省略该路径，极大地简化了代码。\n基本引入方式\n绝对路径引入模块\nmod front_of_house {\n    pub mod hosting {\n        pub fn add_to_waitlist() {}\n    }\n}\n \nuse crate::front_of_house::hosting;\n相对路径引入模块中的函数\nmod front_of_house {\n    pub mod hosting {\n        pub fn add_to_waitlist() {}\n    }\n}\n \nuse front_of_house::hosting::add_to_waitlist;\n引入模块还是函数\n从使用简洁性来说，引入函数自然是更甚一筹，但是在某些时候，引入模块会更好：\n\n需要引入同一个模块的多个函数\n作用域中存在同名函数\n\n避免同名引用\nuse std::fmt;\nuse std::io;\n \nfn function1() -&gt; fmt::Result {\n    // --snip--\n}\n \nfn function2() -&gt; io::Result&lt;()&gt; {\n    // --snip--\n}\nas 别名引用\nuse std::fmt::Result;\nuse std::io::Result as IoResult;\n \nfn function1() -&gt; Result {\n    // --snip--\n}\n \nfn function2() -&gt; IoResult&lt;()&gt; {\n    // --snip--\n}\n引入项再导出\n外部的模块项被引入到当前模块中时，它的可见性自动被设置为私有的，如果你希望允许其它外部代码引用我们的模块项，那么可以对它进行再导出：\nmod front_of_house {\n    pub mod hosting {\n        pub fn add_to_waitlist() {}\n    }\n}\n \npub use crate::front_of_house::hosting;\n \npub fn eat_at_restaurant() {\n    hosting::add_to_waitlist();\n}\n如上，使用 pub use 即可实现。这里 use 代表引入 hosting 模块到当前作用域，pub 表示将该引入的内容再度设置为可见。\n使用第三方包\n\n修改 Cargo.toml 文件，在 [dependencies] 区域添加一行：rand = &quot;0.8.3&quot;；\n下一步就是在代码中使用：use rand::Rng;\n\nRust 社区已经为我们贡献了大量高质量的第三方包，你可以在 crates.io 或者 lib.rs 中检索和使用，从目前来说查找包更推荐 lib.rs，搜索功能更强大，内容展示也更加合理，但是下载依赖包还是得用crates.io。\n使用 {} 简化引入方式\n对于以下一行一行的引入方式：\nuse std::collections::HashMap;\nuse std::collections::BTreeMap;\nuse std::collections::HashSet;\n \nuse std::cmp::Ordering;\nuse std::io;\n可以使用 {} 来一起引入进来，在大型项目中，使用这种方式来引入，可以减少大量 use 的使用：\nuse std::collections::{HashMap,BTreeMap,HashSet};\nuse std::{cmp::Ordering, io};\n对于下面的同时引入模块和模块中的项：\nuse std::io;\nuse std::io::Write;\n可以使用 {} 的方式进行简化:\nuse std::io::{self, Write};\n上面使用到了模块章节提到的 self 关键字，用来替代模块自身，结合上一节中的 self，可以得出它在模块中的两个用途：\n\nuse self::xxx，表示加载当前模块中的 xxx。此时 self 可省略\nuse xxx::{self, yyy}，表示，加载当前路径下模块 xxx 本身，以及模块 xxx 下的 yyy\n\n使用 * 引入模块下的所有项\n对于之前一行一行引入 std::collections 的方式，我们还可以使用\nuse std::collections::*;\n当使用 * 来引入的时候要格外小心，因为你很难知道到底哪些被引入到了当前作用域中，有哪些会和你自己程序中的名称相冲突；\n在实际项目中，这种引用方式往往用于快速写测试代码，它可以把所有东西一次性引入到 tests 模块中。\n受限的可见性\n如果我们想要让某一项可以在整个包中都可以被使用，那么有两种办法：\n\n在包根中定义一个非 pub 类型的 X(父模块的项对子模块都是可见的，因此包根中的项对模块树上的所有模块都可见)；\n在子模块中定义一个 pub 类型的 Y，同时通过 use 将其引入到包根；\n\nmod a {\n    pub mod b {\n        pub fn c() {\n            println!(&quot;{:?}&quot;,crate::X);\n        }\n        #[derive(Debug)]\n        pub struct Y;\n    }\n}\n \n#[derive(Debug)]\nstruct X;\nuse a::b::Y;\nfn d() {\n    println!(&quot;{:?}&quot;,Y);\n}\n限制可见性语法\npub(crate) 或 pub(in crate::a) 就是限制可见性语法，前者是限制在整个包内可见，后者是通过绝对路径，限制在包内的某个模块内可见，总结一下：\n\npub 意味着可见性无任何限制\npub(crate) 表示在当前包可见\npub(self) 在当前模块可见\npub(super) 在父模块可见\npub(in &lt;path&gt;) 表示在某个路径代表的模块中可见，其中 path 必须是父模块或者祖先模块\n"},"rust/rust-bible/basic/21-注释与文档":{"title":"21-注释与文档","links":[],"tags":[],"content":"注释的种类\n在 Rust 中，注释分为三类：\n\n代码注释，用于说明某一块代码的功能，读者往往是同一个项目的协作开发者\n文档注释，支持 Markdown，对项目描述、公共 API 等用户关心的功能进行介绍，同时还能提供示例代码，目标读者往往是想要了解你项目的人\n包和模块注释，严格来说这也是文档注释中的一种，它主要用于说明当前包和模块的功能，方便用户迅速了解一个项目\n\n代码注释\n行注释 + 块注释\n文档注释\n当查看一个 crates.io 上的包时，往往需要通过它提供的文档来浏览相关的功能特性、使用方式，这种文档就是通过文档注释实现的。\nRust 提供了 cargo doc 的命令，可以用于把这些文档注释转换成 HTML 网页文件，最终展示给用户浏览，这样用户就知道这个包是做什么的以及该如何使用。\n文档注释使用 ///，当然也支持文档块注释 /** ... */， 例如：\n/// `add_one` 将指定值加1\n///\n/// # Examples\n///\n/// ```\n/// let arg = 5;\n/// let answer = my_crate::add_one(arg);\n///\n/// assert_eq!(6, answer);\n/// ```\npub fn add_one(x: i32) -&gt; i32 {\n    x + 1\n}\n\n文档注释需要位于 lib 类型的包中；\n文档注释可以使用 markdown语法！例如 # Examples 的标题，以及代码块高亮；\n被注释的对象需要使用 pub 对外可见，记住：文档注释是给用户看的，内部实现细节不应该被暴露出去；\n\n常用文档标题\n之前我们见到了在文档注释中该如何使用 markdown，其中包括 # Examples 标题。除了这个标题，还有一些常用的，你可以在项目中酌情使用：\n\nPanics：函数可能会出现的异常状况，这样调用函数的人就可以提前规避\nErrors：描述可能出现的错误及什么情况会导致错误，有助于调用者针对不同的错误采取不同的处理方式\nSafety：如果函数使用 unsafe 代码，那么调用者就需要注意一些使用条件，以确保 unsafe 代码块的正常工作\n\n包和模块级别的注释\n除了函数、结构体等 Rust 项的注释，你还可以给包和模块添加注释，需要注意的是，这些注释要添加到包、模块的最上方！\n/*! lib包是world_hello二进制包的依赖包，\n 里面包含了compute等有用模块 */\n \npub mod compute;\n文档测试(Doc Test)\nRust 允许我们在文档注释中写单元测试用例，使用 cargo test 运行测试，这些测试的名字叫 Doc test 文档测试。\n造成 panic 的文档测试\n文档测试中可以使用 panic：\n/// ```rust,should_panic\n/// // panics on division by zero\n/// world_hello::compute::div(10, 0);\n/// ```\n保留测试，隐藏文档\n在某些时候，我们希望保留文档测试的功能，但是又要将某些测试用例的内容从文档中隐藏起来，使用 #注释即可：\n/// ```\n/// # // 使用#开头的行会在文档中被隐藏起来，但是依然会在文档测试中运行\n/// # fn try_main() -&gt; Result&lt;(), String&gt; {\n/// let res = world_hello::compute::try_div(10, 0)?;\n/// # Ok(()) // returning from try_main\n/// # }\n/// # fn main() {\n/// #    try_main().unwrap();\n/// #\n/// # }\n/// ```\npub fn try_div(a: i32, b: i32) -&gt; Result&lt;i32, String&gt; {\n    if b == 0 {\n        Err(String::from(&quot;Divide-by-zero&quot;))\n    } else {\n        Ok(a / b)\n    }\n}\n文档注释中的代码跳转\nRust 在文档注释中还提供了一个非常强大的功能，那就是可以实现对外部项的链接：\n/// `add_one` 返回一个[`Option`]类型\npub fn add_one(x: i32) -&gt; Option&lt;i32&gt; {\n    Some(x + 1)\n}\n此处的 [Option] 就是一个链接，指向了标准库中的 Option 枚举类型，有两种方式可以进行跳转:\n\n在 IDE 中，使用 Command + 鼠标左键(macOS)，CTRL + 鼠标左键(Windows)\n在文档中直接点击链接\n\n除了跳转到标准库，你还可以通过指定具体的路径跳转到自己代码或者其它库的指定项：\npub mod a {\n    /// `add_one` 返回一个[`Option`]类型\n    /// 跳转到[`crate::MySpecialFormatter`]\n    pub fn add_one(x: i32) -&gt; Option&lt;i32&gt; {\n        Some(x + 1)\n    }\n}\n \npub struct MySpecialFormatter;\n如果遇到同名项，可以使用标示类型的方式进行跳转：\n/// 跳转到结构体  [`Foo`](struct@Foo)\npub struct Bar;\n \n/// 跳转到同名函数 [`Foo`](fn@Foo)\npub struct Foo {}\n \n/// 跳转到同名宏 [`foo!`]\npub fn Foo() {}\n \n#[macro_export]\nmacro_rules! foo {\n  () =&gt; {}\n}\n文档搜索别名\nRust 文档支持搜索功能，我们可以为自己的类型定义几个别名，以实现更好的搜索展现，当别名命中时，搜索结果会被放在第一位：\n#[doc(alias = &quot;x&quot;)]\n#[doc(alias = &quot;big&quot;)]\npub struct BigX;\n \n#[doc(alias(&quot;y&quot;, &quot;big&quot;))]\npub struct BigY;"},"rust/rust-bible/basic/22-格式化输出":{"title":"22-格式化输出","links":[],"tags":[],"content":"println!(&quot;Hello&quot;);                 // =&gt; &quot;Hello&quot;\nprintln!(&quot;Hello, {}!&quot;, &quot;world&quot;);   // =&gt; &quot;Hello, world!&quot;\nprintln!(&quot;The number is {}&quot;, 1);   // =&gt; &quot;The number is 1&quot;\nprintln!(&quot;{:?}&quot;, (3, 4));          // =&gt; &quot;(3, 4)&quot;\nprintln!(&quot;{value}&quot;, value=4);      // =&gt; &quot;4&quot;\nprintln!(&quot;{} {}&quot;, 1, 2);           // =&gt; &quot;1 2&quot;\nprintln!(&quot;{:04}&quot;, 42);             // =&gt; &quot;0042&quot; with leading zeros\n可以看到 println! 宏接受的是可变参数，第一个参数是一个字符串常量，它表示最终输出字符串的格式，包含其中形如 {} 的符号是占位符，会被 println! 后面的参数依次替换。\nprint!，println!，format!\n\nprint! 将格式化文本输出到标准输出，不带换行符\nprintln! 同上，但是在行的末尾添加换行符\nformat! 将格式化文本输出到 String 字符串\n\n在实际项目中，最常用的是 println! 及 format!，前者常用来调试输出，后者常用来生成格式化的字符串：\nfn main() {\n    let s = &quot;hello&quot;;\n    println!(&quot;{}, world&quot;, s);\n    let s1 = format!(&quot;{}, world&quot;, s);\n    print!(&quot;{}&quot;, s1);\n    print!(&quot;{}\\n&quot;, &quot;!&quot;);\n}\neprint!，eprintln!\n它们输出到标准错误输出：\neprintln!(&quot;Error: Could not complete task&quot;)\n它们仅应该被用于输出错误信息和进度信息。\n{} 与 {:?}\n\n{} 适用于实现了 std::fmt::Display 特征的类型，用来以更优雅、更友好的方式格式化文本，例如展示给用户\n{:?} 适用于实现了 std::fmt::Debug 特征的类型，用于调试场景\n\n当你在写代码需要调试时，使用 {:?}，剩下的场景，选择 {}。\nDebug 特征\n大多数 Rust 类型都实现了 Debug 特征或者支持派生该特征。\n对于数值、字符串、数组，可以直接使用 {:?} 进行输出，但是对于结构体，需要**派生Debug**特征后，才能进行输出，总之很简单。\nDisplay 特征\n实现了 Display 特征的 Rust 类型并没有那么多，往往需要我们自定义想要的格式化方式：\n没有实现 Display 特征，但是你又不能像派生 Debug 一般派生 Display，只能另寻他法：\n\n使用 {:?} 或 {:#?}\n为自定义类型实现 Display 特征\n使用 newtype 为外部类型实现 Display 特征\n\n{:#?}\n{:#?} 与 {:?} 几乎一样，唯一的区别在于它能更优美地输出内容；\n因此对于 Display 不支持的类型，可以考虑使用 {:#?} 进行格式化，虽然理论上它更适合进行调试输出。\n为自定义类型实现 Display 特征\n如果你的类型是定义在当前作用域中的，那么可以为其实现 Display 特征，即可用于格式化输出：\nstruct Person {\n    name: String,\n    age: u8,\n}\n \nuse std::fmt;\nimpl fmt::Display for Person {\n    fn fmt(&amp;self, f: &amp;mut fmt::Formatter) -&gt; fmt::Result {\n        write!(\n            f,\n            &quot;大佬在上，请受我一拜，小弟姓名{}，年芳{}，家里无田又无车，生活苦哈哈&quot;,\n            self.name, self.age\n        )\n    }\n}\n为外部类型实现 Display 特征\n在 Rust 中，无法直接为外部类型实现外部特征，但是可以使用newtype解决此问题：\nstruct Array(Vec&lt;i32&gt;);\n \nuse std::fmt;\nimpl fmt::Display for Array {\n    fn fmt(&amp;self, f: &amp;mut fmt::Formatter) -&gt; fmt::Result {\n        write!(f, &quot;数组是：{:?}&quot;, self.0)\n    }\n}\nArray 就是我们的 newtype，它将想要格式化输出的 Vec 包裹在内，最后只要为 Array 实现 Display 特征，即可进行格式化输出；\n位置参数\n除了按照依次顺序使用值去替换占位符之外，还能让指定位置的参数去替换某个占位符，例如 {1}，表示用第二个参数替换该占位符(索引从 0 开始)：\nprintln!(&quot;{}{}&quot;, 1, 2); // =&gt;&quot;12&quot;\nprintln!(&quot;{1}{0}&quot;, 1, 2); // =&gt;&quot;21&quot;\n具名参数\n还可以为参数指定名称：\nprintln!(&quot;{argument}&quot;, argument = &quot;test&quot;); // =&gt; &quot;test&quot;\nprintln!(&quot;{name} {}&quot;, 1, name = 2); // =&gt; &quot;2 1&quot;\n需要注意的是：带名称的参数必须放在不带名称参数的后面，例如下面代码将报错：\nprintln!(&quot;{abc} {1}&quot;, abc = &quot;def&quot;, 2);\n格式化参数\n格式化输出，意味着对输出格式会有更多的要求，例如只输出浮点数的小数点后两位：\nlet v = 3.1415926;\n// Display =&gt; 3.14\nprintln!(&quot;{:.2}&quot;, v);\n// Debug =&gt; 3.14\nprintln!(&quot;{:.2?}&quot;, v);\n宽度\n宽度用来指示输出目标的长度，如果长度不够，则进行填充和对齐：\n字符串填充\n字符串格式化默认使用空格进行填充，并且进行左对齐。\n数字填充:符号和 0\n数字格式化默认也是使用空格进行填充，但与字符串左对齐不同的是，数字是右对齐。\n// 宽度是5 =&gt; Hello     5!\nprintln!(&quot;Hello {:5}!&quot;, 5);\n// 显式的输出正号 =&gt; Hello +5!\nprintln!(&quot;Hello {:+}!&quot;, 5);\n// 宽度5，使用0进行填充 =&gt; Hello 00005!\nprintln!(&quot;Hello {:05}!&quot;, 5);\n// 负号也要占用一位宽度 =&gt; Hello -0005!\nprintln!(&quot;Hello {:05}!&quot;, -5);\n对齐\nfn main() {\n    // 以下全部都会补齐5个字符的长度\n    // 左对齐 =&gt; Hello x    !\n    println!(&quot;Hello {:&lt;5}!&quot;, &quot;x&quot;);\n    // 右对齐 =&gt; Hello     x!\n    println!(&quot;Hello {:&gt;5}!&quot;, &quot;x&quot;);\n    // 居中对齐 =&gt; Hello   x  !\n    println!(&quot;Hello {:^5}!&quot;, &quot;x&quot;);\n \n    // 对齐并使用指定符号填充 =&gt; Hello x&amp;&amp;&amp;&amp;!\n    // 指定符号填充的前提条件是必须有对齐字符\n    println!(&quot;Hello {:&amp;&lt;5}!&quot;, &quot;x&quot;);\n}\n精度\n精度可以用于控制浮点数的精度或者字符串的长度\nfn main() {\n    let v = 3.1415926;\n    // 保留小数点后两位 =&gt; 3.14\n    println!(&quot;{:.2}&quot;, v);\n    // 带符号保留小数点后两位 =&gt; +3.14\n    println!(&quot;{:+.2}&quot;, v);\n    // 不带小数 =&gt; 3\n    println!(&quot;{:.0}&quot;, v);\n    // 通过参数来设定精度 =&gt; 3.1416，相当于{:.4}\n    println!(&quot;{:.1$}&quot;, v, 4);\n \n    let s = &quot;hi我是Sunface孙飞&quot;;\n    // 保留字符串前三个字符 =&gt; hi我\n    println!(&quot;{:.3}&quot;, s);\n    // {:.*}接收两个参数，第一个是精度，第二个是被格式化的值 =&gt; Hello abc!\n    println!(&quot;Hello {:.*}!&quot;, 3, &quot;abcdefg&quot;);\n}\n进制\n可以使用 # 号来控制数字的进制输出：\n\n#b, 二进制\n#o, 八进制\n#x, 小写十六进制\n#X, 大写十六进制\nx, 不带前缀的小写十六进制\n\nfn main() {\n    // 二进制 =&gt; 0b11011!\n    println!(&quot;{:#b}!&quot;, 27);\n    // 八进制 =&gt; 0o33!\n    println!(&quot;{:#o}!&quot;, 27);\n    // 十进制 =&gt; 27!\n    println!(&quot;{}!&quot;, 27);\n    // 小写十六进制 =&gt; 0x1b!\n    println!(&quot;{:#x}!&quot;, 27);\n    // 大写十六进制 =&gt; 0x1B!\n    println!(&quot;{:#X}!&quot;, 27);\n \n    // 不带前缀的十六进制 =&gt; 1b!\n    println!(&quot;{:x}!&quot;, 27);\n \n    // 使用0填充二进制，宽度为10 =&gt; 0b00011011!\n    println!(&quot;{:#010b}!&quot;, 27);\n}\n指数\nfn main() {\n    println!(&quot;{:2e}&quot;, 1000000000); // =&gt; 1e9\n    println!(&quot;{:2E}&quot;, 1000000000); // =&gt; 1E9\n}\n指针地址\nlet v= vec![1, 2, 3];\nprintln!(&quot;{:p}&quot;, v.as_ptr()) // =&gt; 0x600002324050\n转义\n有时需要输出 {和}，但这两个字符是特殊字符，需要进行转义：\nfn main() {\n    // &quot;{{&quot; 转义为 &#039;{&#039;   &quot;}}&quot; 转义为 &#039;}&#039;   &quot;\\&quot;&quot; 转义为 &#039;&quot;&#039;\n    // =&gt; Hello &quot;{World}&quot;\n    println!(&quot; Hello \\&quot;{{World}}\\&quot; &quot;);\n \n    // 下面代码会报错，因为占位符{}只有一个右括号}，左括号被转义成字符串的内容\n    // println!(&quot; {{ Hello } &quot;);\n    // 也不可使用 &#039;\\&#039; 来转义 &quot;{}&quot;\n    // println!(&quot; \\{ Hello \\} &quot;)\n}\n在格式化字符串时捕获环境中的值\n在以前，想要输出一个函数的返回值，你需要这么做：\nfn get_person() -&gt; String {\n    String::from(&quot;sunface&quot;)\n}\nfn main() {\n    let p = get_person();\n    println!(&quot;Hello, {}!&quot;, p);                // implicit position\n    println!(&quot;Hello, {0}!&quot;, p);               // explicit index\n    println!(&quot;Hello, {person}!&quot;, person = p);\n}\n问题倒也不大，但是一旦格式化字符串长了后，就会非常冗余，而在 1.58 后，我们可以这么写：\nfn get_person() -&gt; String {\n    String::from(&quot;sunface&quot;)\n}\nfn main() {\n    let person = get_person();\n    println!(&quot;Hello, {person}!&quot;);\n}\n是不是清晰、简洁了很多？甚至还可以将环境中的值用于格式化参数:\nlet (width, precision) = get_format();\nfor (name, score) in get_scores() {\n  println!(&quot;{name}: {score:width$.precision$}&quot;);\n}\n它只能捕获普通的变量，对于更复杂的类型（例如表达式），可以先将它赋值给一个变量或使用以前的 name = expression 形式的格式化参数。"},"rust/rust-bible/disabuse":{"title":"疑难解惑","links":[],"tags":[],"content":"疑难解惑\n函数传参\n\nfn do1(c: String) {}：表示实参会将所有权传递给 c；\nfn do2(c: &amp;String) {}：表示实参的不可变引用（指针）传递给 c，实参需带 &amp; 声明；\nfn do3(c: &amp;mut String) {}：表示实参可变引用（指针）传递给 c，实参需带 let mut 声明，且传入需带 &amp;mut；\nfn do4(mut c: String) {}：表示实参会将所有权传递给 c，且在函数体内 c 是可读可写的，实参无需 mut 声明；\nfn do5(mut c: &amp;mut String) {}：表示实参可变引用指向的值传递给 c，且 c 在函数体内部是可读可写的，实参需带 let mut 声明，且传入需带 &amp;mut；\n\n总结，在函数参数中：\n\n\n冒号左边的部分，如：mut c，这个 mut 是对函数体内部有效；\n\n\n冒号右边的部分，如：&amp;mut String，这个 &amp;mut 是针对外部实参传入时的形式（声明）说明。\n\n\nfn main() {\n    let d1 = &quot;str&quot;.to_string();\n    do1(d1);\n \n    let d2 = &quot;str&quot;.to_string();\n    do2(&amp;d2);\n \n    let mut d3 = &quot;str&quot;.to_string();\n    do3(&amp;mut d3);\n \n    let d4 = &quot;str&quot;.to_string();\n    do4(d4);\n \n    let mut d5 = &quot;str&quot;.to_string();\n    do5(&amp;mut d5);\n}\n \nfn do1(c: String) {}\n \nfn do2(c: &amp;String) {}\n \nfn do3(c: &amp;mut String) {}\n \nfn do4(mut c: String) {}\n \nfn do5(mut c: &amp;mut String) {}"},"rust/rust-bible/practice/basic":{"title":"入门实战：文件搜索工具","links":["rust/rust-bible/advanced/02-函数式编程-迭代器","rust/rust-bible/basic/19-返回值与错误处理","rust/rust-bible/basic/18-生命周期"],"tags":[],"content":"构建一个简单命令行程序\n在前往更高的山峰前，我们应该驻足欣赏下身后的风景，虽然是半览众山不咋小，但总比身在此山中无法窥全貌要强一丢丢。\n在本章中，我们将一起构建一个命令行程序，目标是尽可能帮大家融会贯通之前的学到的知识。\nlinux 系统中的 grep 命令很强大，可以完成各种文件搜索任务，我们肯定做不了那么强大，但是假冒一个伪劣的版本还是可以的，它将从命令行参数中读取指定的文件名和字符串，然后在相应的文件中找到包含该字符串的内容，最终打印出来。\n实现基本功能\n无论功能设计的再怎么花里胡哨，对于一个文件查找命令而言，首先得指定文件和待查找的字符串，它们需要用户从命令行给予输入，然后我们在程序内进行读取。\n接收命令行参数\n国际惯例，先创建一个新的项目 minigrep ，该名字充分体现了我们的自信：就是不如 grep。\ncargo new minigrep\n首先来思考下，如果要传入文件路径和待搜索的字符串，那这个命令该长啥样，我觉得大概率是这样：\ncargo run -- searchstring example-filename.txt\n-- 告诉 cargo 后面的参数是给我们的程序使用的，而不是给 cargo 自己使用，例如 -- 前的 run 就是给它用的。\n接下来就是在程序中读取传入的参数，这个很简单，下面代码就可以：\n// in main.rs\nuse std::env;\n \nfn main() {\n    let args: Vec&lt;String&gt; = env::args().collect();\n    dbg!(args);\n}\n首先通过 use 引入标准库中的 env 包，然后 env::args 方法会读取并分析传入的命令行参数，最终通过 collect 方法输出一个集合类型 Vector。\n可能有同学疑惑，为啥不直接引入 args ，例如 use std::env::args ，这样就无需 env::args 来繁琐调用，直接args.collect() 即可。原因很简单，args 方法只会使用一次，啰嗦就啰嗦点吧，把相同的好名字让给 let args.. 这位大哥不好吗？毕竟人家要出场多次的。\n\n不可信的输入\n所有的用户输入都不可信！不可信！不可信！\n重要的话说三遍，我们的命令行程序也是，用户会输入什么你根本就不知道，例如他输入了一个非 Unicode 字符，你能阻止吗？显然不能，但是这种输入会直接让我们的程序崩溃！\n原因是当传入的命令行参数包含非 Unicode 字符时， std::env::args 会直接崩溃，如果有这种特殊需求，建议大家使用 std::env::args_os，该方法产生的数组将包含 OsString 类型，而不是之前的 String 类型，前者对于非 Unicode 字符会有更好的处理。\n至于为啥我们不用，两个理由，你信哪个：1. 用户爱输入啥输入啥，反正崩溃了，他就知道自己错了，其次 args_os 会引入额外的跨平台复杂性。\n\ncollect 方法其实并不是std::env包提供的，而是迭代器自带的方法(env::args() 会返回一个迭代器)，它会将迭代器消费后转换成我们想要的集合类型，关于迭代器和 collect 的具体介绍，请参考这里。\n最后，代码中使用 dbg! 宏来输出读取到的数组内容，来看看长啥样：\n$ cargo run\n   Compiling minigrep v0.1.0 (file:///projects/minigrep)\n    Finished dev [unoptimized + debuginfo] target(s) in 0.61s\n     Running `target/debug/minigrep`\n[src/main.rs:5] args = [\n    &quot;target/debug/minigrep&quot;,\n]\n \n$ cargo run -- needle haystack\n   Compiling minigrep v0.1.0 (file:///projects/minigrep)\n    Finished dev [unoptimized + debuginfo] target(s) in 1.57s\n     Running `target/debug/minigrep needle haystack`\n[src/main.rs:5] args = [\n    &quot;target/debug/minigrep&quot;,\n    &quot;needle&quot;,\n    &quot;haystack&quot;,\n]\n上面两个版本分别是无参数和两个参数，其中无参数版本实际上也会读取到一个字符串，仔细看，是不是长得很像我们的程序名，Bingo! env::args 读取到的参数中第一个就是程序的可执行路径名。\n存储读取到的参数\n在编程中，给予清晰合理的变量名是一项基本功，咱总不能到处都是 args[1] 、args[2] 这样的糟糕代码吧。\n因此我们需要两个变量来存储文件路径和待搜索的字符串：\nuse std::env;\n \nfn main() {\n    let args: Vec&lt;String&gt; = env::args().collect();\n \n    let query = &amp;args[1];\n    let file_path = &amp;args[2];\n \n    println!(&quot;Searching for {}&quot;, query);\n    println!(&quot;In file {}&quot;, file_path);\n}\n很简单的代码，来运行下：\n$ cargo run -- test sample.txt\n   Compiling minigrep v0.1.0 (file:///projects/minigrep)\n    Finished dev [unoptimized + debuginfo] target(s) in 0.0s\n     Running `target/debug/minigrep test sample.txt`\nSearching for test\nIn file sample.txt\n输出结果很清晰的说明了我们的目标：在文件 sample.txt 中搜索包含 test 字符串的内容。\n事实上，就算作为一个简单的程序，它也太过于简单了，例如用户不提供任何参数怎么办？因此，错误处理显然是不可少的，但是在添加之前，先来看看如何读取文件内容。\n文件读取\n既然读取文件，那么首先我们需要创建一个文件并给予一些内容，来首诗歌如何？“我啥也不是，你呢?”\nI&#039;m nobody! Who are you?\n我啥也不是，你呢？\nAre you nobody, too?\n牛逼如你也是无名之辈吗？\nThen there&#039;s a pair of us - don&#039;t tell!\n那我们就是天生一对，嘘！别说话！\nThey&#039;d banish us, you know.\n你知道，我们不属于这里。\nHow dreary to be somebody!\n因为这里属于没劲的大人物！\nHow public, like a frog\n他们就像青蛙一样呱噪，\nTo tell your name the livelong day\n成天将自己的大名\nTo an admiring bog!\n传遍整个无聊的沼泽！\n在项目根目录创建 poem.txt 文件，并写入如上的优美诗歌(可能翻译的很烂，别打我，哈哈，事实上大家写入英文内容就够了)。\n接下来修改 main.rs 来读取文件内容：\nuse std::env;\nuse std::fs;\n \nfn main() {\n    // --省略之前的内容--\n    println!(&quot;In file {}&quot;, file_path);\n \n    let contents = fs::read_to_string(file_path)\n        .expect(&quot;Should have been able to read the file&quot;);\n \n    println!(&quot;With text:\\n{contents}&quot;);\n}\n首先，通过 use std::fs 引入文件操作包，然后通过 fs::read_to_string 读取指定的文件内容，最后返回的 contents 是 std::io::Result&lt;String&gt; 类型。\n运行下试试，这里无需输入第二个参数，因为我们还没有实现查询功能。\n完美，虽然代码还有很多瑕疵，例如所有内容都在 main 函数，这个不符合软件工程，没有错误处理，功能不完善等。不过没关系，万事开头难，好歹我们成功迈开了第一步。\n好了，是时候重构赚波 KPI 了，读者：are you serious? 这就开始重构了？\n增加模块化和错误处理\n但凡稍微没那么糟糕的程序，都应该具有代码模块化和错误处理，不然连玩具都谈不上。\n梳理我们的代码和目标后，可以整理出大致四个改进点：\n\n单一且庞大的函数。对于 minigrep 程序而言， main 函数当前执行两个任务：解析命令行参数和读取文件。但随着代码的增加，main 函数承载的功能也将快速增加。从软件工程角度来看，一个函数具有的功能越多，越是难以阅读和维护。因此最好的办法是将大的函数拆分成更小的功能单元。\n配置变量散乱在各处。还有一点要考虑的是，当前 main 函数中的变量都是独立存在的，这些变量很可能被整个程序所访问，在这个背景下，独立的变量越多，越是难以维护，因此我们还可以将这些用于配置的变量整合到一个结构体中。\n细化错误提示。 目前的实现中，我们使用 expect 方法来输出文件读取失败时的错误信息，这个没问题，但是无论任何情况下，都只输出 Should have been able to read the file 这条错误提示信息，显然是有问题的，毕竟文件不存在、无权限等等都是可能的错误，一条大一统的消息无法给予用户更多的提示。\n使用错误而不是异常。 假如用户不给任何命令行参数，那我们的程序显然会无情崩溃，原因很简单：index out of bounds，一个数组访问越界的 panic，但问题来了，用户能看懂吗？甚至于未来接收的维护者能看懂吗？因此需要增加合适的错误处理代码，来给予使用者给详细友善的提示。还有就是需要在一个统一的位置来处理所有错误，利人利己！\n\n分离 main 函数\n关于如何处理庞大的 main 函数，Rust 社区给出了统一的指导方案:\n\n将程序分割为 main.rs 和 lib.rs，并将程序的逻辑代码移动到后者内\n命令行解析属于非常基础的功能，严格来说不算是逻辑代码的一部分，因此还可以放在 main.rs 中\n\n这个方案有一个很优雅的名字: 关注点分离 (Separation of Concerns)。简而言之，main.rs 负责启动程序，lib.rs 负责逻辑代码的运行。从测试的角度而言，这种分离也非常合理： lib.rs 中的主体逻辑代码可以得到简单且充分的测试，至于 main.rs ？确实没办法针对其编写额外的测试代码，但是它的代码也很少啊，很容易就能保证它的正确性。\n分离命令行解析\n根据之前的分析，我们需要将命令行解析的代码分离到一个单独的函数，然后将该函数放置在 main.rs 中：\n// in main.rs\nfn main() {\n    let args: Vec&lt;String&gt; = env::args().collect();\n \n    let (query, file_path) = parse_config(&amp;args);\n \n    // --省略--\n}\n \nfn parse_config(args: &amp;[String]) -&gt; (&amp;str, &amp;str) {\n    let query = &amp;args[1];\n    let file_path = &amp;args[2];\n \n    (query, file_path)\n}\n经过分离后，之前的设计目标完美达成，即精简了 main 函数，又将配置相关的代码放在了 main.rs 文件里。\n看起来貌似是杀鸡用了牛刀，但是重构就是这样，一步一步，踏踏实实的前行，否则未来代码多一些后，你岂不是还要再重来一次重构？因此打好项目的基础是非常重要的！\n聚合配置变量\n前文提到，配置变量并不适合分散的到处都是，因此使用一个结构体来统一存放是非常好的选择，这样修改后，后续的使用以及未来的代码维护都将更加简单明了。\nfn main() {\n    let args: Vec&lt;String&gt; = env::args().collect();\n \n    let config = parse_config(&amp;args);\n \n    println!(&quot;Searching for {}&quot;, config.query);\n    println!(&quot;In file {}&quot;, config.file_path);\n \n    let contents = fs::read_to_string(config.file_path)\n        .expect(&quot;Should have been able to read the file&quot;);\n \n    // --snip--\n}\n \nstruct Config {\n    query: String,\n    file_path: String,\n}\n \nfn parse_config(args: &amp;[String]) -&gt; Config {\n    let query = args[1].clone();\n    let file_path = args[2].clone();\n \n    Config { query, file_path }\n}\n值得注意的是，Config 中存储的并不是 &amp;str 这样的引用类型，而是一个 String 字符串，也就是 Config 并没有去借用外部的字符串，而是拥有内部字符串的所有权。clone 方法的使用也可以佐证这一点。大家可以尝试不用 clone 方法，看看该如何解决相关的报错 :D\n\nclone 的得与失\n在上面的代码中，除了使用 clone ，还有其它办法来达成同样的目的，但 clone 无疑是最简单的方法：直接完整的复制目标数据，无需被所有权、借用等问题所困扰，但是它也有其缺点，那就是有一定的性能损耗。\n因此是否使用 clone 更多是一种性能上的权衡，对于上面的使用而言，由于是配置的初始化，因此整个程序只需要执行一次，性能损耗几乎是可以忽略不计的。\n总之，判断是否使用 clone:\n\n是否严肃的项目，玩具项目直接用 clone 就行，简单不好吗？\n要看所在的代码路径是否是热点路径(hot path)，例如执行次数较多的显然就是热点路径，热点路径就值得去使用性能更好的实现方式\n\n\n好了，言归正传，从 C 语言过来的同学可能会觉得上面的代码已经很棒了，但是从 OO 语言角度来说，还差了那么一点意思。\n下面我们试着来优化下，通过构造函数来初始化一个 Config 实例，而不是直接通过函数返回实例，典型的，标准库中的 String::new 函数就是一个范例。\nfn main() {\n    let args: Vec&lt;String&gt; = env::args().collect();\n \n    let config = Config::new(&amp;args);\n \n    // --snip--\n}\n \n// --snip--\n \nimpl Config {\n    fn new(args: &amp;[String]) -&gt; Config {\n        let query = args[1].clone();\n        let file_path = args[2].clone();\n \n        Config { query, file_path }\n    }\n}\n修改后，类似 String::new 的调用，我们可以通过 Config::new 来创建一个实例，看起来代码是不是更有那味儿了 ：）\n错误处理\n回顾一下，如果用户不输入任何命令行参数，我们的程序会怎么样？\n$ cargo run\n   Compiling minigrep v0.1.0 (file:///projects/minigrep)\n    Finished dev [unoptimized + debuginfo] target(s) in 0.0s\n     Running `target/debug/minigrep`\nthread &#039;main&#039; panicked at &#039;index out of bounds: the len is 1 but the index is 1&#039;, src/main.rs:27:21\nnote: run with `RUST_BACKTRACE=1` environment variable to display a backtrace\n结果喜闻乐见，由于 args 数组没有任何元素，因此通过索引访问时，会直接报出数组访问越界的 panic。\n报错信息对于开发者会很明确，但是对于使用者而言，就相当难理解了，下面一起来解决它。\n改进报错信息\n还记得在错误处理章节，我们提到过 panic 的两种用法: 被动触发和主动调用嘛？上面代码的出现方式很明显是被动触发，这种报错信息是不可控的，下面我们先改成主动调用的方式：\n// in main.rs\n // --snip--\n    fn new(args: &amp;[String]) -&gt; Config {\n        if args.len() &lt; 3 {\n            panic!(&quot;not enough arguments&quot;);\n        }\n        // --snip--\n目的很明确，一旦传入的参数数组长度小于 3，则报错并让程序崩溃推出，这样后续的数组访问就不会再越界了。\n$ cargo run\n   Compiling minigrep v0.1.0 (file:///projects/minigrep)\n    Finished dev [unoptimized + debuginfo] target(s) in 0.0s\n     Running `target/debug/minigrep`\nthread &#039;main&#039; panicked at &#039;not enough arguments&#039;, src/main.rs:26:13\nnote: run with `RUST_BACKTRACE=1` environment variable to display a backtrace\n不错，用户看到了更为明确的提示，但是还是有一大堆 debug 输出，这些我们其实是不想让用户看到的。这么看来，想要输出对用户友好的信息, panic 是不太适合的，它更适合告知开发者，哪里出现了问题。\n返回 Result 来替代直接 panic\n那只能祭出之前学过的错误处理大法了，也就是返回一个 Result：成功时包含 Config 实例，失败时包含一条错误信息。\n有一点需要额外注意下，从代码惯例的角度出发，new 往往不会失败，毕竟新建一个实例没道理失败，对不？因此修改为 build 会更加合适。\nimpl Config {\n    fn build(args: &amp;[String]) -&gt; Result&lt;Config, &amp;&#039;static str&gt; {\n        if args.len() &lt; 3 {\n            return Err(&quot;not enough arguments&quot;);\n        }\n \n        let query = args[1].clone();\n        let file_path = args[2].clone();\n \n        Ok(Config { query, file_path })\n    }\n}\n这里的 Result 可能包含一个 Config 实例，也可能包含一条错误信息 &amp;static str，不熟悉这种字符串类型的同学可以回头看看字符串章节，代码中的字符串字面量都是该类型，且拥有 &#039;static 生命周期。\n处理返回的 Result\n接下来就是在调用 build 函数时，对返回的 Result 进行处理了，目的就是给出准确且友好的报错提示, 为了让大家更好的回顾我们修改过的内容，这里给出整体代码：\nuse std::env;\nuse std::fs;\nuse std::process;\n \nfn main() {\n    let args: Vec&lt;String&gt; = env::args().collect();\n \n    // 对 build 返回的 `Result` 进行处理\n    let config = Config::build(&amp;args).unwrap_or_else(|err| {\n        println!(&quot;Problem parsing arguments: {err}&quot;);\n        process::exit(1);\n    });\n \n \n    println!(&quot;Searching for {}&quot;, config.query);\n    println!(&quot;In file {}&quot;, config.file_path);\n \n    let contents = fs::read_to_string(config.file_path)\n        .expect(&quot;Should have been able to read the file&quot;);\n \n    println!(&quot;With text:\\n{contents}&quot;);\n}\n \nstruct Config {\n    query: String,\n    file_path: String,\n}\n \nimpl Config {\n    fn build(args: &amp;[String]) -&gt; Result&lt;Config, &amp;&#039;static str&gt; {\n        if args.len() &lt; 3 {\n            return Err(&quot;not enough arguments&quot;);\n        }\n \n        let query = args[1].clone();\n        let file_path = args[2].clone();\n \n        Ok(Config { query, file_path })\n    }\n}\n上面代码有几点值得注意:\n\n当 Result 包含错误时，我们不再调用 panic 让程序崩溃，而是通过 process::exit(1) 来终结进程，其中 1 是一个信号值(事实上非 0 值都可以)，通知调用我们程序的进程，程序是因为错误而退出的。\nunwrap_or_else 是定义在 Result&lt;T,E&gt; 上的常用方法，如果 Result 是 Ok，那该方法就类似 unwrap：返回 Ok 内部的值；如果是 Err，就调用闭包中的自定义代码对错误进行进一步处理\n\n综上可知，config 变量的值是一个 Config 实例，而 unwrap_or_else 闭包中的 err 参数，它的类型是 &#039;static str，值是 “not enough arguments” 那个字符串字面量。\n运行后，可以看到以下输出：\n$ cargo run\n   Compiling minigrep v0.1.0 (file:///projects/minigrep)\n    Finished dev [unoptimized + debuginfo] target(s) in 0.48s\n     Running `target/debug/minigrep`\nProblem parsing arguments: not enough arguments\n终于，我们得到了自己想要的输出：既告知了用户为何报错，又消除了多余的 debug 信息，非常棒。可能有用户疑惑，cargo run 底下还有一大堆 debug 信息呢，实际上，这是 cargo run 自带的，大家可以试试编译成二进制可执行文件后再调用，会是什么效果。\n分离主体逻辑\n接下来可以继续精简 main 函数，那就是将主体逻辑( 例如业务逻辑 )从 main 中分离出去，这样 main 函数就保留主流程调用，非常简洁。\n// in main.rs\nfn main() {\n    let args: Vec&lt;String&gt; = env::args().collect();\n \n    let config = Config::build(&amp;args).unwrap_or_else(|err| {\n        println!(&quot;Problem parsing arguments: {err}&quot;);\n        process::exit(1);\n    });\n \n    println!(&quot;Searching for {}&quot;, config.query);\n    println!(&quot;In file {}&quot;, config.file_path);\n \n    run(config);\n}\n \nfn run(config: Config) {\n    let contents = fs::read_to_string(config.file_path)\n        .expect(&quot;Should have been able to read the file&quot;);\n \n    println!(&quot;With text:\\n{contents}&quot;);\n}\n \n// --snip--\n如上所示，main 函数仅保留主流程各个环节的调用，一眼看过去非常简洁清晰。\n继续之前，先请大家仔细看看 run 函数，你们觉得还缺少什么？提示：参考 build 函数的改进过程。\n使用 ? 和特征对象来返回错误\n答案就是 run 函数没有错误处理，因为在文章开头我们提到过，错误处理最好统一在一个地方完成，这样极其有利于后续的代码维护。\n//in main.rs\nuse std::error::Error;\n \n// --snip--\n \nfn run(config: Config) -&gt; Result&lt;(), Box&lt;dyn Error&gt;&gt; {\n    let contents = fs::read_to_string(config.file_path)?;\n \n    println!(&quot;With text:\\n{contents}&quot;);\n \n    Ok(())\n}\n值得注意的是这里的 Result&lt;(), Box&lt;dyn Error&gt;&gt; 返回类型，首先我们的程序无需返回任何值，但是为了满足 Result&lt;T,E&gt; 的要求，因此使用了 Ok(()) 返回一个单元类型 ()。\n最重要的是 Box&lt;dyn Error&gt;， 如果按照顺序学到这里，大家应该知道这是一个Error 的特征对象(为了使用 Error，我们通过 use std::error::Error; 进行了引入)，它表示函数返回一个类型，该类型实现了 Error 特征，这样我们就无需指定具体的错误类型，否则你还需要查看 fs::read_to_string 返回的错误类型，然后复制到我们的 run 函数返回中，这么做一个是麻烦，最主要的是，一旦这么做，意味着我们无法在上层调用时统一处理错误，但是 Box&lt;dyn Error&gt; 不同，其它函数也可以返回这个特征对象，然后调用者就可以使用统一的方式来处理不同函数返回的 Box&lt;dyn Error&gt;。\n明白了 Box&lt;dyn Error&gt; 的重要战略地位，接下来大家分析下，fs::read_to_string 返回的具体错误类型是怎么被转化为 Box&lt;dyn Error&gt; 的？其实原因在之前章节都有讲过，这里就不直接给出答案了，参见 ?-传播界的大明星。\n运行代码没任何问题，不过 Rust 编译器也给出了善意的提示，那就是 Result 并没有被使用，这可能意味着存在错误的潜在可能性。\n处理返回的错误\nfn main() {\n    // --snip--\n \n    println!(&quot;Searching for {}&quot;, config.query);\n    println!(&quot;In file {}&quot;, config.file_path);\n \n    if let Err(e) = run(config) {\n        println!(&quot;Application error: {e}&quot;);\n        process::exit(1);\n    }\n}\n先回忆下在 build 函数调用时，我们怎么处理错误的？然后与这里的方式做一下对比，是不是发现了一些区别？\n没错 if let 的使用让代码变得更简洁，可读性也更加好，原因是，我们并不关注 run 返回的 Ok 值，因此只需要用 if let 去匹配是否存在错误即可。\n好了，截止目前，代码看起来越来越美好了，距离我们的目标也只差一个：将主体逻辑代码分离到一个独立的文件 lib.rs 中。\n分离逻辑代码到库包中\n首先，创建一个 src/lib.rs 文件，然后将所有的非 main 函数都移动到其中。代码大概类似：\nuse std::error::Error;\nuse std::fs;\n \npub struct Config {\n    pub query: String,\n    pub file_path: String,\n}\n \nimpl Config {\n    pub fn build(args: &amp;[String]) -&gt; Result&lt;Config, &amp;&#039;static str&gt; {\n        // --snip--\n    }\n}\n \npub fn run(config: Config) -&gt; Result&lt;(), Box&lt;dyn Error&gt;&gt; {\n    // --snip--\n}\n为了内容的简洁性，这里忽略了具体的实现，下一步就是在 main.rs 中引入 lib.rs 中定义的 Config 类型。\nuse std::env;\nuse std::process;\n \nuse minigrep::Config;\n \nfn main() {\n    // --snip--\n    let args: Vec&lt;String&gt; = env::args().collect();\n \n    let config = Config::build(&amp;args).unwrap_or_else(|err| {\n        println!(&quot;Problem parsing arguments: {err}&quot;);\n        process::exit(1);\n    });\n \n    println!(&quot;Searching for {}&quot;, config.query);\n    println!(&quot;In file {}&quot;, config.file_path);\n \n    if let Err(e) = minigrep::run(config) {\n        // --snip--\n        println!(&quot;Application error: {e}&quot;);\n        process::exit(1);\n    }\n}\n很明显，这里的 mingrep::run 的调用，以及 Config 的引入，跟使用其它第三方包已经没有任何区别，也意味着我们成功的将逻辑代码放置到一个独立的库包中，其它包只要引入和调用就行。\n呼，一顿书写猛如虎，回头一看。。。这么长的篇幅就写了这么点简单的代码？？只能说，我也希望像很多国内的大学教材一样，只要列出定理和解题方法，然后留下足够的习题，就万事大吉了，但是咱们不行。\n接下来，到了最喜(令)闻(人)乐(讨)见(厌)的环节：写测试代码，一起来开心吧。\n测试驱动开发\n在之前的章节中，我们完成了对项目结构的重构，并将进入逻辑代码编程的环节，但在此之前，我们需要先编写一些测试代码，也是最近颇为流行的测试驱动开发模式(TDD, Test Driven Development)：\n\n编写一个注定失败的测试，并且失败的原因和你指定的一样\n编写一个成功的测试\n编写你的逻辑代码，直到通过测试\n\n这三个步骤将在我们的开发过程中不断循环，直到所有的代码都开发完成并成功通过所有测试。\n注定失败的测试用例\n既然要添加测试，那之前的 println! 语句将没有大的用处，毕竟 println! 存在的目的就是为了让我们看到结果是否正确，而现在测试用例将取而代之。\n接下来，在 lib.rs 文件中，添加 tests 模块和 test 函数：\n#[cfg(test)]\nmod tests {\n    use super::*;\n \n    #[test]\n    fn one_result() {\n        let query = &quot;duct&quot;;\n        let contents = &quot;\\\nRust:\nsafe, fast, productive.\nPick three.&quot;;\n \n        assert_eq!(vec![&quot;safe, fast, productive.&quot;], search(query, contents));\n    }\n}\n测试用例将在指定的内容中搜索 duct 字符串，目测可得：其中有一行内容是包含有目标字符串的。\n但目前为止，还无法运行该测试用例，更何况还想幸灾乐祸的看其失败，原因是 search 函数还没有实现！毕竟是测试驱动、测试先行。\n// in lib.rs\npub fn search&lt;&#039;a&gt;(query: &amp;str, contents: &amp;&#039;a str) -&gt; Vec&lt;&amp;&#039;a str&gt; {\n    vec![]\n}\n先添加一个简单的 search 函数实现，非常简单粗暴的返回一个空的数组，显而易见测试用例将成功通过，真是一个居心叵测的测试用例！\n注意这里生命周期 &#039;a 的使用，之前的章节有详细介绍，不太明白的同学可以回头看看。\n喔，这么复杂的代码，都用上生命周期了！嘚瑟两下试试：$ cargo test，太棒了！它失败了…\n务必成功的测试用例\n接着就是测试驱动的第二步：编写注定成功的测试。当然，前提条件是实现我们的 search 函数。它包含以下步骤：\n\n遍历迭代 contents 的每一行\n检查该行内容是否包含我们的目标字符串\n若包含，则放入返回值列表中，否则忽略\n返回匹配到的返回值列表\n\n遍历迭代每一行\nRust 提供了一个很便利的 lines 方法将目标字符串进行按行分割：\n// in lib.rs\npub fn search&lt;&#039;a&gt;(query: &amp;str, contents: &amp;&#039;a str) -&gt; Vec&lt;&amp;&#039;a str&gt; {\n    for line in contents.lines() {\n        // do something with line\n    }\n}\n这里的 lines 返回一个迭代器，关于迭代器在后续章节会详细讲解，现在只要知道 for 可以遍历取出迭代器中的值即可。\n在每一行中查询目标字符串\n// in lib.rs\npub fn search&lt;&#039;a&gt;(query: &amp;str, contents: &amp;&#039;a str) -&gt; Vec&lt;&amp;&#039;a str&gt; {\n    for line in contents.lines() {\n        if line.contains(query) {\n            // do something with line\n        }\n    }\n}\n与之前的 lines 函数类似，Rust 的字符串还提供了 contains 方法，用于检查 line 是否包含待查询的 query。\n接下来，只要返回合适的值，就可以完成 search 函数的编写。\n存储匹配到的结果\n简单，创建一个 Vec 动态数组，然后将查询到的每一个 line 推进数组中即可：\n// in lib.rs\npub fn search&lt;&#039;a&gt;(query: &amp;str, contents: &amp;&#039;a str) -&gt; Vec&lt;&amp;&#039;a str&gt; {\n    let mut results = Vec::new();\n \n    for line in contents.lines() {\n        if line.contains(query) {\n            results.push(line);\n        }\n    }\n \n    results\n}\n至此，search 函数已经完成了既定目标，为了检查功能是否正确，运行下我们之前编写的测试用例，测试通过，意味着我们的代码也完美运行，接下来就是在 run 函数中大显身手了。\n在 run 函数中调用 search 函数\n// in src/lib.rs\npub fn run(config: Config) -&gt; Result&lt;(), Box&lt;dyn Error&gt;&gt; {\n    let contents = fs::read_to_string(config.file_path)?;\n \n    for line in search(&amp;config.query, &amp;contents) {\n        println!(&quot;{line}&quot;);\n    }\n \n    Ok(())\n}\n好，再运行下看看结果，看起来我们距离成功从未如此之近！\n$ cargo run -- frog poem.txt\n   Compiling minigrep v0.1.0 (file:///projects/minigrep)\n    Finished dev [unoptimized + debuginfo] target(s) in 0.38s\n     Running `target/debug/minigrep frog poem.txt`\nHow public, like a frog\n酷！成功查询到包含 frog 的行，再来试试 body :\n$ cargo run -- body poem.txt\n   Compiling minigrep v0.1.0 (file:///projects/minigrep)\n    Finished dev [unoptimized + debuginfo] target(s) in 0.0s\n     Running `target/debug/minigrep body poem.txt`\nI&#039;m nobody! Who are you?\nAre you nobody, too?\nHow dreary to be somebody!\n完美，三行，一行不少，为了确保万无一失，再来试试查询一个不存在的单词：\ncargo run -- monomorphization poem.txt\n   Compiling minigrep v0.1.0 (file:///projects/minigrep)\n    Finished dev [unoptimized + debuginfo] target(s) in 0.0s\n     Running `target/debug/minigrep monomorphization poem.txt`\n至此，章节开头的目标已经全部完成，接下来思考一个小问题：如果要为程序加上大小写不敏感的控制命令，由用户进行输入，该怎么实现比较好呢？毕竟在实际搜索查询中，同时支持大小写敏感和不敏感还是很重要的。\n答案留待下一章节揭晓。\n使用环境变量来增强程序\n在上一章节中，留下了一个悬念，该如何实现用户控制的大小写敏感，其实答案很简单，你在其它程序中肯定也遇到过不少，例如如何控制 panic 后的栈展开？ Rust 提供的解决方案是通过命令行参数来控制：\nRUST_BACKTRACE=1 cargo run\n与之类似，我们也可以使用环境变量来控制大小写敏感，例如：\nIGNORE_CASE=1 cargo run -- to poem.txt\n既然有了目标，那么一起来看看该如何实现吧。\n编写大小写不敏感的测试用例\n还是遵循之前的规则：测试驱动，这次是对一个新的大小写不敏感函数进行测试 search_case_insensitive。\n还记得 TDD 的测试步骤嘛？首先编写一个注定失败的用例：\n// in src/lib.rs\n#[cfg(test)]\nmod tests {\n    use super::*;\n \n    #[test]\n    fn case_sensitive() {\n        let query = &quot;duct&quot;;\n        let contents = &quot;\\\nRust:\nsafe, fast, productive.\nPick three.\nDuct tape.&quot;;\n \n        assert_eq!(vec![&quot;safe, fast, productive.&quot;], search(query, contents));\n    }\n \n    #[test]\n    fn case_insensitive() {\n        let query = &quot;rUsT&quot;;\n        let contents = &quot;\\\nRust:\nsafe, fast, productive.\nPick three.\nTrust me.&quot;;\n \n        assert_eq!(\n            vec![&quot;Rust:&quot;, &quot;Trust me.&quot;],\n            search_case_insensitive(query, contents)\n        );\n    }\n}\n可以看到，这里新增了一个 case_insensitive 测试用例，并对 search_case_insensitive 进行了测试，结果显而易见，函数都没有实现，自然会失败。\n接着来实现这个大小写不敏感的搜索函数：\npub fn search_case_insensitive&lt;&#039;a&gt;(\n    query: &amp;str,\n    contents: &amp;&#039;a str,\n) -&gt; Vec&lt;&amp;&#039;a str&gt; {\n    let query = query.to_lowercase();\n    let mut results = Vec::new();\n \n    for line in contents.lines() {\n        if line.to_lowercase().contains(&amp;query) {\n            results.push(line);\n        }\n    }\n \n    results\n}\n跟之前一样，但是引入了一个新的方法 to_lowercase，它会将 line 转换成全小写的字符串，类似的方法在其它语言中也差不多，就不再赘述。\n还要注意的是 query 现在是 String 类型，而不是之前的 &amp;str，因为 to_lowercase 返回的是 String。\n修改后，再来跑一次测试，看能否通过。\nOk，TDD的第二步也完成了，测试通过，接下来就是最后一步，在 run 中调用新的搜索函数。但是在此之前，要新增一个配置项，用于控制是否开启大小写敏感。\n// in lib.rs\npub struct Config {\n    pub query: String,\n    pub file_path: String,\n    pub ignore_case: bool,\n}\n接下来就是检查该字段，来判断是否启动大小写敏感：\npub fn run(config: Config) -&gt; Result&lt;(), Box&lt;dyn Error&gt;&gt; {\n    let contents = fs::read_to_string(config.file_path)?;\n \n    let results = if config.ignore_case {\n        search_case_insensitive(&amp;config.query, &amp;contents)\n    } else {\n        search(&amp;config.query, &amp;contents)\n    };\n \n    for line in results {\n        println!(&quot;{line}&quot;);\n    }\n \n    Ok(())\n}\n现在的问题来了，该如何控制这个配置项呢。这个就要借助于章节开头提到的环境变量，好在 Rust 的 env 包提供了相应的方法。\nuse std::env;\n// --snip--\n \nimpl Config {\n    pub fn build(args: &amp;[String]) -&gt; Result&lt;Config, &amp;&#039;static str&gt; {\n        if args.len() &lt; 3 {\n            return Err(&quot;not enough arguments&quot;);\n        }\n \n        let query = args[1].clone();\n        let file_path = args[2].clone();\n \n        let ignore_case = env::var(&quot;IGNORE_CASE&quot;).is_ok();\n \n        Ok(Config {\n            query,\n            file_path,\n            ignore_case,\n        })\n    }\n}\nenv::var 没啥好说的，倒是 is_ok 值得说道下。该方法是 Result 提供的，用于检查是否有值，有就返回 true，没有则返回 false，刚好完美符合我们的使用场景，因为我们并不关心 Ok&lt;T&gt; 中具体的值。\n运行下试试：\n$ cargo run -- to poem.txt\n   Compiling minigrep v0.1.0 (file:///projects/minigrep)\n    Finished dev [unoptimized + debuginfo] target(s) in 0.0s\n     Running `target/debug/minigrep to poem.txt`\nAre you nobody, too?\nHow dreary to be somebody!\n看起来没有问题，接下来测试下大小写不敏感：\nIGNORE_CASE=1 cargo run -- to poem.txt\n大小写不敏感后，查询到的内容明显多了很多，也很符合我们的预期。\n最后，给大家留一个小作业：同时使用命令行参数和环境变量的方式来控制大小写不敏感，其中环境变量的优先级更高，也就是两个都设置的情况下，优先使用环境变量的设置。\n重定向错误信息的输出\n迄今为止，所有的输出信息，无论 debug 还是 error 类型，都是通过 println! 宏输出到终端的标准输出( stdout )，但是对于程序来说，错误信息更适合输出到标准错误输出(stderr)。\n这样修改后，用户就可以选择将普通的日志类信息输出到日志文件 1，然后将错误信息输出到日志文件 2，甚至还可以输出到终端命令行。\n目前的错误输出位置\n我们先来观察下，目前的输出信息包括错误，是否是如上面所说，都写到标准错误输出。\n测试方式很简单，将标准错误输出的内容重定向到文件中，看看是否包含故意生成的错误信息即可。\n$ cargo run &gt; output.txt\n首先，这里的运行没有带任何参数，因此会报出类如文件不存在的错误，其次，通过 &gt; 操作符，标准输出上的内容被重定向到文件 output.txt 中，不再打印到控制上。\n大家先观察下控制台，然后再看看 output.txt，是否发现如下的错误信息已经如期被写入到文件中？\nProblem parsing arguments: not enough arguments\n所以，可以得出一个结论，如果错误信息输出到标准输出，那么它们将跟普通的日志信息混在一起，难以分辨，因此我们需要将错误信息进行单独输出。\n标准错误输出 stderr\n将错误信息重定向到 stderr 很简单，只需在打印错误的地方，将 println! 宏替换为 eprintln!即可。\nfn main() {\n    let args: Vec&lt;String&gt; = env::args().collect();\n \n    let config = Config::build(&amp;args).unwrap_or_else(|err| {\n        eprintln!(&quot;Problem parsing arguments: {err}&quot;);\n        process::exit(1);\n    });\n \n    if let Err(e) = minigrep::run(config) {\n        eprintln!(&quot;Application error: {e}&quot;);\n        process::exit(1);\n    }\n}\n接下来，还是同样的运行命令：\n$ cargo run &gt; output.txt\nProblem parsing arguments: not enough arguments\n可以看到，日志信息成功的重定向到 output.txt 文件中，而错误信息由于 eprintln! 的使用，被写入到标准错误输出中，默认还是输出在控制台中。\n再来试试没有错误的情况：\n$ cargo run -- to poem.txt &gt; output.txt\n至此，简易搜索程序 minigrep 已经基本完成，下一章节将使用迭代器进行部分改进，请大家在看完迭代器后，再回头阅读。\n使用迭代器来改进我们的程序\n在之前的 minigrep 中，功能虽然已经 ok，但是一些细节上还值得打磨下，下面一起看看如何使用迭代器来改进 Config::build 和 search 的实现。\n移除 clone 的使用\n虽然之前有讲过为什么这里可以使用 clone，但是也许总有同学心有芥蒂，毕竟程序员嘛，都希望代码处处完美，而不是丑陋的处处妥协。\n之前的代码两行 clone 着实有点啰嗦，好在，在学习完迭代器后，我们知道了 build 函数实际上可以直接拿走迭代器的所有权，而不是去借用一个数组切片 &amp;[String]。\n这里先不给出代码，下面统一给出。\n直接使用返回的迭代器\n在之前的实现中，我们的 args 是一个动态数组：\nfn main() {\n    let args: Vec&lt;String&gt; = env::args().collect();\n \n    let config = Config::build(&amp;args).unwrap_or_else(|err| {\n        eprintln!(&quot;Problem parsing arguments: {err}&quot;);\n        process::exit(1);\n    });\n \n    // --snip--\n}\n当时还提到了 collect 方法的使用，相信大家学完迭代器后，对这个方法会有更加深入的认识。\n现在呢，无需数组了，直接传入迭代器即可：\nfn main() {\n    let config = Config::build(env::args()).unwrap_or_else(|err| {\n        eprintln!(&quot;Problem parsing arguments: {err}&quot;);\n        process::exit(1);\n    });\n \n    // --snip--\n}\n如上所示，我们甚至省去了一行代码，原因是 env::args 可以直接返回一个迭代器，再作为 Config::build 的参数传入，下面再来改写 build 方法。\nimpl Config {\n    pub fn build(\n        mut args: impl Iterator&lt;Item = String&gt;,\n    ) -&gt; Result&lt;Config, &amp;&#039;static str&gt; {\n        // --snip--\n    }\n为了可读性和更好的通用性，这里的 args 类型并没有使用本身的 std::env::Args ，而是使用了特征约束的方式来描述 impl Iterator&lt;Item = String&gt;，这样意味着 arg 可以是任何实现了 String 迭代器的类型。\n还有一点值得注意，由于迭代器的所有权已经转移到 build 内，因此可以直接对其进行修改，这里加上了 mut 关键字。\n移除数组索引的使用\n数组索引会越界，为了安全性和简洁性，使用 Iterator 特征自带的 next 方法是一个更好的选择：\nimpl Config {\n    pub fn build(\n        mut args: impl Iterator&lt;Item = String&gt;,\n    ) -&gt; Result&lt;Config, &amp;&#039;static str&gt; {\n        // 第一个参数是程序名，由于无需使用，因此这里直接空调用一次\n        args.next();\n \n        let query = match args.next() {\n            Some(arg) =&gt; arg,\n            None =&gt; return Err(&quot;Didn&#039;t get a query string&quot;),\n        };\n \n        let file_path = match args.next() {\n            Some(arg) =&gt; arg,\n            None =&gt; return Err(&quot;Didn&#039;t get a file path&quot;),\n        };\n \n        let ignore_case = env::var(&quot;IGNORE_CASE&quot;).is_ok();\n \n        Ok(Config {\n            query,\n            file_path,\n            ignore_case,\n        })\n    }\n}\n喔，上面使用了迭代器和模式匹配的代码，看上去是不是很 Rust？我想我们已经走在了正确的道路上。\n使用迭代器适配器让代码更简洁\n为了帮大家更好的回忆和对比，之前的 search 长这样：\n// in lib.rs\npub fn search&lt;&#039;a&gt;(query: &amp;str, contents: &amp;&#039;a str) -&gt; Vec&lt;&amp;&#039;a str&gt; {\n    let mut results = Vec::new();\n \n    for line in contents.lines() {\n        if line.contains(query) {\n            results.push(line);\n        }\n    }\n \n    results\n}\n引入了迭代器后，就连古板的 search 函数也可以变得更 rusty 些：\npub fn search&lt;&#039;a&gt;(query: &amp;str, contents: &amp;&#039;a str) -&gt; Vec&lt;&amp;&#039;a str&gt; {\n    contents\n        .lines()\n        .filter(|line| line.contains(query))\n        .collect()\n}\nRock，让我们的函数编程 Style rock 起来，这种一行到底的写法有时真的让人沉迷。\n总结\n至此，整个大章节全部结束，本章没有试图覆盖已学的方方面面( 也许未来会 )，而是聚焦于 Rust 的一些核心知识：所有权、生命周期、借用、模式匹配等等。\n强烈推荐大家忘记已有的一切，自己重新实现一遍 minigrep，甚至可以根据自己的想法和喜好，来完善一些，也欢迎在评论中附上自己的练习项目，供其它人学习参考( 提个小建议，项目主页写清楚新增的功能、亮点等 )。\n从下一章开始，我们将正式开始 Rust 进阶学习，请深呼吸一口，然后问自己：你..准备好了吗？"},"summary/read-code":{"title":"read-code","links":[],"tags":[],"content":"为什么要读源码\n语言只是一个工具，关键还是需要利用自己的思想，解决问题;\n不过相对于背那些八股文，我感觉通读这个领域的源码，了解各种优秀的思想，才能真正带来技术上的进步，这也是进阶必不可少的一步。\n在我们未有足够经验的时候，去了解一个未知的框架，都感觉是庞然大物，不可触及。但其实遵循一定的方法，层层抽丝剥茧，就可以慢慢发现作者很多精妙的想法，甚至彩蛋，这也是读别人源码能带来的乐趣。\n问题驱动——不要为了看源码而看源码\n首先我们要明确一点，看源码的目的是什么？\n不要为了面试需要读而读，不然适得其反，枯燥无味，浪费时间，不知所言，还不如多看别人源码分析文章来得快。\n怎样去读源码\n带着问题去看源码，比如想了解一下 React 的合成事件系统的原理，想了解 React 的 setState 前后发生了什么，或者想了解 Webpack 插件系统的原理。也有可能是遇到了一个 bug，怀疑是框架/工具的问题。在这样的情况下，带着一个具体的目标去看源码，就会有的放矢。\n应用文档\n不要着急直接去拉仓库代码来看，如果这个框架有相关应用文档的，先耐心看完整个应用文档，而且要看原版，如果是英语的，尽量不要找翻译的版本，因为时效性和准确性问题，可能会让你走了弯路。\n结合文档以及一些博客技术文章，可在看源码之前对项目的原理有一个基本的了解。所谓原理就是，这个项目有哪些组成部分，为了达到最终的产出，要经过哪几步流程。这些流程里，业界主流的方案有哪几种。\npackage.json配置字段\n\n\ndependencies：项目生产依赖，代表项目被应用时候，必须依赖的其他包\n\n\ndevDependencies：项目开发依赖，代表项目在开发时候，必须依赖的其他包\n\n\npeerDependencies：项目对等依赖，代表项目在运行时候，必须依赖外部项目本身安装的依赖，而不是自身内部的依赖\n\n\nmain：commonJS规范下（使用require引用）指定入口，如果不指定，会默认引用根目录下index.js\n\n\nmodule：ESM规范下（使用import引用）指定入口；\n\n\nbrowser：浏览器运行环境的模块引用入口，main和module不区分运行环境\n\n\nfiles：指定npm包发布的文件列表，例如指定构建后的文件列表，源码不发布\n\n\nworkspaces：配置工作区，例如你开发的是一个大框架，包含很多子package，则将子package路径配置到工作区里，而将这个大框架的private设置为true，因为这个大框架不是你要发布的包\n\n\nbin：配置自定义命令，键值将被注册为快捷脚本，对应文件入口为命令执行文件，基本脚手架都会用到这个\n\n\n本地运行\n看源码的第一步就是把项目的代码仓库 clone 到本地。然后按项目 README 或者 CONTRIBUTING 上的构建指南，在本地 build 一下。\n从源码入口文件开始，逐步去debug整个源码逻辑结构，可以先看函数定义和引用，再附加过程中的各项注释，形成自己的笔记文档。\n\n\n如果是前端框架，我们可以在 HTML 中里直接引入本地 build 出的 umd bundle（记得用 development build，不然会把代码压缩，可读性差），然后写一个简单的 demo，demo 里引入本地的 build；\n\n\n如果是基于 Nodejs 的工具，我们可以用 npm link 把这个工具的命令 link 到本地。也可以直接看项目的 package.json 的入口文件，直接用 node 运行那个文件；\n\n\n以 React 为例，React 的 Contributing Guide 里就 Development Workflow 这一节；\n目录结构\n看具体的代码之前，我们需要理清项目的目录结构，这样我们才能更快的知道在哪里地方找相关功能的代码。\n例如 React 的目录结构。React 是一个 monorepo。也就是一个仓库里包含了多个子仓库。我们在 packages 目录下可以看到很多单独的 package；\n在 React 16 之后，React 的代码分为 React Core，Renderer 和 Reconciler 三部分。\n这是因为 React 的设计让我们可以把负责映射数据到 UI 的 Reconciler 以及负责渲染 Vritual DOM 到各个终端的 Renderer 和 React Core 分开。React Core 包含了 React 的类定义和一些顶级 API。\n大部分的渲染和 View 层 diff 的逻辑都在 Reconciler 和 Renderer 中；\n\n如果这个项目是一个 monorepo，首先我们要找到核心的那个 package，然后看里面的代码。\n不是 monorepo 的话，一般来说：\n\n如果这个项目是一个 CLI 的工具，那 bin 目录下放的就是命令行界面相关的入口文件，lib 或者 src 下面就是工具的核心代码；\n如果这个项目是一个前端 View 层框架，那目录结构就和 Vue 类似；\n\n调试方法\n\n\n使用断点，全局搜索，查看调用栈\n\n\n阅读前端源码的思路 - 知乎 (zhihu.com)\n\n\n如何阅读大型前端开源项目的源码 - 掘金 (juejin.cn)\n\n"}}